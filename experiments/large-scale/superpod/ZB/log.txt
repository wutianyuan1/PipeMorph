 iteration        1/    1200 | consumed samples:           48 | elapsed time per iteration (ms): 94055.2 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4294967296.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        2/    1200 | consumed samples:           96 | elapsed time per iteration (ms): 1219.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2147483648.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        3/    1200 | consumed samples:          144 | elapsed time per iteration (ms): 965.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1073741824.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        4/    1200 | consumed samples:          192 | elapsed time per iteration (ms): 954.3 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 536870912.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        5/    1200 | consumed samples:          240 | elapsed time per iteration (ms): 966.5 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        6/    1200 | consumed samples:          288 | elapsed time per iteration (ms): 972.7 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 134217728.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        7/    1200 | consumed samples:          336 | elapsed time per iteration (ms): 1270.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 67108864.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        8/    1200 | consumed samples:          384 | elapsed time per iteration (ms): 1489.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 33554432.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        9/    1200 | consumed samples:          432 | elapsed time per iteration (ms): 946.7 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 16777216.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       10/    1200 | consumed samples:          480 | elapsed time per iteration (ms): 953.0 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 8388608.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       11/    1200 | consumed samples:          528 | elapsed time per iteration (ms): 1126.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4194304.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       12/    1200 | consumed samples:          576 | elapsed time per iteration (ms): 950.5 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       13/    1200 | consumed samples:          624 | elapsed time per iteration (ms): 956.6 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       14/    1200 | consumed samples:          672 | elapsed time per iteration (ms): 959.7 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 524288.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       15/    1200 | consumed samples:          720 | elapsed time per iteration (ms): 1131.2 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       16/    1200 | consumed samples:          768 | elapsed time per iteration (ms): 1184.4 | learning rate: 1.573E-08 | global batch size:    48 | lm loss: 1.064595E+01 | loss scale: 262144.0 | grad norm: 156.315 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       17/    1200 | consumed samples:          816 | elapsed time per iteration (ms): 2632.4 | learning rate: 3.146E-08 | global batch size:    48 | lm loss: 1.065338E+01 | loss scale: 262144.0 | grad norm: 158.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       18/    1200 | consumed samples:          864 | elapsed time per iteration (ms): 2391.3 | learning rate: 4.719E-08 | global batch size:    48 | lm loss: 1.065830E+01 | loss scale: 262144.0 | grad norm: 155.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       19/    1200 | consumed samples:          912 | elapsed time per iteration (ms): 2374.2 | learning rate: 6.291E-08 | global batch size:    48 | lm loss: 1.045710E+01 | loss scale: 262144.0 | grad norm: 149.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       20/    1200 | consumed samples:          960 | elapsed time per iteration (ms): 2263.7 | learning rate: 7.864E-08 | global batch size:    48 | lm loss: 9.879968E+00 | loss scale: 262144.0 | grad norm: 138.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       21/    1200 | consumed samples:         1008 | elapsed time per iteration (ms): 2228.7 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 131072.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       22/    1200 | consumed samples:         1056 | elapsed time per iteration (ms): 2231.7 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       23/    1200 | consumed samples:         1104 | elapsed time per iteration (ms): 2221.3 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       24/    1200 | consumed samples:         1152 | elapsed time per iteration (ms): 2262.9 | learning rate: 9.437E-08 | global batch size:    48 | lm loss: 1.011889E+01 | loss scale: 32768.0 | grad norm: 672.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       25/    1200 | consumed samples:         1200 | elapsed time per iteration (ms): 2399.8 | learning rate: 1.101E-07 | global batch size:    48 | lm loss: 1.000791E+01 | loss scale: 32768.0 | grad norm: 653.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       26/    1200 | consumed samples:         1248 | elapsed time per iteration (ms): 2268.2 | learning rate: 1.258E-07 | global batch size:    48 | lm loss: 9.404112E+00 | loss scale: 32768.0 | grad norm: 269.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       27/    1200 | consumed samples:         1296 | elapsed time per iteration (ms): 2367.6 | learning rate: 1.416E-07 | global batch size:    48 | lm loss: 9.102152E+00 | loss scale: 32768.0 | grad norm: 197.323 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       28/    1200 | consumed samples:         1344 | elapsed time per iteration (ms): 2359.7 | learning rate: 1.573E-07 | global batch size:    48 | lm loss: 8.698307E+00 | loss scale: 32768.0 | grad norm: 64.270 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       29/    1200 | consumed samples:         1392 | elapsed time per iteration (ms): 2279.0 | learning rate: 1.730E-07 | global batch size:    48 | lm loss: 8.757597E+00 | loss scale: 32768.0 | grad norm: 63.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       30/    1200 | consumed samples:         1440 | elapsed time per iteration (ms): 2259.7 | learning rate: 1.887E-07 | global batch size:    48 | lm loss: 8.674874E+00 | loss scale: 32768.0 | grad norm: 66.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       31/    1200 | consumed samples:         1488 | elapsed time per iteration (ms): 2257.0 | learning rate: 2.045E-07 | global batch size:    48 | lm loss: 8.522375E+00 | loss scale: 32768.0 | grad norm: 43.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       32/    1200 | consumed samples:         1536 | elapsed time per iteration (ms): 2308.9 | learning rate: 2.202E-07 | global batch size:    48 | lm loss: 8.419993E+00 | loss scale: 32768.0 | grad norm: 52.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       33/    1200 | consumed samples:         1584 | elapsed time per iteration (ms): 2269.9 | learning rate: 2.359E-07 | global batch size:    48 | lm loss: 8.359005E+00 | loss scale: 32768.0 | grad norm: 57.129 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       34/    1200 | consumed samples:         1632 | elapsed time per iteration (ms): 2341.5 | learning rate: 2.517E-07 | global batch size:    48 | lm loss: 8.416605E+00 | loss scale: 32768.0 | grad norm: 68.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       35/    1200 | consumed samples:         1680 | elapsed time per iteration (ms): 2262.5 | learning rate: 2.674E-07 | global batch size:    48 | lm loss: 8.288352E+00 | loss scale: 32768.0 | grad norm: 49.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       36/    1200 | consumed samples:         1728 | elapsed time per iteration (ms): 2257.7 | learning rate: 2.831E-07 | global batch size:    48 | lm loss: 8.271061E+00 | loss scale: 32768.0 | grad norm: 80.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       37/    1200 | consumed samples:         1776 | elapsed time per iteration (ms): 2508.0 | learning rate: 2.988E-07 | global batch size:    48 | lm loss: 8.203588E+00 | loss scale: 32768.0 | grad norm: 31.243 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       38/    1200 | consumed samples:         1824 | elapsed time per iteration (ms): 2282.9 | learning rate: 3.146E-07 | global batch size:    48 | lm loss: 8.231887E+00 | loss scale: 32768.0 | grad norm: 49.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       39/    1200 | consumed samples:         1872 | elapsed time per iteration (ms): 2262.3 | learning rate: 3.303E-07 | global batch size:    48 | lm loss: 8.114100E+00 | loss scale: 32768.0 | grad norm: 33.189 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       40/    1200 | consumed samples:         1920 | elapsed time per iteration (ms): 2264.1 | learning rate: 3.460E-07 | global batch size:    48 | lm loss: 8.127762E+00 | loss scale: 32768.0 | grad norm: 29.137 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       41/    1200 | consumed samples:         1968 | elapsed time per iteration (ms): 2273.9 | learning rate: 3.618E-07 | global batch size:    48 | lm loss: 8.112835E+00 | loss scale: 32768.0 | grad norm: 70.190 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       42/    1200 | consumed samples:         2016 | elapsed time per iteration (ms): 2270.8 | learning rate: 3.775E-07 | global batch size:    48 | lm loss: 8.078146E+00 | loss scale: 32768.0 | grad norm: 39.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       43/    1200 | consumed samples:         2064 | elapsed time per iteration (ms): 2332.8 | learning rate: 3.932E-07 | global batch size:    48 | lm loss: 8.024878E+00 | loss scale: 32768.0 | grad norm: 25.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       44/    1200 | consumed samples:         2112 | elapsed time per iteration (ms): 2273.5 | learning rate: 4.089E-07 | global batch size:    48 | lm loss: 8.069037E+00 | loss scale: 32768.0 | grad norm: 41.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       45/    1200 | consumed samples:         2160 | elapsed time per iteration (ms): 2264.7 | learning rate: 4.247E-07 | global batch size:    48 | lm loss: 8.154215E+00 | loss scale: 32768.0 | grad norm: 85.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       46/    1200 | consumed samples:         2208 | elapsed time per iteration (ms): 2274.0 | learning rate: 4.404E-07 | global batch size:    48 | lm loss: 8.106767E+00 | loss scale: 32768.0 | grad norm: 74.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       47/    1200 | consumed samples:         2256 | elapsed time per iteration (ms): 2461.3 | learning rate: 4.561E-07 | global batch size:    48 | lm loss: 8.082594E+00 | loss scale: 32768.0 | grad norm: 30.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       48/    1200 | consumed samples:         2304 | elapsed time per iteration (ms): 2260.7 | learning rate: 4.719E-07 | global batch size:    48 | lm loss: 7.997400E+00 | loss scale: 32768.0 | grad norm: 25.252 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       49/    1200 | consumed samples:         2352 | elapsed time per iteration (ms): 2308.3 | learning rate: 4.876E-07 | global batch size:    48 | lm loss: 8.081524E+00 | loss scale: 32768.0 | grad norm: 115.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       50/    1200 | consumed samples:         2400 | elapsed time per iteration (ms): 2260.6 | learning rate: 5.033E-07 | global batch size:    48 | lm loss: 8.188581E+00 | loss scale: 32768.0 | grad norm: 123.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       51/    1200 | consumed samples:         2448 | elapsed time per iteration (ms): 2261.6 | learning rate: 5.190E-07 | global batch size:    48 | lm loss: 8.016584E+00 | loss scale: 32768.0 | grad norm: 78.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       52/    1200 | consumed samples:         2496 | elapsed time per iteration (ms): 2335.1 | learning rate: 5.348E-07 | global batch size:    48 | lm loss: 7.959307E+00 | loss scale: 32768.0 | grad norm: 38.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       53/    1200 | consumed samples:         2544 | elapsed time per iteration (ms): 2258.5 | learning rate: 5.505E-07 | global batch size:    48 | lm loss: 7.990664E+00 | loss scale: 32768.0 | grad norm: 21.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       54/    1200 | consumed samples:         2592 | elapsed time per iteration (ms): 2266.8 | learning rate: 5.662E-07 | global batch size:    48 | lm loss: 7.930719E+00 | loss scale: 32768.0 | grad norm: 23.221 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       55/    1200 | consumed samples:         2640 | elapsed time per iteration (ms): 2271.0 | learning rate: 5.820E-07 | global batch size:    48 | lm loss: 7.827173E+00 | loss scale: 32768.0 | grad norm: 28.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       56/    1200 | consumed samples:         2688 | elapsed time per iteration (ms): 2406.2 | learning rate: 5.977E-07 | global batch size:    48 | lm loss: 7.946066E+00 | loss scale: 32768.0 | grad norm: 46.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       57/    1200 | consumed samples:         2736 | elapsed time per iteration (ms): 2358.9 | learning rate: 6.134E-07 | global batch size:    48 | lm loss: 7.930828E+00 | loss scale: 32768.0 | grad norm: 17.558 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       58/    1200 | consumed samples:         2784 | elapsed time per iteration (ms): 2288.0 | learning rate: 6.291E-07 | global batch size:    48 | lm loss: 7.850894E+00 | loss scale: 32768.0 | grad norm: 17.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       59/    1200 | consumed samples:         2832 | elapsed time per iteration (ms): 2266.0 | learning rate: 6.449E-07 | global batch size:    48 | lm loss: 7.848691E+00 | loss scale: 32768.0 | grad norm: 18.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       60/    1200 | consumed samples:         2880 | elapsed time per iteration (ms): 2262.3 | learning rate: 6.606E-07 | global batch size:    48 | lm loss: 7.844734E+00 | loss scale: 32768.0 | grad norm: 28.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       61/    1200 | consumed samples:         2928 | elapsed time per iteration (ms): 2385.1 | learning rate: 6.763E-07 | global batch size:    48 | lm loss: 7.843095E+00 | loss scale: 32768.0 | grad norm: 33.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       62/    1200 | consumed samples:         2976 | elapsed time per iteration (ms): 2314.1 | learning rate: 6.921E-07 | global batch size:    48 | lm loss: 7.817948E+00 | loss scale: 32768.0 | grad norm: 19.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       63/    1200 | consumed samples:         3024 | elapsed time per iteration (ms): 2274.7 | learning rate: 7.078E-07 | global batch size:    48 | lm loss: 7.839793E+00 | loss scale: 32768.0 | grad norm: 12.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       64/    1200 | consumed samples:         3072 | elapsed time per iteration (ms): 2267.6 | learning rate: 7.235E-07 | global batch size:    48 | lm loss: 7.796875E+00 | loss scale: 32768.0 | grad norm: 18.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       65/    1200 | consumed samples:         3120 | elapsed time per iteration (ms): 2265.7 | learning rate: 7.392E-07 | global batch size:    48 | lm loss: 7.677135E+00 | loss scale: 32768.0 | grad norm: 15.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       66/    1200 | consumed samples:         3168 | elapsed time per iteration (ms): 2370.3 | learning rate: 7.550E-07 | global batch size:    48 | lm loss: 7.783973E+00 | loss scale: 32768.0 | grad norm: 21.127 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       67/    1200 | consumed samples:         3216 | elapsed time per iteration (ms): 2373.3 | learning rate: 7.707E-07 | global batch size:    48 | lm loss: 7.827737E+00 | loss scale: 32768.0 | grad norm: 25.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       68/    1200 | consumed samples:         3264 | elapsed time per iteration (ms): 2266.7 | learning rate: 7.864E-07 | global batch size:    48 | lm loss: 7.749515E+00 | loss scale: 32768.0 | grad norm: 21.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       69/    1200 | consumed samples:         3312 | elapsed time per iteration (ms): 2388.0 | learning rate: 8.022E-07 | global batch size:    48 | lm loss: 7.647816E+00 | loss scale: 32768.0 | grad norm: 22.533 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       70/    1200 | consumed samples:         3360 | elapsed time per iteration (ms): 2353.4 | learning rate: 8.179E-07 | global batch size:    48 | lm loss: 7.750089E+00 | loss scale: 32768.0 | grad norm: 22.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       71/    1200 | consumed samples:         3408 | elapsed time per iteration (ms): 2267.4 | learning rate: 8.336E-07 | global batch size:    48 | lm loss: 7.614849E+00 | loss scale: 32768.0 | grad norm: 15.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       72/    1200 | consumed samples:         3456 | elapsed time per iteration (ms): 2261.6 | learning rate: 8.493E-07 | global batch size:    48 | lm loss: 7.681921E+00 | loss scale: 32768.0 | grad norm: 12.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       73/    1200 | consumed samples:         3504 | elapsed time per iteration (ms): 2265.5 | learning rate: 8.651E-07 | global batch size:    48 | lm loss: 7.601383E+00 | loss scale: 32768.0 | grad norm: 21.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       74/    1200 | consumed samples:         3552 | elapsed time per iteration (ms): 2255.5 | learning rate: 8.808E-07 | global batch size:    48 | lm loss: 7.571964E+00 | loss scale: 32768.0 | grad norm: 14.143 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       75/    1200 | consumed samples:         3600 | elapsed time per iteration (ms): 2400.6 | learning rate: 8.965E-07 | global batch size:    48 | lm loss: 7.600965E+00 | loss scale: 32768.0 | grad norm: 10.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       76/    1200 | consumed samples:         3648 | elapsed time per iteration (ms): 2255.1 | learning rate: 9.123E-07 | global batch size:    48 | lm loss: 7.678252E+00 | loss scale: 32768.0 | grad norm: 22.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       77/    1200 | consumed samples:         3696 | elapsed time per iteration (ms): 2362.4 | learning rate: 9.280E-07 | global batch size:    48 | lm loss: 7.560709E+00 | loss scale: 32768.0 | grad norm: 16.566 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       78/    1200 | consumed samples:         3744 | elapsed time per iteration (ms): 2265.9 | learning rate: 9.437E-07 | global batch size:    48 | lm loss: 7.463670E+00 | loss scale: 32768.0 | grad norm: 18.325 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       79/    1200 | consumed samples:         3792 | elapsed time per iteration (ms): 2373.7 | learning rate: 9.594E-07 | global batch size:    48 | lm loss: 7.539518E+00 | loss scale: 32768.0 | grad norm: 13.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       80/    1200 | consumed samples:         3840 | elapsed time per iteration (ms): 2263.2 | learning rate: 9.752E-07 | global batch size:    48 | lm loss: 7.554595E+00 | loss scale: 32768.0 | grad norm: 33.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       81/    1200 | consumed samples:         3888 | elapsed time per iteration (ms): 2342.2 | learning rate: 9.909E-07 | global batch size:    48 | lm loss: 7.522870E+00 | loss scale: 32768.0 | grad norm: 23.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       82/    1200 | consumed samples:         3936 | elapsed time per iteration (ms): 2267.2 | learning rate: 1.007E-06 | global batch size:    48 | lm loss: 7.578803E+00 | loss scale: 32768.0 | grad norm: 15.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       83/    1200 | consumed samples:         3984 | elapsed time per iteration (ms): 2266.3 | learning rate: 1.022E-06 | global batch size:    48 | lm loss: 7.461776E+00 | loss scale: 32768.0 | grad norm: 13.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       84/    1200 | consumed samples:         4032 | elapsed time per iteration (ms): 2263.3 | learning rate: 1.038E-06 | global batch size:    48 | lm loss: 7.506434E+00 | loss scale: 32768.0 | grad norm: 15.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       85/    1200 | consumed samples:         4080 | elapsed time per iteration (ms): 2386.2 | learning rate: 1.054E-06 | global batch size:    48 | lm loss: 7.486061E+00 | loss scale: 32768.0 | grad norm: 22.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       86/    1200 | consumed samples:         4128 | elapsed time per iteration (ms): 1422.5 | learning rate: 1.070E-06 | global batch size:    48 | lm loss: 7.524589E+00 | loss scale: 32768.0 | grad norm: 21.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       87/    1200 | consumed samples:         4176 | elapsed time per iteration (ms): 1314.5 | learning rate: 1.085E-06 | global batch size:    48 | lm loss: 7.535740E+00 | loss scale: 32768.0 | grad norm: 24.382 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       88/    1200 | consumed samples:         4224 | elapsed time per iteration (ms): 1244.4 | learning rate: 1.101E-06 | global batch size:    48 | lm loss: 7.384780E+00 | loss scale: 32768.0 | grad norm: 9.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       89/    1200 | consumed samples:         4272 | elapsed time per iteration (ms): 1121.6 | learning rate: 1.117E-06 | global batch size:    48 | lm loss: 7.461233E+00 | loss scale: 32768.0 | grad norm: 16.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       90/    1200 | consumed samples:         4320 | elapsed time per iteration (ms): 1114.3 | learning rate: 1.132E-06 | global batch size:    48 | lm loss: 7.371311E+00 | loss scale: 32768.0 | grad norm: 13.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       91/    1200 | consumed samples:         4368 | elapsed time per iteration (ms): 993.1 | learning rate: 1.148E-06 | global batch size:    48 | lm loss: 7.401240E+00 | loss scale: 32768.0 | grad norm: 18.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       92/    1200 | consumed samples:         4416 | elapsed time per iteration (ms): 992.6 | learning rate: 1.164E-06 | global batch size:    48 | lm loss: 7.339136E+00 | loss scale: 32768.0 | grad norm: 16.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       93/    1200 | consumed samples:         4464 | elapsed time per iteration (ms): 1000.6 | learning rate: 1.180E-06 | global batch size:    48 | lm loss: 7.437624E+00 | loss scale: 32768.0 | grad norm: 19.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       94/    1200 | consumed samples:         4512 | elapsed time per iteration (ms): 1350.5 | learning rate: 1.195E-06 | global batch size:    48 | lm loss: 7.293014E+00 | loss scale: 32768.0 | grad norm: 12.217 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       95/    1200 | consumed samples:         4560 | elapsed time per iteration (ms): 1068.9 | learning rate: 1.211E-06 | global batch size:    48 | lm loss: 7.369732E+00 | loss scale: 32768.0 | grad norm: 14.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       96/    1200 | consumed samples:         4608 | elapsed time per iteration (ms): 1061.2 | learning rate: 1.227E-06 | global batch size:    48 | lm loss: 7.396235E+00 | loss scale: 32768.0 | grad norm: 10.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       97/    1200 | consumed samples:         4656 | elapsed time per iteration (ms): 1312.9 | learning rate: 1.243E-06 | global batch size:    48 | lm loss: 7.278118E+00 | loss scale: 32768.0 | grad norm: 12.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       98/    1200 | consumed samples:         4704 | elapsed time per iteration (ms): 1148.1 | learning rate: 1.258E-06 | global batch size:    48 | lm loss: 7.093921E+00 | loss scale: 32768.0 | grad norm: 10.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       99/    1200 | consumed samples:         4752 | elapsed time per iteration (ms): 1190.0 | learning rate: 1.274E-06 | global batch size:    48 | lm loss: 7.339246E+00 | loss scale: 32768.0 | grad norm: 10.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      100/    1200 | consumed samples:         4800 | elapsed time per iteration (ms): 1265.8 | learning rate: 1.290E-06 | global batch size:    48 | lm loss: 7.333570E+00 | loss scale: 32768.0 | grad norm: 12.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      101/    1200 | consumed samples:         4848 | elapsed time per iteration (ms): 1390.3 | learning rate: 1.305E-06 | global batch size:    48 | lm loss: 7.178007E+00 | loss scale: 32768.0 | grad norm: 8.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      102/    1200 | consumed samples:         4896 | elapsed time per iteration (ms): 1285.8 | learning rate: 1.321E-06 | global batch size:    48 | lm loss: 7.185754E+00 | loss scale: 32768.0 | grad norm: 11.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      103/    1200 | consumed samples:         4944 | elapsed time per iteration (ms): 1353.4 | learning rate: 1.337E-06 | global batch size:    48 | lm loss: 7.198635E+00 | loss scale: 32768.0 | grad norm: 10.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      104/    1200 | consumed samples:         4992 | elapsed time per iteration (ms): 1422.1 | learning rate: 1.353E-06 | global batch size:    48 | lm loss: 7.119062E+00 | loss scale: 32768.0 | grad norm: 16.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      105/    1200 | consumed samples:         5040 | elapsed time per iteration (ms): 1313.2 | learning rate: 1.368E-06 | global batch size:    48 | lm loss: 7.160285E+00 | loss scale: 32768.0 | grad norm: 10.136 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      106/    1200 | consumed samples:         5088 | elapsed time per iteration (ms): 1700.7 | learning rate: 1.384E-06 | global batch size:    48 | lm loss: 7.090118E+00 | loss scale: 32768.0 | grad norm: 11.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      107/    1200 | consumed samples:         5136 | elapsed time per iteration (ms): 1300.9 | learning rate: 1.400E-06 | global batch size:    48 | lm loss: 7.087859E+00 | loss scale: 32768.0 | grad norm: 13.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      108/    1200 | consumed samples:         5184 | elapsed time per iteration (ms): 1508.1 | learning rate: 1.416E-06 | global batch size:    48 | lm loss: 7.120779E+00 | loss scale: 32768.0 | grad norm: 22.555 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      109/    1200 | consumed samples:         5232 | elapsed time per iteration (ms): 1402.1 | learning rate: 1.431E-06 | global batch size:    48 | lm loss: 7.061327E+00 | loss scale: 32768.0 | grad norm: 11.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      110/    1200 | consumed samples:         5280 | elapsed time per iteration (ms): 1288.1 | learning rate: 1.447E-06 | global batch size:    48 | lm loss: 7.146583E+00 | loss scale: 32768.0 | grad norm: 11.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      111/    1200 | consumed samples:         5328 | elapsed time per iteration (ms): 1347.8 | learning rate: 1.463E-06 | global batch size:    48 | lm loss: 7.088788E+00 | loss scale: 32768.0 | grad norm: 10.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      112/    1200 | consumed samples:         5376 | elapsed time per iteration (ms): 1006.3 | learning rate: 1.478E-06 | global batch size:    48 | lm loss: 7.101760E+00 | loss scale: 32768.0 | grad norm: 10.144 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      113/    1200 | consumed samples:         5424 | elapsed time per iteration (ms): 1188.9 | learning rate: 1.494E-06 | global batch size:    48 | lm loss: 7.151349E+00 | loss scale: 32768.0 | grad norm: 25.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      114/    1200 | consumed samples:         5472 | elapsed time per iteration (ms): 1426.2 | learning rate: 1.510E-06 | global batch size:    48 | lm loss: 7.178739E+00 | loss scale: 32768.0 | grad norm: 19.290 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      115/    1200 | consumed samples:         5520 | elapsed time per iteration (ms): 993.2 | learning rate: 1.526E-06 | global batch size:    48 | lm loss: 7.081869E+00 | loss scale: 32768.0 | grad norm: 11.278 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      116/    1200 | consumed samples:         5568 | elapsed time per iteration (ms): 999.2 | learning rate: 1.541E-06 | global batch size:    48 | lm loss: 7.126964E+00 | loss scale: 32768.0 | grad norm: 11.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      117/    1200 | consumed samples:         5616 | elapsed time per iteration (ms): 1106.9 | learning rate: 1.557E-06 | global batch size:    48 | lm loss: 6.938873E+00 | loss scale: 32768.0 | grad norm: 8.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      118/    1200 | consumed samples:         5664 | elapsed time per iteration (ms): 1114.6 | learning rate: 1.573E-06 | global batch size:    48 | lm loss: 7.045137E+00 | loss scale: 32768.0 | grad norm: 9.135 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      119/    1200 | consumed samples:         5712 | elapsed time per iteration (ms): 1048.4 | learning rate: 1.589E-06 | global batch size:    48 | lm loss: 7.072136E+00 | loss scale: 32768.0 | grad norm: 12.234 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      120/    1200 | consumed samples:         5760 | elapsed time per iteration (ms): 1121.0 | learning rate: 1.604E-06 | global batch size:    48 | lm loss: 7.000780E+00 | loss scale: 32768.0 | grad norm: 10.567 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      121/    1200 | consumed samples:         5808 | elapsed time per iteration (ms): 3175.4 | learning rate: 1.620E-06 | global batch size:    48 | lm loss: 7.099237E+00 | loss scale: 32768.0 | grad norm: 10.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      122/    1200 | consumed samples:         5856 | elapsed time per iteration (ms): 3072.0 | learning rate: 1.636E-06 | global batch size:    48 | lm loss: 7.048301E+00 | loss scale: 32768.0 | grad norm: 11.299 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      123/    1200 | consumed samples:         5904 | elapsed time per iteration (ms): 3147.8 | learning rate: 1.652E-06 | global batch size:    48 | lm loss: 6.998693E+00 | loss scale: 32768.0 | grad norm: 13.265 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      124/    1200 | consumed samples:         5952 | elapsed time per iteration (ms): 3058.8 | learning rate: 1.667E-06 | global batch size:    48 | lm loss: 7.034952E+00 | loss scale: 32768.0 | grad norm: 7.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      125/    1200 | consumed samples:         6000 | elapsed time per iteration (ms): 3145.8 | learning rate: 1.683E-06 | global batch size:    48 | lm loss: 6.864954E+00 | loss scale: 32768.0 | grad norm: 11.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      126/    1200 | consumed samples:         6048 | elapsed time per iteration (ms): 3061.3 | learning rate: 1.699E-06 | global batch size:    48 | lm loss: 7.006668E+00 | loss scale: 32768.0 | grad norm: 15.838 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      127/    1200 | consumed samples:         6096 | elapsed time per iteration (ms): 3076.9 | learning rate: 1.714E-06 | global batch size:    48 | lm loss: 6.942394E+00 | loss scale: 32768.0 | grad norm: 17.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      128/    1200 | consumed samples:         6144 | elapsed time per iteration (ms): 3052.4 | learning rate: 1.730E-06 | global batch size:    48 | lm loss: 7.012870E+00 | loss scale: 32768.0 | grad norm: 10.707 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      129/    1200 | consumed samples:         6192 | elapsed time per iteration (ms): 3061.2 | learning rate: 1.746E-06 | global batch size:    48 | lm loss: 6.885618E+00 | loss scale: 32768.0 | grad norm: 9.368 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      130/    1200 | consumed samples:         6240 | elapsed time per iteration (ms): 3258.9 | learning rate: 1.762E-06 | global batch size:    48 | lm loss: 6.943102E+00 | loss scale: 32768.0 | grad norm: 11.371 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      131/    1200 | consumed samples:         6288 | elapsed time per iteration (ms): 3049.5 | learning rate: 1.777E-06 | global batch size:    48 | lm loss: 6.955492E+00 | loss scale: 32768.0 | grad norm: 15.214 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      132/    1200 | consumed samples:         6336 | elapsed time per iteration (ms): 3175.1 | learning rate: 1.793E-06 | global batch size:    48 | lm loss: 6.953244E+00 | loss scale: 32768.0 | grad norm: 8.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      133/    1200 | consumed samples:         6384 | elapsed time per iteration (ms): 3050.5 | learning rate: 1.809E-06 | global batch size:    48 | lm loss: 6.849318E+00 | loss scale: 32768.0 | grad norm: 8.153 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      134/    1200 | consumed samples:         6432 | elapsed time per iteration (ms): 3127.1 | learning rate: 1.825E-06 | global batch size:    48 | lm loss: 6.850626E+00 | loss scale: 32768.0 | grad norm: 11.169 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      135/    1200 | consumed samples:         6480 | elapsed time per iteration (ms): 3085.2 | learning rate: 1.840E-06 | global batch size:    48 | lm loss: 6.885326E+00 | loss scale: 32768.0 | grad norm: 8.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      136/    1200 | consumed samples:         6528 | elapsed time per iteration (ms): 3048.1 | learning rate: 1.856E-06 | global batch size:    48 | lm loss: 7.033746E+00 | loss scale: 32768.0 | grad norm: 19.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      137/    1200 | consumed samples:         6576 | elapsed time per iteration (ms): 3060.6 | learning rate: 1.872E-06 | global batch size:    48 | lm loss: 6.880209E+00 | loss scale: 32768.0 | grad norm: 8.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      138/    1200 | consumed samples:         6624 | elapsed time per iteration (ms): 3183.3 | learning rate: 1.887E-06 | global batch size:    48 | lm loss: 6.986168E+00 | loss scale: 32768.0 | grad norm: 7.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      139/    1200 | consumed samples:         6672 | elapsed time per iteration (ms): 3105.9 | learning rate: 1.903E-06 | global batch size:    48 | lm loss: 6.846906E+00 | loss scale: 32768.0 | grad norm: 10.377 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      140/    1200 | consumed samples:         6720 | elapsed time per iteration (ms): 3148.0 | learning rate: 1.919E-06 | global batch size:    48 | lm loss: 6.949976E+00 | loss scale: 32768.0 | grad norm: 9.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      141/    1200 | consumed samples:         6768 | elapsed time per iteration (ms): 3054.2 | learning rate: 1.935E-06 | global batch size:    48 | lm loss: 6.873573E+00 | loss scale: 32768.0 | grad norm: 11.316 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      142/    1200 | consumed samples:         6816 | elapsed time per iteration (ms): 3054.4 | learning rate: 1.950E-06 | global batch size:    48 | lm loss: 6.803744E+00 | loss scale: 32768.0 | grad norm: 12.142 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      143/    1200 | consumed samples:         6864 | elapsed time per iteration (ms): 3105.7 | learning rate: 1.966E-06 | global batch size:    48 | lm loss: 6.843658E+00 | loss scale: 32768.0 | grad norm: 8.380 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      144/    1200 | consumed samples:         6912 | elapsed time per iteration (ms): 3080.0 | learning rate: 1.982E-06 | global batch size:    48 | lm loss: 6.745358E+00 | loss scale: 32768.0 | grad norm: 9.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      145/    1200 | consumed samples:         6960 | elapsed time per iteration (ms): 3053.7 | learning rate: 1.998E-06 | global batch size:    48 | lm loss: 6.824911E+00 | loss scale: 32768.0 | grad norm: 9.331 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      146/    1200 | consumed samples:         7008 | elapsed time per iteration (ms): 3046.0 | learning rate: 2.013E-06 | global batch size:    48 | lm loss: 6.781439E+00 | loss scale: 32768.0 | grad norm: 8.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      147/    1200 | consumed samples:         7056 | elapsed time per iteration (ms): 3156.8 | learning rate: 2.029E-06 | global batch size:    48 | lm loss: 6.773241E+00 | loss scale: 32768.0 | grad norm: 9.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      148/    1200 | consumed samples:         7104 | elapsed time per iteration (ms): 3127.4 | learning rate: 2.045E-06 | global batch size:    48 | lm loss: 6.768932E+00 | loss scale: 32768.0 | grad norm: 8.134 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      149/    1200 | consumed samples:         7152 | elapsed time per iteration (ms): 3044.9 | learning rate: 2.060E-06 | global batch size:    48 | lm loss: 6.858994E+00 | loss scale: 32768.0 | grad norm: 7.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      150/    1200 | consumed samples:         7200 | elapsed time per iteration (ms): 3060.7 | learning rate: 2.076E-06 | global batch size:    48 | lm loss: 6.725740E+00 | loss scale: 32768.0 | grad norm: 9.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      151/    1200 | consumed samples:         7248 | elapsed time per iteration (ms): 3059.6 | learning rate: 2.092E-06 | global batch size:    48 | lm loss: 6.754873E+00 | loss scale: 32768.0 | grad norm: 13.203 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      152/    1200 | consumed samples:         7296 | elapsed time per iteration (ms): 3043.8 | learning rate: 2.108E-06 | global batch size:    48 | lm loss: 6.783948E+00 | loss scale: 32768.0 | grad norm: 7.164 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      153/    1200 | consumed samples:         7344 | elapsed time per iteration (ms): 3081.9 | learning rate: 2.123E-06 | global batch size:    48 | lm loss: 6.787480E+00 | loss scale: 32768.0 | grad norm: 8.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      154/    1200 | consumed samples:         7392 | elapsed time per iteration (ms): 3075.2 | learning rate: 2.139E-06 | global batch size:    48 | lm loss: 6.767547E+00 | loss scale: 32768.0 | grad norm: 9.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      155/    1200 | consumed samples:         7440 | elapsed time per iteration (ms): 3060.1 | learning rate: 2.155E-06 | global batch size:    48 | lm loss: 6.743893E+00 | loss scale: 32768.0 | grad norm: 9.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      156/    1200 | consumed samples:         7488 | elapsed time per iteration (ms): 3145.2 | learning rate: 2.171E-06 | global batch size:    48 | lm loss: 6.645530E+00 | loss scale: 32768.0 | grad norm: 14.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      157/    1200 | consumed samples:         7536 | elapsed time per iteration (ms): 3132.9 | learning rate: 2.186E-06 | global batch size:    48 | lm loss: 6.726966E+00 | loss scale: 32768.0 | grad norm: 7.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      158/    1200 | consumed samples:         7584 | elapsed time per iteration (ms): 3054.1 | learning rate: 2.202E-06 | global batch size:    48 | lm loss: 6.737802E+00 | loss scale: 32768.0 | grad norm: 10.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      159/    1200 | consumed samples:         7632 | elapsed time per iteration (ms): 3046.0 | learning rate: 2.218E-06 | global batch size:    48 | lm loss: 6.723672E+00 | loss scale: 32768.0 | grad norm: 6.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      160/    1200 | consumed samples:         7680 | elapsed time per iteration (ms): 3139.5 | learning rate: 2.233E-06 | global batch size:    48 | lm loss: 6.659835E+00 | loss scale: 32768.0 | grad norm: 6.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      161/    1200 | consumed samples:         7728 | elapsed time per iteration (ms): 3146.1 | learning rate: 2.249E-06 | global batch size:    48 | lm loss: 6.594519E+00 | loss scale: 32768.0 | grad norm: 10.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      162/    1200 | consumed samples:         7776 | elapsed time per iteration (ms): 3077.0 | learning rate: 2.265E-06 | global batch size:    48 | lm loss: 6.632246E+00 | loss scale: 32768.0 | grad norm: 9.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      163/    1200 | consumed samples:         7824 | elapsed time per iteration (ms): 3046.0 | learning rate: 2.281E-06 | global batch size:    48 | lm loss: 6.639266E+00 | loss scale: 32768.0 | grad norm: 7.273 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      164/    1200 | consumed samples:         7872 | elapsed time per iteration (ms): 3048.5 | learning rate: 2.296E-06 | global batch size:    48 | lm loss: 6.636423E+00 | loss scale: 32768.0 | grad norm: 8.340 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      165/    1200 | consumed samples:         7920 | elapsed time per iteration (ms): 3191.9 | learning rate: 2.312E-06 | global batch size:    48 | lm loss: 6.631211E+00 | loss scale: 32768.0 | grad norm: 8.379 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      166/    1200 | consumed samples:         7968 | elapsed time per iteration (ms): 3134.0 | learning rate: 2.328E-06 | global batch size:    48 | lm loss: 6.688893E+00 | loss scale: 32768.0 | grad norm: 8.481 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      167/    1200 | consumed samples:         8016 | elapsed time per iteration (ms): 3054.3 | learning rate: 2.344E-06 | global batch size:    48 | lm loss: 6.528568E+00 | loss scale: 32768.0 | grad norm: 9.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      168/    1200 | consumed samples:         8064 | elapsed time per iteration (ms): 3052.6 | learning rate: 2.359E-06 | global batch size:    48 | lm loss: 6.692420E+00 | loss scale: 32768.0 | grad norm: 10.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      169/    1200 | consumed samples:         8112 | elapsed time per iteration (ms): 3074.2 | learning rate: 2.375E-06 | global batch size:    48 | lm loss: 6.690752E+00 | loss scale: 32768.0 | grad norm: 9.805 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      170/    1200 | consumed samples:         8160 | elapsed time per iteration (ms): 3060.4 | learning rate: 2.391E-06 | global batch size:    48 | lm loss: 6.625206E+00 | loss scale: 32768.0 | grad norm: 8.357 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      171/    1200 | consumed samples:         8208 | elapsed time per iteration (ms): 3086.0 | learning rate: 2.406E-06 | global batch size:    48 | lm loss: 6.558454E+00 | loss scale: 32768.0 | grad norm: 9.246 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      172/    1200 | consumed samples:         8256 | elapsed time per iteration (ms): 3052.5 | learning rate: 2.422E-06 | global batch size:    48 | lm loss: 6.625031E+00 | loss scale: 32768.0 | grad norm: 7.535 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      173/    1200 | consumed samples:         8304 | elapsed time per iteration (ms): 3053.9 | learning rate: 2.438E-06 | global batch size:    48 | lm loss: 6.612943E+00 | loss scale: 32768.0 | grad norm: 7.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      174/    1200 | consumed samples:         8352 | elapsed time per iteration (ms): 3151.5 | learning rate: 2.454E-06 | global batch size:    48 | lm loss: 6.571683E+00 | loss scale: 32768.0 | grad norm: 9.542 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      175/    1200 | consumed samples:         8400 | elapsed time per iteration (ms): 3151.0 | learning rate: 2.469E-06 | global batch size:    48 | lm loss: 6.621669E+00 | loss scale: 32768.0 | grad norm: 6.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      176/    1200 | consumed samples:         8448 | elapsed time per iteration (ms): 3106.2 | learning rate: 2.485E-06 | global batch size:    48 | lm loss: 6.652655E+00 | loss scale: 32768.0 | grad norm: 7.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      177/    1200 | consumed samples:         8496 | elapsed time per iteration (ms): 3043.7 | learning rate: 2.501E-06 | global batch size:    48 | lm loss: 6.594578E+00 | loss scale: 32768.0 | grad norm: 7.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      178/    1200 | consumed samples:         8544 | elapsed time per iteration (ms): 3068.7 | learning rate: 2.517E-06 | global batch size:    48 | lm loss: 6.604879E+00 | loss scale: 32768.0 | grad norm: 8.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      179/    1200 | consumed samples:         8592 | elapsed time per iteration (ms): 3055.4 | learning rate: 2.532E-06 | global batch size:    48 | lm loss: 6.444448E+00 | loss scale: 32768.0 | grad norm: 9.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      180/    1200 | consumed samples:         8640 | elapsed time per iteration (ms): 3135.1 | learning rate: 2.548E-06 | global batch size:    48 | lm loss: 6.497937E+00 | loss scale: 32768.0 | grad norm: 7.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      181/    1200 | consumed samples:         8688 | elapsed time per iteration (ms): 3073.8 | learning rate: 2.564E-06 | global batch size:    48 | lm loss: 6.571640E+00 | loss scale: 32768.0 | grad norm: 8.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      182/    1200 | consumed samples:         8736 | elapsed time per iteration (ms): 3059.1 | learning rate: 2.580E-06 | global batch size:    48 | lm loss: 6.533820E+00 | loss scale: 32768.0 | grad norm: 8.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      183/    1200 | consumed samples:         8784 | elapsed time per iteration (ms): 3154.6 | learning rate: 2.595E-06 | global batch size:    48 | lm loss: 6.682606E+00 | loss scale: 32768.0 | grad norm: 10.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      184/    1200 | consumed samples:         8832 | elapsed time per iteration (ms): 3148.9 | learning rate: 2.611E-06 | global batch size:    48 | lm loss: 6.539716E+00 | loss scale: 32768.0 | grad norm: 8.576 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      185/    1200 | consumed samples:         8880 | elapsed time per iteration (ms): 3084.0 | learning rate: 2.627E-06 | global batch size:    48 | lm loss: 6.515322E+00 | loss scale: 32768.0 | grad norm: 8.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      186/    1200 | consumed samples:         8928 | elapsed time per iteration (ms): 3060.0 | learning rate: 2.642E-06 | global batch size:    48 | lm loss: 6.624323E+00 | loss scale: 32768.0 | grad norm: 9.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      187/    1200 | consumed samples:         8976 | elapsed time per iteration (ms): 3060.8 | learning rate: 2.658E-06 | global batch size:    48 | lm loss: 6.705251E+00 | loss scale: 32768.0 | grad norm: 9.576 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      188/    1200 | consumed samples:         9024 | elapsed time per iteration (ms): 3056.8 | learning rate: 2.674E-06 | global batch size:    48 | lm loss: 6.602552E+00 | loss scale: 32768.0 | grad norm: 9.357 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      189/    1200 | consumed samples:         9072 | elapsed time per iteration (ms): 3093.8 | learning rate: 2.690E-06 | global batch size:    48 | lm loss: 6.531281E+00 | loss scale: 32768.0 | grad norm: 8.345 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      190/    1200 | consumed samples:         9120 | elapsed time per iteration (ms): 3057.5 | learning rate: 2.705E-06 | global batch size:    48 | lm loss: 6.546922E+00 | loss scale: 32768.0 | grad norm: 9.222 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      191/    1200 | consumed samples:         9168 | elapsed time per iteration (ms): 2491.3 | learning rate: 2.721E-06 | global batch size:    48 | lm loss: 6.529390E+00 | loss scale: 32768.0 | grad norm: 7.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      192/    1200 | consumed samples:         9216 | elapsed time per iteration (ms): 2147.0 | learning rate: 2.737E-06 | global batch size:    48 | lm loss: 6.498402E+00 | loss scale: 32768.0 | grad norm: 6.949 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      193/    1200 | consumed samples:         9264 | elapsed time per iteration (ms): 1096.2 | learning rate: 2.753E-06 | global batch size:    48 | lm loss: 6.436588E+00 | loss scale: 32768.0 | grad norm: 5.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      194/    1200 | consumed samples:         9312 | elapsed time per iteration (ms): 1045.3 | learning rate: 2.768E-06 | global batch size:    48 | lm loss: 6.467779E+00 | loss scale: 32768.0 | grad norm: 8.285 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      195/    1200 | consumed samples:         9360 | elapsed time per iteration (ms): 1033.8 | learning rate: 2.784E-06 | global batch size:    48 | lm loss: 6.565130E+00 | loss scale: 32768.0 | grad norm: 8.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      196/    1200 | consumed samples:         9408 | elapsed time per iteration (ms): 1117.7 | learning rate: 2.800E-06 | global batch size:    48 | lm loss: 6.608953E+00 | loss scale: 32768.0 | grad norm: 10.314 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      197/    1200 | consumed samples:         9456 | elapsed time per iteration (ms): 986.0 | learning rate: 2.815E-06 | global batch size:    48 | lm loss: 6.532041E+00 | loss scale: 32768.0 | grad norm: 6.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      198/    1200 | consumed samples:         9504 | elapsed time per iteration (ms): 1059.3 | learning rate: 2.831E-06 | global batch size:    48 | lm loss: 6.487464E+00 | loss scale: 32768.0 | grad norm: 6.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      199/    1200 | consumed samples:         9552 | elapsed time per iteration (ms): 979.5 | learning rate: 2.847E-06 | global batch size:    48 | lm loss: 6.567201E+00 | loss scale: 32768.0 | grad norm: 6.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      200/    1200 | consumed samples:         9600 | elapsed time per iteration (ms): 1122.1 | learning rate: 2.863E-06 | global batch size:    48 | lm loss: 6.438718E+00 | loss scale: 32768.0 | grad norm: 6.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      201/    1200 | consumed samples:         9648 | elapsed time per iteration (ms): 1233.2 | learning rate: 2.878E-06 | global batch size:    48 | lm loss: 6.491395E+00 | loss scale: 32768.0 | grad norm: 7.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      202/    1200 | consumed samples:         9696 | elapsed time per iteration (ms): 1164.0 | learning rate: 2.894E-06 | global batch size:    48 | lm loss: 6.518180E+00 | loss scale: 32768.0 | grad norm: 7.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      203/    1200 | consumed samples:         9744 | elapsed time per iteration (ms): 1140.2 | learning rate: 2.910E-06 | global batch size:    48 | lm loss: 6.559813E+00 | loss scale: 32768.0 | grad norm: 8.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      204/    1200 | consumed samples:         9792 | elapsed time per iteration (ms): 1114.5 | learning rate: 2.926E-06 | global batch size:    48 | lm loss: 6.412548E+00 | loss scale: 32768.0 | grad norm: 10.293 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      205/    1200 | consumed samples:         9840 | elapsed time per iteration (ms): 1107.7 | learning rate: 2.941E-06 | global batch size:    48 | lm loss: 6.488084E+00 | loss scale: 32768.0 | grad norm: 7.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      206/    1200 | consumed samples:         9888 | elapsed time per iteration (ms): 981.9 | learning rate: 2.957E-06 | global batch size:    48 | lm loss: 6.459340E+00 | loss scale: 32768.0 | grad norm: 7.173 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      207/    1200 | consumed samples:         9936 | elapsed time per iteration (ms): 1058.1 | learning rate: 2.973E-06 | global batch size:    48 | lm loss: 6.405831E+00 | loss scale: 32768.0 | grad norm: 6.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      208/    1200 | consumed samples:         9984 | elapsed time per iteration (ms): 1098.7 | learning rate: 2.988E-06 | global batch size:    48 | lm loss: 6.497621E+00 | loss scale: 32768.0 | grad norm: 7.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      209/    1200 | consumed samples:        10032 | elapsed time per iteration (ms): 1250.5 | learning rate: 3.004E-06 | global batch size:    48 | lm loss: 6.358373E+00 | loss scale: 32768.0 | grad norm: 6.867 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      210/    1200 | consumed samples:        10080 | elapsed time per iteration (ms): 1163.0 | learning rate: 3.020E-06 | global batch size:    48 | lm loss: 6.390478E+00 | loss scale: 32768.0 | grad norm: 6.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      211/    1200 | consumed samples:        10128 | elapsed time per iteration (ms): 1117.5 | learning rate: 3.036E-06 | global batch size:    48 | lm loss: 6.443766E+00 | loss scale: 32768.0 | grad norm: 7.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      212/    1200 | consumed samples:        10176 | elapsed time per iteration (ms): 1089.8 | learning rate: 3.051E-06 | global batch size:    48 | lm loss: 6.371163E+00 | loss scale: 32768.0 | grad norm: 6.231 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      213/    1200 | consumed samples:        10224 | elapsed time per iteration (ms): 988.3 | learning rate: 3.067E-06 | global batch size:    48 | lm loss: 6.392514E+00 | loss scale: 32768.0 | grad norm: 6.589 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      214/    1200 | consumed samples:        10272 | elapsed time per iteration (ms): 984.3 | learning rate: 3.083E-06 | global batch size:    48 | lm loss: 6.457443E+00 | loss scale: 32768.0 | grad norm: 10.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      215/    1200 | consumed samples:        10320 | elapsed time per iteration (ms): 1003.9 | learning rate: 3.099E-06 | global batch size:    48 | lm loss: 6.459865E+00 | loss scale: 32768.0 | grad norm: 9.352 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      216/    1200 | consumed samples:        10368 | elapsed time per iteration (ms): 1333.3 | learning rate: 3.114E-06 | global batch size:    48 | lm loss: 6.502833E+00 | loss scale: 32768.0 | grad norm: 6.986 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      217/    1200 | consumed samples:        10416 | elapsed time per iteration (ms): 1099.1 | learning rate: 3.130E-06 | global batch size:    48 | lm loss: 6.513755E+00 | loss scale: 32768.0 | grad norm: 7.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      218/    1200 | consumed samples:        10464 | elapsed time per iteration (ms): 1161.4 | learning rate: 3.146E-06 | global batch size:    48 | lm loss: 6.422708E+00 | loss scale: 32768.0 | grad norm: 6.366 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      219/    1200 | consumed samples:        10512 | elapsed time per iteration (ms): 1124.7 | learning rate: 3.161E-06 | global batch size:    48 | lm loss: 6.448337E+00 | loss scale: 32768.0 | grad norm: 7.119 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      220/    1200 | consumed samples:        10560 | elapsed time per iteration (ms): 1269.0 | learning rate: 3.177E-06 | global batch size:    48 | lm loss: 6.379642E+00 | loss scale: 32768.0 | grad norm: 8.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      221/    1200 | consumed samples:        10608 | elapsed time per iteration (ms): 1076.0 | learning rate: 3.193E-06 | global batch size:    48 | lm loss: 6.322303E+00 | loss scale: 32768.0 | grad norm: 5.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      222/    1200 | consumed samples:        10656 | elapsed time per iteration (ms): 981.1 | learning rate: 3.209E-06 | global batch size:    48 | lm loss: 6.427459E+00 | loss scale: 32768.0 | grad norm: 6.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      223/    1200 | consumed samples:        10704 | elapsed time per iteration (ms): 1121.9 | learning rate: 3.224E-06 | global batch size:    48 | lm loss: 6.388845E+00 | loss scale: 32768.0 | grad norm: 5.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      224/    1200 | consumed samples:        10752 | elapsed time per iteration (ms): 988.0 | learning rate: 3.240E-06 | global batch size:    48 | lm loss: 6.248296E+00 | loss scale: 32768.0 | grad norm: 6.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      225/    1200 | consumed samples:        10800 | elapsed time per iteration (ms): 1118.7 | learning rate: 3.256E-06 | global batch size:    48 | lm loss: 6.349025E+00 | loss scale: 32768.0 | grad norm: 7.367 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      226/    1200 | consumed samples:        10848 | elapsed time per iteration (ms): 1047.3 | learning rate: 3.272E-06 | global batch size:    48 | lm loss: 6.358183E+00 | loss scale: 32768.0 | grad norm: 6.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      227/    1200 | consumed samples:        10896 | elapsed time per iteration (ms): 1098.7 | learning rate: 3.287E-06 | global batch size:    48 | lm loss: 6.371078E+00 | loss scale: 32768.0 | grad norm: 7.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      228/    1200 | consumed samples:        10944 | elapsed time per iteration (ms): 1306.3 | learning rate: 3.303E-06 | global batch size:    48 | lm loss: 6.406243E+00 | loss scale: 32768.0 | grad norm: 5.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      229/    1200 | consumed samples:        10992 | elapsed time per iteration (ms): 1182.7 | learning rate: 3.319E-06 | global batch size:    48 | lm loss: 6.336622E+00 | loss scale: 32768.0 | grad norm: 5.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      230/    1200 | consumed samples:        11040 | elapsed time per iteration (ms): 977.9 | learning rate: 3.334E-06 | global batch size:    48 | lm loss: 6.422384E+00 | loss scale: 32768.0 | grad norm: 6.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      231/    1200 | consumed samples:        11088 | elapsed time per iteration (ms): 1232.8 | learning rate: 3.350E-06 | global batch size:    48 | lm loss: 6.407139E+00 | loss scale: 32768.0 | grad norm: 7.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      232/    1200 | consumed samples:        11136 | elapsed time per iteration (ms): 1435.2 | learning rate: 3.366E-06 | global batch size:    48 | lm loss: 6.380524E+00 | loss scale: 32768.0 | grad norm: 7.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      233/    1200 | consumed samples:        11184 | elapsed time per iteration (ms): 1876.7 | learning rate: 3.382E-06 | global batch size:    48 | lm loss: 6.302909E+00 | loss scale: 32768.0 | grad norm: 10.274 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      234/    1200 | consumed samples:        11232 | elapsed time per iteration (ms): 1904.2 | learning rate: 3.397E-06 | global batch size:    48 | lm loss: 6.387524E+00 | loss scale: 32768.0 | grad norm: 11.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      235/    1200 | consumed samples:        11280 | elapsed time per iteration (ms): 1987.1 | learning rate: 3.413E-06 | global batch size:    48 | lm loss: 6.293483E+00 | loss scale: 32768.0 | grad norm: 7.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      236/    1200 | consumed samples:        11328 | elapsed time per iteration (ms): 1825.6 | learning rate: 3.429E-06 | global batch size:    48 | lm loss: 6.327327E+00 | loss scale: 32768.0 | grad norm: 7.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      237/    1200 | consumed samples:        11376 | elapsed time per iteration (ms): 1954.7 | learning rate: 3.445E-06 | global batch size:    48 | lm loss: 6.347042E+00 | loss scale: 32768.0 | grad norm: 10.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      238/    1200 | consumed samples:        11424 | elapsed time per iteration (ms): 1924.5 | learning rate: 3.460E-06 | global batch size:    48 | lm loss: 6.391841E+00 | loss scale: 32768.0 | grad norm: 6.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      239/    1200 | consumed samples:        11472 | elapsed time per iteration (ms): 1825.5 | learning rate: 3.476E-06 | global batch size:    48 | lm loss: 6.417007E+00 | loss scale: 32768.0 | grad norm: 5.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      240/    1200 | consumed samples:        11520 | elapsed time per iteration (ms): 1877.1 | learning rate: 3.492E-06 | global batch size:    48 | lm loss: 6.225006E+00 | loss scale: 32768.0 | grad norm: 7.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      241/    1200 | consumed samples:        11568 | elapsed time per iteration (ms): 1843.3 | learning rate: 3.507E-06 | global batch size:    48 | lm loss: 6.274532E+00 | loss scale: 32768.0 | grad norm: 9.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      242/    1200 | consumed samples:        11616 | elapsed time per iteration (ms): 1837.1 | learning rate: 3.523E-06 | global batch size:    48 | lm loss: 6.412992E+00 | loss scale: 32768.0 | grad norm: 9.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      243/    1200 | consumed samples:        11664 | elapsed time per iteration (ms): 2086.5 | learning rate: 3.539E-06 | global batch size:    48 | lm loss: 6.407957E+00 | loss scale: 32768.0 | grad norm: 8.539 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      244/    1200 | consumed samples:        11712 | elapsed time per iteration (ms): 1829.3 | learning rate: 3.555E-06 | global batch size:    48 | lm loss: 6.351963E+00 | loss scale: 32768.0 | grad norm: 5.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      245/    1200 | consumed samples:        11760 | elapsed time per iteration (ms): 1883.6 | learning rate: 3.570E-06 | global batch size:    48 | lm loss: 6.359482E+00 | loss scale: 32768.0 | grad norm: 7.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      246/    1200 | consumed samples:        11808 | elapsed time per iteration (ms): 1909.0 | learning rate: 3.586E-06 | global batch size:    48 | lm loss: 6.394522E+00 | loss scale: 32768.0 | grad norm: 6.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      247/    1200 | consumed samples:        11856 | elapsed time per iteration (ms): 1969.7 | learning rate: 3.602E-06 | global batch size:    48 | lm loss: 6.336637E+00 | loss scale: 32768.0 | grad norm: 6.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      248/    1200 | consumed samples:        11904 | elapsed time per iteration (ms): 1828.1 | learning rate: 3.618E-06 | global batch size:    48 | lm loss: 6.281112E+00 | loss scale: 32768.0 | grad norm: 6.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      249/    1200 | consumed samples:        11952 | elapsed time per iteration (ms): 1837.1 | learning rate: 3.633E-06 | global batch size:    48 | lm loss: 6.178160E+00 | loss scale: 32768.0 | grad norm: 5.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      250/    1200 | consumed samples:        12000 | elapsed time per iteration (ms): 1831.3 | learning rate: 3.649E-06 | global batch size:    48 | lm loss: 6.306474E+00 | loss scale: 32768.0 | grad norm: 6.464 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      251/    1200 | consumed samples:        12048 | elapsed time per iteration (ms): 1901.9 | learning rate: 3.665E-06 | global batch size:    48 | lm loss: 6.297941E+00 | loss scale: 32768.0 | grad norm: 5.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      252/    1200 | consumed samples:        12096 | elapsed time per iteration (ms): 1921.3 | learning rate: 3.681E-06 | global batch size:    48 | lm loss: 6.280101E+00 | loss scale: 32768.0 | grad norm: 6.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      253/    1200 | consumed samples:        12144 | elapsed time per iteration (ms): 1950.4 | learning rate: 3.696E-06 | global batch size:    48 | lm loss: 6.300331E+00 | loss scale: 32768.0 | grad norm: 8.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      254/    1200 | consumed samples:        12192 | elapsed time per iteration (ms): 1961.3 | learning rate: 3.712E-06 | global batch size:    48 | lm loss: 6.275074E+00 | loss scale: 32768.0 | grad norm: 9.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      255/    1200 | consumed samples:        12240 | elapsed time per iteration (ms): 1907.3 | learning rate: 3.728E-06 | global batch size:    48 | lm loss: 6.311139E+00 | loss scale: 32768.0 | grad norm: 7.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      256/    1200 | consumed samples:        12288 | elapsed time per iteration (ms): 1933.3 | learning rate: 3.743E-06 | global batch size:    48 | lm loss: 6.268869E+00 | loss scale: 32768.0 | grad norm: 5.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      257/    1200 | consumed samples:        12336 | elapsed time per iteration (ms): 1837.4 | learning rate: 3.759E-06 | global batch size:    48 | lm loss: 6.208293E+00 | loss scale: 32768.0 | grad norm: 5.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      258/    1200 | consumed samples:        12384 | elapsed time per iteration (ms): 1837.3 | learning rate: 3.775E-06 | global batch size:    48 | lm loss: 6.278468E+00 | loss scale: 32768.0 | grad norm: 8.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      259/    1200 | consumed samples:        12432 | elapsed time per iteration (ms): 1842.2 | learning rate: 3.791E-06 | global batch size:    48 | lm loss: 6.264624E+00 | loss scale: 32768.0 | grad norm: 8.302 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      260/    1200 | consumed samples:        12480 | elapsed time per iteration (ms): 1899.2 | learning rate: 3.806E-06 | global batch size:    48 | lm loss: 6.380214E+00 | loss scale: 32768.0 | grad norm: 6.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      261/    1200 | consumed samples:        12528 | elapsed time per iteration (ms): 1995.0 | learning rate: 3.822E-06 | global batch size:    48 | lm loss: 6.204939E+00 | loss scale: 32768.0 | grad norm: 6.116 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      262/    1200 | consumed samples:        12576 | elapsed time per iteration (ms): 1884.7 | learning rate: 3.838E-06 | global batch size:    48 | lm loss: 6.181085E+00 | loss scale: 32768.0 | grad norm: 6.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      263/    1200 | consumed samples:        12624 | elapsed time per iteration (ms): 1831.9 | learning rate: 3.854E-06 | global batch size:    48 | lm loss: 6.190626E+00 | loss scale: 32768.0 | grad norm: 5.164 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      264/    1200 | consumed samples:        12672 | elapsed time per iteration (ms): 1913.1 | learning rate: 3.869E-06 | global batch size:    48 | lm loss: 6.306579E+00 | loss scale: 32768.0 | grad norm: 5.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      265/    1200 | consumed samples:        12720 | elapsed time per iteration (ms): 1938.2 | learning rate: 3.885E-06 | global batch size:    48 | lm loss: 6.187150E+00 | loss scale: 32768.0 | grad norm: 6.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      266/    1200 | consumed samples:        12768 | elapsed time per iteration (ms): 1905.5 | learning rate: 3.901E-06 | global batch size:    48 | lm loss: 6.324098E+00 | loss scale: 32768.0 | grad norm: 5.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      267/    1200 | consumed samples:        12816 | elapsed time per iteration (ms): 1827.9 | learning rate: 3.916E-06 | global batch size:    48 | lm loss: 6.250158E+00 | loss scale: 32768.0 | grad norm: 6.132 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      268/    1200 | consumed samples:        12864 | elapsed time per iteration (ms): 1900.7 | learning rate: 3.932E-06 | global batch size:    48 | lm loss: 6.234686E+00 | loss scale: 32768.0 | grad norm: 6.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      269/    1200 | consumed samples:        12912 | elapsed time per iteration (ms): 2007.2 | learning rate: 3.948E-06 | global batch size:    48 | lm loss: 6.223565E+00 | loss scale: 32768.0 | grad norm: 6.347 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      270/    1200 | consumed samples:        12960 | elapsed time per iteration (ms): 1895.0 | learning rate: 3.964E-06 | global batch size:    48 | lm loss: 6.199121E+00 | loss scale: 32768.0 | grad norm: 8.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      271/    1200 | consumed samples:        13008 | elapsed time per iteration (ms): 1906.9 | learning rate: 3.979E-06 | global batch size:    48 | lm loss: 6.253704E+00 | loss scale: 32768.0 | grad norm: 7.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      272/    1200 | consumed samples:        13056 | elapsed time per iteration (ms): 1833.1 | learning rate: 3.995E-06 | global batch size:    48 | lm loss: 6.299804E+00 | loss scale: 32768.0 | grad norm: 5.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      273/    1200 | consumed samples:        13104 | elapsed time per iteration (ms): 1908.3 | learning rate: 4.011E-06 | global batch size:    48 | lm loss: 6.290843E+00 | loss scale: 32768.0 | grad norm: 7.338 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      274/    1200 | consumed samples:        13152 | elapsed time per iteration (ms): 1936.7 | learning rate: 4.027E-06 | global batch size:    48 | lm loss: 6.236863E+00 | loss scale: 32768.0 | grad norm: 7.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      275/    1200 | consumed samples:        13200 | elapsed time per iteration (ms): 1834.1 | learning rate: 4.042E-06 | global batch size:    48 | lm loss: 6.187706E+00 | loss scale: 32768.0 | grad norm: 5.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      276/    1200 | consumed samples:        13248 | elapsed time per iteration (ms): 1899.5 | learning rate: 4.058E-06 | global batch size:    48 | lm loss: 6.224736E+00 | loss scale: 32768.0 | grad norm: 5.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      277/    1200 | consumed samples:        13296 | elapsed time per iteration (ms): 1873.9 | learning rate: 4.074E-06 | global batch size:    48 | lm loss: 6.315495E+00 | loss scale: 32768.0 | grad norm: 5.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      278/    1200 | consumed samples:        13344 | elapsed time per iteration (ms): 1871.2 | learning rate: 4.089E-06 | global batch size:    48 | lm loss: 6.212055E+00 | loss scale: 32768.0 | grad norm: 5.355 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      279/    1200 | consumed samples:        13392 | elapsed time per iteration (ms): 2070.6 | learning rate: 4.105E-06 | global batch size:    48 | lm loss: 6.238122E+00 | loss scale: 32768.0 | grad norm: 5.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      280/    1200 | consumed samples:        13440 | elapsed time per iteration (ms): 1828.9 | learning rate: 4.121E-06 | global batch size:    48 | lm loss: 6.279367E+00 | loss scale: 32768.0 | grad norm: 7.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      281/    1200 | consumed samples:        13488 | elapsed time per iteration (ms): 1841.6 | learning rate: 4.137E-06 | global batch size:    48 | lm loss: 6.391584E+00 | loss scale: 32768.0 | grad norm: 11.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      282/    1200 | consumed samples:        13536 | elapsed time per iteration (ms): 1966.2 | learning rate: 4.152E-06 | global batch size:    48 | lm loss: 6.241455E+00 | loss scale: 32768.0 | grad norm: 8.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      283/    1200 | consumed samples:        13584 | elapsed time per iteration (ms): 1942.2 | learning rate: 4.168E-06 | global batch size:    48 | lm loss: 6.181157E+00 | loss scale: 32768.0 | grad norm: 6.129 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      284/    1200 | consumed samples:        13632 | elapsed time per iteration (ms): 1845.4 | learning rate: 4.184E-06 | global batch size:    48 | lm loss: 6.255680E+00 | loss scale: 32768.0 | grad norm: 6.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      285/    1200 | consumed samples:        13680 | elapsed time per iteration (ms): 2076.5 | learning rate: 4.200E-06 | global batch size:    48 | lm loss: 6.289146E+00 | loss scale: 32768.0 | grad norm: 5.368 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      286/    1200 | consumed samples:        13728 | elapsed time per iteration (ms): 1829.4 | learning rate: 4.215E-06 | global batch size:    48 | lm loss: 6.213638E+00 | loss scale: 32768.0 | grad norm: 5.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      287/    1200 | consumed samples:        13776 | elapsed time per iteration (ms): 1960.2 | learning rate: 4.231E-06 | global batch size:    48 | lm loss: 6.247694E+00 | loss scale: 32768.0 | grad norm: 5.598 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      288/    1200 | consumed samples:        13824 | elapsed time per iteration (ms): 1887.5 | learning rate: 4.247E-06 | global batch size:    48 | lm loss: 6.219972E+00 | loss scale: 32768.0 | grad norm: 5.240 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      289/    1200 | consumed samples:        13872 | elapsed time per iteration (ms): 1832.7 | learning rate: 4.262E-06 | global batch size:    48 | lm loss: 6.249701E+00 | loss scale: 32768.0 | grad norm: 6.268 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      290/    1200 | consumed samples:        13920 | elapsed time per iteration (ms): 1827.3 | learning rate: 4.278E-06 | global batch size:    48 | lm loss: 6.188028E+00 | loss scale: 32768.0 | grad norm: 6.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      291/    1200 | consumed samples:        13968 | elapsed time per iteration (ms): 1907.6 | learning rate: 4.294E-06 | global batch size:    48 | lm loss: 6.217422E+00 | loss scale: 32768.0 | grad norm: 6.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      292/    1200 | consumed samples:        14016 | elapsed time per iteration (ms): 1939.7 | learning rate: 4.310E-06 | global batch size:    48 | lm loss: 6.234176E+00 | loss scale: 32768.0 | grad norm: 5.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      293/    1200 | consumed samples:        14064 | elapsed time per iteration (ms): 1991.3 | learning rate: 4.325E-06 | global batch size:    48 | lm loss: 6.310895E+00 | loss scale: 32768.0 | grad norm: 5.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      294/    1200 | consumed samples:        14112 | elapsed time per iteration (ms): 1830.5 | learning rate: 4.341E-06 | global batch size:    48 | lm loss: 6.230854E+00 | loss scale: 32768.0 | grad norm: 6.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      295/    1200 | consumed samples:        14160 | elapsed time per iteration (ms): 2007.4 | learning rate: 4.357E-06 | global batch size:    48 | lm loss: 6.184495E+00 | loss scale: 32768.0 | grad norm: 5.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      296/    1200 | consumed samples:        14208 | elapsed time per iteration (ms): 1830.0 | learning rate: 4.373E-06 | global batch size:    48 | lm loss: 6.210857E+00 | loss scale: 32768.0 | grad norm: 5.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      297/    1200 | consumed samples:        14256 | elapsed time per iteration (ms): 1888.6 | learning rate: 4.388E-06 | global batch size:    48 | lm loss: 6.272749E+00 | loss scale: 32768.0 | grad norm: 5.263 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      298/    1200 | consumed samples:        14304 | elapsed time per iteration (ms): 1825.1 | learning rate: 4.404E-06 | global batch size:    48 | lm loss: 6.190744E+00 | loss scale: 32768.0 | grad norm: 4.863 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      299/    1200 | consumed samples:        14352 | elapsed time per iteration (ms): 1836.0 | learning rate: 4.420E-06 | global batch size:    48 | lm loss: 6.190806E+00 | loss scale: 32768.0 | grad norm: 5.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      300/    1200 | consumed samples:        14400 | elapsed time per iteration (ms): 1941.5 | learning rate: 4.435E-06 | global batch size:    48 | lm loss: 6.160110E+00 | loss scale: 32768.0 | grad norm: 5.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      301/    1200 | consumed samples:        14448 | elapsed time per iteration (ms): 1542.3 | learning rate: 4.451E-06 | global batch size:    48 | lm loss: 6.142275E+00 | loss scale: 32768.0 | grad norm: 5.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      302/    1200 | consumed samples:        14496 | elapsed time per iteration (ms): 1194.2 | learning rate: 4.467E-06 | global batch size:    48 | lm loss: 6.099874E+00 | loss scale: 32768.0 | grad norm: 5.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      303/    1200 | consumed samples:        14544 | elapsed time per iteration (ms): 987.1 | learning rate: 4.483E-06 | global batch size:    48 | lm loss: 6.112606E+00 | loss scale: 32768.0 | grad norm: 5.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      304/    1200 | consumed samples:        14592 | elapsed time per iteration (ms): 1240.6 | learning rate: 4.498E-06 | global batch size:    48 | lm loss: 6.141764E+00 | loss scale: 32768.0 | grad norm: 8.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      305/    1200 | consumed samples:        14640 | elapsed time per iteration (ms): 1112.2 | learning rate: 4.514E-06 | global batch size:    48 | lm loss: 6.263393E+00 | loss scale: 32768.0 | grad norm: 11.380 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      306/    1200 | consumed samples:        14688 | elapsed time per iteration (ms): 1047.2 | learning rate: 4.530E-06 | global batch size:    48 | lm loss: 6.175942E+00 | loss scale: 32768.0 | grad norm: 5.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      307/    1200 | consumed samples:        14736 | elapsed time per iteration (ms): 999.0 | learning rate: 4.546E-06 | global batch size:    48 | lm loss: 6.232299E+00 | loss scale: 32768.0 | grad norm: 8.505 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      308/    1200 | consumed samples:        14784 | elapsed time per iteration (ms): 998.1 | learning rate: 4.561E-06 | global batch size:    48 | lm loss: 6.280704E+00 | loss scale: 32768.0 | grad norm: 8.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      309/    1200 | consumed samples:        14832 | elapsed time per iteration (ms): 1248.2 | learning rate: 4.577E-06 | global batch size:    48 | lm loss: 6.108802E+00 | loss scale: 32768.0 | grad norm: 6.581 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      310/    1200 | consumed samples:        14880 | elapsed time per iteration (ms): 1155.6 | learning rate: 4.593E-06 | global batch size:    48 | lm loss: 6.162716E+00 | loss scale: 32768.0 | grad norm: 5.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      311/    1200 | consumed samples:        14928 | elapsed time per iteration (ms): 981.7 | learning rate: 4.609E-06 | global batch size:    48 | lm loss: 6.204143E+00 | loss scale: 32768.0 | grad norm: 6.353 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      312/    1200 | consumed samples:        14976 | elapsed time per iteration (ms): 1122.4 | learning rate: 4.624E-06 | global batch size:    48 | lm loss: 6.175520E+00 | loss scale: 32768.0 | grad norm: 5.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      313/    1200 | consumed samples:        15024 | elapsed time per iteration (ms): 1124.4 | learning rate: 4.640E-06 | global batch size:    48 | lm loss: 6.266992E+00 | loss scale: 32768.0 | grad norm: 6.318 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      314/    1200 | consumed samples:        15072 | elapsed time per iteration (ms): 1105.8 | learning rate: 4.656E-06 | global batch size:    48 | lm loss: 6.146600E+00 | loss scale: 32768.0 | grad norm: 6.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      315/    1200 | consumed samples:        15120 | elapsed time per iteration (ms): 1123.9 | learning rate: 4.671E-06 | global batch size:    48 | lm loss: 6.192354E+00 | loss scale: 32768.0 | grad norm: 5.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      316/    1200 | consumed samples:        15168 | elapsed time per iteration (ms): 1239.7 | learning rate: 4.687E-06 | global batch size:    48 | lm loss: 6.162935E+00 | loss scale: 32768.0 | grad norm: 5.568 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      317/    1200 | consumed samples:        15216 | elapsed time per iteration (ms): 1042.5 | learning rate: 4.703E-06 | global batch size:    48 | lm loss: 6.184437E+00 | loss scale: 32768.0 | grad norm: 5.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      318/    1200 | consumed samples:        15264 | elapsed time per iteration (ms): 1163.8 | learning rate: 4.719E-06 | global batch size:    48 | lm loss: 6.152731E+00 | loss scale: 32768.0 | grad norm: 5.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      319/    1200 | consumed samples:        15312 | elapsed time per iteration (ms): 1208.1 | learning rate: 4.734E-06 | global batch size:    48 | lm loss: 6.083719E+00 | loss scale: 32768.0 | grad norm: 5.345 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      320/    1200 | consumed samples:        15360 | elapsed time per iteration (ms): 976.0 | learning rate: 4.750E-06 | global batch size:    48 | lm loss: 6.232248E+00 | loss scale: 32768.0 | grad norm: 6.141 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      321/    1200 | consumed samples:        15408 | elapsed time per iteration (ms): 1089.8 | learning rate: 4.766E-06 | global batch size:    48 | lm loss: 6.184463E+00 | loss scale: 32768.0 | grad norm: 5.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      322/    1200 | consumed samples:        15456 | elapsed time per iteration (ms): 984.9 | learning rate: 4.782E-06 | global batch size:    48 | lm loss: 6.097726E+00 | loss scale: 32768.0 | grad norm: 5.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      323/    1200 | consumed samples:        15504 | elapsed time per iteration (ms): 987.3 | learning rate: 4.797E-06 | global batch size:    48 | lm loss: 6.089574E+00 | loss scale: 32768.0 | grad norm: 5.078 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      324/    1200 | consumed samples:        15552 | elapsed time per iteration (ms): 1313.4 | learning rate: 4.813E-06 | global batch size:    48 | lm loss: 6.086013E+00 | loss scale: 32768.0 | grad norm: 4.980 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      325/    1200 | consumed samples:        15600 | elapsed time per iteration (ms): 1053.8 | learning rate: 4.829E-06 | global batch size:    48 | lm loss: 6.251140E+00 | loss scale: 32768.0 | grad norm: 5.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      326/    1200 | consumed samples:        15648 | elapsed time per iteration (ms): 1036.4 | learning rate: 4.844E-06 | global batch size:    48 | lm loss: 6.043700E+00 | loss scale: 32768.0 | grad norm: 4.601 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      327/    1200 | consumed samples:        15696 | elapsed time per iteration (ms): 1110.7 | learning rate: 4.860E-06 | global batch size:    48 | lm loss: 6.097211E+00 | loss scale: 32768.0 | grad norm: 5.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      328/    1200 | consumed samples:        15744 | elapsed time per iteration (ms): 1300.0 | learning rate: 4.876E-06 | global batch size:    48 | lm loss: 6.127906E+00 | loss scale: 32768.0 | grad norm: 4.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      329/    1200 | consumed samples:        15792 | elapsed time per iteration (ms): 985.2 | learning rate: 4.892E-06 | global batch size:    48 | lm loss: 6.105900E+00 | loss scale: 32768.0 | grad norm: 5.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      330/    1200 | consumed samples:        15840 | elapsed time per iteration (ms): 969.9 | learning rate: 4.907E-06 | global batch size:    48 | lm loss: 6.073625E+00 | loss scale: 32768.0 | grad norm: 4.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      331/    1200 | consumed samples:        15888 | elapsed time per iteration (ms): 1119.0 | learning rate: 4.923E-06 | global batch size:    48 | lm loss: 6.078196E+00 | loss scale: 32768.0 | grad norm: 5.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      332/    1200 | consumed samples:        15936 | elapsed time per iteration (ms): 1079.6 | learning rate: 4.939E-06 | global batch size:    48 | lm loss: 6.080494E+00 | loss scale: 32768.0 | grad norm: 5.246 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      333/    1200 | consumed samples:        15984 | elapsed time per iteration (ms): 1238.8 | learning rate: 4.955E-06 | global batch size:    48 | lm loss: 6.130201E+00 | loss scale: 32768.0 | grad norm: 4.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      334/    1200 | consumed samples:        16032 | elapsed time per iteration (ms): 1048.1 | learning rate: 4.970E-06 | global batch size:    48 | lm loss: 6.097051E+00 | loss scale: 32768.0 | grad norm: 4.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      335/    1200 | consumed samples:        16080 | elapsed time per iteration (ms): 982.8 | learning rate: 4.986E-06 | global batch size:    48 | lm loss: 6.000076E+00 | loss scale: 32768.0 | grad norm: 5.712 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      336/    1200 | consumed samples:        16128 | elapsed time per iteration (ms): 1378.2 | learning rate: 5.002E-06 | global batch size:    48 | lm loss: 6.162050E+00 | loss scale: 32768.0 | grad norm: 4.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      337/    1200 | consumed samples:        16176 | elapsed time per iteration (ms): 1115.2 | learning rate: 5.017E-06 | global batch size:    48 | lm loss: 6.149734E+00 | loss scale: 32768.0 | grad norm: 4.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      338/    1200 | consumed samples:        16224 | elapsed time per iteration (ms): 981.4 | learning rate: 5.033E-06 | global batch size:    48 | lm loss: 6.127064E+00 | loss scale: 32768.0 | grad norm: 7.126 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      339/    1200 | consumed samples:        16272 | elapsed time per iteration (ms): 1111.3 | learning rate: 5.049E-06 | global batch size:    48 | lm loss: 6.195920E+00 | loss scale: 32768.0 | grad norm: 5.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      340/    1200 | consumed samples:        16320 | elapsed time per iteration (ms): 1242.8 | learning rate: 5.065E-06 | global batch size:    48 | lm loss: 6.144678E+00 | loss scale: 32768.0 | grad norm: 5.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      341/    1200 | consumed samples:        16368 | elapsed time per iteration (ms): 4361.9 | learning rate: 5.080E-06 | global batch size:    48 | lm loss: 6.202559E+00 | loss scale: 32768.0 | grad norm: 5.290 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      342/    1200 | consumed samples:        16416 | elapsed time per iteration (ms): 4339.7 | learning rate: 5.096E-06 | global batch size:    48 | lm loss: 6.192995E+00 | loss scale: 32768.0 | grad norm: 5.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      343/    1200 | consumed samples:        16464 | elapsed time per iteration (ms): 4383.0 | learning rate: 5.112E-06 | global batch size:    48 | lm loss: 6.157960E+00 | loss scale: 32768.0 | grad norm: 4.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      344/    1200 | consumed samples:        16512 | elapsed time per iteration (ms): 4380.8 | learning rate: 5.128E-06 | global batch size:    48 | lm loss: 6.151889E+00 | loss scale: 32768.0 | grad norm: 5.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      345/    1200 | consumed samples:        16560 | elapsed time per iteration (ms): 4389.7 | learning rate: 5.143E-06 | global batch size:    48 | lm loss: 6.119245E+00 | loss scale: 32768.0 | grad norm: 5.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      346/    1200 | consumed samples:        16608 | elapsed time per iteration (ms): 4377.9 | learning rate: 5.159E-06 | global batch size:    48 | lm loss: 6.038322E+00 | loss scale: 32768.0 | grad norm: 6.319 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      347/    1200 | consumed samples:        16656 | elapsed time per iteration (ms): 4399.8 | learning rate: 5.175E-06 | global batch size:    48 | lm loss: 6.185927E+00 | loss scale: 32768.0 | grad norm: 6.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      348/    1200 | consumed samples:        16704 | elapsed time per iteration (ms): 4470.5 | learning rate: 5.190E-06 | global batch size:    48 | lm loss: 6.166860E+00 | loss scale: 32768.0 | grad norm: 5.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      349/    1200 | consumed samples:        16752 | elapsed time per iteration (ms): 4380.0 | learning rate: 5.206E-06 | global batch size:    48 | lm loss: 6.084613E+00 | loss scale: 32768.0 | grad norm: 5.373 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      350/    1200 | consumed samples:        16800 | elapsed time per iteration (ms): 4380.1 | learning rate: 5.222E-06 | global batch size:    48 | lm loss: 6.136848E+00 | loss scale: 32768.0 | grad norm: 5.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      351/    1200 | consumed samples:        16848 | elapsed time per iteration (ms): 4377.0 | learning rate: 5.238E-06 | global batch size:    48 | lm loss: 6.070439E+00 | loss scale: 32768.0 | grad norm: 5.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      352/    1200 | consumed samples:        16896 | elapsed time per iteration (ms): 4412.1 | learning rate: 5.253E-06 | global batch size:    48 | lm loss: 6.165811E+00 | loss scale: 32768.0 | grad norm: 6.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      353/    1200 | consumed samples:        16944 | elapsed time per iteration (ms): 4386.9 | learning rate: 5.269E-06 | global batch size:    48 | lm loss: 6.136208E+00 | loss scale: 32768.0 | grad norm: 5.564 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      354/    1200 | consumed samples:        16992 | elapsed time per iteration (ms): 4392.7 | learning rate: 5.285E-06 | global batch size:    48 | lm loss: 6.009424E+00 | loss scale: 32768.0 | grad norm: 4.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      355/    1200 | consumed samples:        17040 | elapsed time per iteration (ms): 4469.3 | learning rate: 5.301E-06 | global batch size:    48 | lm loss: 6.054262E+00 | loss scale: 32768.0 | grad norm: 5.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      356/    1200 | consumed samples:        17088 | elapsed time per iteration (ms): 4386.4 | learning rate: 5.316E-06 | global batch size:    48 | lm loss: 6.012886E+00 | loss scale: 32768.0 | grad norm: 4.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      357/    1200 | consumed samples:        17136 | elapsed time per iteration (ms): 4382.4 | learning rate: 5.332E-06 | global batch size:    48 | lm loss: 5.987518E+00 | loss scale: 32768.0 | grad norm: 4.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      358/    1200 | consumed samples:        17184 | elapsed time per iteration (ms): 4383.9 | learning rate: 5.348E-06 | global batch size:    48 | lm loss: 6.014417E+00 | loss scale: 32768.0 | grad norm: 4.844 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      359/    1200 | consumed samples:        17232 | elapsed time per iteration (ms): 4373.8 | learning rate: 5.363E-06 | global batch size:    48 | lm loss: 6.093796E+00 | loss scale: 32768.0 | grad norm: 4.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      360/    1200 | consumed samples:        17280 | elapsed time per iteration (ms): 4467.8 | learning rate: 5.379E-06 | global batch size:    48 | lm loss: 6.113615E+00 | loss scale: 32768.0 | grad norm: 4.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      361/    1200 | consumed samples:        17328 | elapsed time per iteration (ms): 4385.3 | learning rate: 5.395E-06 | global batch size:    48 | lm loss: 5.971406E+00 | loss scale: 32768.0 | grad norm: 4.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      362/    1200 | consumed samples:        17376 | elapsed time per iteration (ms): 4376.6 | learning rate: 5.411E-06 | global batch size:    48 | lm loss: 5.973264E+00 | loss scale: 32768.0 | grad norm: 5.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      363/    1200 | consumed samples:        17424 | elapsed time per iteration (ms): 4383.0 | learning rate: 5.426E-06 | global batch size:    48 | lm loss: 6.052023E+00 | loss scale: 32768.0 | grad norm: 5.197 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      364/    1200 | consumed samples:        17472 | elapsed time per iteration (ms): 4498.5 | learning rate: 5.442E-06 | global batch size:    48 | lm loss: 6.017747E+00 | loss scale: 32768.0 | grad norm: 4.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      365/    1200 | consumed samples:        17520 | elapsed time per iteration (ms): 4383.2 | learning rate: 5.458E-06 | global batch size:    48 | lm loss: 6.055700E+00 | loss scale: 32768.0 | grad norm: 4.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      366/    1200 | consumed samples:        17568 | elapsed time per iteration (ms): 4388.7 | learning rate: 5.474E-06 | global batch size:    48 | lm loss: 6.058681E+00 | loss scale: 32768.0 | grad norm: 6.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      367/    1200 | consumed samples:        17616 | elapsed time per iteration (ms): 4379.6 | learning rate: 5.489E-06 | global batch size:    48 | lm loss: 6.029569E+00 | loss scale: 32768.0 | grad norm: 4.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      368/    1200 | consumed samples:        17664 | elapsed time per iteration (ms): 4378.3 | learning rate: 5.505E-06 | global batch size:    48 | lm loss: 6.004359E+00 | loss scale: 32768.0 | grad norm: 5.543 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      369/    1200 | consumed samples:        17712 | elapsed time per iteration (ms): 4382.1 | learning rate: 5.521E-06 | global batch size:    48 | lm loss: 6.115947E+00 | loss scale: 32768.0 | grad norm: 5.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      370/    1200 | consumed samples:        17760 | elapsed time per iteration (ms): 4378.2 | learning rate: 5.536E-06 | global batch size:    48 | lm loss: 6.196143E+00 | loss scale: 32768.0 | grad norm: 6.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      371/    1200 | consumed samples:        17808 | elapsed time per iteration (ms): 4463.5 | learning rate: 5.552E-06 | global batch size:    48 | lm loss: 6.002841E+00 | loss scale: 32768.0 | grad norm: 5.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      372/    1200 | consumed samples:        17856 | elapsed time per iteration (ms): 4469.5 | learning rate: 5.568E-06 | global batch size:    48 | lm loss: 5.997204E+00 | loss scale: 32768.0 | grad norm: 5.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      373/    1200 | consumed samples:        17904 | elapsed time per iteration (ms): 4384.6 | learning rate: 5.584E-06 | global batch size:    48 | lm loss: 5.960422E+00 | loss scale: 32768.0 | grad norm: 4.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      374/    1200 | consumed samples:        17952 | elapsed time per iteration (ms): 4373.2 | learning rate: 5.599E-06 | global batch size:    48 | lm loss: 6.083179E+00 | loss scale: 32768.0 | grad norm: 4.564 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      375/    1200 | consumed samples:        18000 | elapsed time per iteration (ms): 4378.9 | learning rate: 5.615E-06 | global batch size:    48 | lm loss: 6.097240E+00 | loss scale: 32768.0 | grad norm: 4.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      376/    1200 | consumed samples:        18048 | elapsed time per iteration (ms): 4408.5 | learning rate: 5.631E-06 | global batch size:    48 | lm loss: 6.144582E+00 | loss scale: 32768.0 | grad norm: 5.305 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      377/    1200 | consumed samples:        18096 | elapsed time per iteration (ms): 4393.5 | learning rate: 5.647E-06 | global batch size:    48 | lm loss: 5.929817E+00 | loss scale: 32768.0 | grad norm: 4.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      378/    1200 | consumed samples:        18144 | elapsed time per iteration (ms): 4400.7 | learning rate: 5.662E-06 | global batch size:    48 | lm loss: 6.032630E+00 | loss scale: 32768.0 | grad norm: 4.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      379/    1200 | consumed samples:        18192 | elapsed time per iteration (ms): 4380.1 | learning rate: 5.678E-06 | global batch size:    48 | lm loss: 5.963116E+00 | loss scale: 32768.0 | grad norm: 4.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      380/    1200 | consumed samples:        18240 | elapsed time per iteration (ms): 4378.2 | learning rate: 5.694E-06 | global batch size:    48 | lm loss: 6.042372E+00 | loss scale: 32768.0 | grad norm: 4.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      381/    1200 | consumed samples:        18288 | elapsed time per iteration (ms): 4379.2 | learning rate: 5.710E-06 | global batch size:    48 | lm loss: 5.941941E+00 | loss scale: 32768.0 | grad norm: 4.257 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      382/    1200 | consumed samples:        18336 | elapsed time per iteration (ms): 4452.9 | learning rate: 5.725E-06 | global batch size:    48 | lm loss: 6.062200E+00 | loss scale: 32768.0 | grad norm: 4.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      383/    1200 | consumed samples:        18384 | elapsed time per iteration (ms): 4380.3 | learning rate: 5.741E-06 | global batch size:    48 | lm loss: 5.962650E+00 | loss scale: 32768.0 | grad norm: 5.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      384/    1200 | consumed samples:        18432 | elapsed time per iteration (ms): 4471.9 | learning rate: 5.757E-06 | global batch size:    48 | lm loss: 6.001786E+00 | loss scale: 32768.0 | grad norm: 4.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      385/    1200 | consumed samples:        18480 | elapsed time per iteration (ms): 4388.4 | learning rate: 5.772E-06 | global batch size:    48 | lm loss: 6.085783E+00 | loss scale: 32768.0 | grad norm: 4.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      386/    1200 | consumed samples:        18528 | elapsed time per iteration (ms): 4465.9 | learning rate: 5.788E-06 | global batch size:    48 | lm loss: 6.094405E+00 | loss scale: 32768.0 | grad norm: 4.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      387/    1200 | consumed samples:        18576 | elapsed time per iteration (ms): 4385.7 | learning rate: 5.804E-06 | global batch size:    48 | lm loss: 6.005422E+00 | loss scale: 32768.0 | grad norm: 4.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      388/    1200 | consumed samples:        18624 | elapsed time per iteration (ms): 4413.8 | learning rate: 5.820E-06 | global batch size:    48 | lm loss: 5.938056E+00 | loss scale: 32768.0 | grad norm: 4.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      389/    1200 | consumed samples:        18672 | elapsed time per iteration (ms): 4387.7 | learning rate: 5.835E-06 | global batch size:    48 | lm loss: 6.004388E+00 | loss scale: 32768.0 | grad norm: 4.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      390/    1200 | consumed samples:        18720 | elapsed time per iteration (ms): 4374.7 | learning rate: 5.851E-06 | global batch size:    48 | lm loss: 5.959002E+00 | loss scale: 32768.0 | grad norm: 5.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      391/    1200 | consumed samples:        18768 | elapsed time per iteration (ms): 4382.0 | learning rate: 5.867E-06 | global batch size:    48 | lm loss: 5.976360E+00 | loss scale: 32768.0 | grad norm: 4.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      392/    1200 | consumed samples:        18816 | elapsed time per iteration (ms): 4385.0 | learning rate: 5.883E-06 | global batch size:    48 | lm loss: 5.939493E+00 | loss scale: 32768.0 | grad norm: 4.298 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      393/    1200 | consumed samples:        18864 | elapsed time per iteration (ms): 4378.2 | learning rate: 5.898E-06 | global batch size:    48 | lm loss: 5.950640E+00 | loss scale: 32768.0 | grad norm: 4.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      394/    1200 | consumed samples:        18912 | elapsed time per iteration (ms): 4387.2 | learning rate: 5.914E-06 | global batch size:    48 | lm loss: 6.034647E+00 | loss scale: 32768.0 | grad norm: 4.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      395/    1200 | consumed samples:        18960 | elapsed time per iteration (ms): 4465.0 | learning rate: 5.930E-06 | global batch size:    48 | lm loss: 5.980814E+00 | loss scale: 32768.0 | grad norm: 4.734 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      396/    1200 | consumed samples:        19008 | elapsed time per iteration (ms): 4474.9 | learning rate: 5.945E-06 | global batch size:    48 | lm loss: 6.052096E+00 | loss scale: 32768.0 | grad norm: 4.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      397/    1200 | consumed samples:        19056 | elapsed time per iteration (ms): 4395.0 | learning rate: 5.961E-06 | global batch size:    48 | lm loss: 5.909225E+00 | loss scale: 32768.0 | grad norm: 4.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      398/    1200 | consumed samples:        19104 | elapsed time per iteration (ms): 4387.3 | learning rate: 5.977E-06 | global batch size:    48 | lm loss: 6.014728E+00 | loss scale: 32768.0 | grad norm: 4.557 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      399/    1200 | consumed samples:        19152 | elapsed time per iteration (ms): 4391.0 | learning rate: 5.993E-06 | global batch size:    48 | lm loss: 5.974349E+00 | loss scale: 32768.0 | grad norm: 5.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      400/    1200 | consumed samples:        19200 | elapsed time per iteration (ms): 4550.9 | learning rate: 6.008E-06 | global batch size:    48 | lm loss: 5.969717E+00 | loss scale: 32768.0 | grad norm: 4.597 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      401/    1200 | consumed samples:        19248 | elapsed time per iteration (ms): 4382.4 | learning rate: 6.024E-06 | global batch size:    48 | lm loss: 5.925951E+00 | loss scale: 32768.0 | grad norm: 4.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      402/    1200 | consumed samples:        19296 | elapsed time per iteration (ms): 4467.4 | learning rate: 6.040E-06 | global batch size:    48 | lm loss: 5.972789E+00 | loss scale: 32768.0 | grad norm: 4.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      403/    1200 | consumed samples:        19344 | elapsed time per iteration (ms): 4380.6 | learning rate: 6.056E-06 | global batch size:    48 | lm loss: 6.029511E+00 | loss scale: 32768.0 | grad norm: 4.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      404/    1200 | consumed samples:        19392 | elapsed time per iteration (ms): 4377.2 | learning rate: 6.071E-06 | global batch size:    48 | lm loss: 6.018762E+00 | loss scale: 32768.0 | grad norm: 4.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      405/    1200 | consumed samples:        19440 | elapsed time per iteration (ms): 4377.1 | learning rate: 6.087E-06 | global batch size:    48 | lm loss: 5.991366E+00 | loss scale: 32768.0 | grad norm: 4.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      406/    1200 | consumed samples:        19488 | elapsed time per iteration (ms): 4382.6 | learning rate: 6.103E-06 | global batch size:    48 | lm loss: 5.987656E+00 | loss scale: 32768.0 | grad norm: 4.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      407/    1200 | consumed samples:        19536 | elapsed time per iteration (ms): 4386.1 | learning rate: 6.118E-06 | global batch size:    48 | lm loss: 6.062625E+00 | loss scale: 32768.0 | grad norm: 5.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      408/    1200 | consumed samples:        19584 | elapsed time per iteration (ms): 4467.9 | learning rate: 6.134E-06 | global batch size:    48 | lm loss: 6.066355E+00 | loss scale: 32768.0 | grad norm: 5.240 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      409/    1200 | consumed samples:        19632 | elapsed time per iteration (ms): 4394.1 | learning rate: 6.150E-06 | global batch size:    48 | lm loss: 5.981590E+00 | loss scale: 32768.0 | grad norm: 4.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      410/    1200 | consumed samples:        19680 | elapsed time per iteration (ms): 4382.2 | learning rate: 6.166E-06 | global batch size:    48 | lm loss: 5.860420E+00 | loss scale: 32768.0 | grad norm: 4.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      411/    1200 | consumed samples:        19728 | elapsed time per iteration (ms): 3296.5 | learning rate: 6.181E-06 | global batch size:    48 | lm loss: 5.994730E+00 | loss scale: 32768.0 | grad norm: 5.201 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      412/    1200 | consumed samples:        19776 | elapsed time per iteration (ms): 1095.9 | learning rate: 6.197E-06 | global batch size:    48 | lm loss: 5.948995E+00 | loss scale: 32768.0 | grad norm: 4.192 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      413/    1200 | consumed samples:        19824 | elapsed time per iteration (ms): 976.9 | learning rate: 6.213E-06 | global batch size:    48 | lm loss: 5.910872E+00 | loss scale: 32768.0 | grad norm: 4.597 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      414/    1200 | consumed samples:        19872 | elapsed time per iteration (ms): 1126.5 | learning rate: 6.229E-06 | global batch size:    48 | lm loss: 6.058679E+00 | loss scale: 32768.0 | grad norm: 4.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      415/    1200 | consumed samples:        19920 | elapsed time per iteration (ms): 979.5 | learning rate: 6.244E-06 | global batch size:    48 | lm loss: 5.925699E+00 | loss scale: 32768.0 | grad norm: 4.176 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      416/    1200 | consumed samples:        19968 | elapsed time per iteration (ms): 984.3 | learning rate: 6.260E-06 | global batch size:    48 | lm loss: 5.960404E+00 | loss scale: 32768.0 | grad norm: 4.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      417/    1200 | consumed samples:        20016 | elapsed time per iteration (ms): 1250.7 | learning rate: 6.276E-06 | global batch size:    48 | lm loss: 5.890096E+00 | loss scale: 32768.0 | grad norm: 4.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      418/    1200 | consumed samples:        20064 | elapsed time per iteration (ms): 1095.3 | learning rate: 6.291E-06 | global batch size:    48 | lm loss: 5.963785E+00 | loss scale: 32768.0 | grad norm: 4.318 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      419/    1200 | consumed samples:        20112 | elapsed time per iteration (ms): 983.3 | learning rate: 6.307E-06 | global batch size:    48 | lm loss: 5.997213E+00 | loss scale: 32768.0 | grad norm: 4.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      420/    1200 | consumed samples:        20160 | elapsed time per iteration (ms): 1092.7 | learning rate: 6.323E-06 | global batch size:    48 | lm loss: 5.989921E+00 | loss scale: 32768.0 | grad norm: 4.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      421/    1200 | consumed samples:        20208 | elapsed time per iteration (ms): 985.9 | learning rate: 6.339E-06 | global batch size:    48 | lm loss: 6.069702E+00 | loss scale: 32768.0 | grad norm: 4.857 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      422/    1200 | consumed samples:        20256 | elapsed time per iteration (ms): 1189.1 | learning rate: 6.354E-06 | global batch size:    48 | lm loss: 5.802417E+00 | loss scale: 32768.0 | grad norm: 4.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      423/    1200 | consumed samples:        20304 | elapsed time per iteration (ms): 1043.7 | learning rate: 6.370E-06 | global batch size:    48 | lm loss: 5.944101E+00 | loss scale: 32768.0 | grad norm: 4.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      424/    1200 | consumed samples:        20352 | elapsed time per iteration (ms): 1110.4 | learning rate: 6.386E-06 | global batch size:    48 | lm loss: 5.907079E+00 | loss scale: 32768.0 | grad norm: 4.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      425/    1200 | consumed samples:        20400 | elapsed time per iteration (ms): 1242.9 | learning rate: 6.402E-06 | global batch size:    48 | lm loss: 5.921928E+00 | loss scale: 32768.0 | grad norm: 4.351 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      426/    1200 | consumed samples:        20448 | elapsed time per iteration (ms): 1248.6 | learning rate: 6.417E-06 | global batch size:    48 | lm loss: 6.022528E+00 | loss scale: 32768.0 | grad norm: 4.239 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      427/    1200 | consumed samples:        20496 | elapsed time per iteration (ms): 1102.2 | learning rate: 6.433E-06 | global batch size:    48 | lm loss: 5.985866E+00 | loss scale: 32768.0 | grad norm: 4.259 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      428/    1200 | consumed samples:        20544 | elapsed time per iteration (ms): 1061.0 | learning rate: 6.449E-06 | global batch size:    48 | lm loss: 6.072514E+00 | loss scale: 32768.0 | grad norm: 4.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      429/    1200 | consumed samples:        20592 | elapsed time per iteration (ms): 985.9 | learning rate: 6.464E-06 | global batch size:    48 | lm loss: 5.980120E+00 | loss scale: 32768.0 | grad norm: 4.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      430/    1200 | consumed samples:        20640 | elapsed time per iteration (ms): 1055.8 | learning rate: 6.480E-06 | global batch size:    48 | lm loss: 5.867067E+00 | loss scale: 32768.0 | grad norm: 3.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      431/    1200 | consumed samples:        20688 | elapsed time per iteration (ms): 1045.5 | learning rate: 6.496E-06 | global batch size:    48 | lm loss: 5.963236E+00 | loss scale: 32768.0 | grad norm: 4.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      432/    1200 | consumed samples:        20736 | elapsed time per iteration (ms): 1159.2 | learning rate: 6.512E-06 | global batch size:    48 | lm loss: 5.984470E+00 | loss scale: 32768.0 | grad norm: 4.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      433/    1200 | consumed samples:        20784 | elapsed time per iteration (ms): 1116.8 | learning rate: 6.527E-06 | global batch size:    48 | lm loss: 5.808898E+00 | loss scale: 32768.0 | grad norm: 4.128 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      434/    1200 | consumed samples:        20832 | elapsed time per iteration (ms): 986.2 | learning rate: 6.543E-06 | global batch size:    48 | lm loss: 6.007905E+00 | loss scale: 32768.0 | grad norm: 4.189 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      435/    1200 | consumed samples:        20880 | elapsed time per iteration (ms): 1237.0 | learning rate: 6.559E-06 | global batch size:    48 | lm loss: 5.916819E+00 | loss scale: 32768.0 | grad norm: 3.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      436/    1200 | consumed samples:        20928 | elapsed time per iteration (ms): 1243.1 | learning rate: 6.575E-06 | global batch size:    48 | lm loss: 5.932224E+00 | loss scale: 32768.0 | grad norm: 4.369 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      437/    1200 | consumed samples:        20976 | elapsed time per iteration (ms): 991.3 | learning rate: 6.590E-06 | global batch size:    48 | lm loss: 5.886339E+00 | loss scale: 32768.0 | grad norm: 3.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      438/    1200 | consumed samples:        21024 | elapsed time per iteration (ms): 1065.5 | learning rate: 6.606E-06 | global batch size:    48 | lm loss: 5.926371E+00 | loss scale: 32768.0 | grad norm: 4.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      439/    1200 | consumed samples:        21072 | elapsed time per iteration (ms): 1087.3 | learning rate: 6.622E-06 | global batch size:    48 | lm loss: 5.912055E+00 | loss scale: 32768.0 | grad norm: 4.240 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      440/    1200 | consumed samples:        21120 | elapsed time per iteration (ms): 1098.7 | learning rate: 6.638E-06 | global batch size:    48 | lm loss: 5.966884E+00 | loss scale: 32768.0 | grad norm: 4.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      441/    1200 | consumed samples:        21168 | elapsed time per iteration (ms): 1052.7 | learning rate: 6.653E-06 | global batch size:    48 | lm loss: 6.054195E+00 | loss scale: 32768.0 | grad norm: 4.696 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      442/    1200 | consumed samples:        21216 | elapsed time per iteration (ms): 986.3 | learning rate: 6.669E-06 | global batch size:    48 | lm loss: 5.986988E+00 | loss scale: 32768.0 | grad norm: 4.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      443/    1200 | consumed samples:        21264 | elapsed time per iteration (ms): 1219.9 | learning rate: 6.685E-06 | global batch size:    48 | lm loss: 5.822721E+00 | loss scale: 32768.0 | grad norm: 4.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      444/    1200 | consumed samples:        21312 | elapsed time per iteration (ms): 1249.1 | learning rate: 6.700E-06 | global batch size:    48 | lm loss: 5.939214E+00 | loss scale: 32768.0 | grad norm: 4.224 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      445/    1200 | consumed samples:        21360 | elapsed time per iteration (ms): 1101.4 | learning rate: 6.716E-06 | global batch size:    48 | lm loss: 6.033861E+00 | loss scale: 32768.0 | grad norm: 4.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      446/    1200 | consumed samples:        21408 | elapsed time per iteration (ms): 1073.4 | learning rate: 6.732E-06 | global batch size:    48 | lm loss: 5.943599E+00 | loss scale: 32768.0 | grad norm: 4.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      447/    1200 | consumed samples:        21456 | elapsed time per iteration (ms): 985.7 | learning rate: 6.748E-06 | global batch size:    48 | lm loss: 6.010215E+00 | loss scale: 32768.0 | grad norm: 4.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      448/    1200 | consumed samples:        21504 | elapsed time per iteration (ms): 1248.4 | learning rate: 6.763E-06 | global batch size:    48 | lm loss: 5.899082E+00 | loss scale: 32768.0 | grad norm: 3.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      449/    1200 | consumed samples:        21552 | elapsed time per iteration (ms): 982.5 | learning rate: 6.779E-06 | global batch size:    48 | lm loss: 5.917405E+00 | loss scale: 32768.0 | grad norm: 4.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      450/    1200 | consumed samples:        21600 | elapsed time per iteration (ms): 1168.1 | learning rate: 6.795E-06 | global batch size:    48 | lm loss: 5.948549E+00 | loss scale: 32768.0 | grad norm: 4.290 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      451/    1200 | consumed samples:        21648 | elapsed time per iteration (ms): 1959.9 | learning rate: 6.811E-06 | global batch size:    48 | lm loss: 5.872858E+00 | loss scale: 32768.0 | grad norm: 3.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      452/    1200 | consumed samples:        21696 | elapsed time per iteration (ms): 3750.5 | learning rate: 6.826E-06 | global batch size:    48 | lm loss: 5.968187E+00 | loss scale: 32768.0 | grad norm: 3.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      453/    1200 | consumed samples:        21744 | elapsed time per iteration (ms): 3821.2 | learning rate: 6.842E-06 | global batch size:    48 | lm loss: 5.836386E+00 | loss scale: 32768.0 | grad norm: 3.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      454/    1200 | consumed samples:        21792 | elapsed time per iteration (ms): 3809.0 | learning rate: 6.858E-06 | global batch size:    48 | lm loss: 5.937660E+00 | loss scale: 32768.0 | grad norm: 4.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      455/    1200 | consumed samples:        21840 | elapsed time per iteration (ms): 3750.6 | learning rate: 6.873E-06 | global batch size:    48 | lm loss: 5.885617E+00 | loss scale: 32768.0 | grad norm: 3.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      456/    1200 | consumed samples:        21888 | elapsed time per iteration (ms): 3746.4 | learning rate: 6.889E-06 | global batch size:    48 | lm loss: 6.089666E+00 | loss scale: 32768.0 | grad norm: 3.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      457/    1200 | consumed samples:        21936 | elapsed time per iteration (ms): 3752.9 | learning rate: 6.905E-06 | global batch size:    48 | lm loss: 5.911352E+00 | loss scale: 32768.0 | grad norm: 3.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      458/    1200 | consumed samples:        21984 | elapsed time per iteration (ms): 3754.3 | learning rate: 6.921E-06 | global batch size:    48 | lm loss: 5.776723E+00 | loss scale: 32768.0 | grad norm: 3.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      459/    1200 | consumed samples:        22032 | elapsed time per iteration (ms): 3764.1 | learning rate: 6.936E-06 | global batch size:    48 | lm loss: 5.871396E+00 | loss scale: 32768.0 | grad norm: 3.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      460/    1200 | consumed samples:        22080 | elapsed time per iteration (ms): 3757.7 | learning rate: 6.952E-06 | global batch size:    48 | lm loss: 5.938556E+00 | loss scale: 32768.0 | grad norm: 3.822 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      461/    1200 | consumed samples:        22128 | elapsed time per iteration (ms): 3752.5 | learning rate: 6.968E-06 | global batch size:    48 | lm loss: 5.824577E+00 | loss scale: 32768.0 | grad norm: 3.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      462/    1200 | consumed samples:        22176 | elapsed time per iteration (ms): 3815.9 | learning rate: 6.984E-06 | global batch size:    48 | lm loss: 5.896198E+00 | loss scale: 32768.0 | grad norm: 4.196 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      463/    1200 | consumed samples:        22224 | elapsed time per iteration (ms): 3815.3 | learning rate: 6.999E-06 | global batch size:    48 | lm loss: 5.858089E+00 | loss scale: 32768.0 | grad norm: 4.559 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      464/    1200 | consumed samples:        22272 | elapsed time per iteration (ms): 3747.2 | learning rate: 7.015E-06 | global batch size:    48 | lm loss: 5.939968E+00 | loss scale: 32768.0 | grad norm: 4.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      465/    1200 | consumed samples:        22320 | elapsed time per iteration (ms): 3756.3 | learning rate: 7.031E-06 | global batch size:    48 | lm loss: 5.873957E+00 | loss scale: 32768.0 | grad norm: 4.292 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      466/    1200 | consumed samples:        22368 | elapsed time per iteration (ms): 3748.3 | learning rate: 7.046E-06 | global batch size:    48 | lm loss: 5.876163E+00 | loss scale: 32768.0 | grad norm: 4.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      467/    1200 | consumed samples:        22416 | elapsed time per iteration (ms): 3751.9 | learning rate: 7.062E-06 | global batch size:    48 | lm loss: 5.886693E+00 | loss scale: 32768.0 | grad norm: 3.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      468/    1200 | consumed samples:        22464 | elapsed time per iteration (ms): 3762.9 | learning rate: 7.078E-06 | global batch size:    48 | lm loss: 5.900009E+00 | loss scale: 32768.0 | grad norm: 3.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      469/    1200 | consumed samples:        22512 | elapsed time per iteration (ms): 3772.0 | learning rate: 7.094E-06 | global batch size:    48 | lm loss: 5.871544E+00 | loss scale: 32768.0 | grad norm: 3.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      470/    1200 | consumed samples:        22560 | elapsed time per iteration (ms): 3751.7 | learning rate: 7.109E-06 | global batch size:    48 | lm loss: 5.930193E+00 | loss scale: 32768.0 | grad norm: 3.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      471/    1200 | consumed samples:        22608 | elapsed time per iteration (ms): 3918.9 | learning rate: 7.125E-06 | global batch size:    48 | lm loss: 5.786636E+00 | loss scale: 32768.0 | grad norm: 3.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      472/    1200 | consumed samples:        22656 | elapsed time per iteration (ms): 3814.4 | learning rate: 7.141E-06 | global batch size:    48 | lm loss: 5.896511E+00 | loss scale: 32768.0 | grad norm: 4.108 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      473/    1200 | consumed samples:        22704 | elapsed time per iteration (ms): 3754.1 | learning rate: 7.157E-06 | global batch size:    48 | lm loss: 5.926311E+00 | loss scale: 32768.0 | grad norm: 3.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      474/    1200 | consumed samples:        22752 | elapsed time per iteration (ms): 3752.6 | learning rate: 7.172E-06 | global batch size:    48 | lm loss: 5.802817E+00 | loss scale: 32768.0 | grad norm: 3.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      475/    1200 | consumed samples:        22800 | elapsed time per iteration (ms): 3755.1 | learning rate: 7.188E-06 | global batch size:    48 | lm loss: 5.887945E+00 | loss scale: 32768.0 | grad norm: 4.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      476/    1200 | consumed samples:        22848 | elapsed time per iteration (ms): 3749.2 | learning rate: 7.204E-06 | global batch size:    48 | lm loss: 5.864091E+00 | loss scale: 32768.0 | grad norm: 3.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      477/    1200 | consumed samples:        22896 | elapsed time per iteration (ms): 3777.7 | learning rate: 7.219E-06 | global batch size:    48 | lm loss: 5.892414E+00 | loss scale: 32768.0 | grad norm: 3.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      478/    1200 | consumed samples:        22944 | elapsed time per iteration (ms): 3751.4 | learning rate: 7.235E-06 | global batch size:    48 | lm loss: 5.907831E+00 | loss scale: 32768.0 | grad norm: 3.761 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      479/    1200 | consumed samples:        22992 | elapsed time per iteration (ms): 3750.9 | learning rate: 7.251E-06 | global batch size:    48 | lm loss: 5.948927E+00 | loss scale: 32768.0 | grad norm: 3.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      480/    1200 | consumed samples:        23040 | elapsed time per iteration (ms): 3806.7 | learning rate: 7.267E-06 | global batch size:    48 | lm loss: 5.933782E+00 | loss scale: 32768.0 | grad norm: 3.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      481/    1200 | consumed samples:        23088 | elapsed time per iteration (ms): 3812.6 | learning rate: 7.282E-06 | global batch size:    48 | lm loss: 5.810141E+00 | loss scale: 32768.0 | grad norm: 3.549 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      482/    1200 | consumed samples:        23136 | elapsed time per iteration (ms): 3759.4 | learning rate: 7.298E-06 | global batch size:    48 | lm loss: 5.884779E+00 | loss scale: 32768.0 | grad norm: 3.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      483/    1200 | consumed samples:        23184 | elapsed time per iteration (ms): 3761.0 | learning rate: 7.314E-06 | global batch size:    48 | lm loss: 5.845297E+00 | loss scale: 32768.0 | grad norm: 3.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      484/    1200 | consumed samples:        23232 | elapsed time per iteration (ms): 3751.7 | learning rate: 7.330E-06 | global batch size:    48 | lm loss: 5.929269E+00 | loss scale: 32768.0 | grad norm: 3.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      485/    1200 | consumed samples:        23280 | elapsed time per iteration (ms): 3829.4 | learning rate: 7.345E-06 | global batch size:    48 | lm loss: 5.893785E+00 | loss scale: 32768.0 | grad norm: 3.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      486/    1200 | consumed samples:        23328 | elapsed time per iteration (ms): 3767.9 | learning rate: 7.361E-06 | global batch size:    48 | lm loss: 5.843889E+00 | loss scale: 32768.0 | grad norm: 3.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      487/    1200 | consumed samples:        23376 | elapsed time per iteration (ms): 3756.9 | learning rate: 7.377E-06 | global batch size:    48 | lm loss: 5.921407E+00 | loss scale: 32768.0 | grad norm: 3.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      488/    1200 | consumed samples:        23424 | elapsed time per iteration (ms): 3755.9 | learning rate: 7.392E-06 | global batch size:    48 | lm loss: 5.898641E+00 | loss scale: 32768.0 | grad norm: 4.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      489/    1200 | consumed samples:        23472 | elapsed time per iteration (ms): 3808.2 | learning rate: 7.408E-06 | global batch size:    48 | lm loss: 5.741623E+00 | loss scale: 32768.0 | grad norm: 4.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      490/    1200 | consumed samples:        23520 | elapsed time per iteration (ms): 3817.2 | learning rate: 7.424E-06 | global batch size:    48 | lm loss: 5.826982E+00 | loss scale: 32768.0 | grad norm: 3.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      491/    1200 | consumed samples:        23568 | elapsed time per iteration (ms): 3754.0 | learning rate: 7.440E-06 | global batch size:    48 | lm loss: 5.879169E+00 | loss scale: 32768.0 | grad norm: 3.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      492/    1200 | consumed samples:        23616 | elapsed time per iteration (ms): 3753.2 | learning rate: 7.455E-06 | global batch size:    48 | lm loss: 5.813032E+00 | loss scale: 32768.0 | grad norm: 3.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      493/    1200 | consumed samples:        23664 | elapsed time per iteration (ms): 3753.9 | learning rate: 7.471E-06 | global batch size:    48 | lm loss: 5.918131E+00 | loss scale: 32768.0 | grad norm: 3.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      494/    1200 | consumed samples:        23712 | elapsed time per iteration (ms): 3749.4 | learning rate: 7.487E-06 | global batch size:    48 | lm loss: 5.782257E+00 | loss scale: 32768.0 | grad norm: 3.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      495/    1200 | consumed samples:        23760 | elapsed time per iteration (ms): 3770.7 | learning rate: 7.503E-06 | global batch size:    48 | lm loss: 5.923779E+00 | loss scale: 32768.0 | grad norm: 3.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      496/    1200 | consumed samples:        23808 | elapsed time per iteration (ms): 3749.1 | learning rate: 7.518E-06 | global batch size:    48 | lm loss: 5.918086E+00 | loss scale: 32768.0 | grad norm: 3.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      497/    1200 | consumed samples:        23856 | elapsed time per iteration (ms): 3758.4 | learning rate: 7.534E-06 | global batch size:    48 | lm loss: 5.870809E+00 | loss scale: 32768.0 | grad norm: 3.723 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      498/    1200 | consumed samples:        23904 | elapsed time per iteration (ms): 3817.3 | learning rate: 7.550E-06 | global batch size:    48 | lm loss: 5.943345E+00 | loss scale: 32768.0 | grad norm: 3.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      499/    1200 | consumed samples:        23952 | elapsed time per iteration (ms): 3814.9 | learning rate: 7.565E-06 | global batch size:    48 | lm loss: 5.793485E+00 | loss scale: 32768.0 | grad norm: 3.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      500/    1200 | consumed samples:        24000 | elapsed time per iteration (ms): 3750.0 | learning rate: 7.581E-06 | global batch size:    48 | lm loss: 5.794245E+00 | loss scale: 32768.0 | grad norm: 3.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      501/    1200 | consumed samples:        24048 | elapsed time per iteration (ms): 3756.0 | learning rate: 7.597E-06 | global batch size:    48 | lm loss: 5.815228E+00 | loss scale: 32768.0 | grad norm: 3.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      502/    1200 | consumed samples:        24096 | elapsed time per iteration (ms): 3873.4 | learning rate: 7.613E-06 | global batch size:    48 | lm loss: 5.829610E+00 | loss scale: 32768.0 | grad norm: 4.126 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      503/    1200 | consumed samples:        24144 | elapsed time per iteration (ms): 3770.0 | learning rate: 7.628E-06 | global batch size:    48 | lm loss: 5.881667E+00 | loss scale: 32768.0 | grad norm: 3.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      504/    1200 | consumed samples:        24192 | elapsed time per iteration (ms): 3762.8 | learning rate: 7.644E-06 | global batch size:    48 | lm loss: 5.842396E+00 | loss scale: 32768.0 | grad norm: 3.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      505/    1200 | consumed samples:        24240 | elapsed time per iteration (ms): 3756.7 | learning rate: 7.660E-06 | global batch size:    48 | lm loss: 5.857818E+00 | loss scale: 32768.0 | grad norm: 3.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      506/    1200 | consumed samples:        24288 | elapsed time per iteration (ms): 3751.9 | learning rate: 7.676E-06 | global batch size:    48 | lm loss: 5.743656E+00 | loss scale: 32768.0 | grad norm: 3.545 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      507/    1200 | consumed samples:        24336 | elapsed time per iteration (ms): 3813.3 | learning rate: 7.691E-06 | global batch size:    48 | lm loss: 5.871119E+00 | loss scale: 32768.0 | grad norm: 3.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      508/    1200 | consumed samples:        24384 | elapsed time per iteration (ms): 3813.8 | learning rate: 7.707E-06 | global batch size:    48 | lm loss: 5.906236E+00 | loss scale: 32768.0 | grad norm: 3.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      509/    1200 | consumed samples:        24432 | elapsed time per iteration (ms): 3755.0 | learning rate: 7.723E-06 | global batch size:    48 | lm loss: 5.795324E+00 | loss scale: 32768.0 | grad norm: 3.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      510/    1200 | consumed samples:        24480 | elapsed time per iteration (ms): 3750.9 | learning rate: 7.739E-06 | global batch size:    48 | lm loss: 5.904425E+00 | loss scale: 32768.0 | grad norm: 3.851 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      511/    1200 | consumed samples:        24528 | elapsed time per iteration (ms): 3752.7 | learning rate: 7.754E-06 | global batch size:    48 | lm loss: 5.886121E+00 | loss scale: 32768.0 | grad norm: 4.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      512/    1200 | consumed samples:        24576 | elapsed time per iteration (ms): 3752.6 | learning rate: 7.770E-06 | global batch size:    48 | lm loss: 5.676534E+00 | loss scale: 32768.0 | grad norm: 3.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      513/    1200 | consumed samples:        24624 | elapsed time per iteration (ms): 3777.9 | learning rate: 7.786E-06 | global batch size:    48 | lm loss: 5.771051E+00 | loss scale: 32768.0 | grad norm: 4.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      514/    1200 | consumed samples:        24672 | elapsed time per iteration (ms): 3838.3 | learning rate: 7.801E-06 | global batch size:    48 | lm loss: 5.875161E+00 | loss scale: 32768.0 | grad norm: 3.881 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      515/    1200 | consumed samples:        24720 | elapsed time per iteration (ms): 3756.6 | learning rate: 7.817E-06 | global batch size:    48 | lm loss: 5.909681E+00 | loss scale: 32768.0 | grad norm: 3.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      516/    1200 | consumed samples:        24768 | elapsed time per iteration (ms): 3818.7 | learning rate: 7.833E-06 | global batch size:    48 | lm loss: 5.796656E+00 | loss scale: 32768.0 | grad norm: 3.588 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      517/    1200 | consumed samples:        24816 | elapsed time per iteration (ms): 3818.8 | learning rate: 7.849E-06 | global batch size:    48 | lm loss: 5.821110E+00 | loss scale: 32768.0 | grad norm: 3.384 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      518/    1200 | consumed samples:        24864 | elapsed time per iteration (ms): 3751.1 | learning rate: 7.864E-06 | global batch size:    48 | lm loss: 5.837774E+00 | loss scale: 32768.0 | grad norm: 3.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      519/    1200 | consumed samples:        24912 | elapsed time per iteration (ms): 3754.8 | learning rate: 7.880E-06 | global batch size:    48 | lm loss: 5.873958E+00 | loss scale: 32768.0 | grad norm: 3.542 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      520/    1200 | consumed samples:        24960 | elapsed time per iteration (ms): 3749.1 | learning rate: 7.896E-06 | global batch size:    48 | lm loss: 5.761259E+00 | loss scale: 32768.0 | grad norm: 3.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      521/    1200 | consumed samples:        25008 | elapsed time per iteration (ms): 1120.4 | learning rate: 7.912E-06 | global batch size:    48 | lm loss: 5.871150E+00 | loss scale: 32768.0 | grad norm: 3.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      522/    1200 | consumed samples:        25056 | elapsed time per iteration (ms): 1046.3 | learning rate: 7.927E-06 | global batch size:    48 | lm loss: 5.751054E+00 | loss scale: 32768.0 | grad norm: 3.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      523/    1200 | consumed samples:        25104 | elapsed time per iteration (ms): 984.3 | learning rate: 7.943E-06 | global batch size:    48 | lm loss: 5.813092E+00 | loss scale: 32768.0 | grad norm: 3.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      524/    1200 | consumed samples:        25152 | elapsed time per iteration (ms): 983.7 | learning rate: 7.959E-06 | global batch size:    48 | lm loss: 5.734432E+00 | loss scale: 32768.0 | grad norm: 3.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      525/    1200 | consumed samples:        25200 | elapsed time per iteration (ms): 1213.3 | learning rate: 7.974E-06 | global batch size:    48 | lm loss: 5.902896E+00 | loss scale: 32768.0 | grad norm: 3.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      526/    1200 | consumed samples:        25248 | elapsed time per iteration (ms): 1308.6 | learning rate: 7.990E-06 | global batch size:    48 | lm loss: 5.879909E+00 | loss scale: 32768.0 | grad norm: 3.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      527/    1200 | consumed samples:        25296 | elapsed time per iteration (ms): 999.1 | learning rate: 8.006E-06 | global batch size:    48 | lm loss: 5.885239E+00 | loss scale: 32768.0 | grad norm: 3.250 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      528/    1200 | consumed samples:        25344 | elapsed time per iteration (ms): 1104.9 | learning rate: 8.022E-06 | global batch size:    48 | lm loss: 5.766508E+00 | loss scale: 32768.0 | grad norm: 3.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      529/    1200 | consumed samples:        25392 | elapsed time per iteration (ms): 1118.9 | learning rate: 8.037E-06 | global batch size:    48 | lm loss: 5.857479E+00 | loss scale: 32768.0 | grad norm: 3.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      530/    1200 | consumed samples:        25440 | elapsed time per iteration (ms): 1057.0 | learning rate: 8.053E-06 | global batch size:    48 | lm loss: 5.838222E+00 | loss scale: 32768.0 | grad norm: 3.242 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      531/    1200 | consumed samples:        25488 | elapsed time per iteration (ms): 1064.7 | learning rate: 8.069E-06 | global batch size:    48 | lm loss: 5.797040E+00 | loss scale: 32768.0 | grad norm: 3.308 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      532/    1200 | consumed samples:        25536 | elapsed time per iteration (ms): 1116.7 | learning rate: 8.085E-06 | global batch size:    48 | lm loss: 5.795884E+00 | loss scale: 32768.0 | grad norm: 3.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      533/    1200 | consumed samples:        25584 | elapsed time per iteration (ms): 1108.9 | learning rate: 8.100E-06 | global batch size:    48 | lm loss: 5.647745E+00 | loss scale: 32768.0 | grad norm: 3.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      534/    1200 | consumed samples:        25632 | elapsed time per iteration (ms): 1286.4 | learning rate: 8.116E-06 | global batch size:    48 | lm loss: 5.725873E+00 | loss scale: 32768.0 | grad norm: 3.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      535/    1200 | consumed samples:        25680 | elapsed time per iteration (ms): 1096.3 | learning rate: 8.132E-06 | global batch size:    48 | lm loss: 5.768722E+00 | loss scale: 32768.0 | grad norm: 3.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      536/    1200 | consumed samples:        25728 | elapsed time per iteration (ms): 1223.4 | learning rate: 8.147E-06 | global batch size:    48 | lm loss: 5.854211E+00 | loss scale: 32768.0 | grad norm: 3.362 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      537/    1200 | consumed samples:        25776 | elapsed time per iteration (ms): 992.6 | learning rate: 8.163E-06 | global batch size:    48 | lm loss: 5.809209E+00 | loss scale: 32768.0 | grad norm: 3.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      538/    1200 | consumed samples:        25824 | elapsed time per iteration (ms): 991.7 | learning rate: 8.179E-06 | global batch size:    48 | lm loss: 5.738053E+00 | loss scale: 32768.0 | grad norm: 3.311 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      539/    1200 | consumed samples:        25872 | elapsed time per iteration (ms): 1097.3 | learning rate: 8.195E-06 | global batch size:    48 | lm loss: 5.762634E+00 | loss scale: 32768.0 | grad norm: 3.541 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      540/    1200 | consumed samples:        25920 | elapsed time per iteration (ms): 1172.2 | learning rate: 8.210E-06 | global batch size:    48 | lm loss: 5.877401E+00 | loss scale: 32768.0 | grad norm: 3.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      541/    1200 | consumed samples:        25968 | elapsed time per iteration (ms): 1118.2 | learning rate: 8.226E-06 | global batch size:    48 | lm loss: 5.844711E+00 | loss scale: 32768.0 | grad norm: 3.256 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      542/    1200 | consumed samples:        26016 | elapsed time per iteration (ms): 1062.1 | learning rate: 8.242E-06 | global batch size:    48 | lm loss: 5.823527E+00 | loss scale: 32768.0 | grad norm: 3.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      543/    1200 | consumed samples:        26064 | elapsed time per iteration (ms): 1120.3 | learning rate: 8.258E-06 | global batch size:    48 | lm loss: 5.990162E+00 | loss scale: 32768.0 | grad norm: 3.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      544/    1200 | consumed samples:        26112 | elapsed time per iteration (ms): 1221.9 | learning rate: 8.273E-06 | global batch size:    48 | lm loss: 5.770285E+00 | loss scale: 32768.0 | grad norm: 3.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      545/    1200 | consumed samples:        26160 | elapsed time per iteration (ms): 987.7 | learning rate: 8.289E-06 | global batch size:    48 | lm loss: 5.682003E+00 | loss scale: 32768.0 | grad norm: 3.737 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      546/    1200 | consumed samples:        26208 | elapsed time per iteration (ms): 995.2 | learning rate: 8.305E-06 | global batch size:    48 | lm loss: 5.725832E+00 | loss scale: 32768.0 | grad norm: 3.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      547/    1200 | consumed samples:        26256 | elapsed time per iteration (ms): 1130.2 | learning rate: 8.320E-06 | global batch size:    48 | lm loss: 5.760946E+00 | loss scale: 32768.0 | grad norm: 3.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      548/    1200 | consumed samples:        26304 | elapsed time per iteration (ms): 987.0 | learning rate: 8.336E-06 | global batch size:    48 | lm loss: 5.768592E+00 | loss scale: 32768.0 | grad norm: 3.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      549/    1200 | consumed samples:        26352 | elapsed time per iteration (ms): 1113.7 | learning rate: 8.352E-06 | global batch size:    48 | lm loss: 5.755373E+00 | loss scale: 32768.0 | grad norm: 3.245 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      550/    1200 | consumed samples:        26400 | elapsed time per iteration (ms): 1197.1 | learning rate: 8.368E-06 | global batch size:    48 | lm loss: 5.796274E+00 | loss scale: 32768.0 | grad norm: 3.204 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      551/    1200 | consumed samples:        26448 | elapsed time per iteration (ms): 984.1 | learning rate: 8.383E-06 | global batch size:    48 | lm loss: 5.704728E+00 | loss scale: 32768.0 | grad norm: 3.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      552/    1200 | consumed samples:        26496 | elapsed time per iteration (ms): 1252.7 | learning rate: 8.399E-06 | global batch size:    48 | lm loss: 5.860395E+00 | loss scale: 32768.0 | grad norm: 3.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      553/    1200 | consumed samples:        26544 | elapsed time per iteration (ms): 1154.7 | learning rate: 8.415E-06 | global batch size:    48 | lm loss: 5.706571E+00 | loss scale: 32768.0 | grad norm: 3.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      554/    1200 | consumed samples:        26592 | elapsed time per iteration (ms): 1093.7 | learning rate: 8.431E-06 | global batch size:    48 | lm loss: 5.739770E+00 | loss scale: 32768.0 | grad norm: 3.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      555/    1200 | consumed samples:        26640 | elapsed time per iteration (ms): 1091.3 | learning rate: 8.446E-06 | global batch size:    48 | lm loss: 5.875732E+00 | loss scale: 32768.0 | grad norm: 3.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      556/    1200 | consumed samples:        26688 | elapsed time per iteration (ms): 1106.4 | learning rate: 8.462E-06 | global batch size:    48 | lm loss: 5.710460E+00 | loss scale: 32768.0 | grad norm: 3.138 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      557/    1200 | consumed samples:        26736 | elapsed time per iteration (ms): 1118.9 | learning rate: 8.478E-06 | global batch size:    48 | lm loss: 5.889975E+00 | loss scale: 32768.0 | grad norm: 3.304 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      558/    1200 | consumed samples:        26784 | elapsed time per iteration (ms): 1122.2 | learning rate: 8.493E-06 | global batch size:    48 | lm loss: 5.692155E+00 | loss scale: 32768.0 | grad norm: 3.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      559/    1200 | consumed samples:        26832 | elapsed time per iteration (ms): 993.2 | learning rate: 8.509E-06 | global batch size:    48 | lm loss: 5.658251E+00 | loss scale: 32768.0 | grad norm: 3.350 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      560/    1200 | consumed samples:        26880 | elapsed time per iteration (ms): 1002.4 | learning rate: 8.525E-06 | global batch size:    48 | lm loss: 5.772695E+00 | loss scale: 32768.0 | grad norm: 3.314 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      561/    1200 | consumed samples:        26928 | elapsed time per iteration (ms): 4159.3 | learning rate: 8.541E-06 | global batch size:    48 | lm loss: 5.793555E+00 | loss scale: 32768.0 | grad norm: 3.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      562/    1200 | consumed samples:        26976 | elapsed time per iteration (ms): 4213.0 | learning rate: 8.556E-06 | global batch size:    48 | lm loss: 5.784158E+00 | loss scale: 32768.0 | grad norm: 3.369 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      563/    1200 | consumed samples:        27024 | elapsed time per iteration (ms): 4151.8 | learning rate: 8.572E-06 | global batch size:    48 | lm loss: 5.749273E+00 | loss scale: 32768.0 | grad norm: 3.309 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      564/    1200 | consumed samples:        27072 | elapsed time per iteration (ms): 4153.0 | learning rate: 8.588E-06 | global batch size:    48 | lm loss: 5.673508E+00 | loss scale: 32768.0 | grad norm: 3.360 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      565/    1200 | consumed samples:        27120 | elapsed time per iteration (ms): 4221.1 | learning rate: 8.604E-06 | global batch size:    48 | lm loss: 5.810781E+00 | loss scale: 32768.0 | grad norm: 3.267 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      566/    1200 | consumed samples:        27168 | elapsed time per iteration (ms): 4178.3 | learning rate: 8.619E-06 | global batch size:    48 | lm loss: 5.796491E+00 | loss scale: 32768.0 | grad norm: 3.206 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      567/    1200 | consumed samples:        27216 | elapsed time per iteration (ms): 4165.1 | learning rate: 8.635E-06 | global batch size:    48 | lm loss: 5.776546E+00 | loss scale: 32768.0 | grad norm: 3.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      568/    1200 | consumed samples:        27264 | elapsed time per iteration (ms): 4155.9 | learning rate: 8.651E-06 | global batch size:    48 | lm loss: 5.744446E+00 | loss scale: 32768.0 | grad norm: 3.219 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      569/    1200 | consumed samples:        27312 | elapsed time per iteration (ms): 4160.3 | learning rate: 8.667E-06 | global batch size:    48 | lm loss: 5.651182E+00 | loss scale: 32768.0 | grad norm: 3.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      570/    1200 | consumed samples:        27360 | elapsed time per iteration (ms): 4157.7 | learning rate: 8.682E-06 | global batch size:    48 | lm loss: 5.814033E+00 | loss scale: 32768.0 | grad norm: 3.354 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      571/    1200 | consumed samples:        27408 | elapsed time per iteration (ms): 4212.6 | learning rate: 8.698E-06 | global batch size:    48 | lm loss: 5.764151E+00 | loss scale: 32768.0 | grad norm: 3.177 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      572/    1200 | consumed samples:        27456 | elapsed time per iteration (ms): 4151.9 | learning rate: 8.714E-06 | global batch size:    48 | lm loss: 5.793646E+00 | loss scale: 32768.0 | grad norm: 3.158 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      573/    1200 | consumed samples:        27504 | elapsed time per iteration (ms): 4240.6 | learning rate: 8.729E-06 | global batch size:    48 | lm loss: 5.706386E+00 | loss scale: 32768.0 | grad norm: 3.139 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      574/    1200 | consumed samples:        27552 | elapsed time per iteration (ms): 4173.3 | learning rate: 8.745E-06 | global batch size:    48 | lm loss: 5.677026E+00 | loss scale: 32768.0 | grad norm: 3.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      575/    1200 | consumed samples:        27600 | elapsed time per iteration (ms): 4164.6 | learning rate: 8.761E-06 | global batch size:    48 | lm loss: 5.731760E+00 | loss scale: 32768.0 | grad norm: 3.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      576/    1200 | consumed samples:        27648 | elapsed time per iteration (ms): 4162.0 | learning rate: 8.777E-06 | global batch size:    48 | lm loss: 5.711866E+00 | loss scale: 32768.0 | grad norm: 3.229 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      577/    1200 | consumed samples:        27696 | elapsed time per iteration (ms): 4153.6 | learning rate: 8.792E-06 | global batch size:    48 | lm loss: 5.821865E+00 | loss scale: 32768.0 | grad norm: 3.226 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      578/    1200 | consumed samples:        27744 | elapsed time per iteration (ms): 4155.6 | learning rate: 8.808E-06 | global batch size:    48 | lm loss: 5.650093E+00 | loss scale: 32768.0 | grad norm: 3.171 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      579/    1200 | consumed samples:        27792 | elapsed time per iteration (ms): 4152.6 | learning rate: 8.824E-06 | global batch size:    48 | lm loss: 5.615974E+00 | loss scale: 32768.0 | grad norm: 3.198 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      580/    1200 | consumed samples:        27840 | elapsed time per iteration (ms): 4217.3 | learning rate: 8.840E-06 | global batch size:    48 | lm loss: 5.719622E+00 | loss scale: 32768.0 | grad norm: 3.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      581/    1200 | consumed samples:        27888 | elapsed time per iteration (ms): 4302.0 | learning rate: 8.855E-06 | global batch size:    48 | lm loss: 5.775399E+00 | loss scale: 32768.0 | grad norm: 3.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      582/    1200 | consumed samples:        27936 | elapsed time per iteration (ms): 4175.7 | learning rate: 8.871E-06 | global batch size:    48 | lm loss: 5.776542E+00 | loss scale: 32768.0 | grad norm: 3.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      583/    1200 | consumed samples:        27984 | elapsed time per iteration (ms): 4152.0 | learning rate: 8.887E-06 | global batch size:    48 | lm loss: 5.636095E+00 | loss scale: 32768.0 | grad norm: 3.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      584/    1200 | consumed samples:        28032 | elapsed time per iteration (ms): 4149.9 | learning rate: 8.902E-06 | global batch size:    48 | lm loss: 5.823850E+00 | loss scale: 32768.0 | grad norm: 3.205 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      585/    1200 | consumed samples:        28080 | elapsed time per iteration (ms): 4168.6 | learning rate: 8.918E-06 | global batch size:    48 | lm loss: 5.695862E+00 | loss scale: 32768.0 | grad norm: 3.215 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      586/    1200 | consumed samples:        28128 | elapsed time per iteration (ms): 4149.3 | learning rate: 8.934E-06 | global batch size:    48 | lm loss: 5.703563E+00 | loss scale: 32768.0 | grad norm: 3.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      587/    1200 | consumed samples:        28176 | elapsed time per iteration (ms): 4152.7 | learning rate: 8.950E-06 | global batch size:    48 | lm loss: 5.567268E+00 | loss scale: 32768.0 | grad norm: 3.116 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      588/    1200 | consumed samples:        28224 | elapsed time per iteration (ms): 4154.2 | learning rate: 8.965E-06 | global batch size:    48 | lm loss: 5.806166E+00 | loss scale: 32768.0 | grad norm: 3.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      589/    1200 | consumed samples:        28272 | elapsed time per iteration (ms): 4207.1 | learning rate: 8.981E-06 | global batch size:    48 | lm loss: 5.776850E+00 | loss scale: 32768.0 | grad norm: 3.171 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      590/    1200 | consumed samples:        28320 | elapsed time per iteration (ms): 4181.6 | learning rate: 8.997E-06 | global batch size:    48 | lm loss: 5.706838E+00 | loss scale: 32768.0 | grad norm: 3.305 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      591/    1200 | consumed samples:        28368 | elapsed time per iteration (ms): 4228.3 | learning rate: 9.013E-06 | global batch size:    48 | lm loss: 5.759374E+00 | loss scale: 32768.0 | grad norm: 3.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      592/    1200 | consumed samples:        28416 | elapsed time per iteration (ms): 4155.9 | learning rate: 9.028E-06 | global batch size:    48 | lm loss: 5.818277E+00 | loss scale: 32768.0 | grad norm: 3.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      593/    1200 | consumed samples:        28464 | elapsed time per iteration (ms): 4157.0 | learning rate: 9.044E-06 | global batch size:    48 | lm loss: 5.607787E+00 | loss scale: 32768.0 | grad norm: 3.237 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      594/    1200 | consumed samples:        28512 | elapsed time per iteration (ms): 4159.3 | learning rate: 9.060E-06 | global batch size:    48 | lm loss: 5.617395E+00 | loss scale: 32768.0 | grad norm: 3.150 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      595/    1200 | consumed samples:        28560 | elapsed time per iteration (ms): 4161.8 | learning rate: 9.075E-06 | global batch size:    48 | lm loss: 5.667445E+00 | loss scale: 32768.0 | grad norm: 3.170 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      596/    1200 | consumed samples:        28608 | elapsed time per iteration (ms): 4155.4 | learning rate: 9.091E-06 | global batch size:    48 | lm loss: 5.711130E+00 | loss scale: 32768.0 | grad norm: 3.195 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      597/    1200 | consumed samples:        28656 | elapsed time per iteration (ms): 4154.5 | learning rate: 9.107E-06 | global batch size:    48 | lm loss: 5.671405E+00 | loss scale: 32768.0 | grad norm: 2.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      598/    1200 | consumed samples:        28704 | elapsed time per iteration (ms): 4232.0 | learning rate: 9.123E-06 | global batch size:    48 | lm loss: 5.682071E+00 | loss scale: 32768.0 | grad norm: 2.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      599/    1200 | consumed samples:        28752 | elapsed time per iteration (ms): 4231.6 | learning rate: 9.138E-06 | global batch size:    48 | lm loss: 5.763990E+00 | loss scale: 32768.0 | grad norm: 3.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      600/    1200 | consumed samples:        28800 | elapsed time per iteration (ms): 4153.0 | learning rate: 9.154E-06 | global batch size:    48 | lm loss: 5.788958E+00 | loss scale: 32768.0 | grad norm: 3.181 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      601/    1200 | consumed samples:        28848 | elapsed time per iteration (ms): 4155.8 | learning rate: 9.170E-06 | global batch size:    48 | lm loss: 5.710811E+00 | loss scale: 32768.0 | grad norm: 2.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      602/    1200 | consumed samples:        28896 | elapsed time per iteration (ms): 4155.3 | learning rate: 9.186E-06 | global batch size:    48 | lm loss: 5.643144E+00 | loss scale: 32768.0 | grad norm: 3.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      603/    1200 | consumed samples:        28944 | elapsed time per iteration (ms): 4168.4 | learning rate: 9.201E-06 | global batch size:    48 | lm loss: 5.655635E+00 | loss scale: 32768.0 | grad norm: 3.136 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      604/    1200 | consumed samples:        28992 | elapsed time per iteration (ms): 4158.6 | learning rate: 9.217E-06 | global batch size:    48 | lm loss: 5.700877E+00 | loss scale: 32768.0 | grad norm: 3.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      605/    1200 | consumed samples:        29040 | elapsed time per iteration (ms): 4154.4 | learning rate: 9.233E-06 | global batch size:    48 | lm loss: 5.687980E+00 | loss scale: 32768.0 | grad norm: 3.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      606/    1200 | consumed samples:        29088 | elapsed time per iteration (ms): 4168.4 | learning rate: 9.248E-06 | global batch size:    48 | lm loss: 5.770019E+00 | loss scale: 32768.0 | grad norm: 3.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      607/    1200 | consumed samples:        29136 | elapsed time per iteration (ms): 4353.2 | learning rate: 9.264E-06 | global batch size:    48 | lm loss: 5.667373E+00 | loss scale: 32768.0 | grad norm: 3.150 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      608/    1200 | consumed samples:        29184 | elapsed time per iteration (ms): 4150.3 | learning rate: 9.280E-06 | global batch size:    48 | lm loss: 5.647944E+00 | loss scale: 32768.0 | grad norm: 2.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      609/    1200 | consumed samples:        29232 | elapsed time per iteration (ms): 4155.2 | learning rate: 9.296E-06 | global batch size:    48 | lm loss: 5.566607E+00 | loss scale: 32768.0 | grad norm: 3.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      610/    1200 | consumed samples:        29280 | elapsed time per iteration (ms): 4161.8 | learning rate: 9.311E-06 | global batch size:    48 | lm loss: 5.681011E+00 | loss scale: 32768.0 | grad norm: 2.967 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      611/    1200 | consumed samples:        29328 | elapsed time per iteration (ms): 4152.4 | learning rate: 9.327E-06 | global batch size:    48 | lm loss: 5.723373E+00 | loss scale: 32768.0 | grad norm: 3.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      612/    1200 | consumed samples:        29376 | elapsed time per iteration (ms): 4163.6 | learning rate: 9.343E-06 | global batch size:    48 | lm loss: 5.713409E+00 | loss scale: 32768.0 | grad norm: 3.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      613/    1200 | consumed samples:        29424 | elapsed time per iteration (ms): 4159.8 | learning rate: 9.359E-06 | global batch size:    48 | lm loss: 5.711053E+00 | loss scale: 32768.0 | grad norm: 3.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      614/    1200 | consumed samples:        29472 | elapsed time per iteration (ms): 4180.9 | learning rate: 9.374E-06 | global batch size:    48 | lm loss: 5.703546E+00 | loss scale: 32768.0 | grad norm: 3.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      615/    1200 | consumed samples:        29520 | elapsed time per iteration (ms): 4159.3 | learning rate: 9.390E-06 | global batch size:    48 | lm loss: 5.668943E+00 | loss scale: 32768.0 | grad norm: 3.136 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      616/    1200 | consumed samples:        29568 | elapsed time per iteration (ms): 4217.3 | learning rate: 9.406E-06 | global batch size:    48 | lm loss: 5.668709E+00 | loss scale: 32768.0 | grad norm: 3.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      617/    1200 | consumed samples:        29616 | elapsed time per iteration (ms): 4317.2 | learning rate: 9.421E-06 | global batch size:    48 | lm loss: 5.720615E+00 | loss scale: 32768.0 | grad norm: 3.308 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      618/    1200 | consumed samples:        29664 | elapsed time per iteration (ms): 4149.0 | learning rate: 9.437E-06 | global batch size:    48 | lm loss: 5.724241E+00 | loss scale: 32768.0 | grad norm: 3.320 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      619/    1200 | consumed samples:        29712 | elapsed time per iteration (ms): 4155.1 | learning rate: 9.453E-06 | global batch size:    48 | lm loss: 5.692142E+00 | loss scale: 32768.0 | grad norm: 3.127 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      620/    1200 | consumed samples:        29760 | elapsed time per iteration (ms): 4158.6 | learning rate: 9.469E-06 | global batch size:    48 | lm loss: 5.687812E+00 | loss scale: 32768.0 | grad norm: 3.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      621/    1200 | consumed samples:        29808 | elapsed time per iteration (ms): 4167.5 | learning rate: 9.484E-06 | global batch size:    48 | lm loss: 5.726458E+00 | loss scale: 32768.0 | grad norm: 3.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      622/    1200 | consumed samples:        29856 | elapsed time per iteration (ms): 4173.5 | learning rate: 9.500E-06 | global batch size:    48 | lm loss: 5.713326E+00 | loss scale: 32768.0 | grad norm: 3.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      623/    1200 | consumed samples:        29904 | elapsed time per iteration (ms): 4150.4 | learning rate: 9.516E-06 | global batch size:    48 | lm loss: 5.689090E+00 | loss scale: 32768.0 | grad norm: 2.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      624/    1200 | consumed samples:        29952 | elapsed time per iteration (ms): 4149.8 | learning rate: 9.532E-06 | global batch size:    48 | lm loss: 5.615100E+00 | loss scale: 32768.0 | grad norm: 2.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      625/    1200 | consumed samples:        30000 | elapsed time per iteration (ms): 4242.3 | learning rate: 9.547E-06 | global batch size:    48 | lm loss: 5.605961E+00 | loss scale: 32768.0 | grad norm: 3.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      626/    1200 | consumed samples:        30048 | elapsed time per iteration (ms): 4156.2 | learning rate: 9.563E-06 | global batch size:    48 | lm loss: 5.657576E+00 | loss scale: 32768.0 | grad norm: 2.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      627/    1200 | consumed samples:        30096 | elapsed time per iteration (ms): 4158.3 | learning rate: 9.579E-06 | global batch size:    48 | lm loss: 5.722835E+00 | loss scale: 32768.0 | grad norm: 3.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      628/    1200 | consumed samples:        30144 | elapsed time per iteration (ms): 4158.2 | learning rate: 9.594E-06 | global batch size:    48 | lm loss: 5.844237E+00 | loss scale: 32768.0 | grad norm: 3.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      629/    1200 | consumed samples:        30192 | elapsed time per iteration (ms): 4160.8 | learning rate: 9.610E-06 | global batch size:    48 | lm loss: 5.700781E+00 | loss scale: 32768.0 | grad norm: 3.162 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      630/    1200 | consumed samples:        30240 | elapsed time per iteration (ms): 4188.6 | learning rate: 9.626E-06 | global batch size:    48 | lm loss: 5.700760E+00 | loss scale: 32768.0 | grad norm: 3.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      631/    1200 | consumed samples:        30288 | elapsed time per iteration (ms): 3699.0 | learning rate: 9.642E-06 | global batch size:    48 | lm loss: 5.659174E+00 | loss scale: 32768.0 | grad norm: 3.121 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      632/    1200 | consumed samples:        30336 | elapsed time per iteration (ms): 2345.3 | learning rate: 9.657E-06 | global batch size:    48 | lm loss: 5.605062E+00 | loss scale: 32768.0 | grad norm: 3.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      633/    1200 | consumed samples:        30384 | elapsed time per iteration (ms): 1292.8 | learning rate: 9.673E-06 | global batch size:    48 | lm loss: 5.730718E+00 | loss scale: 32768.0 | grad norm: 3.309 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      634/    1200 | consumed samples:        30432 | elapsed time per iteration (ms): 1256.9 | learning rate: 9.689E-06 | global batch size:    48 | lm loss: 5.723096E+00 | loss scale: 32768.0 | grad norm: 2.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      635/    1200 | consumed samples:        30480 | elapsed time per iteration (ms): 1113.2 | learning rate: 9.705E-06 | global batch size:    48 | lm loss: 5.642690E+00 | loss scale: 32768.0 | grad norm: 3.198 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      636/    1200 | consumed samples:        30528 | elapsed time per iteration (ms): 1106.8 | learning rate: 9.720E-06 | global batch size:    48 | lm loss: 5.692796E+00 | loss scale: 32768.0 | grad norm: 2.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      637/    1200 | consumed samples:        30576 | elapsed time per iteration (ms): 1020.8 | learning rate: 9.736E-06 | global batch size:    48 | lm loss: 5.732486E+00 | loss scale: 32768.0 | grad norm: 2.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      638/    1200 | consumed samples:        30624 | elapsed time per iteration (ms): 1054.9 | learning rate: 9.752E-06 | global batch size:    48 | lm loss: 5.668486E+00 | loss scale: 32768.0 | grad norm: 3.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      639/    1200 | consumed samples:        30672 | elapsed time per iteration (ms): 1050.0 | learning rate: 9.768E-06 | global batch size:    48 | lm loss: 5.674823E+00 | loss scale: 32768.0 | grad norm: 3.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      640/    1200 | consumed samples:        30720 | elapsed time per iteration (ms): 1120.2 | learning rate: 9.783E-06 | global batch size:    48 | lm loss: 5.709787E+00 | loss scale: 32768.0 | grad norm: 3.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      641/    1200 | consumed samples:        30768 | elapsed time per iteration (ms): 985.8 | learning rate: 9.799E-06 | global batch size:    48 | lm loss: 5.741579E+00 | loss scale: 32768.0 | grad norm: 3.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      642/    1200 | consumed samples:        30816 | elapsed time per iteration (ms): 1105.3 | learning rate: 9.815E-06 | global batch size:    48 | lm loss: 5.642751E+00 | loss scale: 32768.0 | grad norm: 2.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      643/    1200 | consumed samples:        30864 | elapsed time per iteration (ms): 1360.8 | learning rate: 9.830E-06 | global batch size:    48 | lm loss: 5.692857E+00 | loss scale: 32768.0 | grad norm: 2.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      644/    1200 | consumed samples:        30912 | elapsed time per iteration (ms): 984.2 | learning rate: 9.846E-06 | global batch size:    48 | lm loss: 5.662841E+00 | loss scale: 32768.0 | grad norm: 2.952 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      645/    1200 | consumed samples:        30960 | elapsed time per iteration (ms): 987.4 | learning rate: 9.862E-06 | global batch size:    48 | lm loss: 5.689506E+00 | loss scale: 32768.0 | grad norm: 2.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      646/    1200 | consumed samples:        31008 | elapsed time per iteration (ms): 1056.8 | learning rate: 9.878E-06 | global batch size:    48 | lm loss: 5.825467E+00 | loss scale: 32768.0 | grad norm: 3.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      647/    1200 | consumed samples:        31056 | elapsed time per iteration (ms): 1142.9 | learning rate: 9.893E-06 | global batch size:    48 | lm loss: 5.633283E+00 | loss scale: 32768.0 | grad norm: 2.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      648/    1200 | consumed samples:        31104 | elapsed time per iteration (ms): 1286.1 | learning rate: 9.909E-06 | global batch size:    48 | lm loss: 5.638021E+00 | loss scale: 32768.0 | grad norm: 2.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      649/    1200 | consumed samples:        31152 | elapsed time per iteration (ms): 995.0 | learning rate: 9.925E-06 | global batch size:    48 | lm loss: 5.611701E+00 | loss scale: 32768.0 | grad norm: 2.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      650/    1200 | consumed samples:        31200 | elapsed time per iteration (ms): 1128.6 | learning rate: 9.941E-06 | global batch size:    48 | lm loss: 5.664869E+00 | loss scale: 32768.0 | grad norm: 2.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      651/    1200 | consumed samples:        31248 | elapsed time per iteration (ms): 1131.8 | learning rate: 9.956E-06 | global batch size:    48 | lm loss: 5.631676E+00 | loss scale: 32768.0 | grad norm: 2.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      652/    1200 | consumed samples:        31296 | elapsed time per iteration (ms): 1234.0 | learning rate: 9.972E-06 | global batch size:    48 | lm loss: 5.588372E+00 | loss scale: 32768.0 | grad norm: 2.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      653/    1200 | consumed samples:        31344 | elapsed time per iteration (ms): 986.9 | learning rate: 9.988E-06 | global batch size:    48 | lm loss: 5.621332E+00 | loss scale: 32768.0 | grad norm: 2.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      654/    1200 | consumed samples:        31392 | elapsed time per iteration (ms): 1059.1 | learning rate: 1.000E-05 | global batch size:    48 | lm loss: 5.678327E+00 | loss scale: 32768.0 | grad norm: 2.835 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      655/    1200 | consumed samples:        31440 | elapsed time per iteration (ms): 989.9 | learning rate: 1.002E-05 | global batch size:    48 | lm loss: 5.542541E+00 | loss scale: 32768.0 | grad norm: 2.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      656/    1200 | consumed samples:        31488 | elapsed time per iteration (ms): 990.5 | learning rate: 1.003E-05 | global batch size:    48 | lm loss: 5.582415E+00 | loss scale: 32768.0 | grad norm: 2.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      657/    1200 | consumed samples:        31536 | elapsed time per iteration (ms): 1180.4 | learning rate: 1.005E-05 | global batch size:    48 | lm loss: 5.593401E+00 | loss scale: 32768.0 | grad norm: 2.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      658/    1200 | consumed samples:        31584 | elapsed time per iteration (ms): 989.3 | learning rate: 1.007E-05 | global batch size:    48 | lm loss: 5.693934E+00 | loss scale: 32768.0 | grad norm: 2.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      659/    1200 | consumed samples:        31632 | elapsed time per iteration (ms): 1109.0 | learning rate: 1.008E-05 | global batch size:    48 | lm loss: 5.723982E+00 | loss scale: 32768.0 | grad norm: 2.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      660/    1200 | consumed samples:        31680 | elapsed time per iteration (ms): 1238.2 | learning rate: 1.010E-05 | global batch size:    48 | lm loss: 5.659336E+00 | loss scale: 32768.0 | grad norm: 2.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      661/    1200 | consumed samples:        31728 | elapsed time per iteration (ms): 1119.6 | learning rate: 1.011E-05 | global batch size:    48 | lm loss: 5.640604E+00 | loss scale: 32768.0 | grad norm: 2.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      662/    1200 | consumed samples:        31776 | elapsed time per iteration (ms): 1069.4 | learning rate: 1.013E-05 | global batch size:    48 | lm loss: 5.553501E+00 | loss scale: 32768.0 | grad norm: 2.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      663/    1200 | consumed samples:        31824 | elapsed time per iteration (ms): 1097.8 | learning rate: 1.014E-05 | global batch size:    48 | lm loss: 5.651071E+00 | loss scale: 32768.0 | grad norm: 2.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      664/    1200 | consumed samples:        31872 | elapsed time per iteration (ms): 1151.0 | learning rate: 1.016E-05 | global batch size:    48 | lm loss: 5.629048E+00 | loss scale: 32768.0 | grad norm: 2.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      665/    1200 | consumed samples:        31920 | elapsed time per iteration (ms): 1274.6 | learning rate: 1.018E-05 | global batch size:    48 | lm loss: 5.607345E+00 | loss scale: 32768.0 | grad norm: 3.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      666/    1200 | consumed samples:        31968 | elapsed time per iteration (ms): 1135.1 | learning rate: 1.019E-05 | global batch size:    48 | lm loss: 5.592169E+00 | loss scale: 32768.0 | grad norm: 2.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      667/    1200 | consumed samples:        32016 | elapsed time per iteration (ms): 986.7 | learning rate: 1.021E-05 | global batch size:    48 | lm loss: 5.545117E+00 | loss scale: 32768.0 | grad norm: 2.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      668/    1200 | consumed samples:        32064 | elapsed time per iteration (ms): 986.9 | learning rate: 1.022E-05 | global batch size:    48 | lm loss: 5.552128E+00 | loss scale: 32768.0 | grad norm: 2.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      669/    1200 | consumed samples:        32112 | elapsed time per iteration (ms): 1239.8 | learning rate: 1.024E-05 | global batch size:    48 | lm loss: 5.499193E+00 | loss scale: 32768.0 | grad norm: 2.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      670/    1200 | consumed samples:        32160 | elapsed time per iteration (ms): 1203.7 | learning rate: 1.026E-05 | global batch size:    48 | lm loss: 5.600173E+00 | loss scale: 32768.0 | grad norm: 3.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      671/    1200 | consumed samples:        32208 | elapsed time per iteration (ms): 1268.8 | learning rate: 1.027E-05 | global batch size:    48 | lm loss: 5.573102E+00 | loss scale: 32768.0 | grad norm: 2.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      672/    1200 | consumed samples:        32256 | elapsed time per iteration (ms): 1902.8 | learning rate: 1.029E-05 | global batch size:    48 | lm loss: 5.667228E+00 | loss scale: 32768.0 | grad norm: 2.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      673/    1200 | consumed samples:        32304 | elapsed time per iteration (ms): 1916.5 | learning rate: 1.030E-05 | global batch size:    48 | lm loss: 5.613804E+00 | loss scale: 32768.0 | grad norm: 2.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      674/    1200 | consumed samples:        32352 | elapsed time per iteration (ms): 2025.2 | learning rate: 1.032E-05 | global batch size:    48 | lm loss: 5.620396E+00 | loss scale: 32768.0 | grad norm: 2.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      675/    1200 | consumed samples:        32400 | elapsed time per iteration (ms): 1943.4 | learning rate: 1.033E-05 | global batch size:    48 | lm loss: 5.646140E+00 | loss scale: 32768.0 | grad norm: 2.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      676/    1200 | consumed samples:        32448 | elapsed time per iteration (ms): 1956.3 | learning rate: 1.035E-05 | global batch size:    48 | lm loss: 5.569732E+00 | loss scale: 32768.0 | grad norm: 2.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      677/    1200 | consumed samples:        32496 | elapsed time per iteration (ms): 1977.2 | learning rate: 1.037E-05 | global batch size:    48 | lm loss: 5.649758E+00 | loss scale: 32768.0 | grad norm: 2.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      678/    1200 | consumed samples:        32544 | elapsed time per iteration (ms): 2074.6 | learning rate: 1.038E-05 | global batch size:    48 | lm loss: 5.522680E+00 | loss scale: 32768.0 | grad norm: 2.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      679/    1200 | consumed samples:        32592 | elapsed time per iteration (ms): 2014.2 | learning rate: 1.040E-05 | global batch size:    48 | lm loss: 5.595155E+00 | loss scale: 32768.0 | grad norm: 2.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      680/    1200 | consumed samples:        32640 | elapsed time per iteration (ms): 1942.8 | learning rate: 1.041E-05 | global batch size:    48 | lm loss: 5.672623E+00 | loss scale: 32768.0 | grad norm: 2.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      681/    1200 | consumed samples:        32688 | elapsed time per iteration (ms): 2033.7 | learning rate: 1.043E-05 | global batch size:    48 | lm loss: 5.583460E+00 | loss scale: 32768.0 | grad norm: 2.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      682/    1200 | consumed samples:        32736 | elapsed time per iteration (ms): 1912.3 | learning rate: 1.044E-05 | global batch size:    48 | lm loss: 5.523470E+00 | loss scale: 32768.0 | grad norm: 2.872 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      683/    1200 | consumed samples:        32784 | elapsed time per iteration (ms): 1929.8 | learning rate: 1.046E-05 | global batch size:    48 | lm loss: 5.594844E+00 | loss scale: 32768.0 | grad norm: 2.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      684/    1200 | consumed samples:        32832 | elapsed time per iteration (ms): 2083.5 | learning rate: 1.048E-05 | global batch size:    48 | lm loss: 5.554529E+00 | loss scale: 32768.0 | grad norm: 2.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      685/    1200 | consumed samples:        32880 | elapsed time per iteration (ms): 1980.4 | learning rate: 1.049E-05 | global batch size:    48 | lm loss: 5.598516E+00 | loss scale: 32768.0 | grad norm: 2.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      686/    1200 | consumed samples:        32928 | elapsed time per iteration (ms): 1935.9 | learning rate: 1.051E-05 | global batch size:    48 | lm loss: 5.628152E+00 | loss scale: 32768.0 | grad norm: 2.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      687/    1200 | consumed samples:        32976 | elapsed time per iteration (ms): 2055.0 | learning rate: 1.052E-05 | global batch size:    48 | lm loss: 5.609074E+00 | loss scale: 32768.0 | grad norm: 2.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      688/    1200 | consumed samples:        33024 | elapsed time per iteration (ms): 2168.5 | learning rate: 1.054E-05 | global batch size:    48 | lm loss: 5.605568E+00 | loss scale: 32768.0 | grad norm: 2.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      689/    1200 | consumed samples:        33072 | elapsed time per iteration (ms): 1915.7 | learning rate: 1.055E-05 | global batch size:    48 | lm loss: 5.614244E+00 | loss scale: 32768.0 | grad norm: 2.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      690/    1200 | consumed samples:        33120 | elapsed time per iteration (ms): 1915.3 | learning rate: 1.057E-05 | global batch size:    48 | lm loss: 5.663274E+00 | loss scale: 32768.0 | grad norm: 2.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      691/    1200 | consumed samples:        33168 | elapsed time per iteration (ms): 1916.6 | learning rate: 1.059E-05 | global batch size:    48 | lm loss: 5.519672E+00 | loss scale: 32768.0 | grad norm: 2.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      692/    1200 | consumed samples:        33216 | elapsed time per iteration (ms): 1904.2 | learning rate: 1.060E-05 | global batch size:    48 | lm loss: 5.555804E+00 | loss scale: 32768.0 | grad norm: 2.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      693/    1200 | consumed samples:        33264 | elapsed time per iteration (ms): 1943.1 | learning rate: 1.062E-05 | global batch size:    48 | lm loss: 5.484715E+00 | loss scale: 32768.0 | grad norm: 2.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      694/    1200 | consumed samples:        33312 | elapsed time per iteration (ms): 1944.2 | learning rate: 1.063E-05 | global batch size:    48 | lm loss: 5.596687E+00 | loss scale: 32768.0 | grad norm: 2.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      695/    1200 | consumed samples:        33360 | elapsed time per iteration (ms): 1941.7 | learning rate: 1.065E-05 | global batch size:    48 | lm loss: 5.545239E+00 | loss scale: 32768.0 | grad norm: 2.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      696/    1200 | consumed samples:        33408 | elapsed time per iteration (ms): 2240.2 | learning rate: 1.066E-05 | global batch size:    48 | lm loss: 5.601982E+00 | loss scale: 32768.0 | grad norm: 2.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      697/    1200 | consumed samples:        33456 | elapsed time per iteration (ms): 2074.4 | learning rate: 1.068E-05 | global batch size:    48 | lm loss: 5.637763E+00 | loss scale: 32768.0 | grad norm: 2.783 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      698/    1200 | consumed samples:        33504 | elapsed time per iteration (ms): 1914.9 | learning rate: 1.070E-05 | global batch size:    48 | lm loss: 5.568772E+00 | loss scale: 32768.0 | grad norm: 2.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      699/    1200 | consumed samples:        33552 | elapsed time per iteration (ms): 1911.9 | learning rate: 1.071E-05 | global batch size:    48 | lm loss: 5.645374E+00 | loss scale: 32768.0 | grad norm: 2.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      700/    1200 | consumed samples:        33600 | elapsed time per iteration (ms): 1957.8 | learning rate: 1.073E-05 | global batch size:    48 | lm loss: 5.485499E+00 | loss scale: 32768.0 | grad norm: 2.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      701/    1200 | consumed samples:        33648 | elapsed time per iteration (ms): 1909.8 | learning rate: 1.074E-05 | global batch size:    48 | lm loss: 5.638160E+00 | loss scale: 32768.0 | grad norm: 2.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      702/    1200 | consumed samples:        33696 | elapsed time per iteration (ms): 2007.9 | learning rate: 1.076E-05 | global batch size:    48 | lm loss: 5.541542E+00 | loss scale: 32768.0 | grad norm: 2.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      703/    1200 | consumed samples:        33744 | elapsed time per iteration (ms): 1971.3 | learning rate: 1.077E-05 | global batch size:    48 | lm loss: 5.538855E+00 | loss scale: 32768.0 | grad norm: 2.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      704/    1200 | consumed samples:        33792 | elapsed time per iteration (ms): 1920.6 | learning rate: 1.079E-05 | global batch size:    48 | lm loss: 5.606313E+00 | loss scale: 32768.0 | grad norm: 2.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      705/    1200 | consumed samples:        33840 | elapsed time per iteration (ms): 2164.3 | learning rate: 1.081E-05 | global batch size:    48 | lm loss: 5.624059E+00 | loss scale: 32768.0 | grad norm: 2.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      706/    1200 | consumed samples:        33888 | elapsed time per iteration (ms): 1996.6 | learning rate: 1.082E-05 | global batch size:    48 | lm loss: 5.544169E+00 | loss scale: 32768.0 | grad norm: 2.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      707/    1200 | consumed samples:        33936 | elapsed time per iteration (ms): 1918.6 | learning rate: 1.084E-05 | global batch size:    48 | lm loss: 5.606124E+00 | loss scale: 32768.0 | grad norm: 2.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      708/    1200 | consumed samples:        33984 | elapsed time per iteration (ms): 2054.8 | learning rate: 1.085E-05 | global batch size:    48 | lm loss: 5.549232E+00 | loss scale: 32768.0 | grad norm: 2.578 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      709/    1200 | consumed samples:        34032 | elapsed time per iteration (ms): 1934.3 | learning rate: 1.087E-05 | global batch size:    48 | lm loss: 5.614425E+00 | loss scale: 32768.0 | grad norm: 2.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      710/    1200 | consumed samples:        34080 | elapsed time per iteration (ms): 1938.9 | learning rate: 1.088E-05 | global batch size:    48 | lm loss: 5.603668E+00 | loss scale: 32768.0 | grad norm: 2.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      711/    1200 | consumed samples:        34128 | elapsed time per iteration (ms): 2008.6 | learning rate: 1.090E-05 | global batch size:    48 | lm loss: 5.616201E+00 | loss scale: 32768.0 | grad norm: 2.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      712/    1200 | consumed samples:        34176 | elapsed time per iteration (ms): 2072.6 | learning rate: 1.092E-05 | global batch size:    48 | lm loss: 5.703933E+00 | loss scale: 32768.0 | grad norm: 2.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      713/    1200 | consumed samples:        34224 | elapsed time per iteration (ms): 1914.7 | learning rate: 1.093E-05 | global batch size:    48 | lm loss: 5.544103E+00 | loss scale: 32768.0 | grad norm: 2.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      714/    1200 | consumed samples:        34272 | elapsed time per iteration (ms): 2040.1 | learning rate: 1.095E-05 | global batch size:    48 | lm loss: 5.570131E+00 | loss scale: 32768.0 | grad norm: 2.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      715/    1200 | consumed samples:        34320 | elapsed time per iteration (ms): 1996.8 | learning rate: 1.096E-05 | global batch size:    48 | lm loss: 5.548894E+00 | loss scale: 32768.0 | grad norm: 2.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      716/    1200 | consumed samples:        34368 | elapsed time per iteration (ms): 1908.7 | learning rate: 1.098E-05 | global batch size:    48 | lm loss: 5.495958E+00 | loss scale: 32768.0 | grad norm: 2.781 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      717/    1200 | consumed samples:        34416 | elapsed time per iteration (ms): 1908.9 | learning rate: 1.099E-05 | global batch size:    48 | lm loss: 5.623157E+00 | loss scale: 32768.0 | grad norm: 2.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      718/    1200 | consumed samples:        34464 | elapsed time per iteration (ms): 1934.2 | learning rate: 1.101E-05 | global batch size:    48 | lm loss: 5.584735E+00 | loss scale: 32768.0 | grad norm: 2.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      719/    1200 | consumed samples:        34512 | elapsed time per iteration (ms): 2026.5 | learning rate: 1.103E-05 | global batch size:    48 | lm loss: 5.569238E+00 | loss scale: 32768.0 | grad norm: 2.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      720/    1200 | consumed samples:        34560 | elapsed time per iteration (ms): 2108.4 | learning rate: 1.104E-05 | global batch size:    48 | lm loss: 5.565524E+00 | loss scale: 32768.0 | grad norm: 2.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      721/    1200 | consumed samples:        34608 | elapsed time per iteration (ms): 2005.6 | learning rate: 1.106E-05 | global batch size:    48 | lm loss: 5.593542E+00 | loss scale: 32768.0 | grad norm: 2.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      722/    1200 | consumed samples:        34656 | elapsed time per iteration (ms): 1912.4 | learning rate: 1.107E-05 | global batch size:    48 | lm loss: 5.647052E+00 | loss scale: 32768.0 | grad norm: 2.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      723/    1200 | consumed samples:        34704 | elapsed time per iteration (ms): 2049.6 | learning rate: 1.109E-05 | global batch size:    48 | lm loss: 5.573000E+00 | loss scale: 32768.0 | grad norm: 2.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      724/    1200 | consumed samples:        34752 | elapsed time per iteration (ms): 2033.3 | learning rate: 1.110E-05 | global batch size:    48 | lm loss: 5.593886E+00 | loss scale: 32768.0 | grad norm: 2.599 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      725/    1200 | consumed samples:        34800 | elapsed time per iteration (ms): 1917.9 | learning rate: 1.112E-05 | global batch size:    48 | lm loss: 5.639894E+00 | loss scale: 32768.0 | grad norm: 2.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      726/    1200 | consumed samples:        34848 | elapsed time per iteration (ms): 1939.1 | learning rate: 1.114E-05 | global batch size:    48 | lm loss: 5.583029E+00 | loss scale: 32768.0 | grad norm: 2.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      727/    1200 | consumed samples:        34896 | elapsed time per iteration (ms): 2031.6 | learning rate: 1.115E-05 | global batch size:    48 | lm loss: 5.473729E+00 | loss scale: 32768.0 | grad norm: 2.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      728/    1200 | consumed samples:        34944 | elapsed time per iteration (ms): 1917.1 | learning rate: 1.117E-05 | global batch size:    48 | lm loss: 5.447401E+00 | loss scale: 32768.0 | grad norm: 2.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      729/    1200 | consumed samples:        34992 | elapsed time per iteration (ms): 1973.0 | learning rate: 1.118E-05 | global batch size:    48 | lm loss: 5.502437E+00 | loss scale: 32768.0 | grad norm: 2.585 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      730/    1200 | consumed samples:        35040 | elapsed time per iteration (ms): 1923.6 | learning rate: 1.120E-05 | global batch size:    48 | lm loss: 5.543555E+00 | loss scale: 32768.0 | grad norm: 2.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      731/    1200 | consumed samples:        35088 | elapsed time per iteration (ms): 1928.8 | learning rate: 1.121E-05 | global batch size:    48 | lm loss: 5.558058E+00 | loss scale: 32768.0 | grad norm: 2.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      732/    1200 | consumed samples:        35136 | elapsed time per iteration (ms): 2128.3 | learning rate: 1.123E-05 | global batch size:    48 | lm loss: 5.743114E+00 | loss scale: 32768.0 | grad norm: 2.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      733/    1200 | consumed samples:        35184 | elapsed time per iteration (ms): 1995.1 | learning rate: 1.125E-05 | global batch size:    48 | lm loss: 5.509725E+00 | loss scale: 32768.0 | grad norm: 2.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      734/    1200 | consumed samples:        35232 | elapsed time per iteration (ms): 1963.4 | learning rate: 1.126E-05 | global batch size:    48 | lm loss: 5.580532E+00 | loss scale: 32768.0 | grad norm: 2.578 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      735/    1200 | consumed samples:        35280 | elapsed time per iteration (ms): 1926.1 | learning rate: 1.128E-05 | global batch size:    48 | lm loss: 5.611881E+00 | loss scale: 32768.0 | grad norm: 2.601 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      736/    1200 | consumed samples:        35328 | elapsed time per iteration (ms): 2148.6 | learning rate: 1.129E-05 | global batch size:    48 | lm loss: 5.524122E+00 | loss scale: 32768.0 | grad norm: 2.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      737/    1200 | consumed samples:        35376 | elapsed time per iteration (ms): 1983.4 | learning rate: 1.131E-05 | global batch size:    48 | lm loss: 5.500957E+00 | loss scale: 32768.0 | grad norm: 2.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      738/    1200 | consumed samples:        35424 | elapsed time per iteration (ms): 1938.1 | learning rate: 1.132E-05 | global batch size:    48 | lm loss: 5.488536E+00 | loss scale: 32768.0 | grad norm: 2.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      739/    1200 | consumed samples:        35472 | elapsed time per iteration (ms): 1919.9 | learning rate: 1.134E-05 | global batch size:    48 | lm loss: 5.534435E+00 | loss scale: 32768.0 | grad norm: 2.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      740/    1200 | consumed samples:        35520 | elapsed time per iteration (ms): 1920.8 | learning rate: 1.136E-05 | global batch size:    48 | lm loss: 5.489217E+00 | loss scale: 32768.0 | grad norm: 2.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      741/    1200 | consumed samples:        35568 | elapsed time per iteration (ms): 1462.0 | learning rate: 1.137E-05 | global batch size:    48 | lm loss: 5.513770E+00 | loss scale: 32768.0 | grad norm: 2.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      742/    1200 | consumed samples:        35616 | elapsed time per iteration (ms): 1325.0 | learning rate: 1.139E-05 | global batch size:    48 | lm loss: 5.443771E+00 | loss scale: 32768.0 | grad norm: 2.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      743/    1200 | consumed samples:        35664 | elapsed time per iteration (ms): 1130.3 | learning rate: 1.140E-05 | global batch size:    48 | lm loss: 5.517573E+00 | loss scale: 32768.0 | grad norm: 2.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      744/    1200 | consumed samples:        35712 | elapsed time per iteration (ms): 1124.3 | learning rate: 1.142E-05 | global batch size:    48 | lm loss: 5.542360E+00 | loss scale: 32768.0 | grad norm: 2.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      745/    1200 | consumed samples:        35760 | elapsed time per iteration (ms): 997.0 | learning rate: 1.143E-05 | global batch size:    48 | lm loss: 5.610498E+00 | loss scale: 32768.0 | grad norm: 2.564 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      746/    1200 | consumed samples:        35808 | elapsed time per iteration (ms): 995.9 | learning rate: 1.145E-05 | global batch size:    48 | lm loss: 5.485872E+00 | loss scale: 32768.0 | grad norm: 2.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      747/    1200 | consumed samples:        35856 | elapsed time per iteration (ms): 1175.2 | learning rate: 1.147E-05 | global batch size:    48 | lm loss: 5.532656E+00 | loss scale: 32768.0 | grad norm: 2.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      748/    1200 | consumed samples:        35904 | elapsed time per iteration (ms): 1118.5 | learning rate: 1.148E-05 | global batch size:    48 | lm loss: 5.528543E+00 | loss scale: 32768.0 | grad norm: 2.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      749/    1200 | consumed samples:        35952 | elapsed time per iteration (ms): 1116.8 | learning rate: 1.150E-05 | global batch size:    48 | lm loss: 5.493554E+00 | loss scale: 32768.0 | grad norm: 2.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      750/    1200 | consumed samples:        36000 | elapsed time per iteration (ms): 1302.2 | learning rate: 1.151E-05 | global batch size:    48 | lm loss: 5.466545E+00 | loss scale: 32768.0 | grad norm: 2.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      751/    1200 | consumed samples:        36048 | elapsed time per iteration (ms): 1162.5 | learning rate: 1.153E-05 | global batch size:    48 | lm loss: 5.481758E+00 | loss scale: 32768.0 | grad norm: 2.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      752/    1200 | consumed samples:        36096 | elapsed time per iteration (ms): 1004.6 | learning rate: 1.154E-05 | global batch size:    48 | lm loss: 5.516201E+00 | loss scale: 32768.0 | grad norm: 2.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      753/    1200 | consumed samples:        36144 | elapsed time per iteration (ms): 991.8 | learning rate: 1.156E-05 | global batch size:    48 | lm loss: 5.592298E+00 | loss scale: 32768.0 | grad norm: 2.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      754/    1200 | consumed samples:        36192 | elapsed time per iteration (ms): 990.7 | learning rate: 1.158E-05 | global batch size:    48 | lm loss: 5.543571E+00 | loss scale: 32768.0 | grad norm: 2.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      755/    1200 | consumed samples:        36240 | elapsed time per iteration (ms): 1127.5 | learning rate: 1.159E-05 | global batch size:    48 | lm loss: 5.462372E+00 | loss scale: 32768.0 | grad norm: 2.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      756/    1200 | consumed samples:        36288 | elapsed time per iteration (ms): 1175.8 | learning rate: 1.161E-05 | global batch size:    48 | lm loss: 5.505880E+00 | loss scale: 32768.0 | grad norm: 2.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      757/    1200 | consumed samples:        36336 | elapsed time per iteration (ms): 984.2 | learning rate: 1.162E-05 | global batch size:    48 | lm loss: 5.457506E+00 | loss scale: 32768.0 | grad norm: 2.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      758/    1200 | consumed samples:        36384 | elapsed time per iteration (ms): 1342.3 | learning rate: 1.164E-05 | global batch size:    48 | lm loss: 5.457657E+00 | loss scale: 32768.0 | grad norm: 2.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      759/    1200 | consumed samples:        36432 | elapsed time per iteration (ms): 1108.8 | learning rate: 1.165E-05 | global batch size:    48 | lm loss: 5.423823E+00 | loss scale: 32768.0 | grad norm: 2.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      760/    1200 | consumed samples:        36480 | elapsed time per iteration (ms): 1239.7 | learning rate: 1.167E-05 | global batch size:    48 | lm loss: 5.485497E+00 | loss scale: 32768.0 | grad norm: 2.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      761/    1200 | consumed samples:        36528 | elapsed time per iteration (ms): 1000.0 | learning rate: 1.169E-05 | global batch size:    48 | lm loss: 5.556077E+00 | loss scale: 32768.0 | grad norm: 2.603 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      762/    1200 | consumed samples:        36576 | elapsed time per iteration (ms): 987.4 | learning rate: 1.170E-05 | global batch size:    48 | lm loss: 5.579818E+00 | loss scale: 32768.0 | grad norm: 2.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      763/    1200 | consumed samples:        36624 | elapsed time per iteration (ms): 1116.1 | learning rate: 1.172E-05 | global batch size:    48 | lm loss: 5.551191E+00 | loss scale: 32768.0 | grad norm: 2.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      764/    1200 | consumed samples:        36672 | elapsed time per iteration (ms): 1002.3 | learning rate: 1.173E-05 | global batch size:    48 | lm loss: 5.522882E+00 | loss scale: 32768.0 | grad norm: 2.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      765/    1200 | consumed samples:        36720 | elapsed time per iteration (ms): 1061.9 | learning rate: 1.175E-05 | global batch size:    48 | lm loss: 5.522019E+00 | loss scale: 32768.0 | grad norm: 3.562 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      766/    1200 | consumed samples:        36768 | elapsed time per iteration (ms): 1186.1 | learning rate: 1.177E-05 | global batch size:    48 | lm loss: 5.539761E+00 | loss scale: 32768.0 | grad norm: 2.697 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      767/    1200 | consumed samples:        36816 | elapsed time per iteration (ms): 1184.8 | learning rate: 1.178E-05 | global batch size:    48 | lm loss: 5.496333E+00 | loss scale: 32768.0 | grad norm: 2.603 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      768/    1200 | consumed samples:        36864 | elapsed time per iteration (ms): 1252.5 | learning rate: 1.180E-05 | global batch size:    48 | lm loss: 5.456583E+00 | loss scale: 32768.0 | grad norm: 2.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      769/    1200 | consumed samples:        36912 | elapsed time per iteration (ms): 1185.2 | learning rate: 1.181E-05 | global batch size:    48 | lm loss: 5.506619E+00 | loss scale: 32768.0 | grad norm: 3.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      770/    1200 | consumed samples:        36960 | elapsed time per iteration (ms): 985.0 | learning rate: 1.183E-05 | global batch size:    48 | lm loss: 5.475047E+00 | loss scale: 32768.0 | grad norm: 2.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      771/    1200 | consumed samples:        37008 | elapsed time per iteration (ms): 983.9 | learning rate: 1.184E-05 | global batch size:    48 | lm loss: 5.458865E+00 | loss scale: 32768.0 | grad norm: 2.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      772/    1200 | consumed samples:        37056 | elapsed time per iteration (ms): 1113.7 | learning rate: 1.186E-05 | global batch size:    48 | lm loss: 5.573987E+00 | loss scale: 32768.0 | grad norm: 2.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      773/    1200 | consumed samples:        37104 | elapsed time per iteration (ms): 1105.1 | learning rate: 1.188E-05 | global batch size:    48 | lm loss: 5.602847E+00 | loss scale: 32768.0 | grad norm: 2.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      774/    1200 | consumed samples:        37152 | elapsed time per iteration (ms): 1268.9 | learning rate: 1.189E-05 | global batch size:    48 | lm loss: 5.503812E+00 | loss scale: 32768.0 | grad norm: 2.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      775/    1200 | consumed samples:        37200 | elapsed time per iteration (ms): 988.9 | learning rate: 1.191E-05 | global batch size:    48 | lm loss: 5.550470E+00 | loss scale: 32768.0 | grad norm: 2.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      776/    1200 | consumed samples:        37248 | elapsed time per iteration (ms): 1093.2 | learning rate: 1.192E-05 | global batch size:    48 | lm loss: 5.627700E+00 | loss scale: 32768.0 | grad norm: 2.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      777/    1200 | consumed samples:        37296 | elapsed time per iteration (ms): 1124.4 | learning rate: 1.194E-05 | global batch size:    48 | lm loss: 5.475344E+00 | loss scale: 32768.0 | grad norm: 2.342 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      778/    1200 | consumed samples:        37344 | elapsed time per iteration (ms): 1112.1 | learning rate: 1.195E-05 | global batch size:    48 | lm loss: 5.417442E+00 | loss scale: 32768.0 | grad norm: 2.382 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      779/    1200 | consumed samples:        37392 | elapsed time per iteration (ms): 992.6 | learning rate: 1.197E-05 | global batch size:    48 | lm loss: 5.582599E+00 | loss scale: 32768.0 | grad norm: 2.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      780/    1200 | consumed samples:        37440 | elapsed time per iteration (ms): 1131.6 | learning rate: 1.199E-05 | global batch size:    48 | lm loss: 5.455300E+00 | loss scale: 32768.0 | grad norm: 2.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      781/    1200 | consumed samples:        37488 | elapsed time per iteration (ms): 3489.3 | learning rate: 1.200E-05 | global batch size:    48 | lm loss: 5.536092E+00 | loss scale: 32768.0 | grad norm: 2.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      782/    1200 | consumed samples:        37536 | elapsed time per iteration (ms): 3605.1 | learning rate: 1.202E-05 | global batch size:    48 | lm loss: 5.577540E+00 | loss scale: 32768.0 | grad norm: 2.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      783/    1200 | consumed samples:        37584 | elapsed time per iteration (ms): 3797.8 | learning rate: 1.203E-05 | global batch size:    48 | lm loss: 5.469798E+00 | loss scale: 32768.0 | grad norm: 2.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      784/    1200 | consumed samples:        37632 | elapsed time per iteration (ms): 3730.1 | learning rate: 1.205E-05 | global batch size:    48 | lm loss: 5.361318E+00 | loss scale: 32768.0 | grad norm: 2.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      785/    1200 | consumed samples:        37680 | elapsed time per iteration (ms): 3679.5 | learning rate: 1.206E-05 | global batch size:    48 | lm loss: 5.510927E+00 | loss scale: 32768.0 | grad norm: 2.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      786/    1200 | consumed samples:        37728 | elapsed time per iteration (ms): 3685.3 | learning rate: 1.208E-05 | global batch size:    48 | lm loss: 5.527412E+00 | loss scale: 32768.0 | grad norm: 2.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      787/    1200 | consumed samples:        37776 | elapsed time per iteration (ms): 3673.5 | learning rate: 1.210E-05 | global batch size:    48 | lm loss: 5.530210E+00 | loss scale: 32768.0 | grad norm: 2.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      788/    1200 | consumed samples:        37824 | elapsed time per iteration (ms): 3677.3 | learning rate: 1.211E-05 | global batch size:    48 | lm loss: 5.564691E+00 | loss scale: 32768.0 | grad norm: 2.303 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      789/    1200 | consumed samples:        37872 | elapsed time per iteration (ms): 3678.5 | learning rate: 1.213E-05 | global batch size:    48 | lm loss: 5.480924E+00 | loss scale: 32768.0 | grad norm: 2.380 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      790/    1200 | consumed samples:        37920 | elapsed time per iteration (ms): 3679.4 | learning rate: 1.214E-05 | global batch size:    48 | lm loss: 5.578163E+00 | loss scale: 32768.0 | grad norm: 2.544 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      791/    1200 | consumed samples:        37968 | elapsed time per iteration (ms): 3681.8 | learning rate: 1.216E-05 | global batch size:    48 | lm loss: 5.419467E+00 | loss scale: 32768.0 | grad norm: 2.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      792/    1200 | consumed samples:        38016 | elapsed time per iteration (ms): 3681.4 | learning rate: 1.217E-05 | global batch size:    48 | lm loss: 5.464181E+00 | loss scale: 32768.0 | grad norm: 2.503 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      793/    1200 | consumed samples:        38064 | elapsed time per iteration (ms): 3683.7 | learning rate: 1.219E-05 | global batch size:    48 | lm loss: 5.483831E+00 | loss scale: 32768.0 | grad norm: 2.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      794/    1200 | consumed samples:        38112 | elapsed time per iteration (ms): 3801.6 | learning rate: 1.221E-05 | global batch size:    48 | lm loss: 5.532978E+00 | loss scale: 32768.0 | grad norm: 2.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      795/    1200 | consumed samples:        38160 | elapsed time per iteration (ms): 3733.0 | learning rate: 1.222E-05 | global batch size:    48 | lm loss: 5.522784E+00 | loss scale: 32768.0 | grad norm: 2.541 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      796/    1200 | consumed samples:        38208 | elapsed time per iteration (ms): 3731.9 | learning rate: 1.224E-05 | global batch size:    48 | lm loss: 5.518848E+00 | loss scale: 32768.0 | grad norm: 2.324 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      797/    1200 | consumed samples:        38256 | elapsed time per iteration (ms): 3687.6 | learning rate: 1.225E-05 | global batch size:    48 | lm loss: 5.513522E+00 | loss scale: 32768.0 | grad norm: 2.339 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      798/    1200 | consumed samples:        38304 | elapsed time per iteration (ms): 3697.8 | learning rate: 1.227E-05 | global batch size:    48 | lm loss: 5.470565E+00 | loss scale: 32768.0 | grad norm: 2.283 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      799/    1200 | consumed samples:        38352 | elapsed time per iteration (ms): 3677.1 | learning rate: 1.228E-05 | global batch size:    48 | lm loss: 5.485578E+00 | loss scale: 32768.0 | grad norm: 2.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      800/    1200 | consumed samples:        38400 | elapsed time per iteration (ms): 3676.3 | learning rate: 1.230E-05 | global batch size:    48 | lm loss: 5.444950E+00 | loss scale: 32768.0 | grad norm: 2.281 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      801/    1200 | consumed samples:        38448 | elapsed time per iteration (ms): 3679.6 | learning rate: 1.232E-05 | global batch size:    48 | lm loss: 5.443977E+00 | loss scale: 32768.0 | grad norm: 2.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      802/    1200 | consumed samples:        38496 | elapsed time per iteration (ms): 3680.4 | learning rate: 1.233E-05 | global batch size:    48 | lm loss: 5.376432E+00 | loss scale: 32768.0 | grad norm: 2.361 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      803/    1200 | consumed samples:        38544 | elapsed time per iteration (ms): 3691.1 | learning rate: 1.235E-05 | global batch size:    48 | lm loss: 5.481748E+00 | loss scale: 32768.0 | grad norm: 2.549 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      804/    1200 | consumed samples:        38592 | elapsed time per iteration (ms): 3682.6 | learning rate: 1.236E-05 | global batch size:    48 | lm loss: 5.534134E+00 | loss scale: 32768.0 | grad norm: 2.560 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      805/    1200 | consumed samples:        38640 | elapsed time per iteration (ms): 3689.7 | learning rate: 1.238E-05 | global batch size:    48 | lm loss: 5.492652E+00 | loss scale: 32768.0 | grad norm: 2.353 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      806/    1200 | consumed samples:        38688 | elapsed time per iteration (ms): 3682.7 | learning rate: 1.239E-05 | global batch size:    48 | lm loss: 5.379862E+00 | loss scale: 32768.0 | grad norm: 2.334 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      807/    1200 | consumed samples:        38736 | elapsed time per iteration (ms): 3814.7 | learning rate: 1.241E-05 | global batch size:    48 | lm loss: 5.524252E+00 | loss scale: 32768.0 | grad norm: 2.377 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      808/    1200 | consumed samples:        38784 | elapsed time per iteration (ms): 3745.9 | learning rate: 1.243E-05 | global batch size:    48 | lm loss: 5.440220E+00 | loss scale: 32768.0 | grad norm: 2.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      809/    1200 | consumed samples:        38832 | elapsed time per iteration (ms): 3679.1 | learning rate: 1.244E-05 | global batch size:    48 | lm loss: 5.382272E+00 | loss scale: 32768.0 | grad norm: 2.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      810/    1200 | consumed samples:        38880 | elapsed time per iteration (ms): 3680.0 | learning rate: 1.246E-05 | global batch size:    48 | lm loss: 5.421231E+00 | loss scale: 32768.0 | grad norm: 2.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      811/    1200 | consumed samples:        38928 | elapsed time per iteration (ms): 3678.4 | learning rate: 1.247E-05 | global batch size:    48 | lm loss: 5.397901E+00 | loss scale: 32768.0 | grad norm: 2.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      812/    1200 | consumed samples:        38976 | elapsed time per iteration (ms): 3679.6 | learning rate: 1.249E-05 | global batch size:    48 | lm loss: 5.545994E+00 | loss scale: 32768.0 | grad norm: 2.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      813/    1200 | consumed samples:        39024 | elapsed time per iteration (ms): 3675.0 | learning rate: 1.250E-05 | global batch size:    48 | lm loss: 5.515886E+00 | loss scale: 32768.0 | grad norm: 2.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      814/    1200 | consumed samples:        39072 | elapsed time per iteration (ms): 3677.0 | learning rate: 1.252E-05 | global batch size:    48 | lm loss: 5.436428E+00 | loss scale: 32768.0 | grad norm: 2.321 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      815/    1200 | consumed samples:        39120 | elapsed time per iteration (ms): 3678.1 | learning rate: 1.254E-05 | global batch size:    48 | lm loss: 5.416109E+00 | loss scale: 32768.0 | grad norm: 2.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      816/    1200 | consumed samples:        39168 | elapsed time per iteration (ms): 3696.3 | learning rate: 1.255E-05 | global batch size:    48 | lm loss: 5.594018E+00 | loss scale: 32768.0 | grad norm: 2.560 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      817/    1200 | consumed samples:        39216 | elapsed time per iteration (ms): 3693.5 | learning rate: 1.257E-05 | global batch size:    48 | lm loss: 5.353107E+00 | loss scale: 32768.0 | grad norm: 2.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      818/    1200 | consumed samples:        39264 | elapsed time per iteration (ms): 3680.0 | learning rate: 1.258E-05 | global batch size:    48 | lm loss: 5.457659E+00 | loss scale: 32768.0 | grad norm: 2.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      819/    1200 | consumed samples:        39312 | elapsed time per iteration (ms): 3683.8 | learning rate: 1.260E-05 | global batch size:    48 | lm loss: 5.352858E+00 | loss scale: 32768.0 | grad norm: 2.265 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      820/    1200 | consumed samples:        39360 | elapsed time per iteration (ms): 3845.9 | learning rate: 1.261E-05 | global batch size:    48 | lm loss: 5.476285E+00 | loss scale: 32768.0 | grad norm: 2.293 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      821/    1200 | consumed samples:        39408 | elapsed time per iteration (ms): 3686.8 | learning rate: 1.263E-05 | global batch size:    48 | lm loss: 5.404094E+00 | loss scale: 32768.0 | grad norm: 2.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      822/    1200 | consumed samples:        39456 | elapsed time per iteration (ms): 3677.4 | learning rate: 1.265E-05 | global batch size:    48 | lm loss: 5.493828E+00 | loss scale: 32768.0 | grad norm: 2.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      823/    1200 | consumed samples:        39504 | elapsed time per iteration (ms): 3760.9 | learning rate: 1.266E-05 | global batch size:    48 | lm loss: 5.433787E+00 | loss scale: 32768.0 | grad norm: 2.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      824/    1200 | consumed samples:        39552 | elapsed time per iteration (ms): 3679.1 | learning rate: 1.268E-05 | global batch size:    48 | lm loss: 5.406714E+00 | loss scale: 32768.0 | grad norm: 2.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      825/    1200 | consumed samples:        39600 | elapsed time per iteration (ms): 3683.8 | learning rate: 1.269E-05 | global batch size:    48 | lm loss: 5.529772E+00 | loss scale: 32768.0 | grad norm: 2.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      826/    1200 | consumed samples:        39648 | elapsed time per iteration (ms): 3675.2 | learning rate: 1.271E-05 | global batch size:    48 | lm loss: 5.529005E+00 | loss scale: 32768.0 | grad norm: 2.361 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      827/    1200 | consumed samples:        39696 | elapsed time per iteration (ms): 3684.8 | learning rate: 1.272E-05 | global batch size:    48 | lm loss: 5.445111E+00 | loss scale: 32768.0 | grad norm: 2.267 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      828/    1200 | consumed samples:        39744 | elapsed time per iteration (ms): 3680.7 | learning rate: 1.274E-05 | global batch size:    48 | lm loss: 5.426070E+00 | loss scale: 32768.0 | grad norm: 2.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      829/    1200 | consumed samples:        39792 | elapsed time per iteration (ms): 3696.2 | learning rate: 1.276E-05 | global batch size:    48 | lm loss: 5.424414E+00 | loss scale: 32768.0 | grad norm: 2.607 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      830/    1200 | consumed samples:        39840 | elapsed time per iteration (ms): 3684.3 | learning rate: 1.277E-05 | global batch size:    48 | lm loss: 5.483696E+00 | loss scale: 32768.0 | grad norm: 2.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      831/    1200 | consumed samples:        39888 | elapsed time per iteration (ms): 3681.6 | learning rate: 1.279E-05 | global batch size:    48 | lm loss: 5.545485E+00 | loss scale: 32768.0 | grad norm: 2.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      832/    1200 | consumed samples:        39936 | elapsed time per iteration (ms): 3790.6 | learning rate: 1.280E-05 | global batch size:    48 | lm loss: 5.551408E+00 | loss scale: 32768.0 | grad norm: 2.247 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      833/    1200 | consumed samples:        39984 | elapsed time per iteration (ms): 3684.8 | learning rate: 1.282E-05 | global batch size:    48 | lm loss: 5.541874E+00 | loss scale: 32768.0 | grad norm: 2.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      834/    1200 | consumed samples:        40032 | elapsed time per iteration (ms): 3683.4 | learning rate: 1.283E-05 | global batch size:    48 | lm loss: 5.421719E+00 | loss scale: 32768.0 | grad norm: 2.232 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      835/    1200 | consumed samples:        40080 | elapsed time per iteration (ms): 3808.9 | learning rate: 1.285E-05 | global batch size:    48 | lm loss: 5.485797E+00 | loss scale: 32768.0 | grad norm: 2.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      836/    1200 | consumed samples:        40128 | elapsed time per iteration (ms): 3681.5 | learning rate: 1.287E-05 | global batch size:    48 | lm loss: 5.434165E+00 | loss scale: 32768.0 | grad norm: 2.231 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      837/    1200 | consumed samples:        40176 | elapsed time per iteration (ms): 3679.1 | learning rate: 1.288E-05 | global batch size:    48 | lm loss: 5.396530E+00 | loss scale: 32768.0 | grad norm: 2.360 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      838/    1200 | consumed samples:        40224 | elapsed time per iteration (ms): 3695.9 | learning rate: 1.290E-05 | global batch size:    48 | lm loss: 5.416174E+00 | loss scale: 32768.0 | grad norm: 2.370 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      839/    1200 | consumed samples:        40272 | elapsed time per iteration (ms): 3759.2 | learning rate: 1.291E-05 | global batch size:    48 | lm loss: 5.303308E+00 | loss scale: 32768.0 | grad norm: 2.257 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      840/    1200 | consumed samples:        40320 | elapsed time per iteration (ms): 3678.1 | learning rate: 1.293E-05 | global batch size:    48 | lm loss: 5.463858E+00 | loss scale: 32768.0 | grad norm: 2.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      841/    1200 | consumed samples:        40368 | elapsed time per iteration (ms): 3680.2 | learning rate: 1.294E-05 | global batch size:    48 | lm loss: 5.244742E+00 | loss scale: 32768.0 | grad norm: 2.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      842/    1200 | consumed samples:        40416 | elapsed time per iteration (ms): 3678.0 | learning rate: 1.296E-05 | global batch size:    48 | lm loss: 5.415333E+00 | loss scale: 32768.0 | grad norm: 2.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      843/    1200 | consumed samples:        40464 | elapsed time per iteration (ms): 3683.9 | learning rate: 1.298E-05 | global batch size:    48 | lm loss: 5.474327E+00 | loss scale: 32768.0 | grad norm: 2.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      844/    1200 | consumed samples:        40512 | elapsed time per iteration (ms): 3738.5 | learning rate: 1.299E-05 | global batch size:    48 | lm loss: 5.605348E+00 | loss scale: 32768.0 | grad norm: 3.511 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      845/    1200 | consumed samples:        40560 | elapsed time per iteration (ms): 3681.6 | learning rate: 1.301E-05 | global batch size:    48 | lm loss: 5.425945E+00 | loss scale: 32768.0 | grad norm: 2.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      846/    1200 | consumed samples:        40608 | elapsed time per iteration (ms): 3684.0 | learning rate: 1.302E-05 | global batch size:    48 | lm loss: 5.422916E+00 | loss scale: 32768.0 | grad norm: 2.494 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      847/    1200 | consumed samples:        40656 | elapsed time per iteration (ms): 3681.4 | learning rate: 1.304E-05 | global batch size:    48 | lm loss: 5.446896E+00 | loss scale: 32768.0 | grad norm: 2.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      848/    1200 | consumed samples:        40704 | elapsed time per iteration (ms): 3682.1 | learning rate: 1.305E-05 | global batch size:    48 | lm loss: 5.360649E+00 | loss scale: 32768.0 | grad norm: 2.206 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      849/    1200 | consumed samples:        40752 | elapsed time per iteration (ms): 3684.1 | learning rate: 1.307E-05 | global batch size:    48 | lm loss: 5.370889E+00 | loss scale: 32768.0 | grad norm: 2.382 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      850/    1200 | consumed samples:        40800 | elapsed time per iteration (ms): 3680.5 | learning rate: 1.309E-05 | global batch size:    48 | lm loss: 5.507901E+00 | loss scale: 32768.0 | grad norm: 2.186 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      851/    1200 | consumed samples:        40848 | elapsed time per iteration (ms): 2747.4 | learning rate: 1.310E-05 | global batch size:    48 | lm loss: 5.498945E+00 | loss scale: 32768.0 | grad norm: 2.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      852/    1200 | consumed samples:        40896 | elapsed time per iteration (ms): 1244.9 | learning rate: 1.312E-05 | global batch size:    48 | lm loss: 5.357229E+00 | loss scale: 32768.0 | grad norm: 2.251 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      853/    1200 | consumed samples:        40944 | elapsed time per iteration (ms): 989.9 | learning rate: 1.313E-05 | global batch size:    48 | lm loss: 5.381241E+00 | loss scale: 32768.0 | grad norm: 2.245 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      854/    1200 | consumed samples:        40992 | elapsed time per iteration (ms): 1060.8 | learning rate: 1.315E-05 | global batch size:    48 | lm loss: 5.414241E+00 | loss scale: 32768.0 | grad norm: 2.348 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      855/    1200 | consumed samples:        41040 | elapsed time per iteration (ms): 1071.8 | learning rate: 1.316E-05 | global batch size:    48 | lm loss: 5.420888E+00 | loss scale: 32768.0 | grad norm: 2.280 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      856/    1200 | consumed samples:        41088 | elapsed time per iteration (ms): 1121.9 | learning rate: 1.318E-05 | global batch size:    48 | lm loss: 5.496469E+00 | loss scale: 32768.0 | grad norm: 2.272 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      857/    1200 | consumed samples:        41136 | elapsed time per iteration (ms): 1015.5 | learning rate: 1.320E-05 | global batch size:    48 | lm loss: 5.485222E+00 | loss scale: 32768.0 | grad norm: 2.163 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      858/    1200 | consumed samples:        41184 | elapsed time per iteration (ms): 1116.7 | learning rate: 1.321E-05 | global batch size:    48 | lm loss: 5.398844E+00 | loss scale: 32768.0 | grad norm: 2.335 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      859/    1200 | consumed samples:        41232 | elapsed time per iteration (ms): 1119.4 | learning rate: 1.323E-05 | global batch size:    48 | lm loss: 5.471913E+00 | loss scale: 32768.0 | grad norm: 2.219 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      860/    1200 | consumed samples:        41280 | elapsed time per iteration (ms): 1114.1 | learning rate: 1.324E-05 | global batch size:    48 | lm loss: 5.433292E+00 | loss scale: 32768.0 | grad norm: 2.226 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      861/    1200 | consumed samples:        41328 | elapsed time per iteration (ms): 986.5 | learning rate: 1.326E-05 | global batch size:    48 | lm loss: 5.369486E+00 | loss scale: 32768.0 | grad norm: 2.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      862/    1200 | consumed samples:        41376 | elapsed time per iteration (ms): 1062.3 | learning rate: 1.328E-05 | global batch size:    48 | lm loss: 5.469022E+00 | loss scale: 32768.0 | grad norm: 2.276 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      863/    1200 | consumed samples:        41424 | elapsed time per iteration (ms): 983.9 | learning rate: 1.329E-05 | global batch size:    48 | lm loss: 5.438096E+00 | loss scale: 32768.0 | grad norm: 2.181 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      864/    1200 | consumed samples:        41472 | elapsed time per iteration (ms): 1198.2 | learning rate: 1.331E-05 | global batch size:    48 | lm loss: 5.399097E+00 | loss scale: 32768.0 | grad norm: 2.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      865/    1200 | consumed samples:        41520 | elapsed time per iteration (ms): 985.9 | learning rate: 1.332E-05 | global batch size:    48 | lm loss: 5.365270E+00 | loss scale: 32768.0 | grad norm: 2.141 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      866/    1200 | consumed samples:        41568 | elapsed time per iteration (ms): 980.2 | learning rate: 1.334E-05 | global batch size:    48 | lm loss: 5.362766E+00 | loss scale: 32768.0 | grad norm: 2.271 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      867/    1200 | consumed samples:        41616 | elapsed time per iteration (ms): 1379.6 | learning rate: 1.335E-05 | global batch size:    48 | lm loss: 5.284436E+00 | loss scale: 32768.0 | grad norm: 2.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      868/    1200 | consumed samples:        41664 | elapsed time per iteration (ms): 1220.0 | learning rate: 1.337E-05 | global batch size:    48 | lm loss: 5.326640E+00 | loss scale: 32768.0 | grad norm: 2.206 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      869/    1200 | consumed samples:        41712 | elapsed time per iteration (ms): 1210.8 | learning rate: 1.339E-05 | global batch size:    48 | lm loss: 5.432117E+00 | loss scale: 32768.0 | grad norm: 2.143 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      870/    1200 | consumed samples:        41760 | elapsed time per iteration (ms): 1066.6 | learning rate: 1.340E-05 | global batch size:    48 | lm loss: 5.442159E+00 | loss scale: 32768.0 | grad norm: 2.274 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      871/    1200 | consumed samples:        41808 | elapsed time per iteration (ms): 988.2 | learning rate: 1.342E-05 | global batch size:    48 | lm loss: 5.463189E+00 | loss scale: 32768.0 | grad norm: 2.311 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      872/    1200 | consumed samples:        41856 | elapsed time per iteration (ms): 1075.2 | learning rate: 1.343E-05 | global batch size:    48 | lm loss: 5.370227E+00 | loss scale: 32768.0 | grad norm: 2.174 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      873/    1200 | consumed samples:        41904 | elapsed time per iteration (ms): 1053.0 | learning rate: 1.345E-05 | global batch size:    48 | lm loss: 5.372711E+00 | loss scale: 32768.0 | grad norm: 2.229 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      874/    1200 | consumed samples:        41952 | elapsed time per iteration (ms): 1122.5 | learning rate: 1.346E-05 | global batch size:    48 | lm loss: 5.401742E+00 | loss scale: 32768.0 | grad norm: 2.163 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      875/    1200 | consumed samples:        42000 | elapsed time per iteration (ms): 985.8 | learning rate: 1.348E-05 | global batch size:    48 | lm loss: 5.393534E+00 | loss scale: 32768.0 | grad norm: 2.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      876/    1200 | consumed samples:        42048 | elapsed time per iteration (ms): 1304.5 | learning rate: 1.350E-05 | global batch size:    48 | lm loss: 5.441651E+00 | loss scale: 32768.0 | grad norm: 2.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      877/    1200 | consumed samples:        42096 | elapsed time per iteration (ms): 1249.4 | learning rate: 1.351E-05 | global batch size:    48 | lm loss: 5.331880E+00 | loss scale: 32768.0 | grad norm: 2.269 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      878/    1200 | consumed samples:        42144 | elapsed time per iteration (ms): 1077.3 | learning rate: 1.353E-05 | global batch size:    48 | lm loss: 5.370950E+00 | loss scale: 32768.0 | grad norm: 2.194 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      879/    1200 | consumed samples:        42192 | elapsed time per iteration (ms): 988.2 | learning rate: 1.354E-05 | global batch size:    48 | lm loss: 5.352870E+00 | loss scale: 32768.0 | grad norm: 2.194 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      880/    1200 | consumed samples:        42240 | elapsed time per iteration (ms): 1220.8 | learning rate: 1.356E-05 | global batch size:    48 | lm loss: 5.378570E+00 | loss scale: 32768.0 | grad norm: 2.308 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      881/    1200 | consumed samples:        42288 | elapsed time per iteration (ms): 997.3 | learning rate: 1.357E-05 | global batch size:    48 | lm loss: 5.389646E+00 | loss scale: 32768.0 | grad norm: 2.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      882/    1200 | consumed samples:        42336 | elapsed time per iteration (ms): 1183.7 | learning rate: 1.359E-05 | global batch size:    48 | lm loss: 5.420646E+00 | loss scale: 32768.0 | grad norm: 2.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      883/    1200 | consumed samples:        42384 | elapsed time per iteration (ms): 992.1 | learning rate: 1.361E-05 | global batch size:    48 | lm loss: 5.388428E+00 | loss scale: 32768.0 | grad norm: 2.111 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      884/    1200 | consumed samples:        42432 | elapsed time per iteration (ms): 996.2 | learning rate: 1.362E-05 | global batch size:    48 | lm loss: 5.350700E+00 | loss scale: 32768.0 | grad norm: 2.096 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      885/    1200 | consumed samples:        42480 | elapsed time per iteration (ms): 1132.0 | learning rate: 1.364E-05 | global batch size:    48 | lm loss: 5.376829E+00 | loss scale: 32768.0 | grad norm: 2.283 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      886/    1200 | consumed samples:        42528 | elapsed time per iteration (ms): 1195.1 | learning rate: 1.365E-05 | global batch size:    48 | lm loss: 5.389271E+00 | loss scale: 32768.0 | grad norm: 2.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      887/    1200 | consumed samples:        42576 | elapsed time per iteration (ms): 1081.7 | learning rate: 1.367E-05 | global batch size:    48 | lm loss: 5.431245E+00 | loss scale: 32768.0 | grad norm: 2.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      888/    1200 | consumed samples:        42624 | elapsed time per iteration (ms): 1127.6 | learning rate: 1.368E-05 | global batch size:    48 | lm loss: 5.315621E+00 | loss scale: 32768.0 | grad norm: 2.242 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      889/    1200 | consumed samples:        42672 | elapsed time per iteration (ms): 1056.3 | learning rate: 1.370E-05 | global batch size:    48 | lm loss: 5.425539E+00 | loss scale: 32768.0 | grad norm: 2.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      890/    1200 | consumed samples:        42720 | elapsed time per iteration (ms): 991.6 | learning rate: 1.372E-05 | global batch size:    48 | lm loss: 5.377145E+00 | loss scale: 32768.0 | grad norm: 2.122 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      891/    1200 | consumed samples:        42768 | elapsed time per iteration (ms): 2132.4 | learning rate: 1.373E-05 | global batch size:    48 | lm loss: 5.378523E+00 | loss scale: 32768.0 | grad norm: 2.178 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      892/    1200 | consumed samples:        42816 | elapsed time per iteration (ms): 4319.4 | learning rate: 1.375E-05 | global batch size:    48 | lm loss: 5.331471E+00 | loss scale: 32768.0 | grad norm: 2.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      893/    1200 | consumed samples:        42864 | elapsed time per iteration (ms): 4324.7 | learning rate: 1.376E-05 | global batch size:    48 | lm loss: 5.454193E+00 | loss scale: 32768.0 | grad norm: 2.282 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      894/    1200 | consumed samples:        42912 | elapsed time per iteration (ms): 4457.5 | learning rate: 1.378E-05 | global batch size:    48 | lm loss: 5.349380E+00 | loss scale: 32768.0 | grad norm: 2.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      895/    1200 | consumed samples:        42960 | elapsed time per iteration (ms): 4394.8 | learning rate: 1.379E-05 | global batch size:    48 | lm loss: 5.484076E+00 | loss scale: 32768.0 | grad norm: 2.211 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      896/    1200 | consumed samples:        43008 | elapsed time per iteration (ms): 4330.0 | learning rate: 1.381E-05 | global batch size:    48 | lm loss: 5.424507E+00 | loss scale: 32768.0 | grad norm: 2.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      897/    1200 | consumed samples:        43056 | elapsed time per iteration (ms): 4333.8 | learning rate: 1.383E-05 | global batch size:    48 | lm loss: 5.387091E+00 | loss scale: 32768.0 | grad norm: 2.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      898/    1200 | consumed samples:        43104 | elapsed time per iteration (ms): 4372.0 | learning rate: 1.384E-05 | global batch size:    48 | lm loss: 5.435967E+00 | loss scale: 32768.0 | grad norm: 2.237 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      899/    1200 | consumed samples:        43152 | elapsed time per iteration (ms): 4327.2 | learning rate: 1.386E-05 | global batch size:    48 | lm loss: 5.446953E+00 | loss scale: 32768.0 | grad norm: 2.222 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      900/    1200 | consumed samples:        43200 | elapsed time per iteration (ms): 4328.5 | learning rate: 1.387E-05 | global batch size:    48 | lm loss: 5.319027E+00 | loss scale: 32768.0 | grad norm: 2.193 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      901/    1200 | consumed samples:        43248 | elapsed time per iteration (ms): 4323.3 | learning rate: 1.389E-05 | global batch size:    48 | lm loss: 5.325671E+00 | loss scale: 32768.0 | grad norm: 2.111 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      902/    1200 | consumed samples:        43296 | elapsed time per iteration (ms): 4325.0 | learning rate: 1.390E-05 | global batch size:    48 | lm loss: 5.431348E+00 | loss scale: 32768.0 | grad norm: 2.208 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      903/    1200 | consumed samples:        43344 | elapsed time per iteration (ms): 4457.1 | learning rate: 1.392E-05 | global batch size:    48 | lm loss: 5.403788E+00 | loss scale: 32768.0 | grad norm: 2.164 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      904/    1200 | consumed samples:        43392 | elapsed time per iteration (ms): 4393.8 | learning rate: 1.394E-05 | global batch size:    48 | lm loss: 5.357517E+00 | loss scale: 32768.0 | grad norm: 2.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      905/    1200 | consumed samples:        43440 | elapsed time per iteration (ms): 4439.2 | learning rate: 1.395E-05 | global batch size:    48 | lm loss: 5.409412E+00 | loss scale: 32768.0 | grad norm: 2.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      906/    1200 | consumed samples:        43488 | elapsed time per iteration (ms): 4319.4 | learning rate: 1.397E-05 | global batch size:    48 | lm loss: 5.355636E+00 | loss scale: 32768.0 | grad norm: 2.109 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      907/    1200 | consumed samples:        43536 | elapsed time per iteration (ms): 4333.2 | learning rate: 1.398E-05 | global batch size:    48 | lm loss: 5.415144E+00 | loss scale: 32768.0 | grad norm: 2.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      908/    1200 | consumed samples:        43584 | elapsed time per iteration (ms): 4321.1 | learning rate: 1.400E-05 | global batch size:    48 | lm loss: 5.421564E+00 | loss scale: 32768.0 | grad norm: 2.111 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      909/    1200 | consumed samples:        43632 | elapsed time per iteration (ms): 4345.2 | learning rate: 1.401E-05 | global batch size:    48 | lm loss: 5.411111E+00 | loss scale: 32768.0 | grad norm: 2.128 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      910/    1200 | consumed samples:        43680 | elapsed time per iteration (ms): 4324.8 | learning rate: 1.403E-05 | global batch size:    48 | lm loss: 5.419589E+00 | loss scale: 32768.0 | grad norm: 2.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      911/    1200 | consumed samples:        43728 | elapsed time per iteration (ms): 4349.2 | learning rate: 1.405E-05 | global batch size:    48 | lm loss: 5.422302E+00 | loss scale: 32768.0 | grad norm: 2.237 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      912/    1200 | consumed samples:        43776 | elapsed time per iteration (ms): 4445.0 | learning rate: 1.406E-05 | global batch size:    48 | lm loss: 5.441350E+00 | loss scale: 32768.0 | grad norm: 2.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      913/    1200 | consumed samples:        43824 | elapsed time per iteration (ms): 4500.0 | learning rate: 1.408E-05 | global batch size:    48 | lm loss: 5.419437E+00 | loss scale: 32768.0 | grad norm: 2.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      914/    1200 | consumed samples:        43872 | elapsed time per iteration (ms): 4329.5 | learning rate: 1.409E-05 | global batch size:    48 | lm loss: 5.336390E+00 | loss scale: 32768.0 | grad norm: 2.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      915/    1200 | consumed samples:        43920 | elapsed time per iteration (ms): 4315.9 | learning rate: 1.411E-05 | global batch size:    48 | lm loss: 5.382913E+00 | loss scale: 32768.0 | grad norm: 2.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      916/    1200 | consumed samples:        43968 | elapsed time per iteration (ms): 4317.9 | learning rate: 1.412E-05 | global batch size:    48 | lm loss: 5.404307E+00 | loss scale: 32768.0 | grad norm: 2.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      917/    1200 | consumed samples:        44016 | elapsed time per iteration (ms): 4317.4 | learning rate: 1.414E-05 | global batch size:    48 | lm loss: 5.398565E+00 | loss scale: 32768.0 | grad norm: 2.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      918/    1200 | consumed samples:        44064 | elapsed time per iteration (ms): 4334.9 | learning rate: 1.416E-05 | global batch size:    48 | lm loss: 5.315106E+00 | loss scale: 32768.0 | grad norm: 2.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      919/    1200 | consumed samples:        44112 | elapsed time per iteration (ms): 4312.9 | learning rate: 1.417E-05 | global batch size:    48 | lm loss: 5.319882E+00 | loss scale: 32768.0 | grad norm: 1.966 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      920/    1200 | consumed samples:        44160 | elapsed time per iteration (ms): 4316.6 | learning rate: 1.419E-05 | global batch size:    48 | lm loss: 5.343845E+00 | loss scale: 32768.0 | grad norm: 2.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      921/    1200 | consumed samples:        44208 | elapsed time per iteration (ms): 4448.1 | learning rate: 1.420E-05 | global batch size:    48 | lm loss: 5.338015E+00 | loss scale: 32768.0 | grad norm: 1.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      922/    1200 | consumed samples:        44256 | elapsed time per iteration (ms): 4432.6 | learning rate: 1.422E-05 | global batch size:    48 | lm loss: 5.392763E+00 | loss scale: 32768.0 | grad norm: 2.178 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      923/    1200 | consumed samples:        44304 | elapsed time per iteration (ms): 4316.8 | learning rate: 1.423E-05 | global batch size:    48 | lm loss: 5.348396E+00 | loss scale: 32768.0 | grad norm: 2.114 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      924/    1200 | consumed samples:        44352 | elapsed time per iteration (ms): 4313.4 | learning rate: 1.425E-05 | global batch size:    48 | lm loss: 5.439630E+00 | loss scale: 32768.0 | grad norm: 2.255 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      925/    1200 | consumed samples:        44400 | elapsed time per iteration (ms): 4327.7 | learning rate: 1.427E-05 | global batch size:    48 | lm loss: 5.342073E+00 | loss scale: 32768.0 | grad norm: 2.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      926/    1200 | consumed samples:        44448 | elapsed time per iteration (ms): 4395.0 | learning rate: 1.428E-05 | global batch size:    48 | lm loss: 5.280492E+00 | loss scale: 32768.0 | grad norm: 2.123 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      927/    1200 | consumed samples:        44496 | elapsed time per iteration (ms): 4332.8 | learning rate: 1.430E-05 | global batch size:    48 | lm loss: 5.343188E+00 | loss scale: 32768.0 | grad norm: 2.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      928/    1200 | consumed samples:        44544 | elapsed time per iteration (ms): 4315.0 | learning rate: 1.431E-05 | global batch size:    48 | lm loss: 5.391634E+00 | loss scale: 32768.0 | grad norm: 2.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      929/    1200 | consumed samples:        44592 | elapsed time per iteration (ms): 4361.3 | learning rate: 1.433E-05 | global batch size:    48 | lm loss: 5.273501E+00 | loss scale: 32768.0 | grad norm: 2.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      930/    1200 | consumed samples:        44640 | elapsed time per iteration (ms): 4433.5 | learning rate: 1.434E-05 | global batch size:    48 | lm loss: 5.371200E+00 | loss scale: 32768.0 | grad norm: 2.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      931/    1200 | consumed samples:        44688 | elapsed time per iteration (ms): 4397.6 | learning rate: 1.436E-05 | global batch size:    48 | lm loss: 5.382995E+00 | loss scale: 32768.0 | grad norm: 1.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      932/    1200 | consumed samples:        44736 | elapsed time per iteration (ms): 4318.7 | learning rate: 1.438E-05 | global batch size:    48 | lm loss: 5.444175E+00 | loss scale: 32768.0 | grad norm: 2.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      933/    1200 | consumed samples:        44784 | elapsed time per iteration (ms): 4321.7 | learning rate: 1.439E-05 | global batch size:    48 | lm loss: 5.373208E+00 | loss scale: 32768.0 | grad norm: 2.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      934/    1200 | consumed samples:        44832 | elapsed time per iteration (ms): 4324.4 | learning rate: 1.441E-05 | global batch size:    48 | lm loss: 5.302575E+00 | loss scale: 32768.0 | grad norm: 2.017 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      935/    1200 | consumed samples:        44880 | elapsed time per iteration (ms): 4320.5 | learning rate: 1.442E-05 | global batch size:    48 | lm loss: 5.358648E+00 | loss scale: 32768.0 | grad norm: 2.148 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      936/    1200 | consumed samples:        44928 | elapsed time per iteration (ms): 4460.0 | learning rate: 1.444E-05 | global batch size:    48 | lm loss: 5.395832E+00 | loss scale: 32768.0 | grad norm: 1.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      937/    1200 | consumed samples:        44976 | elapsed time per iteration (ms): 4352.6 | learning rate: 1.445E-05 | global batch size:    48 | lm loss: 5.261187E+00 | loss scale: 32768.0 | grad norm: 1.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      938/    1200 | consumed samples:        45024 | elapsed time per iteration (ms): 4323.1 | learning rate: 1.447E-05 | global batch size:    48 | lm loss: 5.321157E+00 | loss scale: 32768.0 | grad norm: 2.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      939/    1200 | consumed samples:        45072 | elapsed time per iteration (ms): 4451.1 | learning rate: 1.449E-05 | global batch size:    48 | lm loss: 5.351512E+00 | loss scale: 32768.0 | grad norm: 1.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      940/    1200 | consumed samples:        45120 | elapsed time per iteration (ms): 4403.9 | learning rate: 1.450E-05 | global batch size:    48 | lm loss: 5.328983E+00 | loss scale: 32768.0 | grad norm: 1.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      941/    1200 | consumed samples:        45168 | elapsed time per iteration (ms): 4316.7 | learning rate: 1.452E-05 | global batch size:    48 | lm loss: 5.259965E+00 | loss scale: 32768.0 | grad norm: 1.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      942/    1200 | consumed samples:        45216 | elapsed time per iteration (ms): 4325.2 | learning rate: 1.453E-05 | global batch size:    48 | lm loss: 5.258333E+00 | loss scale: 32768.0 | grad norm: 1.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      943/    1200 | consumed samples:        45264 | elapsed time per iteration (ms): 4323.2 | learning rate: 1.455E-05 | global batch size:    48 | lm loss: 5.242837E+00 | loss scale: 32768.0 | grad norm: 2.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      944/    1200 | consumed samples:        45312 | elapsed time per iteration (ms): 4367.7 | learning rate: 1.456E-05 | global batch size:    48 | lm loss: 5.259479E+00 | loss scale: 32768.0 | grad norm: 1.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      945/    1200 | consumed samples:        45360 | elapsed time per iteration (ms): 4340.3 | learning rate: 1.458E-05 | global batch size:    48 | lm loss: 5.387245E+00 | loss scale: 32768.0 | grad norm: 2.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      946/    1200 | consumed samples:        45408 | elapsed time per iteration (ms): 4318.3 | learning rate: 1.460E-05 | global batch size:    48 | lm loss: 5.326796E+00 | loss scale: 32768.0 | grad norm: 2.197 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      947/    1200 | consumed samples:        45456 | elapsed time per iteration (ms): 4317.0 | learning rate: 1.461E-05 | global batch size:    48 | lm loss: 5.322133E+00 | loss scale: 32768.0 | grad norm: 2.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      948/    1200 | consumed samples:        45504 | elapsed time per iteration (ms): 4445.8 | learning rate: 1.463E-05 | global batch size:    48 | lm loss: 5.247158E+00 | loss scale: 32768.0 | grad norm: 1.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      949/    1200 | consumed samples:        45552 | elapsed time per iteration (ms): 4415.5 | learning rate: 1.464E-05 | global batch size:    48 | lm loss: 5.268214E+00 | loss scale: 32768.0 | grad norm: 1.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      950/    1200 | consumed samples:        45600 | elapsed time per iteration (ms): 4313.2 | learning rate: 1.466E-05 | global batch size:    48 | lm loss: 5.297424E+00 | loss scale: 32768.0 | grad norm: 1.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      951/    1200 | consumed samples:        45648 | elapsed time per iteration (ms): 4320.2 | learning rate: 1.467E-05 | global batch size:    48 | lm loss: 5.454578E+00 | loss scale: 32768.0 | grad norm: 3.245 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      952/    1200 | consumed samples:        45696 | elapsed time per iteration (ms): 4324.1 | learning rate: 1.469E-05 | global batch size:    48 | lm loss: 5.370189E+00 | loss scale: 32768.0 | grad norm: 2.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      953/    1200 | consumed samples:        45744 | elapsed time per iteration (ms): 4363.9 | learning rate: 1.471E-05 | global batch size:    48 | lm loss: 5.262938E+00 | loss scale: 32768.0 | grad norm: 1.884 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      954/    1200 | consumed samples:        45792 | elapsed time per iteration (ms): 4328.2 | learning rate: 1.472E-05 | global batch size:    48 | lm loss: 5.448331E+00 | loss scale: 32768.0 | grad norm: 2.121 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      955/    1200 | consumed samples:        45840 | elapsed time per iteration (ms): 4319.0 | learning rate: 1.474E-05 | global batch size:    48 | lm loss: 5.354673E+00 | loss scale: 32768.0 | grad norm: 1.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      956/    1200 | consumed samples:        45888 | elapsed time per iteration (ms): 4318.4 | learning rate: 1.475E-05 | global batch size:    48 | lm loss: 5.379384E+00 | loss scale: 32768.0 | grad norm: 1.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      957/    1200 | consumed samples:        45936 | elapsed time per iteration (ms): 4442.4 | learning rate: 1.477E-05 | global batch size:    48 | lm loss: 5.322406E+00 | loss scale: 32768.0 | grad norm: 1.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      958/    1200 | consumed samples:        45984 | elapsed time per iteration (ms): 4400.3 | learning rate: 1.478E-05 | global batch size:    48 | lm loss: 5.292779E+00 | loss scale: 32768.0 | grad norm: 2.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      959/    1200 | consumed samples:        46032 | elapsed time per iteration (ms): 4314.2 | learning rate: 1.480E-05 | global batch size:    48 | lm loss: 5.394316E+00 | loss scale: 32768.0 | grad norm: 1.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      960/    1200 | consumed samples:        46080 | elapsed time per iteration (ms): 4357.2 | learning rate: 1.482E-05 | global batch size:    48 | lm loss: 5.457209E+00 | loss scale: 32768.0 | grad norm: 2.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      961/    1200 | consumed samples:        46128 | elapsed time per iteration (ms): 1079.7 | learning rate: 1.483E-05 | global batch size:    48 | lm loss: 5.402864E+00 | loss scale: 32768.0 | grad norm: 2.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      962/    1200 | consumed samples:        46176 | elapsed time per iteration (ms): 1070.4 | learning rate: 1.485E-05 | global batch size:    48 | lm loss: 5.295024E+00 | loss scale: 32768.0 | grad norm: 2.097 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      963/    1200 | consumed samples:        46224 | elapsed time per iteration (ms): 1119.6 | learning rate: 1.486E-05 | global batch size:    48 | lm loss: 5.293596E+00 | loss scale: 32768.0 | grad norm: 2.220 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      964/    1200 | consumed samples:        46272 | elapsed time per iteration (ms): 1108.3 | learning rate: 1.488E-05 | global batch size:    48 | lm loss: 5.316105E+00 | loss scale: 32768.0 | grad norm: 2.111 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      965/    1200 | consumed samples:        46320 | elapsed time per iteration (ms): 986.4 | learning rate: 1.490E-05 | global batch size:    48 | lm loss: 5.276195E+00 | loss scale: 32768.0 | grad norm: 2.149 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      966/    1200 | consumed samples:        46368 | elapsed time per iteration (ms): 1250.7 | learning rate: 1.491E-05 | global batch size:    48 | lm loss: 5.371415E+00 | loss scale: 32768.0 | grad norm: 2.036 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      967/    1200 | consumed samples:        46416 | elapsed time per iteration (ms): 1228.0 | learning rate: 1.493E-05 | global batch size:    48 | lm loss: 5.238477E+00 | loss scale: 32768.0 | grad norm: 1.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      968/    1200 | consumed samples:        46464 | elapsed time per iteration (ms): 982.9 | learning rate: 1.494E-05 | global batch size:    48 | lm loss: 5.242381E+00 | loss scale: 32768.0 | grad norm: 2.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      969/    1200 | consumed samples:        46512 | elapsed time per iteration (ms): 988.0 | learning rate: 1.496E-05 | global batch size:    48 | lm loss: 5.338375E+00 | loss scale: 32768.0 | grad norm: 1.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      970/    1200 | consumed samples:        46560 | elapsed time per iteration (ms): 984.5 | learning rate: 1.497E-05 | global batch size:    48 | lm loss: 5.221804E+00 | loss scale: 32768.0 | grad norm: 2.143 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      971/    1200 | consumed samples:        46608 | elapsed time per iteration (ms): 1110.6 | learning rate: 1.499E-05 | global batch size:    48 | lm loss: 5.224671E+00 | loss scale: 32768.0 | grad norm: 1.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      972/    1200 | consumed samples:        46656 | elapsed time per iteration (ms): 1176.6 | learning rate: 1.501E-05 | global batch size:    48 | lm loss: 5.389687E+00 | loss scale: 32768.0 | grad norm: 2.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      973/    1200 | consumed samples:        46704 | elapsed time per iteration (ms): 980.0 | learning rate: 1.502E-05 | global batch size:    48 | lm loss: 5.287198E+00 | loss scale: 32768.0 | grad norm: 2.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      974/    1200 | consumed samples:        46752 | elapsed time per iteration (ms): 1061.4 | learning rate: 1.504E-05 | global batch size:    48 | lm loss: 5.302253E+00 | loss scale: 32768.0 | grad norm: 1.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      975/    1200 | consumed samples:        46800 | elapsed time per iteration (ms): 1312.2 | learning rate: 1.505E-05 | global batch size:    48 | lm loss: 5.326982E+00 | loss scale: 32768.0 | grad norm: 1.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      976/    1200 | consumed samples:        46848 | elapsed time per iteration (ms): 1213.7 | learning rate: 1.507E-05 | global batch size:    48 | lm loss: 5.298194E+00 | loss scale: 32768.0 | grad norm: 1.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      977/    1200 | consumed samples:        46896 | elapsed time per iteration (ms): 994.5 | learning rate: 1.508E-05 | global batch size:    48 | lm loss: 5.406635E+00 | loss scale: 32768.0 | grad norm: 1.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      978/    1200 | consumed samples:        46944 | elapsed time per iteration (ms): 992.2 | learning rate: 1.510E-05 | global batch size:    48 | lm loss: 5.246838E+00 | loss scale: 32768.0 | grad norm: 1.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      979/    1200 | consumed samples:        46992 | elapsed time per iteration (ms): 1113.2 | learning rate: 1.512E-05 | global batch size:    48 | lm loss: 5.222332E+00 | loss scale: 32768.0 | grad norm: 1.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      980/    1200 | consumed samples:        47040 | elapsed time per iteration (ms): 1112.7 | learning rate: 1.513E-05 | global batch size:    48 | lm loss: 5.329069E+00 | loss scale: 32768.0 | grad norm: 1.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      981/    1200 | consumed samples:        47088 | elapsed time per iteration (ms): 1175.4 | learning rate: 1.515E-05 | global batch size:    48 | lm loss: 5.239242E+00 | loss scale: 32768.0 | grad norm: 1.997 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      982/    1200 | consumed samples:        47136 | elapsed time per iteration (ms): 1061.1 | learning rate: 1.516E-05 | global batch size:    48 | lm loss: 5.222702E+00 | loss scale: 32768.0 | grad norm: 1.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      983/    1200 | consumed samples:        47184 | elapsed time per iteration (ms): 983.5 | learning rate: 1.518E-05 | global batch size:    48 | lm loss: 5.252219E+00 | loss scale: 32768.0 | grad norm: 1.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      984/    1200 | consumed samples:        47232 | elapsed time per iteration (ms): 1382.7 | learning rate: 1.519E-05 | global batch size:    48 | lm loss: 5.333379E+00 | loss scale: 32768.0 | grad norm: 1.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      985/    1200 | consumed samples:        47280 | elapsed time per iteration (ms): 1109.7 | learning rate: 1.521E-05 | global batch size:    48 | lm loss: 5.232484E+00 | loss scale: 32768.0 | grad norm: 1.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      986/    1200 | consumed samples:        47328 | elapsed time per iteration (ms): 986.5 | learning rate: 1.523E-05 | global batch size:    48 | lm loss: 5.360408E+00 | loss scale: 32768.0 | grad norm: 1.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      987/    1200 | consumed samples:        47376 | elapsed time per iteration (ms): 997.7 | learning rate: 1.524E-05 | global batch size:    48 | lm loss: 5.316395E+00 | loss scale: 32768.0 | grad norm: 1.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      988/    1200 | consumed samples:        47424 | elapsed time per iteration (ms): 1118.3 | learning rate: 1.526E-05 | global batch size:    48 | lm loss: 5.319571E+00 | loss scale: 32768.0 | grad norm: 1.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      989/    1200 | consumed samples:        47472 | elapsed time per iteration (ms): 1136.3 | learning rate: 1.527E-05 | global batch size:    48 | lm loss: 5.312449E+00 | loss scale: 32768.0 | grad norm: 1.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      990/    1200 | consumed samples:        47520 | elapsed time per iteration (ms): 1129.5 | learning rate: 1.529E-05 | global batch size:    48 | lm loss: 5.325766E+00 | loss scale: 32768.0 | grad norm: 1.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      991/    1200 | consumed samples:        47568 | elapsed time per iteration (ms): 1127.6 | learning rate: 1.530E-05 | global batch size:    48 | lm loss: 5.379059E+00 | loss scale: 32768.0 | grad norm: 1.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      992/    1200 | consumed samples:        47616 | elapsed time per iteration (ms): 1146.3 | learning rate: 1.532E-05 | global batch size:    48 | lm loss: 5.310579E+00 | loss scale: 32768.0 | grad norm: 1.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      993/    1200 | consumed samples:        47664 | elapsed time per iteration (ms): 1120.9 | learning rate: 1.534E-05 | global batch size:    48 | lm loss: 5.315054E+00 | loss scale: 32768.0 | grad norm: 1.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      994/    1200 | consumed samples:        47712 | elapsed time per iteration (ms): 1102.0 | learning rate: 1.535E-05 | global batch size:    48 | lm loss: 5.373178E+00 | loss scale: 32768.0 | grad norm: 1.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      995/    1200 | consumed samples:        47760 | elapsed time per iteration (ms): 981.6 | learning rate: 1.537E-05 | global batch size:    48 | lm loss: 5.271722E+00 | loss scale: 32768.0 | grad norm: 1.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      996/    1200 | consumed samples:        47808 | elapsed time per iteration (ms): 1115.2 | learning rate: 1.538E-05 | global batch size:    48 | lm loss: 5.212635E+00 | loss scale: 32768.0 | grad norm: 1.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      997/    1200 | consumed samples:        47856 | elapsed time per iteration (ms): 1117.6 | learning rate: 1.540E-05 | global batch size:    48 | lm loss: 5.350403E+00 | loss scale: 32768.0 | grad norm: 1.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      998/    1200 | consumed samples:        47904 | elapsed time per iteration (ms): 1294.1 | learning rate: 1.541E-05 | global batch size:    48 | lm loss: 5.259982E+00 | loss scale: 32768.0 | grad norm: 2.161 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      999/    1200 | consumed samples:        47952 | elapsed time per iteration (ms): 1123.3 | learning rate: 1.543E-05 | global batch size:    48 | lm loss: 5.239258E+00 | loss scale: 32768.0 | grad norm: 1.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1000/    1200 | consumed samples:        48000 | elapsed time per iteration (ms): 1121.9 | learning rate: 1.545E-05 | global batch size:    48 | lm loss: 5.302947E+00 | loss scale: 32768.0 | grad norm: 1.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1001/    1200 | consumed samples:        48048 | elapsed time per iteration (ms): 993.9 | learning rate: 1.546E-05 | global batch size:    48 | lm loss: 5.241693E+00 | loss scale: 32768.0 | grad norm: 1.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1002/    1200 | consumed samples:        48096 | elapsed time per iteration (ms): 1120.4 | learning rate: 1.548E-05 | global batch size:    48 | lm loss: 5.208323E+00 | loss scale: 32768.0 | grad norm: 1.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1003/    1200 | consumed samples:        48144 | elapsed time per iteration (ms): 1127.5 | learning rate: 1.549E-05 | global batch size:    48 | lm loss: 5.236437E+00 | loss scale: 32768.0 | grad norm: 1.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1004/    1200 | consumed samples:        48192 | elapsed time per iteration (ms): 1000.9 | learning rate: 1.551E-05 | global batch size:    48 | lm loss: 5.248371E+00 | loss scale: 32768.0 | grad norm: 1.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1005/    1200 | consumed samples:        48240 | elapsed time per iteration (ms): 995.2 | learning rate: 1.552E-05 | global batch size:    48 | lm loss: 5.247900E+00 | loss scale: 32768.0 | grad norm: 1.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1006/    1200 | consumed samples:        48288 | elapsed time per iteration (ms): 1196.5 | learning rate: 1.554E-05 | global batch size:    48 | lm loss: 5.253464E+00 | loss scale: 32768.0 | grad norm: 1.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1007/    1200 | consumed samples:        48336 | elapsed time per iteration (ms): 1173.8 | learning rate: 1.556E-05 | global batch size:    48 | lm loss: 5.309167E+00 | loss scale: 32768.0 | grad norm: 1.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1008/    1200 | consumed samples:        48384 | elapsed time per iteration (ms): 1178.8 | learning rate: 1.557E-05 | global batch size:    48 | lm loss: 5.271181E+00 | loss scale: 32768.0 | grad norm: 1.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1009/    1200 | consumed samples:        48432 | elapsed time per iteration (ms): 987.5 | learning rate: 1.559E-05 | global batch size:    48 | lm loss: 5.277896E+00 | loss scale: 32768.0 | grad norm: 1.876 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1010/    1200 | consumed samples:        48480 | elapsed time per iteration (ms): 991.2 | learning rate: 1.560E-05 | global batch size:    48 | lm loss: 5.217535E+00 | loss scale: 32768.0 | grad norm: 1.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1011/    1200 | consumed samples:        48528 | elapsed time per iteration (ms): 1197.6 | learning rate: 1.562E-05 | global batch size:    48 | lm loss: 5.191556E+00 | loss scale: 32768.0 | grad norm: 1.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1012/    1200 | consumed samples:        48576 | elapsed time per iteration (ms): 1246.6 | learning rate: 1.563E-05 | global batch size:    48 | lm loss: 5.290643E+00 | loss scale: 32768.0 | grad norm: 1.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1013/    1200 | consumed samples:        48624 | elapsed time per iteration (ms): 992.8 | learning rate: 1.565E-05 | global batch size:    48 | lm loss: 5.260194E+00 | loss scale: 32768.0 | grad norm: 1.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1014/    1200 | consumed samples:        48672 | elapsed time per iteration (ms): 1072.4 | learning rate: 1.567E-05 | global batch size:    48 | lm loss: 5.239328E+00 | loss scale: 32768.0 | grad norm: 1.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1015/    1200 | consumed samples:        48720 | elapsed time per iteration (ms): 1308.1 | learning rate: 1.568E-05 | global batch size:    48 | lm loss: 5.248993E+00 | loss scale: 32768.0 | grad norm: 1.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1016/    1200 | consumed samples:        48768 | elapsed time per iteration (ms): 991.7 | learning rate: 1.570E-05 | global batch size:    48 | lm loss: 5.311169E+00 | loss scale: 32768.0 | grad norm: 1.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1017/    1200 | consumed samples:        48816 | elapsed time per iteration (ms): 1205.2 | learning rate: 1.571E-05 | global batch size:    48 | lm loss: 5.195152E+00 | loss scale: 32768.0 | grad norm: 1.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1018/    1200 | consumed samples:        48864 | elapsed time per iteration (ms): 995.2 | learning rate: 1.573E-05 | global batch size:    48 | lm loss: 5.228466E+00 | loss scale: 32768.0 | grad norm: 1.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1019/    1200 | consumed samples:        48912 | elapsed time per iteration (ms): 1000.1 | learning rate: 1.574E-05 | global batch size:    48 | lm loss: 5.390162E+00 | loss scale: 32768.0 | grad norm: 1.885 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1020/    1200 | consumed samples:        48960 | elapsed time per iteration (ms): 1251.0 | learning rate: 1.576E-05 | global batch size:    48 | lm loss: 5.225900E+00 | loss scale: 32768.0 | grad norm: 1.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1021/    1200 | consumed samples:        49008 | elapsed time per iteration (ms): 1117.7 | learning rate: 1.578E-05 | global batch size:    48 | lm loss: 5.312583E+00 | loss scale: 32768.0 | grad norm: 1.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1022/    1200 | consumed samples:        49056 | elapsed time per iteration (ms): 1196.1 | learning rate: 1.579E-05 | global batch size:    48 | lm loss: 5.186934E+00 | loss scale: 32768.0 | grad norm: 1.783 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1023/    1200 | consumed samples:        49104 | elapsed time per iteration (ms): 1116.0 | learning rate: 1.581E-05 | global batch size:    48 | lm loss: 5.255507E+00 | loss scale: 65536.0 | grad norm: 1.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1024/    1200 | consumed samples:        49152 | elapsed time per iteration (ms): 1229.4 | learning rate: 1.582E-05 | global batch size:    48 | lm loss: 5.314469E+00 | loss scale: 65536.0 | grad norm: 1.839 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1025/    1200 | consumed samples:        49200 | elapsed time per iteration (ms): 988.0 | learning rate: 1.584E-05 | global batch size:    48 | lm loss: 5.254461E+00 | loss scale: 65536.0 | grad norm: 1.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1026/    1200 | consumed samples:        49248 | elapsed time per iteration (ms): 1046.6 | learning rate: 1.585E-05 | global batch size:    48 | lm loss: 5.260191E+00 | loss scale: 65536.0 | grad norm: 1.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1027/    1200 | consumed samples:        49296 | elapsed time per iteration (ms): 993.5 | learning rate: 1.587E-05 | global batch size:    48 | lm loss: 5.278723E+00 | loss scale: 65536.0 | grad norm: 1.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1028/    1200 | consumed samples:        49344 | elapsed time per iteration (ms): 983.7 | learning rate: 1.589E-05 | global batch size:    48 | lm loss: 5.135838E+00 | loss scale: 65536.0 | grad norm: 1.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1029/    1200 | consumed samples:        49392 | elapsed time per iteration (ms): 1327.1 | learning rate: 1.590E-05 | global batch size:    48 | lm loss: 5.414969E+00 | loss scale: 65536.0 | grad norm: 1.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1030/    1200 | consumed samples:        49440 | elapsed time per iteration (ms): 1200.3 | learning rate: 1.592E-05 | global batch size:    48 | lm loss: 5.260479E+00 | loss scale: 65536.0 | grad norm: 1.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        1/     170 | consumed samples:           48 | elapsed time per iteration (ms): 98809.1 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4294967296.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        2/     170 | consumed samples:           96 | elapsed time per iteration (ms): 1030.7 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2147483648.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        3/     170 | consumed samples:          144 | elapsed time per iteration (ms): 968.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1073741824.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        4/     170 | consumed samples:          192 | elapsed time per iteration (ms): 950.6 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 536870912.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        5/     170 | consumed samples:          240 | elapsed time per iteration (ms): 980.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        6/     170 | consumed samples:          288 | elapsed time per iteration (ms): 959.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 134217728.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        7/     170 | consumed samples:          336 | elapsed time per iteration (ms): 1279.7 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 67108864.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        8/     170 | consumed samples:          384 | elapsed time per iteration (ms): 1462.0 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 33554432.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        9/     170 | consumed samples:          432 | elapsed time per iteration (ms): 957.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 16777216.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       10/     170 | consumed samples:          480 | elapsed time per iteration (ms): 967.1 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 8388608.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       11/     170 | consumed samples:          528 | elapsed time per iteration (ms): 1122.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4194304.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       12/     170 | consumed samples:          576 | elapsed time per iteration (ms): 948.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       13/     170 | consumed samples:          624 | elapsed time per iteration (ms): 967.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       14/     170 | consumed samples:          672 | elapsed time per iteration (ms): 953.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 524288.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       15/     170 | consumed samples:          720 | elapsed time per iteration (ms): 1153.2 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       16/     170 | consumed samples:          768 | elapsed time per iteration (ms): 1197.7 | learning rate: 1.573E-08 | global batch size:    48 | lm loss: 1.064595E+01 | loss scale: 262144.0 | grad norm: 156.315 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       17/     170 | consumed samples:          816 | elapsed time per iteration (ms): 1473.2 | learning rate: 3.146E-08 | global batch size:    48 | lm loss: 1.065338E+01 | loss scale: 262144.0 | grad norm: 158.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       18/     170 | consumed samples:          864 | elapsed time per iteration (ms): 1150.5 | learning rate: 4.719E-08 | global batch size:    48 | lm loss: 1.065830E+01 | loss scale: 262144.0 | grad norm: 155.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       19/     170 | consumed samples:          912 | elapsed time per iteration (ms): 1098.8 | learning rate: 6.291E-08 | global batch size:    48 | lm loss: 1.045710E+01 | loss scale: 262144.0 | grad norm: 149.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       20/     170 | consumed samples:          960 | elapsed time per iteration (ms): 996.5 | learning rate: 7.864E-08 | global batch size:    48 | lm loss: 9.879968E+00 | loss scale: 262144.0 | grad norm: 138.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       21/     170 | consumed samples:         1008 | elapsed time per iteration (ms): 1003.2 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 131072.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       22/     170 | consumed samples:         1056 | elapsed time per iteration (ms): 961.6 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       23/     170 | consumed samples:         1104 | elapsed time per iteration (ms): 1156.8 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       24/     170 | consumed samples:         1152 | elapsed time per iteration (ms): 1218.2 | learning rate: 9.437E-08 | global batch size:    48 | lm loss: 1.011889E+01 | loss scale: 32768.0 | grad norm: 672.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       25/     170 | consumed samples:         1200 | elapsed time per iteration (ms): 1111.5 | learning rate: 1.101E-07 | global batch size:    48 | lm loss: 1.000791E+01 | loss scale: 32768.0 | grad norm: 653.865 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       26/     170 | consumed samples:         1248 | elapsed time per iteration (ms): 1058.9 | learning rate: 1.258E-07 | global batch size:    48 | lm loss: 9.404112E+00 | loss scale: 32768.0 | grad norm: 269.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       27/     170 | consumed samples:         1296 | elapsed time per iteration (ms): 1108.0 | learning rate: 1.416E-07 | global batch size:    48 | lm loss: 9.102152E+00 | loss scale: 32768.0 | grad norm: 197.323 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       28/     170 | consumed samples:         1344 | elapsed time per iteration (ms): 1123.7 | learning rate: 1.573E-07 | global batch size:    48 | lm loss: 8.698307E+00 | loss scale: 32768.0 | grad norm: 64.270 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       29/     170 | consumed samples:         1392 | elapsed time per iteration (ms): 1120.6 | learning rate: 1.730E-07 | global batch size:    48 | lm loss: 8.757597E+00 | loss scale: 32768.0 | grad norm: 63.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       30/     170 | consumed samples:         1440 | elapsed time per iteration (ms): 994.5 | learning rate: 1.887E-07 | global batch size:    48 | lm loss: 8.674874E+00 | loss scale: 32768.0 | grad norm: 66.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       31/     170 | consumed samples:         1488 | elapsed time per iteration (ms): 1079.8 | learning rate: 2.045E-07 | global batch size:    48 | lm loss: 8.522375E+00 | loss scale: 32768.0 | grad norm: 43.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       32/     170 | consumed samples:         1536 | elapsed time per iteration (ms): 1239.1 | learning rate: 2.202E-07 | global batch size:    48 | lm loss: 8.419993E+00 | loss scale: 32768.0 | grad norm: 52.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       33/     170 | consumed samples:         1584 | elapsed time per iteration (ms): 1062.6 | learning rate: 2.359E-07 | global batch size:    48 | lm loss: 8.359005E+00 | loss scale: 32768.0 | grad norm: 57.129 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       34/     170 | consumed samples:         1632 | elapsed time per iteration (ms): 1116.3 | learning rate: 2.517E-07 | global batch size:    48 | lm loss: 8.416605E+00 | loss scale: 32768.0 | grad norm: 68.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       35/     170 | consumed samples:         1680 | elapsed time per iteration (ms): 1118.1 | learning rate: 2.674E-07 | global batch size:    48 | lm loss: 8.288352E+00 | loss scale: 32768.0 | grad norm: 49.983 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       36/     170 | consumed samples:         1728 | elapsed time per iteration (ms): 986.6 | learning rate: 2.831E-07 | global batch size:    48 | lm loss: 8.271061E+00 | loss scale: 32768.0 | grad norm: 80.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       37/     170 | consumed samples:         1776 | elapsed time per iteration (ms): 1300.5 | learning rate: 2.988E-07 | global batch size:    48 | lm loss: 8.203588E+00 | loss scale: 32768.0 | grad norm: 31.243 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       38/     170 | consumed samples:         1824 | elapsed time per iteration (ms): 1084.0 | learning rate: 3.146E-07 | global batch size:    48 | lm loss: 8.231887E+00 | loss scale: 32768.0 | grad norm: 49.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       39/     170 | consumed samples:         1872 | elapsed time per iteration (ms): 1205.6 | learning rate: 3.303E-07 | global batch size:    48 | lm loss: 8.114100E+00 | loss scale: 32768.0 | grad norm: 33.189 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       40/     170 | consumed samples:         1920 | elapsed time per iteration (ms): 1111.5 | learning rate: 3.460E-07 | global batch size:    48 | lm loss: 8.127762E+00 | loss scale: 32768.0 | grad norm: 29.137 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       41/     170 | consumed samples:         1968 | elapsed time per iteration (ms): 998.7 | learning rate: 3.618E-07 | global batch size:    48 | lm loss: 8.112835E+00 | loss scale: 32768.0 | grad norm: 70.190 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       42/     170 | consumed samples:         2016 | elapsed time per iteration (ms): 1044.6 | learning rate: 3.775E-07 | global batch size:    48 | lm loss: 8.078146E+00 | loss scale: 32768.0 | grad norm: 39.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       43/     170 | consumed samples:         2064 | elapsed time per iteration (ms): 1090.6 | learning rate: 3.932E-07 | global batch size:    48 | lm loss: 8.024878E+00 | loss scale: 32768.0 | grad norm: 25.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       44/     170 | consumed samples:         2112 | elapsed time per iteration (ms): 1124.5 | learning rate: 4.089E-07 | global batch size:    48 | lm loss: 8.069037E+00 | loss scale: 32768.0 | grad norm: 41.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       45/     170 | consumed samples:         2160 | elapsed time per iteration (ms): 990.1 | learning rate: 4.247E-07 | global batch size:    48 | lm loss: 8.154215E+00 | loss scale: 32768.0 | grad norm: 85.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       46/     170 | consumed samples:         2208 | elapsed time per iteration (ms): 1149.3 | learning rate: 4.404E-07 | global batch size:    48 | lm loss: 8.106767E+00 | loss scale: 32768.0 | grad norm: 74.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       47/     170 | consumed samples:         2256 | elapsed time per iteration (ms): 1233.1 | learning rate: 4.561E-07 | global batch size:    48 | lm loss: 8.082594E+00 | loss scale: 32768.0 | grad norm: 30.071 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       48/     170 | consumed samples:         2304 | elapsed time per iteration (ms): 996.6 | learning rate: 4.719E-07 | global batch size:    48 | lm loss: 7.997400E+00 | loss scale: 32768.0 | grad norm: 25.252 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       49/     170 | consumed samples:         2352 | elapsed time per iteration (ms): 1148.3 | learning rate: 4.876E-07 | global batch size:    48 | lm loss: 8.081524E+00 | loss scale: 32768.0 | grad norm: 115.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       50/     170 | consumed samples:         2400 | elapsed time per iteration (ms): 988.9 | learning rate: 5.033E-07 | global batch size:    48 | lm loss: 8.188581E+00 | loss scale: 32768.0 | grad norm: 123.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       51/     170 | consumed samples:         2448 | elapsed time per iteration (ms): 1083.4 | learning rate: 5.190E-07 | global batch size:    48 | lm loss: 8.016584E+00 | loss scale: 32768.0 | grad norm: 78.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       52/     170 | consumed samples:         2496 | elapsed time per iteration (ms): 1095.4 | learning rate: 5.348E-07 | global batch size:    48 | lm loss: 7.959307E+00 | loss scale: 32768.0 | grad norm: 38.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       53/     170 | consumed samples:         2544 | elapsed time per iteration (ms): 1122.8 | learning rate: 5.505E-07 | global batch size:    48 | lm loss: 7.990664E+00 | loss scale: 32768.0 | grad norm: 21.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       54/     170 | consumed samples:         2592 | elapsed time per iteration (ms): 1113.6 | learning rate: 5.662E-07 | global batch size:    48 | lm loss: 7.930719E+00 | loss scale: 32768.0 | grad norm: 23.221 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       55/     170 | consumed samples:         2640 | elapsed time per iteration (ms): 1083.2 | learning rate: 5.820E-07 | global batch size:    48 | lm loss: 7.827173E+00 | loss scale: 32768.0 | grad norm: 28.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       56/     170 | consumed samples:         2688 | elapsed time per iteration (ms): 1253.2 | learning rate: 5.977E-07 | global batch size:    48 | lm loss: 7.946066E+00 | loss scale: 32768.0 | grad norm: 46.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       57/     170 | consumed samples:         2736 | elapsed time per iteration (ms): 1121.7 | learning rate: 6.134E-07 | global batch size:    48 | lm loss: 7.930828E+00 | loss scale: 32768.0 | grad norm: 17.558 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       58/     170 | consumed samples:         2784 | elapsed time per iteration (ms): 1118.7 | learning rate: 6.291E-07 | global batch size:    48 | lm loss: 7.850894E+00 | loss scale: 32768.0 | grad norm: 17.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       59/     170 | consumed samples:         2832 | elapsed time per iteration (ms): 1003.4 | learning rate: 6.449E-07 | global batch size:    48 | lm loss: 7.848691E+00 | loss scale: 32768.0 | grad norm: 18.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       60/     170 | consumed samples:         2880 | elapsed time per iteration (ms): 1048.2 | learning rate: 6.606E-07 | global batch size:    48 | lm loss: 7.844734E+00 | loss scale: 32768.0 | grad norm: 28.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       61/     170 | consumed samples:         2928 | elapsed time per iteration (ms): 1164.7 | learning rate: 6.763E-07 | global batch size:    48 | lm loss: 7.843095E+00 | loss scale: 32768.0 | grad norm: 33.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       62/     170 | consumed samples:         2976 | elapsed time per iteration (ms): 1329.4 | learning rate: 6.921E-07 | global batch size:    48 | lm loss: 7.817948E+00 | loss scale: 32768.0 | grad norm: 19.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       63/     170 | consumed samples:         3024 | elapsed time per iteration (ms): 994.8 | learning rate: 7.078E-07 | global batch size:    48 | lm loss: 7.839793E+00 | loss scale: 32768.0 | grad norm: 12.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       64/     170 | consumed samples:         3072 | elapsed time per iteration (ms): 1106.9 | learning rate: 7.235E-07 | global batch size:    48 | lm loss: 7.796875E+00 | loss scale: 32768.0 | grad norm: 18.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       65/     170 | consumed samples:         3120 | elapsed time per iteration (ms): 998.7 | learning rate: 7.392E-07 | global batch size:    48 | lm loss: 7.677135E+00 | loss scale: 32768.0 | grad norm: 15.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       66/     170 | consumed samples:         3168 | elapsed time per iteration (ms): 1112.2 | learning rate: 7.550E-07 | global batch size:    48 | lm loss: 7.783973E+00 | loss scale: 32768.0 | grad norm: 21.127 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       67/     170 | consumed samples:         3216 | elapsed time per iteration (ms): 1123.1 | learning rate: 7.707E-07 | global batch size:    48 | lm loss: 7.827737E+00 | loss scale: 32768.0 | grad norm: 25.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       68/     170 | consumed samples:         3264 | elapsed time per iteration (ms): 1016.2 | learning rate: 7.864E-07 | global batch size:    48 | lm loss: 7.749515E+00 | loss scale: 32768.0 | grad norm: 21.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       69/     170 | consumed samples:         3312 | elapsed time per iteration (ms): 1155.6 | learning rate: 8.022E-07 | global batch size:    48 | lm loss: 7.647816E+00 | loss scale: 32768.0 | grad norm: 22.533 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       70/     170 | consumed samples:         3360 | elapsed time per iteration (ms): 1218.9 | learning rate: 8.179E-07 | global batch size:    48 | lm loss: 7.750089E+00 | loss scale: 32768.0 | grad norm: 22.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       71/     170 | consumed samples:         3408 | elapsed time per iteration (ms): 1212.7 | learning rate: 8.336E-07 | global batch size:    48 | lm loss: 7.614849E+00 | loss scale: 32768.0 | grad norm: 15.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       72/     170 | consumed samples:         3456 | elapsed time per iteration (ms): 1004.7 | learning rate: 8.493E-07 | global batch size:    48 | lm loss: 7.681921E+00 | loss scale: 32768.0 | grad norm: 12.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       73/     170 | consumed samples:         3504 | elapsed time per iteration (ms): 1126.5 | learning rate: 8.651E-07 | global batch size:    48 | lm loss: 7.601383E+00 | loss scale: 32768.0 | grad norm: 21.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       74/     170 | consumed samples:         3552 | elapsed time per iteration (ms): 1068.5 | learning rate: 8.808E-07 | global batch size:    48 | lm loss: 7.571964E+00 | loss scale: 32768.0 | grad norm: 14.143 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       75/     170 | consumed samples:         3600 | elapsed time per iteration (ms): 1136.6 | learning rate: 8.965E-07 | global batch size:    48 | lm loss: 7.600965E+00 | loss scale: 32768.0 | grad norm: 10.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       76/     170 | consumed samples:         3648 | elapsed time per iteration (ms): 999.8 | learning rate: 9.123E-07 | global batch size:    48 | lm loss: 7.678252E+00 | loss scale: 32768.0 | grad norm: 22.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       77/     170 | consumed samples:         3696 | elapsed time per iteration (ms): 1128.1 | learning rate: 9.280E-07 | global batch size:    48 | lm loss: 7.560709E+00 | loss scale: 32768.0 | grad norm: 16.566 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       78/     170 | consumed samples:         3744 | elapsed time per iteration (ms): 1143.1 | learning rate: 9.437E-07 | global batch size:    48 | lm loss: 7.463670E+00 | loss scale: 32768.0 | grad norm: 18.325 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       79/     170 | consumed samples:         3792 | elapsed time per iteration (ms): 1363.9 | learning rate: 9.594E-07 | global batch size:    48 | lm loss: 7.539518E+00 | loss scale: 32768.0 | grad norm: 13.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       80/     170 | consumed samples:         3840 | elapsed time per iteration (ms): 1141.4 | learning rate: 9.752E-07 | global batch size:    48 | lm loss: 7.554595E+00 | loss scale: 32768.0 | grad norm: 33.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       81/     170 | consumed samples:         3888 | elapsed time per iteration (ms): 1142.4 | learning rate: 9.909E-07 | global batch size:    48 | lm loss: 7.522870E+00 | loss scale: 32768.0 | grad norm: 23.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       82/     170 | consumed samples:         3936 | elapsed time per iteration (ms): 1046.3 | learning rate: 1.007E-06 | global batch size:    48 | lm loss: 7.578803E+00 | loss scale: 32768.0 | grad norm: 15.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       83/     170 | consumed samples:         3984 | elapsed time per iteration (ms): 1023.1 | learning rate: 1.022E-06 | global batch size:    48 | lm loss: 7.461776E+00 | loss scale: 32768.0 | grad norm: 13.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       84/     170 | consumed samples:         4032 | elapsed time per iteration (ms): 995.1 | learning rate: 1.038E-06 | global batch size:    48 | lm loss: 7.506434E+00 | loss scale: 32768.0 | grad norm: 15.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       85/     170 | consumed samples:         4080 | elapsed time per iteration (ms): 1244.2 | learning rate: 1.054E-06 | global batch size:    48 | lm loss: 7.486061E+00 | loss scale: 32768.0 | grad norm: 22.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       86/     170 | consumed samples:         4128 | elapsed time per iteration (ms): 1051.6 | learning rate: 1.070E-06 | global batch size:    48 | lm loss: 7.524589E+00 | loss scale: 32768.0 | grad norm: 21.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       87/     170 | consumed samples:         4176 | elapsed time per iteration (ms): 1337.2 | learning rate: 1.085E-06 | global batch size:    48 | lm loss: 7.535740E+00 | loss scale: 32768.0 | grad norm: 24.382 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       88/     170 | consumed samples:         4224 | elapsed time per iteration (ms): 1195.3 | learning rate: 1.101E-06 | global batch size:    48 | lm loss: 7.384780E+00 | loss scale: 32768.0 | grad norm: 9.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       89/     170 | consumed samples:         4272 | elapsed time per iteration (ms): 1125.5 | learning rate: 1.117E-06 | global batch size:    48 | lm loss: 7.461233E+00 | loss scale: 32768.0 | grad norm: 16.895 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       90/     170 | consumed samples:         4320 | elapsed time per iteration (ms): 1172.1 | learning rate: 1.132E-06 | global batch size:    48 | lm loss: 7.371311E+00 | loss scale: 32768.0 | grad norm: 13.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       91/     170 | consumed samples:         4368 | elapsed time per iteration (ms): 988.2 | learning rate: 1.148E-06 | global batch size:    48 | lm loss: 7.401240E+00 | loss scale: 32768.0 | grad norm: 18.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       92/     170 | consumed samples:         4416 | elapsed time per iteration (ms): 994.1 | learning rate: 1.164E-06 | global batch size:    48 | lm loss: 7.339136E+00 | loss scale: 32768.0 | grad norm: 16.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       93/     170 | consumed samples:         4464 | elapsed time per iteration (ms): 998.6 | learning rate: 1.180E-06 | global batch size:    48 | lm loss: 7.437624E+00 | loss scale: 32768.0 | grad norm: 19.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       94/     170 | consumed samples:         4512 | elapsed time per iteration (ms): 1287.0 | learning rate: 1.195E-06 | global batch size:    48 | lm loss: 7.293014E+00 | loss scale: 32768.0 | grad norm: 12.217 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       95/     170 | consumed samples:         4560 | elapsed time per iteration (ms): 1076.9 | learning rate: 1.211E-06 | global batch size:    48 | lm loss: 7.369732E+00 | loss scale: 32768.0 | grad norm: 14.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       96/     170 | consumed samples:         4608 | elapsed time per iteration (ms): 1046.9 | learning rate: 1.227E-06 | global batch size:    48 | lm loss: 7.396235E+00 | loss scale: 32768.0 | grad norm: 10.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       97/     170 | consumed samples:         4656 | elapsed time per iteration (ms): 1276.1 | learning rate: 1.243E-06 | global batch size:    48 | lm loss: 7.278118E+00 | loss scale: 32768.0 | grad norm: 12.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       98/     170 | consumed samples:         4704 | elapsed time per iteration (ms): 1167.3 | learning rate: 1.258E-06 | global batch size:    48 | lm loss: 7.093921E+00 | loss scale: 32768.0 | grad norm: 10.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       99/     170 | consumed samples:         4752 | elapsed time per iteration (ms): 1161.7 | learning rate: 1.274E-06 | global batch size:    48 | lm loss: 7.339246E+00 | loss scale: 32768.0 | grad norm: 10.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      100/     170 | consumed samples:         4800 | elapsed time per iteration (ms): 1275.0 | learning rate: 1.290E-06 | global batch size:    48 | lm loss: 7.333570E+00 | loss scale: 32768.0 | grad norm: 12.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      101/     170 | consumed samples:         4848 | elapsed time per iteration (ms): 1414.2 | learning rate: 1.305E-06 | global batch size:    48 | lm loss: 7.178007E+00 | loss scale: 32768.0 | grad norm: 8.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      102/     170 | consumed samples:         4896 | elapsed time per iteration (ms): 1283.1 | learning rate: 1.321E-06 | global batch size:    48 | lm loss: 7.185754E+00 | loss scale: 32768.0 | grad norm: 11.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      103/     170 | consumed samples:         4944 | elapsed time per iteration (ms): 1369.3 | learning rate: 1.337E-06 | global batch size:    48 | lm loss: 7.198635E+00 | loss scale: 32768.0 | grad norm: 10.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      104/     170 | consumed samples:         4992 | elapsed time per iteration (ms): 1417.3 | learning rate: 1.353E-06 | global batch size:    48 | lm loss: 7.119062E+00 | loss scale: 32768.0 | grad norm: 16.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      105/     170 | consumed samples:         5040 | elapsed time per iteration (ms): 1339.8 | learning rate: 1.368E-06 | global batch size:    48 | lm loss: 7.160285E+00 | loss scale: 32768.0 | grad norm: 10.136 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      106/     170 | consumed samples:         5088 | elapsed time per iteration (ms): 1695.2 | learning rate: 1.384E-06 | global batch size:    48 | lm loss: 7.090118E+00 | loss scale: 32768.0 | grad norm: 11.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      107/     170 | consumed samples:         5136 | elapsed time per iteration (ms): 1281.4 | learning rate: 1.400E-06 | global batch size:    48 | lm loss: 7.087859E+00 | loss scale: 32768.0 | grad norm: 13.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      108/     170 | consumed samples:         5184 | elapsed time per iteration (ms): 1532.8 | learning rate: 1.416E-06 | global batch size:    48 | lm loss: 7.120779E+00 | loss scale: 32768.0 | grad norm: 22.555 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      109/     170 | consumed samples:         5232 | elapsed time per iteration (ms): 1422.9 | learning rate: 1.431E-06 | global batch size:    48 | lm loss: 7.061327E+00 | loss scale: 32768.0 | grad norm: 11.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      110/     170 | consumed samples:         5280 | elapsed time per iteration (ms): 1302.1 | learning rate: 1.447E-06 | global batch size:    48 | lm loss: 7.146583E+00 | loss scale: 32768.0 | grad norm: 11.025 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      111/     170 | consumed samples:         5328 | elapsed time per iteration (ms): 1329.3 | learning rate: 1.463E-06 | global batch size:    48 | lm loss: 7.088786E+00 | loss scale: 32768.0 | grad norm: 10.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      112/     170 | consumed samples:         5376 | elapsed time per iteration (ms): 1138.8 | learning rate: 1.478E-06 | global batch size:    48 | lm loss: 7.101768E+00 | loss scale: 32768.0 | grad norm: 10.144 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      113/     170 | consumed samples:         5424 | elapsed time per iteration (ms): 1051.0 | learning rate: 1.494E-06 | global batch size:    48 | lm loss: 7.151361E+00 | loss scale: 32768.0 | grad norm: 25.301 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      114/     170 | consumed samples:         5472 | elapsed time per iteration (ms): 1407.5 | learning rate: 1.510E-06 | global batch size:    48 | lm loss: 7.178752E+00 | loss scale: 32768.0 | grad norm: 19.291 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      115/     170 | consumed samples:         5520 | elapsed time per iteration (ms): 1007.7 | learning rate: 1.526E-06 | global batch size:    48 | lm loss: 7.081878E+00 | loss scale: 32768.0 | grad norm: 11.278 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      116/     170 | consumed samples:         5568 | elapsed time per iteration (ms): 1106.5 | learning rate: 1.541E-06 | global batch size:    48 | lm loss: 7.126951E+00 | loss scale: 32768.0 | grad norm: 11.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      117/     170 | consumed samples:         5616 | elapsed time per iteration (ms): 1069.3 | learning rate: 1.557E-06 | global batch size:    48 | lm loss: 6.938869E+00 | loss scale: 32768.0 | grad norm: 8.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      118/     170 | consumed samples:         5664 | elapsed time per iteration (ms): 1105.6 | learning rate: 1.573E-06 | global batch size:    48 | lm loss: 7.045139E+00 | loss scale: 32768.0 | grad norm: 9.134 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      119/     170 | consumed samples:         5712 | elapsed time per iteration (ms): 995.8 | learning rate: 1.589E-06 | global batch size:    48 | lm loss: 7.072112E+00 | loss scale: 32768.0 | grad norm: 12.233 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      120/     170 | consumed samples:         5760 | elapsed time per iteration (ms): 1112.5 | learning rate: 1.604E-06 | global batch size:    48 | lm loss: 7.000796E+00 | loss scale: 32768.0 | grad norm: 10.568 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      121/     170 | consumed samples:         5808 | elapsed time per iteration (ms): 1129.2 | learning rate: 1.620E-06 | global batch size:    48 | lm loss: 7.099246E+00 | loss scale: 32768.0 | grad norm: 10.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      122/     170 | consumed samples:         5856 | elapsed time per iteration (ms): 1145.6 | learning rate: 1.636E-06 | global batch size:    48 | lm loss: 7.048311E+00 | loss scale: 32768.0 | grad norm: 11.299 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      123/     170 | consumed samples:         5904 | elapsed time per iteration (ms): 1228.6 | learning rate: 1.652E-06 | global batch size:    48 | lm loss: 6.998682E+00 | loss scale: 32768.0 | grad norm: 13.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      124/     170 | consumed samples:         5952 | elapsed time per iteration (ms): 1222.6 | learning rate: 1.667E-06 | global batch size:    48 | lm loss: 7.034938E+00 | loss scale: 32768.0 | grad norm: 7.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      125/     170 | consumed samples:         6000 | elapsed time per iteration (ms): 1002.2 | learning rate: 1.683E-06 | global batch size:    48 | lm loss: 6.864955E+00 | loss scale: 32768.0 | grad norm: 11.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      126/     170 | consumed samples:         6048 | elapsed time per iteration (ms): 1005.2 | learning rate: 1.699E-06 | global batch size:    48 | lm loss: 7.006628E+00 | loss scale: 32768.0 | grad norm: 15.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      127/     170 | consumed samples:         6096 | elapsed time per iteration (ms): 1019.8 | learning rate: 1.714E-06 | global batch size:    48 | lm loss: 6.942389E+00 | loss scale: 32768.0 | grad norm: 17.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      128/     170 | consumed samples:         6144 | elapsed time per iteration (ms): 1102.5 | learning rate: 1.730E-06 | global batch size:    48 | lm loss: 7.012831E+00 | loss scale: 32768.0 | grad norm: 10.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      129/     170 | consumed samples:         6192 | elapsed time per iteration (ms): 1147.7 | learning rate: 1.746E-06 | global batch size:    48 | lm loss: 6.885616E+00 | loss scale: 32768.0 | grad norm: 9.369 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      130/     170 | consumed samples:         6240 | elapsed time per iteration (ms): 1325.7 | learning rate: 1.762E-06 | global batch size:    48 | lm loss: 6.943061E+00 | loss scale: 32768.0 | grad norm: 11.368 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      131/     170 | consumed samples:         6288 | elapsed time per iteration (ms): 1349.1 | learning rate: 1.777E-06 | global batch size:    48 | lm loss: 6.955553E+00 | loss scale: 32768.0 | grad norm: 15.221 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      132/     170 | consumed samples:         6336 | elapsed time per iteration (ms): 1110.8 | learning rate: 1.793E-06 | global batch size:    48 | lm loss: 6.953318E+00 | loss scale: 32768.0 | grad norm: 8.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      133/     170 | consumed samples:         6384 | elapsed time per iteration (ms): 1005.9 | learning rate: 1.809E-06 | global batch size:    48 | lm loss: 6.849343E+00 | loss scale: 32768.0 | grad norm: 8.160 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      134/     170 | consumed samples:         6432 | elapsed time per iteration (ms): 1122.6 | learning rate: 1.825E-06 | global batch size:    48 | lm loss: 6.850542E+00 | loss scale: 32768.0 | grad norm: 11.168 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      135/     170 | consumed samples:         6480 | elapsed time per iteration (ms): 995.1 | learning rate: 1.840E-06 | global batch size:    48 | lm loss: 6.885320E+00 | loss scale: 32768.0 | grad norm: 8.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      136/     170 | consumed samples:         6528 | elapsed time per iteration (ms): 993.3 | learning rate: 1.856E-06 | global batch size:    48 | lm loss: 7.033688E+00 | loss scale: 32768.0 | grad norm: 19.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      137/     170 | consumed samples:         6576 | elapsed time per iteration (ms): 1104.8 | learning rate: 1.872E-06 | global batch size:    48 | lm loss: 6.880294E+00 | loss scale: 32768.0 | grad norm: 8.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      138/     170 | consumed samples:         6624 | elapsed time per iteration (ms): 1265.9 | learning rate: 1.887E-06 | global batch size:    48 | lm loss: 6.986227E+00 | loss scale: 32768.0 | grad norm: 7.682 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      139/     170 | consumed samples:         6672 | elapsed time per iteration (ms): 1237.8 | learning rate: 1.903E-06 | global batch size:    48 | lm loss: 6.847109E+00 | loss scale: 32768.0 | grad norm: 10.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      140/     170 | consumed samples:         6720 | elapsed time per iteration (ms): 1110.3 | learning rate: 1.919E-06 | global batch size:    48 | lm loss: 6.950141E+00 | loss scale: 32768.0 | grad norm: 9.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      141/     170 | consumed samples:         6768 | elapsed time per iteration (ms): 1062.1 | learning rate: 1.935E-06 | global batch size:    48 | lm loss: 6.873962E+00 | loss scale: 32768.0 | grad norm: 11.340 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      142/     170 | consumed samples:         6816 | elapsed time per iteration (ms): 991.9 | learning rate: 1.950E-06 | global batch size:    48 | lm loss: 6.803609E+00 | loss scale: 32768.0 | grad norm: 12.076 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      143/     170 | consumed samples:         6864 | elapsed time per iteration (ms): 1059.3 | learning rate: 1.966E-06 | global batch size:    48 | lm loss: 6.843437E+00 | loss scale: 32768.0 | grad norm: 8.344 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      144/     170 | consumed samples:         6912 | elapsed time per iteration (ms): 1130.9 | learning rate: 1.982E-06 | global batch size:    48 | lm loss: 6.745046E+00 | loss scale: 32768.0 | grad norm: 9.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      145/     170 | consumed samples:         6960 | elapsed time per iteration (ms): 1094.1 | learning rate: 1.998E-06 | global batch size:    48 | lm loss: 6.825106E+00 | loss scale: 32768.0 | grad norm: 9.345 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      146/     170 | consumed samples:         7008 | elapsed time per iteration (ms): 1158.7 | learning rate: 2.013E-06 | global batch size:    48 | lm loss: 6.781777E+00 | loss scale: 32768.0 | grad norm: 8.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      147/     170 | consumed samples:         7056 | elapsed time per iteration (ms): 1230.9 | learning rate: 2.029E-06 | global batch size:    48 | lm loss: 6.773166E+00 | loss scale: 32768.0 | grad norm: 9.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      148/     170 | consumed samples:         7104 | elapsed time per iteration (ms): 1128.9 | learning rate: 2.045E-06 | global batch size:    48 | lm loss: 6.769747E+00 | loss scale: 32768.0 | grad norm: 8.234 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      149/     170 | consumed samples:         7152 | elapsed time per iteration (ms): 1108.8 | learning rate: 2.060E-06 | global batch size:    48 | lm loss: 6.861040E+00 | loss scale: 32768.0 | grad norm: 7.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      150/     170 | consumed samples:         7200 | elapsed time per iteration (ms): 996.6 | learning rate: 2.076E-06 | global batch size:    48 | lm loss: 6.728036E+00 | loss scale: 32768.0 | grad norm: 9.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      151/     170 | consumed samples:         7248 | elapsed time per iteration (ms): 1119.6 | learning rate: 2.092E-06 | global batch size:    48 | lm loss: 6.752935E+00 | loss scale: 32768.0 | grad norm: 12.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      152/     170 | consumed samples:         7296 | elapsed time per iteration (ms): 988.4 | learning rate: 2.108E-06 | global batch size:    48 | lm loss: 6.784099E+00 | loss scale: 32768.0 | grad norm: 7.173 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      153/     170 | consumed samples:         7344 | elapsed time per iteration (ms): 1160.6 | learning rate: 2.123E-06 | global batch size:    48 | lm loss: 6.787097E+00 | loss scale: 32768.0 | grad norm: 9.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      154/     170 | consumed samples:         7392 | elapsed time per iteration (ms): 1110.7 | learning rate: 2.139E-06 | global batch size:    48 | lm loss: 6.766797E+00 | loss scale: 32768.0 | grad norm: 9.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      155/     170 | consumed samples:         7440 | elapsed time per iteration (ms): 1058.8 | learning rate: 2.155E-06 | global batch size:    48 | lm loss: 6.744595E+00 | loss scale: 32768.0 | grad norm: 8.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      156/     170 | consumed samples:         7488 | elapsed time per iteration (ms): 998.4 | learning rate: 2.171E-06 | global batch size:    48 | lm loss: 6.646279E+00 | loss scale: 32768.0 | grad norm: 15.138 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      157/     170 | consumed samples:         7536 | elapsed time per iteration (ms): 1114.9 | learning rate: 2.186E-06 | global batch size:    48 | lm loss: 6.727538E+00 | loss scale: 32768.0 | grad norm: 7.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      158/     170 | consumed samples:         7584 | elapsed time per iteration (ms): 1171.9 | learning rate: 2.202E-06 | global batch size:    48 | lm loss: 6.735994E+00 | loss scale: 32768.0 | grad norm: 9.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      159/     170 | consumed samples:         7632 | elapsed time per iteration (ms): 1131.3 | learning rate: 2.218E-06 | global batch size:    48 | lm loss: 6.723379E+00 | loss scale: 32768.0 | grad norm: 6.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      160/     170 | consumed samples:         7680 | elapsed time per iteration (ms): 1194.8 | learning rate: 2.233E-06 | global batch size:    48 | lm loss: 6.660254E+00 | loss scale: 32768.0 | grad norm: 6.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      161/     170 | consumed samples:         7728 | elapsed time per iteration (ms): 1099.1 | learning rate: 2.249E-06 | global batch size:    48 | lm loss: 6.595701E+00 | loss scale: 32768.0 | grad norm: 11.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      162/     170 | consumed samples:         7776 | elapsed time per iteration (ms): 1087.3 | learning rate: 2.265E-06 | global batch size:    48 | lm loss: 6.634120E+00 | loss scale: 32768.0 | grad norm: 10.117 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      163/     170 | consumed samples:         7824 | elapsed time per iteration (ms): 1109.7 | learning rate: 2.281E-06 | global batch size:    48 | lm loss: 6.638964E+00 | loss scale: 32768.0 | grad norm: 7.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      164/     170 | consumed samples:         7872 | elapsed time per iteration (ms): 1125.9 | learning rate: 2.296E-06 | global batch size:    48 | lm loss: 6.635879E+00 | loss scale: 32768.0 | grad norm: 8.269 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      165/     170 | consumed samples:         7920 | elapsed time per iteration (ms): 1123.8 | learning rate: 2.312E-06 | global batch size:    48 | lm loss: 6.631671E+00 | loss scale: 32768.0 | grad norm: 8.150 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      166/     170 | consumed samples:         7968 | elapsed time per iteration (ms): 1128.1 | learning rate: 2.328E-06 | global batch size:    48 | lm loss: 6.687019E+00 | loss scale: 32768.0 | grad norm: 8.232 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      167/     170 | consumed samples:         8016 | elapsed time per iteration (ms): 1290.1 | learning rate: 2.344E-06 | global batch size:    48 | lm loss: 6.526854E+00 | loss scale: 32768.0 | grad norm: 9.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      168/     170 | consumed samples:         8064 | elapsed time per iteration (ms): 1006.7 | learning rate: 2.359E-06 | global batch size:    48 | lm loss: 6.696512E+00 | loss scale: 32768.0 | grad norm: 11.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      169/     170 | consumed samples:         8112 | elapsed time per iteration (ms): 1094.7 | learning rate: 2.375E-06 | global batch size:    48 | lm loss: 6.691249E+00 | loss scale: 32768.0 | grad norm: 9.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      170/     170 | consumed samples:         8160 | elapsed time per iteration (ms): 1183.6 | learning rate: 2.391E-06 | global batch size:    48 | lm loss: 6.627877E+00 | loss scale: 32768.0 | grad norm: 8.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
