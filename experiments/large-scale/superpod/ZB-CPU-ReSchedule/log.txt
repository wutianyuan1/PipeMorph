 iteration        1/    1200 | consumed samples:           48 | elapsed time per iteration (ms): 259478.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4294967296.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        2/    1200 | consumed samples:           96 | elapsed time per iteration (ms): 21362.5 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2147483648.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        3/    1200 | consumed samples:          144 | elapsed time per iteration (ms): 1034.6 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1073741824.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        4/    1200 | consumed samples:          192 | elapsed time per iteration (ms): 1014.6 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 536870912.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        5/    1200 | consumed samples:          240 | elapsed time per iteration (ms): 1086.0 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        6/    1200 | consumed samples:          288 | elapsed time per iteration (ms): 1376.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 134217728.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        7/    1200 | consumed samples:          336 | elapsed time per iteration (ms): 1194.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 67108864.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        8/    1200 | consumed samples:          384 | elapsed time per iteration (ms): 1118.7 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 33554432.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        9/    1200 | consumed samples:          432 | elapsed time per iteration (ms): 1129.1 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 16777216.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       10/    1200 | consumed samples:          480 | elapsed time per iteration (ms): 1103.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 8388608.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       11/    1200 | consumed samples:          528 | elapsed time per iteration (ms): 987.5 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4194304.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       12/    1200 | consumed samples:          576 | elapsed time per iteration (ms): 998.3 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       13/    1200 | consumed samples:          624 | elapsed time per iteration (ms): 1057.1 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       14/    1200 | consumed samples:          672 | elapsed time per iteration (ms): 1341.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 524288.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       15/    1200 | consumed samples:          720 | elapsed time per iteration (ms): 1082.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       16/    1200 | consumed samples:          768 | elapsed time per iteration (ms): 1758.5 | learning rate: 1.573E-08 | global batch size:    48 | lm loss: 1.064832E+01 | loss scale: 262144.0 | grad norm: 156.314 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       17/    1200 | consumed samples:          816 | elapsed time per iteration (ms): 2544.8 | learning rate: 3.146E-08 | global batch size:    48 | lm loss: 1.065000E+01 | loss scale: 262144.0 | grad norm: 158.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       18/    1200 | consumed samples:          864 | elapsed time per iteration (ms): 1614.8 | learning rate: 4.719E-08 | global batch size:    48 | lm loss: 1.065208E+01 | loss scale: 262144.0 | grad norm: 155.325 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       19/    1200 | consumed samples:          912 | elapsed time per iteration (ms): 1550.0 | learning rate: 6.291E-08 | global batch size:    48 | lm loss: 1.061308E+01 | loss scale: 262144.0 | grad norm: 149.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       20/    1200 | consumed samples:          960 | elapsed time per iteration (ms): 2117.9 | learning rate: 7.864E-08 | global batch size:    48 | lm loss: 1.049090E+01 | loss scale: 262144.0 | grad norm: 138.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       21/    1200 | consumed samples:         1008 | elapsed time per iteration (ms): 1843.9 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 131072.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       22/    1200 | consumed samples:         1056 | elapsed time per iteration (ms): 2068.7 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       23/    1200 | consumed samples:         1104 | elapsed time per iteration (ms): 1705.8 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       24/    1200 | consumed samples:         1152 | elapsed time per iteration (ms): 1652.1 | learning rate: 9.437E-08 | global batch size:    48 | lm loss: 1.034958E+01 | loss scale: 32768.0 | grad norm: 672.285 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       25/    1200 | consumed samples:         1200 | elapsed time per iteration (ms): 1543.5 | learning rate: 1.101E-07 | global batch size:    48 | lm loss: 1.031852E+01 | loss scale: 32768.0 | grad norm: 653.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       26/    1200 | consumed samples:         1248 | elapsed time per iteration (ms): 2012.9 | learning rate: 1.258E-07 | global batch size:    48 | lm loss: 1.024232E+01 | loss scale: 32768.0 | grad norm: 269.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       27/    1200 | consumed samples:         1296 | elapsed time per iteration (ms): 1705.1 | learning rate: 1.416E-07 | global batch size:    48 | lm loss: 1.015462E+01 | loss scale: 32768.0 | grad norm: 197.338 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       28/    1200 | consumed samples:         1344 | elapsed time per iteration (ms): 1856.8 | learning rate: 1.573E-07 | global batch size:    48 | lm loss: 1.005060E+01 | loss scale: 32768.0 | grad norm: 64.273 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       29/    1200 | consumed samples:         1392 | elapsed time per iteration (ms): 1896.4 | learning rate: 1.730E-07 | global batch size:    48 | lm loss: 9.964397E+00 | loss scale: 32768.0 | grad norm: 63.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       30/    1200 | consumed samples:         1440 | elapsed time per iteration (ms): 2190.0 | learning rate: 1.887E-07 | global batch size:    48 | lm loss: 9.883802E+00 | loss scale: 32768.0 | grad norm: 66.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       31/    1200 | consumed samples:         1488 | elapsed time per iteration (ms): 1903.2 | learning rate: 2.045E-07 | global batch size:    48 | lm loss: 9.803720E+00 | loss scale: 32768.0 | grad norm: 43.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       32/    1200 | consumed samples:         1536 | elapsed time per iteration (ms): 1871.9 | learning rate: 2.202E-07 | global batch size:    48 | lm loss: 9.726849E+00 | loss scale: 32768.0 | grad norm: 52.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       33/    1200 | consumed samples:         1584 | elapsed time per iteration (ms): 1859.2 | learning rate: 2.359E-07 | global batch size:    48 | lm loss: 9.654857E+00 | loss scale: 32768.0 | grad norm: 57.129 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       34/    1200 | consumed samples:         1632 | elapsed time per iteration (ms): 1797.4 | learning rate: 2.517E-07 | global batch size:    48 | lm loss: 9.592945E+00 | loss scale: 32768.0 | grad norm: 68.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       35/    1200 | consumed samples:         1680 | elapsed time per iteration (ms): 1736.5 | learning rate: 2.674E-07 | global batch size:    48 | lm loss: 9.530818E+00 | loss scale: 32768.0 | grad norm: 49.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       36/    1200 | consumed samples:         1728 | elapsed time per iteration (ms): 1644.9 | learning rate: 2.831E-07 | global batch size:    48 | lm loss: 9.473558E+00 | loss scale: 32768.0 | grad norm: 80.408 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       37/    1200 | consumed samples:         1776 | elapsed time per iteration (ms): 1813.0 | learning rate: 2.988E-07 | global batch size:    48 | lm loss: 9.418341E+00 | loss scale: 32768.0 | grad norm: 31.243 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       38/    1200 | consumed samples:         1824 | elapsed time per iteration (ms): 1827.8 | learning rate: 3.146E-07 | global batch size:    48 | lm loss: 9.368904E+00 | loss scale: 32768.0 | grad norm: 49.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       39/    1200 | consumed samples:         1872 | elapsed time per iteration (ms): 1794.7 | learning rate: 3.303E-07 | global batch size:    48 | lm loss: 9.318708E+00 | loss scale: 32768.0 | grad norm: 33.179 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       40/    1200 | consumed samples:         1920 | elapsed time per iteration (ms): 1920.2 | learning rate: 3.460E-07 | global batch size:    48 | lm loss: 9.272903E+00 | loss scale: 32768.0 | grad norm: 29.157 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       41/    1200 | consumed samples:         1968 | elapsed time per iteration (ms): 1923.3 | learning rate: 3.618E-07 | global batch size:    48 | lm loss: 9.229918E+00 | loss scale: 32768.0 | grad norm: 69.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       42/    1200 | consumed samples:         2016 | elapsed time per iteration (ms): 1655.7 | learning rate: 3.775E-07 | global batch size:    48 | lm loss: 9.188771E+00 | loss scale: 32768.0 | grad norm: 38.878 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       43/    1200 | consumed samples:         2064 | elapsed time per iteration (ms): 1622.8 | learning rate: 3.932E-07 | global batch size:    48 | lm loss: 9.148621E+00 | loss scale: 32768.0 | grad norm: 25.133 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       44/    1200 | consumed samples:         2112 | elapsed time per iteration (ms): 1927.6 | learning rate: 4.089E-07 | global batch size:    48 | lm loss: 9.112590E+00 | loss scale: 32768.0 | grad norm: 40.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       45/    1200 | consumed samples:         2160 | elapsed time per iteration (ms): 1785.4 | learning rate: 4.247E-07 | global batch size:    48 | lm loss: 9.081617E+00 | loss scale: 32768.0 | grad norm: 84.561 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       46/    1200 | consumed samples:         2208 | elapsed time per iteration (ms): 1648.9 | learning rate: 4.404E-07 | global batch size:    48 | lm loss: 9.051167E+00 | loss scale: 32768.0 | grad norm: 75.222 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       47/    1200 | consumed samples:         2256 | elapsed time per iteration (ms): 1633.1 | learning rate: 4.561E-07 | global batch size:    48 | lm loss: 9.021871E+00 | loss scale: 32768.0 | grad norm: 30.263 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       48/    1200 | consumed samples:         2304 | elapsed time per iteration (ms): 1797.6 | learning rate: 4.719E-07 | global batch size:    48 | lm loss: 8.991798E+00 | loss scale: 32768.0 | grad norm: 25.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       49/    1200 | consumed samples:         2352 | elapsed time per iteration (ms): 1860.6 | learning rate: 4.876E-07 | global batch size:    48 | lm loss: 8.965704E+00 | loss scale: 32768.0 | grad norm: 114.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       50/    1200 | consumed samples:         2400 | elapsed time per iteration (ms): 2020.3 | learning rate: 5.033E-07 | global batch size:    48 | lm loss: 8.943961E+00 | loss scale: 32768.0 | grad norm: 121.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       51/    1200 | consumed samples:         2448 | elapsed time per iteration (ms): 2009.9 | learning rate: 5.190E-07 | global batch size:    48 | lm loss: 8.918847E+00 | loss scale: 32768.0 | grad norm: 77.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       52/    1200 | consumed samples:         2496 | elapsed time per iteration (ms): 1663.9 | learning rate: 5.348E-07 | global batch size:    48 | lm loss: 8.893537E+00 | loss scale: 32768.0 | grad norm: 38.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       53/    1200 | consumed samples:         2544 | elapsed time per iteration (ms): 1500.6 | learning rate: 5.505E-07 | global batch size:    48 | lm loss: 8.870337E+00 | loss scale: 32768.0 | grad norm: 21.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       54/    1200 | consumed samples:         2592 | elapsed time per iteration (ms): 1776.6 | learning rate: 5.662E-07 | global batch size:    48 | lm loss: 8.846846E+00 | loss scale: 32768.0 | grad norm: 23.599 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       55/    1200 | consumed samples:         2640 | elapsed time per iteration (ms): 1554.7 | learning rate: 5.820E-07 | global batch size:    48 | lm loss: 8.821966E+00 | loss scale: 32768.0 | grad norm: 28.278 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       56/    1200 | consumed samples:         2688 | elapsed time per iteration (ms): 1970.1 | learning rate: 5.977E-07 | global batch size:    48 | lm loss: 8.801028E+00 | loss scale: 32768.0 | grad norm: 45.294 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       57/    1200 | consumed samples:         2736 | elapsed time per iteration (ms): 1581.4 | learning rate: 6.134E-07 | global batch size:    48 | lm loss: 8.780787E+00 | loss scale: 32768.0 | grad norm: 17.559 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       58/    1200 | consumed samples:         2784 | elapsed time per iteration (ms): 1839.3 | learning rate: 6.291E-07 | global batch size:    48 | lm loss: 8.759646E+00 | loss scale: 32768.0 | grad norm: 17.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       59/    1200 | consumed samples:         2832 | elapsed time per iteration (ms): 1579.6 | learning rate: 6.449E-07 | global batch size:    48 | lm loss: 8.739361E+00 | loss scale: 32768.0 | grad norm: 18.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       60/    1200 | consumed samples:         2880 | elapsed time per iteration (ms): 1815.5 | learning rate: 6.606E-07 | global batch size:    48 | lm loss: 8.719998E+00 | loss scale: 32768.0 | grad norm: 29.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       61/    1200 | consumed samples:         2928 | elapsed time per iteration (ms): 1644.6 | learning rate: 6.763E-07 | global batch size:    48 | lm loss: 8.701450E+00 | loss scale: 32768.0 | grad norm: 34.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       62/    1200 | consumed samples:         2976 | elapsed time per iteration (ms): 1608.8 | learning rate: 6.921E-07 | global batch size:    48 | lm loss: 8.683060E+00 | loss scale: 32768.0 | grad norm: 19.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       63/    1200 | consumed samples:         3024 | elapsed time per iteration (ms): 2220.1 | learning rate: 7.078E-07 | global batch size:    48 | lm loss: 8.665919E+00 | loss scale: 32768.0 | grad norm: 13.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       64/    1200 | consumed samples:         3072 | elapsed time per iteration (ms): 1759.0 | learning rate: 7.235E-07 | global batch size:    48 | lm loss: 8.648647E+00 | loss scale: 32768.0 | grad norm: 19.192 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       65/    1200 | consumed samples:         3120 | elapsed time per iteration (ms): 1673.1 | learning rate: 7.392E-07 | global batch size:    48 | lm loss: 8.629777E+00 | loss scale: 32768.0 | grad norm: 16.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       66/    1200 | consumed samples:         3168 | elapsed time per iteration (ms): 1785.0 | learning rate: 7.550E-07 | global batch size:    48 | lm loss: 8.613592E+00 | loss scale: 32768.0 | grad norm: 19.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       67/    1200 | consumed samples:         3216 | elapsed time per iteration (ms): 1958.1 | learning rate: 7.707E-07 | global batch size:    48 | lm loss: 8.598484E+00 | loss scale: 32768.0 | grad norm: 20.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       68/    1200 | consumed samples:         3264 | elapsed time per iteration (ms): 1867.5 | learning rate: 7.864E-07 | global batch size:    48 | lm loss: 8.582745E+00 | loss scale: 32768.0 | grad norm: 22.985 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       69/    1200 | consumed samples:         3312 | elapsed time per iteration (ms): 1782.4 | learning rate: 8.022E-07 | global batch size:    48 | lm loss: 8.565820E+00 | loss scale: 32768.0 | grad norm: 23.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       70/    1200 | consumed samples:         3360 | elapsed time per iteration (ms): 1911.4 | learning rate: 8.179E-07 | global batch size:    48 | lm loss: 8.551428E+00 | loss scale: 32768.0 | grad norm: 25.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       71/    1200 | consumed samples:         3408 | elapsed time per iteration (ms): 1507.8 | learning rate: 8.336E-07 | global batch size:    48 | lm loss: 8.535112E+00 | loss scale: 32768.0 | grad norm: 15.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       72/    1200 | consumed samples:         3456 | elapsed time per iteration (ms): 1718.2 | learning rate: 8.493E-07 | global batch size:    48 | lm loss: 8.520369E+00 | loss scale: 32768.0 | grad norm: 12.179 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       73/    1200 | consumed samples:         3504 | elapsed time per iteration (ms): 1511.5 | learning rate: 8.651E-07 | global batch size:    48 | lm loss: 8.504963E+00 | loss scale: 32768.0 | grad norm: 24.200 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       74/    1200 | consumed samples:         3552 | elapsed time per iteration (ms): 1842.5 | learning rate: 8.808E-07 | global batch size:    48 | lm loss: 8.490027E+00 | loss scale: 32768.0 | grad norm: 22.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       75/    1200 | consumed samples:         3600 | elapsed time per iteration (ms): 1664.1 | learning rate: 8.965E-07 | global batch size:    48 | lm loss: 8.476257E+00 | loss scale: 32768.0 | grad norm: 17.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       76/    1200 | consumed samples:         3648 | elapsed time per iteration (ms): 2053.9 | learning rate: 9.123E-07 | global batch size:    48 | lm loss: 8.463788E+00 | loss scale: 32768.0 | grad norm: 15.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       77/    1200 | consumed samples:         3696 | elapsed time per iteration (ms): 1812.4 | learning rate: 9.280E-07 | global batch size:    48 | lm loss: 8.449090E+00 | loss scale: 32768.0 | grad norm: 15.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       78/    1200 | consumed samples:         3744 | elapsed time per iteration (ms): 1586.3 | learning rate: 9.437E-07 | global batch size:    48 | lm loss: 8.435119E+00 | loss scale: 32768.0 | grad norm: 42.357 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       79/    1200 | consumed samples:         3792 | elapsed time per iteration (ms): 1919.2 | learning rate: 9.594E-07 | global batch size:    48 | lm loss: 8.422962E+00 | loss scale: 32768.0 | grad norm: 29.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       80/    1200 | consumed samples:         3840 | elapsed time per iteration (ms): 1867.2 | learning rate: 9.752E-07 | global batch size:    48 | lm loss: 8.410001E+00 | loss scale: 32768.0 | grad norm: 29.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       81/    1200 | consumed samples:         3888 | elapsed time per iteration (ms): 1790.7 | learning rate: 9.909E-07 | global batch size:    48 | lm loss: 8.397103E+00 | loss scale: 32768.0 | grad norm: 25.535 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       82/    1200 | consumed samples:         3936 | elapsed time per iteration (ms): 1681.8 | learning rate: 1.007E-06 | global batch size:    48 | lm loss: 8.384640E+00 | loss scale: 32768.0 | grad norm: 13.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       83/    1200 | consumed samples:         3984 | elapsed time per iteration (ms): 2154.5 | learning rate: 1.022E-06 | global batch size:    48 | lm loss: 8.371735E+00 | loss scale: 32768.0 | grad norm: 23.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       84/    1200 | consumed samples:         4032 | elapsed time per iteration (ms): 1745.8 | learning rate: 1.038E-06 | global batch size:    48 | lm loss: 8.361050E+00 | loss scale: 32768.0 | grad norm: 21.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       85/    1200 | consumed samples:         4080 | elapsed time per iteration (ms): 1639.6 | learning rate: 1.054E-06 | global batch size:    48 | lm loss: 8.349260E+00 | loss scale: 32768.0 | grad norm: 13.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       86/    1200 | consumed samples:         4128 | elapsed time per iteration (ms): 1719.8 | learning rate: 1.070E-06 | global batch size:    48 | lm loss: 8.337137E+00 | loss scale: 32768.0 | grad norm: 13.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       87/    1200 | consumed samples:         4176 | elapsed time per iteration (ms): 1279.7 | learning rate: 1.085E-06 | global batch size:    48 | lm loss: 7.561793E+00 | loss scale: 32768.0 | grad norm: 23.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       88/    1200 | consumed samples:         4224 | elapsed time per iteration (ms): 1100.4 | learning rate: 1.101E-06 | global batch size:    48 | lm loss: 7.426022E+00 | loss scale: 32768.0 | grad norm: 18.132 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       89/    1200 | consumed samples:         4272 | elapsed time per iteration (ms): 1288.9 | learning rate: 1.117E-06 | global batch size:    48 | lm loss: 7.480315E+00 | loss scale: 32768.0 | grad norm: 14.404 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       90/    1200 | consumed samples:         4320 | elapsed time per iteration (ms): 1169.1 | learning rate: 1.132E-06 | global batch size:    48 | lm loss: 7.413898E+00 | loss scale: 32768.0 | grad norm: 16.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       91/    1200 | consumed samples:         4368 | elapsed time per iteration (ms): 1071.3 | learning rate: 1.148E-06 | global batch size:    48 | lm loss: 7.392120E+00 | loss scale: 32768.0 | grad norm: 13.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       92/    1200 | consumed samples:         4416 | elapsed time per iteration (ms): 1071.4 | learning rate: 1.164E-06 | global batch size:    48 | lm loss: 7.355820E+00 | loss scale: 32768.0 | grad norm: 19.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       93/    1200 | consumed samples:         4464 | elapsed time per iteration (ms): 1376.3 | learning rate: 1.180E-06 | global batch size:    48 | lm loss: 7.538610E+00 | loss scale: 32768.0 | grad norm: 28.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       94/    1200 | consumed samples:         4512 | elapsed time per iteration (ms): 1263.5 | learning rate: 1.195E-06 | global batch size:    48 | lm loss: 7.449403E+00 | loss scale: 32768.0 | grad norm: 21.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       95/    1200 | consumed samples:         4560 | elapsed time per iteration (ms): 1156.8 | learning rate: 1.211E-06 | global batch size:    48 | lm loss: 7.384695E+00 | loss scale: 32768.0 | grad norm: 10.434 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       96/    1200 | consumed samples:         4608 | elapsed time per iteration (ms): 1188.6 | learning rate: 1.227E-06 | global batch size:    48 | lm loss: 7.427108E+00 | loss scale: 32768.0 | grad norm: 19.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       97/    1200 | consumed samples:         4656 | elapsed time per iteration (ms): 1244.4 | learning rate: 1.243E-06 | global batch size:    48 | lm loss: 7.544582E+00 | loss scale: 32768.0 | grad norm: 50.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       98/    1200 | consumed samples:         4704 | elapsed time per iteration (ms): 1164.6 | learning rate: 1.258E-06 | global batch size:    48 | lm loss: 7.232240E+00 | loss scale: 32768.0 | grad norm: 13.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       99/    1200 | consumed samples:         4752 | elapsed time per iteration (ms): 1076.6 | learning rate: 1.274E-06 | global batch size:    48 | lm loss: 7.458689E+00 | loss scale: 32768.0 | grad norm: 15.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      100/    1200 | consumed samples:         4800 | elapsed time per iteration (ms): 1169.9 | learning rate: 1.290E-06 | global batch size:    48 | lm loss: 7.437881E+00 | loss scale: 32768.0 | grad norm: 10.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      101/    1200 | consumed samples:         4848 | elapsed time per iteration (ms): 1030.0 | learning rate: 1.305E-06 | global batch size:    48 | lm loss: 7.304164E+00 | loss scale: 32768.0 | grad norm: 12.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      102/    1200 | consumed samples:         4896 | elapsed time per iteration (ms): 1241.0 | learning rate: 1.321E-06 | global batch size:    48 | lm loss: 7.244372E+00 | loss scale: 32768.0 | grad norm: 13.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      103/    1200 | consumed samples:         4944 | elapsed time per iteration (ms): 1120.0 | learning rate: 1.337E-06 | global batch size:    48 | lm loss: 7.354286E+00 | loss scale: 32768.0 | grad norm: 26.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      104/    1200 | consumed samples:         4992 | elapsed time per iteration (ms): 1180.0 | learning rate: 1.353E-06 | global batch size:    48 | lm loss: 7.199380E+00 | loss scale: 32768.0 | grad norm: 21.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      105/    1200 | consumed samples:         5040 | elapsed time per iteration (ms): 1120.5 | learning rate: 1.368E-06 | global batch size:    48 | lm loss: 7.187885E+00 | loss scale: 32768.0 | grad norm: 8.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      106/    1200 | consumed samples:         5088 | elapsed time per iteration (ms): 1285.8 | learning rate: 1.384E-06 | global batch size:    48 | lm loss: 7.168082E+00 | loss scale: 32768.0 | grad norm: 8.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      107/    1200 | consumed samples:         5136 | elapsed time per iteration (ms): 1201.4 | learning rate: 1.400E-06 | global batch size:    48 | lm loss: 7.123742E+00 | loss scale: 32768.0 | grad norm: 13.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      108/    1200 | consumed samples:         5184 | elapsed time per iteration (ms): 1032.9 | learning rate: 1.416E-06 | global batch size:    48 | lm loss: 7.158571E+00 | loss scale: 32768.0 | grad norm: 9.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      109/    1200 | consumed samples:         5232 | elapsed time per iteration (ms): 1046.0 | learning rate: 1.431E-06 | global batch size:    48 | lm loss: 7.087473E+00 | loss scale: 32768.0 | grad norm: 8.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      110/    1200 | consumed samples:         5280 | elapsed time per iteration (ms): 1353.7 | learning rate: 1.447E-06 | global batch size:    48 | lm loss: 7.170119E+00 | loss scale: 32768.0 | grad norm: 12.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      111/    1200 | consumed samples:         5328 | elapsed time per iteration (ms): 1182.8 | learning rate: 1.463E-06 | global batch size:    48 | lm loss: 7.098981E+00 | loss scale: 32768.0 | grad norm: 8.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      112/    1200 | consumed samples:         5376 | elapsed time per iteration (ms): 1027.3 | learning rate: 1.478E-06 | global batch size:    48 | lm loss: 7.151359E+00 | loss scale: 32768.0 | grad norm: 6.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      113/    1200 | consumed samples:         5424 | elapsed time per iteration (ms): 1120.9 | learning rate: 1.494E-06 | global batch size:    48 | lm loss: 7.075103E+00 | loss scale: 32768.0 | grad norm: 8.231 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      114/    1200 | consumed samples:         5472 | elapsed time per iteration (ms): 1172.3 | learning rate: 1.510E-06 | global batch size:    48 | lm loss: 7.152511E+00 | loss scale: 32768.0 | grad norm: 16.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      115/    1200 | consumed samples:         5520 | elapsed time per iteration (ms): 1321.6 | learning rate: 1.526E-06 | global batch size:    48 | lm loss: 7.037993E+00 | loss scale: 32768.0 | grad norm: 6.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      116/    1200 | consumed samples:         5568 | elapsed time per iteration (ms): 1189.6 | learning rate: 1.541E-06 | global batch size:    48 | lm loss: 7.136487E+00 | loss scale: 32768.0 | grad norm: 12.256 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      117/    1200 | consumed samples:         5616 | elapsed time per iteration (ms): 1036.7 | learning rate: 1.557E-06 | global batch size:    48 | lm loss: 6.940375E+00 | loss scale: 32768.0 | grad norm: 8.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      118/    1200 | consumed samples:         5664 | elapsed time per iteration (ms): 1031.4 | learning rate: 1.573E-06 | global batch size:    48 | lm loss: 7.046217E+00 | loss scale: 32768.0 | grad norm: 7.294 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      119/    1200 | consumed samples:         5712 | elapsed time per iteration (ms): 1310.6 | learning rate: 1.589E-06 | global batch size:    48 | lm loss: 7.093569E+00 | loss scale: 32768.0 | grad norm: 8.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      120/    1200 | consumed samples:         5760 | elapsed time per iteration (ms): 1196.0 | learning rate: 1.604E-06 | global batch size:    48 | lm loss: 7.011636E+00 | loss scale: 32768.0 | grad norm: 10.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      121/    1200 | consumed samples:         5808 | elapsed time per iteration (ms): 2834.6 | learning rate: 1.620E-06 | global batch size:    48 | lm loss: 8.320315E+00 | loss scale: 32768.0 | grad norm: 8.232 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      122/    1200 | consumed samples:         5856 | elapsed time per iteration (ms): 2580.6 | learning rate: 1.636E-06 | global batch size:    48 | lm loss: 8.303486E+00 | loss scale: 32768.0 | grad norm: 8.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      123/    1200 | consumed samples:         5904 | elapsed time per iteration (ms): 1733.2 | learning rate: 1.652E-06 | global batch size:    48 | lm loss: 8.285578E+00 | loss scale: 32768.0 | grad norm: 7.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      124/    1200 | consumed samples:         5952 | elapsed time per iteration (ms): 1596.1 | learning rate: 1.667E-06 | global batch size:    48 | lm loss: 8.269178E+00 | loss scale: 32768.0 | grad norm: 9.323 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      125/    1200 | consumed samples:         6000 | elapsed time per iteration (ms): 1751.1 | learning rate: 1.683E-06 | global batch size:    48 | lm loss: 8.251255E+00 | loss scale: 32768.0 | grad norm: 11.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      126/    1200 | consumed samples:         6048 | elapsed time per iteration (ms): 1720.8 | learning rate: 1.699E-06 | global batch size:    48 | lm loss: 8.235571E+00 | loss scale: 32768.0 | grad norm: 29.215 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      127/    1200 | consumed samples:         6096 | elapsed time per iteration (ms): 1626.9 | learning rate: 1.714E-06 | global batch size:    48 | lm loss: 8.219926E+00 | loss scale: 32768.0 | grad norm: 12.132 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      128/    1200 | consumed samples:         6144 | elapsed time per iteration (ms): 1859.0 | learning rate: 1.730E-06 | global batch size:    48 | lm loss: 8.205511E+00 | loss scale: 32768.0 | grad norm: 11.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      129/    1200 | consumed samples:         6192 | elapsed time per iteration (ms): 1629.9 | learning rate: 1.746E-06 | global batch size:    48 | lm loss: 8.189604E+00 | loss scale: 32768.0 | grad norm: 9.571 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      130/    1200 | consumed samples:         6240 | elapsed time per iteration (ms): 1723.5 | learning rate: 1.762E-06 | global batch size:    48 | lm loss: 8.174866E+00 | loss scale: 32768.0 | grad norm: 13.139 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      131/    1200 | consumed samples:         6288 | elapsed time per iteration (ms): 1993.5 | learning rate: 1.777E-06 | global batch size:    48 | lm loss: 8.160437E+00 | loss scale: 32768.0 | grad norm: 14.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      132/    1200 | consumed samples:         6336 | elapsed time per iteration (ms): 1616.0 | learning rate: 1.793E-06 | global batch size:    48 | lm loss: 8.146132E+00 | loss scale: 32768.0 | grad norm: 10.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      133/    1200 | consumed samples:         6384 | elapsed time per iteration (ms): 1718.5 | learning rate: 1.809E-06 | global batch size:    48 | lm loss: 8.131131E+00 | loss scale: 32768.0 | grad norm: 8.164 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      134/    1200 | consumed samples:         6432 | elapsed time per iteration (ms): 2087.9 | learning rate: 1.825E-06 | global batch size:    48 | lm loss: 8.115845E+00 | loss scale: 32768.0 | grad norm: 8.273 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      135/    1200 | consumed samples:         6480 | elapsed time per iteration (ms): 1609.8 | learning rate: 1.840E-06 | global batch size:    48 | lm loss: 8.101638E+00 | loss scale: 32768.0 | grad norm: 9.232 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      136/    1200 | consumed samples:         6528 | elapsed time per iteration (ms): 1861.6 | learning rate: 1.856E-06 | global batch size:    48 | lm loss: 8.088846E+00 | loss scale: 32768.0 | grad norm: 11.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      137/    1200 | consumed samples:         6576 | elapsed time per iteration (ms): 1872.1 | learning rate: 1.872E-06 | global batch size:    48 | lm loss: 8.074743E+00 | loss scale: 32768.0 | grad norm: 7.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      138/    1200 | consumed samples:         6624 | elapsed time per iteration (ms): 1753.3 | learning rate: 1.887E-06 | global batch size:    48 | lm loss: 8.062888E+00 | loss scale: 32768.0 | grad norm: 14.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      139/    1200 | consumed samples:         6672 | elapsed time per iteration (ms): 1616.0 | learning rate: 1.903E-06 | global batch size:    48 | lm loss: 8.049443E+00 | loss scale: 32768.0 | grad norm: 8.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      140/    1200 | consumed samples:         6720 | elapsed time per iteration (ms): 1657.3 | learning rate: 1.919E-06 | global batch size:    48 | lm loss: 8.037825E+00 | loss scale: 32768.0 | grad norm: 11.242 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      141/    1200 | consumed samples:         6768 | elapsed time per iteration (ms): 1697.1 | learning rate: 1.935E-06 | global batch size:    48 | lm loss: 8.024845E+00 | loss scale: 32768.0 | grad norm: 6.352 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      142/    1200 | consumed samples:         6816 | elapsed time per iteration (ms): 1994.1 | learning rate: 1.950E-06 | global batch size:    48 | lm loss: 8.012057E+00 | loss scale: 32768.0 | grad norm: 13.342 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      143/    1200 | consumed samples:         6864 | elapsed time per iteration (ms): 1682.8 | learning rate: 1.966E-06 | global batch size:    48 | lm loss: 7.999958E+00 | loss scale: 32768.0 | grad norm: 11.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      144/    1200 | consumed samples:         6912 | elapsed time per iteration (ms): 1640.7 | learning rate: 1.982E-06 | global batch size:    48 | lm loss: 7.987191E+00 | loss scale: 32768.0 | grad norm: 10.230 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      145/    1200 | consumed samples:         6960 | elapsed time per iteration (ms): 1547.8 | learning rate: 1.998E-06 | global batch size:    48 | lm loss: 7.975149E+00 | loss scale: 32768.0 | grad norm: 7.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      146/    1200 | consumed samples:         7008 | elapsed time per iteration (ms): 2061.5 | learning rate: 2.013E-06 | global batch size:    48 | lm loss: 7.962920E+00 | loss scale: 32768.0 | grad norm: 9.344 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      147/    1200 | consumed samples:         7056 | elapsed time per iteration (ms): 1751.6 | learning rate: 2.029E-06 | global batch size:    48 | lm loss: 7.951040E+00 | loss scale: 32768.0 | grad norm: 10.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      148/    1200 | consumed samples:         7104 | elapsed time per iteration (ms): 1856.7 | learning rate: 2.045E-06 | global batch size:    48 | lm loss: 7.939368E+00 | loss scale: 32768.0 | grad norm: 8.548 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      149/    1200 | consumed samples:         7152 | elapsed time per iteration (ms): 1823.5 | learning rate: 2.060E-06 | global batch size:    48 | lm loss: 7.928809E+00 | loss scale: 32768.0 | grad norm: 7.334 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      150/    1200 | consumed samples:         7200 | elapsed time per iteration (ms): 1782.7 | learning rate: 2.076E-06 | global batch size:    48 | lm loss: 7.917006E+00 | loss scale: 32768.0 | grad norm: 7.556 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      151/    1200 | consumed samples:         7248 | elapsed time per iteration (ms): 1667.2 | learning rate: 2.092E-06 | global batch size:    48 | lm loss: 7.905905E+00 | loss scale: 32768.0 | grad norm: 10.547 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      152/    1200 | consumed samples:         7296 | elapsed time per iteration (ms): 1730.1 | learning rate: 2.108E-06 | global batch size:    48 | lm loss: 7.895315E+00 | loss scale: 32768.0 | grad norm: 10.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      153/    1200 | consumed samples:         7344 | elapsed time per iteration (ms): 1714.7 | learning rate: 2.123E-06 | global batch size:    48 | lm loss: 7.884588E+00 | loss scale: 32768.0 | grad norm: 7.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      154/    1200 | consumed samples:         7392 | elapsed time per iteration (ms): 1553.8 | learning rate: 2.139E-06 | global batch size:    48 | lm loss: 7.874053E+00 | loss scale: 32768.0 | grad norm: 7.550 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      155/    1200 | consumed samples:         7440 | elapsed time per iteration (ms): 2168.4 | learning rate: 2.155E-06 | global batch size:    48 | lm loss: 7.863418E+00 | loss scale: 32768.0 | grad norm: 7.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      156/    1200 | consumed samples:         7488 | elapsed time per iteration (ms): 1806.4 | learning rate: 2.171E-06 | global batch size:    48 | lm loss: 7.852326E+00 | loss scale: 32768.0 | grad norm: 11.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      157/    1200 | consumed samples:         7536 | elapsed time per iteration (ms): 1629.0 | learning rate: 2.186E-06 | global batch size:    48 | lm loss: 7.842195E+00 | loss scale: 32768.0 | grad norm: 10.826 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      158/    1200 | consumed samples:         7584 | elapsed time per iteration (ms): 1813.6 | learning rate: 2.202E-06 | global batch size:    48 | lm loss: 7.832119E+00 | loss scale: 32768.0 | grad norm: 6.322 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      159/    1200 | consumed samples:         7632 | elapsed time per iteration (ms): 1604.3 | learning rate: 2.218E-06 | global batch size:    48 | lm loss: 7.822099E+00 | loss scale: 32768.0 | grad norm: 7.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      160/    1200 | consumed samples:         7680 | elapsed time per iteration (ms): 1660.9 | learning rate: 2.233E-06 | global batch size:    48 | lm loss: 7.811752E+00 | loss scale: 32768.0 | grad norm: 7.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      161/    1200 | consumed samples:         7728 | elapsed time per iteration (ms): 1675.6 | learning rate: 2.249E-06 | global batch size:    48 | lm loss: 7.800961E+00 | loss scale: 32768.0 | grad norm: 8.998 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      162/    1200 | consumed samples:         7776 | elapsed time per iteration (ms): 1754.5 | learning rate: 2.265E-06 | global batch size:    48 | lm loss: 7.790709E+00 | loss scale: 32768.0 | grad norm: 9.199 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      163/    1200 | consumed samples:         7824 | elapsed time per iteration (ms): 1537.9 | learning rate: 2.281E-06 | global batch size:    48 | lm loss: 7.780742E+00 | loss scale: 32768.0 | grad norm: 8.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      164/    1200 | consumed samples:         7872 | elapsed time per iteration (ms): 2352.2 | learning rate: 2.296E-06 | global batch size:    48 | lm loss: 7.770678E+00 | loss scale: 32768.0 | grad norm: 6.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      165/    1200 | consumed samples:         7920 | elapsed time per iteration (ms): 1669.4 | learning rate: 2.312E-06 | global batch size:    48 | lm loss: 7.760927E+00 | loss scale: 32768.0 | grad norm: 7.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      166/    1200 | consumed samples:         7968 | elapsed time per iteration (ms): 1748.4 | learning rate: 2.328E-06 | global batch size:    48 | lm loss: 7.751854E+00 | loss scale: 32768.0 | grad norm: 7.307 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      167/    1200 | consumed samples:         8016 | elapsed time per iteration (ms): 1646.4 | learning rate: 2.344E-06 | global batch size:    48 | lm loss: 7.741507E+00 | loss scale: 32768.0 | grad norm: 6.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      168/    1200 | consumed samples:         8064 | elapsed time per iteration (ms): 1687.9 | learning rate: 2.359E-06 | global batch size:    48 | lm loss: 7.732702E+00 | loss scale: 32768.0 | grad norm: 12.568 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      169/    1200 | consumed samples:         8112 | elapsed time per iteration (ms): 1923.8 | learning rate: 2.375E-06 | global batch size:    48 | lm loss: 7.723929E+00 | loss scale: 32768.0 | grad norm: 10.567 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      170/    1200 | consumed samples:         8160 | elapsed time per iteration (ms): 1756.3 | learning rate: 2.391E-06 | global batch size:    48 | lm loss: 7.714886E+00 | loss scale: 32768.0 | grad norm: 7.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      171/    1200 | consumed samples:         8208 | elapsed time per iteration (ms): 1764.0 | learning rate: 2.406E-06 | global batch size:    48 | lm loss: 7.705281E+00 | loss scale: 32768.0 | grad norm: 7.222 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      172/    1200 | consumed samples:         8256 | elapsed time per iteration (ms): 1997.7 | learning rate: 2.422E-06 | global batch size:    48 | lm loss: 7.696617E+00 | loss scale: 32768.0 | grad norm: 7.534 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      173/    1200 | consumed samples:         8304 | elapsed time per iteration (ms): 1735.9 | learning rate: 2.438E-06 | global batch size:    48 | lm loss: 7.688081E+00 | loss scale: 32768.0 | grad norm: 8.156 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      174/    1200 | consumed samples:         8352 | elapsed time per iteration (ms): 1982.5 | learning rate: 2.454E-06 | global batch size:    48 | lm loss: 7.679262E+00 | loss scale: 32768.0 | grad norm: 8.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      175/    1200 | consumed samples:         8400 | elapsed time per iteration (ms): 1717.1 | learning rate: 2.469E-06 | global batch size:    48 | lm loss: 7.671001E+00 | loss scale: 32768.0 | grad norm: 9.556 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      176/    1200 | consumed samples:         8448 | elapsed time per iteration (ms): 1599.4 | learning rate: 2.485E-06 | global batch size:    48 | lm loss: 7.663241E+00 | loss scale: 32768.0 | grad norm: 7.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      177/    1200 | consumed samples:         8496 | elapsed time per iteration (ms): 1625.2 | learning rate: 2.501E-06 | global batch size:    48 | lm loss: 7.654945E+00 | loss scale: 32768.0 | grad norm: 7.011 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      178/    1200 | consumed samples:         8544 | elapsed time per iteration (ms): 1776.4 | learning rate: 2.517E-06 | global batch size:    48 | lm loss: 7.646960E+00 | loss scale: 32768.0 | grad norm: 7.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      179/    1200 | consumed samples:         8592 | elapsed time per iteration (ms): 1684.4 | learning rate: 2.532E-06 | global batch size:    48 | lm loss: 7.637773E+00 | loss scale: 32768.0 | grad norm: 9.260 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      180/    1200 | consumed samples:         8640 | elapsed time per iteration (ms): 2117.8 | learning rate: 2.548E-06 | global batch size:    48 | lm loss: 7.629160E+00 | loss scale: 32768.0 | grad norm: 7.321 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      181/    1200 | consumed samples:         8688 | elapsed time per iteration (ms): 1874.4 | learning rate: 2.564E-06 | global batch size:    48 | lm loss: 7.621122E+00 | loss scale: 32768.0 | grad norm: 8.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      182/    1200 | consumed samples:         8736 | elapsed time per iteration (ms): 1806.2 | learning rate: 2.580E-06 | global batch size:    48 | lm loss: 7.612926E+00 | loss scale: 32768.0 | grad norm: 9.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      183/    1200 | consumed samples:         8784 | elapsed time per iteration (ms): 2005.4 | learning rate: 2.595E-06 | global batch size:    48 | lm loss: 7.605947E+00 | loss scale: 32768.0 | grad norm: 7.508 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      184/    1200 | consumed samples:         8832 | elapsed time per iteration (ms): 1798.9 | learning rate: 2.611E-06 | global batch size:    48 | lm loss: 7.597850E+00 | loss scale: 32768.0 | grad norm: 6.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      185/    1200 | consumed samples:         8880 | elapsed time per iteration (ms): 1756.5 | learning rate: 2.627E-06 | global batch size:    48 | lm loss: 7.589690E+00 | loss scale: 32768.0 | grad norm: 7.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      186/    1200 | consumed samples:         8928 | elapsed time per iteration (ms): 1985.1 | learning rate: 2.642E-06 | global batch size:    48 | lm loss: 7.582527E+00 | loss scale: 32768.0 | grad norm: 9.140 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      187/    1200 | consumed samples:         8976 | elapsed time per iteration (ms): 1564.7 | learning rate: 2.658E-06 | global batch size:    48 | lm loss: 7.575848E+00 | loss scale: 32768.0 | grad norm: 8.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      188/    1200 | consumed samples:         9024 | elapsed time per iteration (ms): 1995.5 | learning rate: 2.674E-06 | global batch size:    48 | lm loss: 7.568892E+00 | loss scale: 32768.0 | grad norm: 8.893 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      189/    1200 | consumed samples:         9072 | elapsed time per iteration (ms): 1753.4 | learning rate: 2.690E-06 | global batch size:    48 | lm loss: 7.561327E+00 | loss scale: 32768.0 | grad norm: 5.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      190/    1200 | consumed samples:         9120 | elapsed time per iteration (ms): 1732.0 | learning rate: 2.705E-06 | global batch size:    48 | lm loss: 7.554164E+00 | loss scale: 32768.0 | grad norm: 10.352 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      191/    1200 | consumed samples:         9168 | elapsed time per iteration (ms): 1725.6 | learning rate: 2.721E-06 | global batch size:    48 | lm loss: 7.546894E+00 | loss scale: 32768.0 | grad norm: 6.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      192/    1200 | consumed samples:         9216 | elapsed time per iteration (ms): 1297.7 | learning rate: 2.737E-06 | global batch size:    48 | lm loss: 6.524255E+00 | loss scale: 32768.0 | grad norm: 8.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      193/    1200 | consumed samples:         9264 | elapsed time per iteration (ms): 1435.0 | learning rate: 2.753E-06 | global batch size:    48 | lm loss: 6.435546E+00 | loss scale: 32768.0 | grad norm: 8.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      194/    1200 | consumed samples:         9312 | elapsed time per iteration (ms): 1111.5 | learning rate: 2.768E-06 | global batch size:    48 | lm loss: 6.455812E+00 | loss scale: 32768.0 | grad norm: 12.170 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      195/    1200 | consumed samples:         9360 | elapsed time per iteration (ms): 1281.9 | learning rate: 2.784E-06 | global batch size:    48 | lm loss: 6.588354E+00 | loss scale: 32768.0 | grad norm: 10.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      196/    1200 | consumed samples:         9408 | elapsed time per iteration (ms): 1038.0 | learning rate: 2.800E-06 | global batch size:    48 | lm loss: 6.603907E+00 | loss scale: 32768.0 | grad norm: 8.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      197/    1200 | consumed samples:         9456 | elapsed time per iteration (ms): 1038.2 | learning rate: 2.815E-06 | global batch size:    48 | lm loss: 6.539472E+00 | loss scale: 32768.0 | grad norm: 9.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      198/    1200 | consumed samples:         9504 | elapsed time per iteration (ms): 1027.8 | learning rate: 2.831E-06 | global batch size:    48 | lm loss: 6.496494E+00 | loss scale: 32768.0 | grad norm: 6.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      199/    1200 | consumed samples:         9552 | elapsed time per iteration (ms): 1294.8 | learning rate: 2.847E-06 | global batch size:    48 | lm loss: 6.583463E+00 | loss scale: 32768.0 | grad norm: 7.582 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      200/    1200 | consumed samples:         9600 | elapsed time per iteration (ms): 1187.9 | learning rate: 2.863E-06 | global batch size:    48 | lm loss: 6.478332E+00 | loss scale: 32768.0 | grad norm: 8.339 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      201/    1200 | consumed samples:         9648 | elapsed time per iteration (ms): 1178.9 | learning rate: 2.878E-06 | global batch size:    48 | lm loss: 6.522442E+00 | loss scale: 32768.0 | grad norm: 7.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      202/    1200 | consumed samples:         9696 | elapsed time per iteration (ms): 1154.3 | learning rate: 2.894E-06 | global batch size:    48 | lm loss: 6.571943E+00 | loss scale: 32768.0 | grad norm: 7.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      203/    1200 | consumed samples:         9744 | elapsed time per iteration (ms): 1096.7 | learning rate: 2.910E-06 | global batch size:    48 | lm loss: 6.572008E+00 | loss scale: 32768.0 | grad norm: 7.958 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      204/    1200 | consumed samples:         9792 | elapsed time per iteration (ms): 1217.2 | learning rate: 2.926E-06 | global batch size:    48 | lm loss: 6.425905E+00 | loss scale: 32768.0 | grad norm: 8.535 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      205/    1200 | consumed samples:         9840 | elapsed time per iteration (ms): 1160.1 | learning rate: 2.941E-06 | global batch size:    48 | lm loss: 6.510650E+00 | loss scale: 32768.0 | grad norm: 7.628 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      206/    1200 | consumed samples:         9888 | elapsed time per iteration (ms): 1031.5 | learning rate: 2.957E-06 | global batch size:    48 | lm loss: 6.437162E+00 | loss scale: 32768.0 | grad norm: 6.104 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      207/    1200 | consumed samples:         9936 | elapsed time per iteration (ms): 1090.0 | learning rate: 2.973E-06 | global batch size:    48 | lm loss: 6.418917E+00 | loss scale: 32768.0 | grad norm: 5.989 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      208/    1200 | consumed samples:         9984 | elapsed time per iteration (ms): 1153.8 | learning rate: 2.988E-06 | global batch size:    48 | lm loss: 6.507769E+00 | loss scale: 32768.0 | grad norm: 7.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      209/    1200 | consumed samples:        10032 | elapsed time per iteration (ms): 1309.7 | learning rate: 3.004E-06 | global batch size:    48 | lm loss: 6.381532E+00 | loss scale: 32768.0 | grad norm: 8.589 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      210/    1200 | consumed samples:        10080 | elapsed time per iteration (ms): 1180.1 | learning rate: 3.020E-06 | global batch size:    48 | lm loss: 6.388973E+00 | loss scale: 32768.0 | grad norm: 5.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      211/    1200 | consumed samples:        10128 | elapsed time per iteration (ms): 1186.5 | learning rate: 3.036E-06 | global batch size:    48 | lm loss: 6.474382E+00 | loss scale: 32768.0 | grad norm: 9.543 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      212/    1200 | consumed samples:        10176 | elapsed time per iteration (ms): 1112.3 | learning rate: 3.051E-06 | global batch size:    48 | lm loss: 6.390703E+00 | loss scale: 32768.0 | grad norm: 7.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      213/    1200 | consumed samples:        10224 | elapsed time per iteration (ms): 1114.9 | learning rate: 3.067E-06 | global batch size:    48 | lm loss: 6.423018E+00 | loss scale: 32768.0 | grad norm: 6.541 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      214/    1200 | consumed samples:        10272 | elapsed time per iteration (ms): 1284.3 | learning rate: 3.083E-06 | global batch size:    48 | lm loss: 6.449780E+00 | loss scale: 32768.0 | grad norm: 8.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      215/    1200 | consumed samples:        10320 | elapsed time per iteration (ms): 1027.5 | learning rate: 3.099E-06 | global batch size:    48 | lm loss: 6.484305E+00 | loss scale: 32768.0 | grad norm: 9.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      216/    1200 | consumed samples:        10368 | elapsed time per iteration (ms): 1166.7 | learning rate: 3.114E-06 | global batch size:    48 | lm loss: 6.534196E+00 | loss scale: 32768.0 | grad norm: 8.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      217/    1200 | consumed samples:        10416 | elapsed time per iteration (ms): 1319.6 | learning rate: 3.130E-06 | global batch size:    48 | lm loss: 6.543432E+00 | loss scale: 32768.0 | grad norm: 6.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      218/    1200 | consumed samples:        10464 | elapsed time per iteration (ms): 1032.1 | learning rate: 3.146E-06 | global batch size:    48 | lm loss: 6.421909E+00 | loss scale: 32768.0 | grad norm: 5.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      219/    1200 | consumed samples:        10512 | elapsed time per iteration (ms): 1024.1 | learning rate: 3.161E-06 | global batch size:    48 | lm loss: 6.452252E+00 | loss scale: 32768.0 | grad norm: 6.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      220/    1200 | consumed samples:        10560 | elapsed time per iteration (ms): 1264.4 | learning rate: 3.177E-06 | global batch size:    48 | lm loss: 6.391341E+00 | loss scale: 32768.0 | grad norm: 7.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      221/    1200 | consumed samples:        10608 | elapsed time per iteration (ms): 1149.8 | learning rate: 3.193E-06 | global batch size:    48 | lm loss: 6.354852E+00 | loss scale: 32768.0 | grad norm: 7.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      222/    1200 | consumed samples:        10656 | elapsed time per iteration (ms): 1130.1 | learning rate: 3.209E-06 | global batch size:    48 | lm loss: 6.419546E+00 | loss scale: 32768.0 | grad norm: 6.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      223/    1200 | consumed samples:        10704 | elapsed time per iteration (ms): 1188.8 | learning rate: 3.224E-06 | global batch size:    48 | lm loss: 6.410242E+00 | loss scale: 32768.0 | grad norm: 6.927 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      224/    1200 | consumed samples:        10752 | elapsed time per iteration (ms): 1035.3 | learning rate: 3.240E-06 | global batch size:    48 | lm loss: 6.254033E+00 | loss scale: 32768.0 | grad norm: 6.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      225/    1200 | consumed samples:        10800 | elapsed time per iteration (ms): 1289.8 | learning rate: 3.256E-06 | global batch size:    48 | lm loss: 6.327470E+00 | loss scale: 32768.0 | grad norm: 6.277 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      226/    1200 | consumed samples:        10848 | elapsed time per iteration (ms): 1105.3 | learning rate: 3.272E-06 | global batch size:    48 | lm loss: 6.372284E+00 | loss scale: 32768.0 | grad norm: 5.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      227/    1200 | consumed samples:        10896 | elapsed time per iteration (ms): 1051.9 | learning rate: 3.287E-06 | global batch size:    48 | lm loss: 6.349404E+00 | loss scale: 32768.0 | grad norm: 6.182 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      228/    1200 | consumed samples:        10944 | elapsed time per iteration (ms): 1030.0 | learning rate: 3.303E-06 | global batch size:    48 | lm loss: 6.408718E+00 | loss scale: 32768.0 | grad norm: 6.247 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      229/    1200 | consumed samples:        10992 | elapsed time per iteration (ms): 1307.9 | learning rate: 3.319E-06 | global batch size:    48 | lm loss: 6.334721E+00 | loss scale: 32768.0 | grad norm: 6.327 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      230/    1200 | consumed samples:        11040 | elapsed time per iteration (ms): 1364.1 | learning rate: 3.334E-06 | global batch size:    48 | lm loss: 6.427227E+00 | loss scale: 32768.0 | grad norm: 6.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      231/    1200 | consumed samples:        11088 | elapsed time per iteration (ms): 2052.6 | learning rate: 3.350E-06 | global batch size:    48 | lm loss: 7.538977E+00 | loss scale: 32768.0 | grad norm: 6.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      232/    1200 | consumed samples:        11136 | elapsed time per iteration (ms): 2435.8 | learning rate: 3.366E-06 | global batch size:    48 | lm loss: 7.530948E+00 | loss scale: 32768.0 | grad norm: 6.288 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      233/    1200 | consumed samples:        11184 | elapsed time per iteration (ms): 1641.9 | learning rate: 3.382E-06 | global batch size:    48 | lm loss: 7.522476E+00 | loss scale: 32768.0 | grad norm: 7.593 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      234/    1200 | consumed samples:        11232 | elapsed time per iteration (ms): 1517.1 | learning rate: 3.397E-06 | global batch size:    48 | lm loss: 7.514702E+00 | loss scale: 32768.0 | grad norm: 8.161 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      235/    1200 | consumed samples:        11280 | elapsed time per iteration (ms): 1701.0 | learning rate: 3.413E-06 | global batch size:    48 | lm loss: 7.506496E+00 | loss scale: 32768.0 | grad norm: 8.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      236/    1200 | consumed samples:        11328 | elapsed time per iteration (ms): 1491.9 | learning rate: 3.429E-06 | global batch size:    48 | lm loss: 7.498655E+00 | loss scale: 32768.0 | grad norm: 6.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      237/    1200 | consumed samples:        11376 | elapsed time per iteration (ms): 1909.1 | learning rate: 3.445E-06 | global batch size:    48 | lm loss: 7.490961E+00 | loss scale: 32768.0 | grad norm: 7.337 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      238/    1200 | consumed samples:        11424 | elapsed time per iteration (ms): 1975.7 | learning rate: 3.460E-06 | global batch size:    48 | lm loss: 7.483747E+00 | loss scale: 32768.0 | grad norm: 7.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      239/    1200 | consumed samples:        11472 | elapsed time per iteration (ms): 1998.7 | learning rate: 3.476E-06 | global batch size:    48 | lm loss: 7.476967E+00 | loss scale: 32768.0 | grad norm: 8.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      240/    1200 | consumed samples:        11520 | elapsed time per iteration (ms): 1710.7 | learning rate: 3.492E-06 | global batch size:    48 | lm loss: 7.468862E+00 | loss scale: 32768.0 | grad norm: 5.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      241/    1200 | consumed samples:        11568 | elapsed time per iteration (ms): 1491.7 | learning rate: 3.507E-06 | global batch size:    48 | lm loss: 7.461132E+00 | loss scale: 32768.0 | grad norm: 8.535 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      242/    1200 | consumed samples:        11616 | elapsed time per iteration (ms): 1610.2 | learning rate: 3.523E-06 | global batch size:    48 | lm loss: 7.454610E+00 | loss scale: 32768.0 | grad norm: 9.551 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      243/    1200 | consumed samples:        11664 | elapsed time per iteration (ms): 1732.2 | learning rate: 3.539E-06 | global batch size:    48 | lm loss: 7.447888E+00 | loss scale: 32768.0 | grad norm: 6.953 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      244/    1200 | consumed samples:        11712 | elapsed time per iteration (ms): 1626.9 | learning rate: 3.555E-06 | global batch size:    48 | lm loss: 7.441084E+00 | loss scale: 32768.0 | grad norm: 6.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      245/    1200 | consumed samples:        11760 | elapsed time per iteration (ms): 1730.8 | learning rate: 3.570E-06 | global batch size:    48 | lm loss: 7.434357E+00 | loss scale: 32768.0 | grad norm: 7.560 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      246/    1200 | consumed samples:        11808 | elapsed time per iteration (ms): 1588.3 | learning rate: 3.586E-06 | global batch size:    48 | lm loss: 7.428173E+00 | loss scale: 32768.0 | grad norm: 9.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      247/    1200 | consumed samples:        11856 | elapsed time per iteration (ms): 1849.1 | learning rate: 3.602E-06 | global batch size:    48 | lm loss: 7.421528E+00 | loss scale: 32768.0 | grad norm: 7.357 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      248/    1200 | consumed samples:        11904 | elapsed time per iteration (ms): 1743.9 | learning rate: 3.618E-06 | global batch size:    48 | lm loss: 7.414543E+00 | loss scale: 32768.0 | grad norm: 6.288 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      249/    1200 | consumed samples:        11952 | elapsed time per iteration (ms): 1746.4 | learning rate: 3.633E-06 | global batch size:    48 | lm loss: 7.407119E+00 | loss scale: 32768.0 | grad norm: 8.201 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      250/    1200 | consumed samples:        12000 | elapsed time per iteration (ms): 1481.9 | learning rate: 3.649E-06 | global batch size:    48 | lm loss: 7.400437E+00 | loss scale: 32768.0 | grad norm: 7.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      251/    1200 | consumed samples:        12048 | elapsed time per iteration (ms): 1921.4 | learning rate: 3.665E-06 | global batch size:    48 | lm loss: 7.393779E+00 | loss scale: 32768.0 | grad norm: 5.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      252/    1200 | consumed samples:        12096 | elapsed time per iteration (ms): 1614.0 | learning rate: 3.681E-06 | global batch size:    48 | lm loss: 7.387055E+00 | loss scale: 32768.0 | grad norm: 7.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      253/    1200 | consumed samples:        12144 | elapsed time per iteration (ms): 1574.6 | learning rate: 3.696E-06 | global batch size:    48 | lm loss: 7.380515E+00 | loss scale: 32768.0 | grad norm: 5.946 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      254/    1200 | consumed samples:        12192 | elapsed time per iteration (ms): 1987.1 | learning rate: 3.712E-06 | global batch size:    48 | lm loss: 7.373728E+00 | loss scale: 32768.0 | grad norm: 7.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      255/    1200 | consumed samples:        12240 | elapsed time per iteration (ms): 1982.0 | learning rate: 3.728E-06 | global batch size:    48 | lm loss: 7.367268E+00 | loss scale: 32768.0 | grad norm: 5.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      256/    1200 | consumed samples:        12288 | elapsed time per iteration (ms): 1717.7 | learning rate: 3.743E-06 | global batch size:    48 | lm loss: 7.360726E+00 | loss scale: 32768.0 | grad norm: 5.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      257/    1200 | consumed samples:        12336 | elapsed time per iteration (ms): 1690.3 | learning rate: 3.759E-06 | global batch size:    48 | lm loss: 7.353898E+00 | loss scale: 32768.0 | grad norm: 6.321 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      258/    1200 | consumed samples:        12384 | elapsed time per iteration (ms): 1496.8 | learning rate: 3.775E-06 | global batch size:    48 | lm loss: 7.347515E+00 | loss scale: 32768.0 | grad norm: 6.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      259/    1200 | consumed samples:        12432 | elapsed time per iteration (ms): 1901.7 | learning rate: 3.791E-06 | global batch size:    48 | lm loss: 7.341057E+00 | loss scale: 32768.0 | grad norm: 5.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      260/    1200 | consumed samples:        12480 | elapsed time per iteration (ms): 1912.7 | learning rate: 3.806E-06 | global batch size:    48 | lm loss: 7.335413E+00 | loss scale: 32768.0 | grad norm: 6.279 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      261/    1200 | consumed samples:        12528 | elapsed time per iteration (ms): 1541.6 | learning rate: 3.822E-06 | global batch size:    48 | lm loss: 7.328819E+00 | loss scale: 32768.0 | grad norm: 5.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      262/    1200 | consumed samples:        12576 | elapsed time per iteration (ms): 1728.5 | learning rate: 3.838E-06 | global batch size:    48 | lm loss: 7.322223E+00 | loss scale: 32768.0 | grad norm: 6.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      263/    1200 | consumed samples:        12624 | elapsed time per iteration (ms): 1492.4 | learning rate: 3.854E-06 | global batch size:    48 | lm loss: 7.315834E+00 | loss scale: 32768.0 | grad norm: 7.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      264/    1200 | consumed samples:        12672 | elapsed time per iteration (ms): 1501.0 | learning rate: 3.869E-06 | global batch size:    48 | lm loss: 7.310140E+00 | loss scale: 32768.0 | grad norm: 5.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      265/    1200 | consumed samples:        12720 | elapsed time per iteration (ms): 1732.1 | learning rate: 3.885E-06 | global batch size:    48 | lm loss: 7.303745E+00 | loss scale: 32768.0 | grad norm: 5.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      266/    1200 | consumed samples:        12768 | elapsed time per iteration (ms): 1782.1 | learning rate: 3.901E-06 | global batch size:    48 | lm loss: 7.298300E+00 | loss scale: 32768.0 | grad norm: 6.350 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      267/    1200 | consumed samples:        12816 | elapsed time per iteration (ms): 1460.7 | learning rate: 3.916E-06 | global batch size:    48 | lm loss: 7.292450E+00 | loss scale: 32768.0 | grad norm: 5.440 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      268/    1200 | consumed samples:        12864 | elapsed time per iteration (ms): 1820.2 | learning rate: 3.932E-06 | global batch size:    48 | lm loss: 7.286531E+00 | loss scale: 32768.0 | grad norm: 6.365 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      269/    1200 | consumed samples:        12912 | elapsed time per iteration (ms): 1469.2 | learning rate: 3.948E-06 | global batch size:    48 | lm loss: 7.280660E+00 | loss scale: 32768.0 | grad norm: 5.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      270/    1200 | consumed samples:        12960 | elapsed time per iteration (ms): 1609.8 | learning rate: 3.964E-06 | global batch size:    48 | lm loss: 7.274693E+00 | loss scale: 32768.0 | grad norm: 6.376 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      271/    1200 | consumed samples:        13008 | elapsed time per iteration (ms): 1964.0 | learning rate: 3.979E-06 | global batch size:    48 | lm loss: 7.269126E+00 | loss scale: 32768.0 | grad norm: 7.362 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      272/    1200 | consumed samples:        13056 | elapsed time per iteration (ms): 1441.6 | learning rate: 3.995E-06 | global batch size:    48 | lm loss: 7.263868E+00 | loss scale: 32768.0 | grad norm: 6.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      273/    1200 | consumed samples:        13104 | elapsed time per iteration (ms): 1672.0 | learning rate: 4.011E-06 | global batch size:    48 | lm loss: 7.258647E+00 | loss scale: 32768.0 | grad norm: 7.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      274/    1200 | consumed samples:        13152 | elapsed time per iteration (ms): 1859.4 | learning rate: 4.027E-06 | global batch size:    48 | lm loss: 7.253209E+00 | loss scale: 32768.0 | grad norm: 10.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      275/    1200 | consumed samples:        13200 | elapsed time per iteration (ms): 1851.4 | learning rate: 4.042E-06 | global batch size:    48 | lm loss: 7.247662E+00 | loss scale: 32768.0 | grad norm: 6.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      276/    1200 | consumed samples:        13248 | elapsed time per iteration (ms): 1471.0 | learning rate: 4.058E-06 | global batch size:    48 | lm loss: 7.242317E+00 | loss scale: 32768.0 | grad norm: 6.594 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      277/    1200 | consumed samples:        13296 | elapsed time per iteration (ms): 1758.4 | learning rate: 4.074E-06 | global batch size:    48 | lm loss: 7.237372E+00 | loss scale: 32768.0 | grad norm: 5.718 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      278/    1200 | consumed samples:        13344 | elapsed time per iteration (ms): 1591.9 | learning rate: 4.089E-06 | global batch size:    48 | lm loss: 7.231976E+00 | loss scale: 32768.0 | grad norm: 5.577 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      279/    1200 | consumed samples:        13392 | elapsed time per iteration (ms): 1678.5 | learning rate: 4.105E-06 | global batch size:    48 | lm loss: 7.226835E+00 | loss scale: 32768.0 | grad norm: 5.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      280/    1200 | consumed samples:        13440 | elapsed time per iteration (ms): 1698.5 | learning rate: 4.121E-06 | global batch size:    48 | lm loss: 7.221864E+00 | loss scale: 32768.0 | grad norm: 5.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      281/    1200 | consumed samples:        13488 | elapsed time per iteration (ms): 1601.2 | learning rate: 4.137E-06 | global batch size:    48 | lm loss: 7.217517E+00 | loss scale: 32768.0 | grad norm: 7.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      282/    1200 | consumed samples:        13536 | elapsed time per iteration (ms): 1922.2 | learning rate: 4.152E-06 | global batch size:    48 | lm loss: 7.212468E+00 | loss scale: 32768.0 | grad norm: 6.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      283/    1200 | consumed samples:        13584 | elapsed time per iteration (ms): 1458.6 | learning rate: 4.168E-06 | global batch size:    48 | lm loss: 7.207317E+00 | loss scale: 32768.0 | grad norm: 6.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      284/    1200 | consumed samples:        13632 | elapsed time per iteration (ms): 1455.1 | learning rate: 4.184E-06 | global batch size:    48 | lm loss: 7.202484E+00 | loss scale: 32768.0 | grad norm: 6.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      285/    1200 | consumed samples:        13680 | elapsed time per iteration (ms): 1713.6 | learning rate: 4.200E-06 | global batch size:    48 | lm loss: 7.197987E+00 | loss scale: 32768.0 | grad norm: 7.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      286/    1200 | consumed samples:        13728 | elapsed time per iteration (ms): 1545.7 | learning rate: 4.215E-06 | global batch size:    48 | lm loss: 7.193076E+00 | loss scale: 32768.0 | grad norm: 6.320 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      287/    1200 | consumed samples:        13776 | elapsed time per iteration (ms): 2030.1 | learning rate: 4.231E-06 | global batch size:    48 | lm loss: 7.188465E+00 | loss scale: 32768.0 | grad norm: 5.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      288/    1200 | consumed samples:        13824 | elapsed time per iteration (ms): 1457.9 | learning rate: 4.247E-06 | global batch size:    48 | lm loss: 7.183703E+00 | loss scale: 32768.0 | grad norm: 5.726 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      289/    1200 | consumed samples:        13872 | elapsed time per iteration (ms): 1722.6 | learning rate: 4.262E-06 | global batch size:    48 | lm loss: 7.179151E+00 | loss scale: 32768.0 | grad norm: 6.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      290/    1200 | consumed samples:        13920 | elapsed time per iteration (ms): 1684.5 | learning rate: 4.278E-06 | global batch size:    48 | lm loss: 7.174256E+00 | loss scale: 32768.0 | grad norm: 5.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      291/    1200 | consumed samples:        13968 | elapsed time per iteration (ms): 2042.0 | learning rate: 4.294E-06 | global batch size:    48 | lm loss: 7.169611E+00 | loss scale: 32768.0 | grad norm: 6.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      292/    1200 | consumed samples:        14016 | elapsed time per iteration (ms): 1537.4 | learning rate: 4.310E-06 | global batch size:    48 | lm loss: 7.165087E+00 | loss scale: 32768.0 | grad norm: 6.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      293/    1200 | consumed samples:        14064 | elapsed time per iteration (ms): 1543.2 | learning rate: 4.325E-06 | global batch size:    48 | lm loss: 7.161041E+00 | loss scale: 32768.0 | grad norm: 6.661 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      294/    1200 | consumed samples:        14112 | elapsed time per iteration (ms): 1788.0 | learning rate: 4.341E-06 | global batch size:    48 | lm loss: 7.156616E+00 | loss scale: 32768.0 | grad norm: 6.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      295/    1200 | consumed samples:        14160 | elapsed time per iteration (ms): 1829.5 | learning rate: 4.357E-06 | global batch size:    48 | lm loss: 7.152114E+00 | loss scale: 32768.0 | grad norm: 7.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      296/    1200 | consumed samples:        14208 | elapsed time per iteration (ms): 1824.8 | learning rate: 4.373E-06 | global batch size:    48 | lm loss: 7.147723E+00 | loss scale: 32768.0 | grad norm: 6.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      297/    1200 | consumed samples:        14256 | elapsed time per iteration (ms): 1562.1 | learning rate: 4.388E-06 | global batch size:    48 | lm loss: 7.143705E+00 | loss scale: 32768.0 | grad norm: 7.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      298/    1200 | consumed samples:        14304 | elapsed time per iteration (ms): 1621.6 | learning rate: 4.404E-06 | global batch size:    48 | lm loss: 7.139286E+00 | loss scale: 32768.0 | grad norm: 6.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      299/    1200 | consumed samples:        14352 | elapsed time per iteration (ms): 1700.2 | learning rate: 4.420E-06 | global batch size:    48 | lm loss: 7.134887E+00 | loss scale: 32768.0 | grad norm: 5.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      300/    1200 | consumed samples:        14400 | elapsed time per iteration (ms): 1533.5 | learning rate: 4.435E-06 | global batch size:    48 | lm loss: 7.130375E+00 | loss scale: 32768.0 | grad norm: 5.382 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      301/    1200 | consumed samples:        14448 | elapsed time per iteration (ms): 1751.2 | learning rate: 4.451E-06 | global batch size:    48 | lm loss: 7.125778E+00 | loss scale: 32768.0 | grad norm: 5.847 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      302/    1200 | consumed samples:        14496 | elapsed time per iteration (ms): 1257.9 | learning rate: 4.467E-06 | global batch size:    48 | lm loss: 6.132806E+00 | loss scale: 32768.0 | grad norm: 6.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      303/    1200 | consumed samples:        14544 | elapsed time per iteration (ms): 1332.7 | learning rate: 4.483E-06 | global batch size:    48 | lm loss: 6.117075E+00 | loss scale: 32768.0 | grad norm: 5.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      304/    1200 | consumed samples:        14592 | elapsed time per iteration (ms): 1127.1 | learning rate: 4.498E-06 | global batch size:    48 | lm loss: 6.127126E+00 | loss scale: 32768.0 | grad norm: 5.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      305/    1200 | consumed samples:        14640 | elapsed time per iteration (ms): 1055.4 | learning rate: 4.514E-06 | global batch size:    48 | lm loss: 6.218959E+00 | loss scale: 32768.0 | grad norm: 5.584 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      306/    1200 | consumed samples:        14688 | elapsed time per iteration (ms): 1090.9 | learning rate: 4.530E-06 | global batch size:    48 | lm loss: 6.162127E+00 | loss scale: 32768.0 | grad norm: 5.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      307/    1200 | consumed samples:        14736 | elapsed time per iteration (ms): 1145.4 | learning rate: 4.546E-06 | global batch size:    48 | lm loss: 6.196695E+00 | loss scale: 32768.0 | grad norm: 5.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      308/    1200 | consumed samples:        14784 | elapsed time per iteration (ms): 1099.5 | learning rate: 4.561E-06 | global batch size:    48 | lm loss: 6.234186E+00 | loss scale: 32768.0 | grad norm: 6.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      309/    1200 | consumed samples:        14832 | elapsed time per iteration (ms): 1042.8 | learning rate: 4.577E-06 | global batch size:    48 | lm loss: 6.082650E+00 | loss scale: 32768.0 | grad norm: 5.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      310/    1200 | consumed samples:        14880 | elapsed time per iteration (ms): 1221.6 | learning rate: 4.593E-06 | global batch size:    48 | lm loss: 6.154146E+00 | loss scale: 32768.0 | grad norm: 5.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      311/    1200 | consumed samples:        14928 | elapsed time per iteration (ms): 1541.7 | learning rate: 4.609E-06 | global batch size:    48 | lm loss: 6.174661E+00 | loss scale: 32768.0 | grad norm: 5.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      312/    1200 | consumed samples:        14976 | elapsed time per iteration (ms): 1097.6 | learning rate: 4.624E-06 | global batch size:    48 | lm loss: 6.170242E+00 | loss scale: 32768.0 | grad norm: 6.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      313/    1200 | consumed samples:        15024 | elapsed time per iteration (ms): 1286.0 | learning rate: 4.640E-06 | global batch size:    48 | lm loss: 6.261055E+00 | loss scale: 32768.0 | grad norm: 5.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      314/    1200 | consumed samples:        15072 | elapsed time per iteration (ms): 1645.9 | learning rate: 4.656E-06 | global batch size:    48 | lm loss: 6.126775E+00 | loss scale: 32768.0 | grad norm: 5.410 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      315/    1200 | consumed samples:        15120 | elapsed time per iteration (ms): 1348.1 | learning rate: 4.671E-06 | global batch size:    48 | lm loss: 6.171752E+00 | loss scale: 32768.0 | grad norm: 6.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      316/    1200 | consumed samples:        15168 | elapsed time per iteration (ms): 1360.9 | learning rate: 4.687E-06 | global batch size:    48 | lm loss: 6.190206E+00 | loss scale: 32768.0 | grad norm: 7.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      317/    1200 | consumed samples:        15216 | elapsed time per iteration (ms): 1353.6 | learning rate: 4.703E-06 | global batch size:    48 | lm loss: 6.174265E+00 | loss scale: 32768.0 | grad norm: 7.031 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      318/    1200 | consumed samples:        15264 | elapsed time per iteration (ms): 1367.6 | learning rate: 4.719E-06 | global batch size:    48 | lm loss: 6.131761E+00 | loss scale: 32768.0 | grad norm: 5.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      319/    1200 | consumed samples:        15312 | elapsed time per iteration (ms): 1601.6 | learning rate: 4.734E-06 | global batch size:    48 | lm loss: 6.078020E+00 | loss scale: 32768.0 | grad norm: 5.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      320/    1200 | consumed samples:        15360 | elapsed time per iteration (ms): 1604.5 | learning rate: 4.750E-06 | global batch size:    48 | lm loss: 6.248439E+00 | loss scale: 32768.0 | grad norm: 6.262 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      321/    1200 | consumed samples:        15408 | elapsed time per iteration (ms): 1486.7 | learning rate: 4.766E-06 | global batch size:    48 | lm loss: 6.188649E+00 | loss scale: 32768.0 | grad norm: 5.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      322/    1200 | consumed samples:        15456 | elapsed time per iteration (ms): 1496.8 | learning rate: 4.782E-06 | global batch size:    48 | lm loss: 6.100061E+00 | loss scale: 32768.0 | grad norm: 5.375 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      323/    1200 | consumed samples:        15504 | elapsed time per iteration (ms): 1687.3 | learning rate: 4.797E-06 | global batch size:    48 | lm loss: 6.095048E+00 | loss scale: 32768.0 | grad norm: 5.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      324/    1200 | consumed samples:        15552 | elapsed time per iteration (ms): 1511.8 | learning rate: 4.813E-06 | global batch size:    48 | lm loss: 6.088931E+00 | loss scale: 32768.0 | grad norm: 6.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      325/    1200 | consumed samples:        15600 | elapsed time per iteration (ms): 1437.6 | learning rate: 4.829E-06 | global batch size:    48 | lm loss: 6.237600E+00 | loss scale: 32768.0 | grad norm: 5.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      326/    1200 | consumed samples:        15648 | elapsed time per iteration (ms): 1008.7 | learning rate: 4.844E-06 | global batch size:    48 | lm loss: 6.037257E+00 | loss scale: 32768.0 | grad norm: 4.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      327/    1200 | consumed samples:        15696 | elapsed time per iteration (ms): 1280.2 | learning rate: 4.860E-06 | global batch size:    48 | lm loss: 6.105915E+00 | loss scale: 32768.0 | grad norm: 5.542 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      328/    1200 | consumed samples:        15744 | elapsed time per iteration (ms): 1138.8 | learning rate: 4.876E-06 | global batch size:    48 | lm loss: 6.139099E+00 | loss scale: 32768.0 | grad norm: 5.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      329/    1200 | consumed samples:        15792 | elapsed time per iteration (ms): 1125.0 | learning rate: 4.892E-06 | global batch size:    48 | lm loss: 6.117875E+00 | loss scale: 32768.0 | grad norm: 5.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      330/    1200 | consumed samples:        15840 | elapsed time per iteration (ms): 1141.1 | learning rate: 4.907E-06 | global batch size:    48 | lm loss: 6.095081E+00 | loss scale: 32768.0 | grad norm: 5.765 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      331/    1200 | consumed samples:        15888 | elapsed time per iteration (ms): 1029.8 | learning rate: 4.923E-06 | global batch size:    48 | lm loss: 6.064896E+00 | loss scale: 32768.0 | grad norm: 4.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      332/    1200 | consumed samples:        15936 | elapsed time per iteration (ms): 1279.6 | learning rate: 4.939E-06 | global batch size:    48 | lm loss: 6.078104E+00 | loss scale: 32768.0 | grad norm: 5.132 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      333/    1200 | consumed samples:        15984 | elapsed time per iteration (ms): 1147.8 | learning rate: 4.955E-06 | global batch size:    48 | lm loss: 6.134426E+00 | loss scale: 32768.0 | grad norm: 5.039 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      334/    1200 | consumed samples:        16032 | elapsed time per iteration (ms): 1131.1 | learning rate: 4.970E-06 | global batch size:    48 | lm loss: 6.118316E+00 | loss scale: 32768.0 | grad norm: 5.439 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      335/    1200 | consumed samples:        16080 | elapsed time per iteration (ms): 1242.8 | learning rate: 4.986E-06 | global batch size:    48 | lm loss: 5.994804E+00 | loss scale: 32768.0 | grad norm: 5.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      336/    1200 | consumed samples:        16128 | elapsed time per iteration (ms): 1111.5 | learning rate: 5.002E-06 | global batch size:    48 | lm loss: 6.173830E+00 | loss scale: 32768.0 | grad norm: 5.207 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      337/    1200 | consumed samples:        16176 | elapsed time per iteration (ms): 1112.6 | learning rate: 5.017E-06 | global batch size:    48 | lm loss: 6.136937E+00 | loss scale: 32768.0 | grad norm: 4.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      338/    1200 | consumed samples:        16224 | elapsed time per iteration (ms): 1277.5 | learning rate: 5.033E-06 | global batch size:    48 | lm loss: 6.114821E+00 | loss scale: 32768.0 | grad norm: 5.161 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      339/    1200 | consumed samples:        16272 | elapsed time per iteration (ms): 1187.4 | learning rate: 5.049E-06 | global batch size:    48 | lm loss: 6.195144E+00 | loss scale: 32768.0 | grad norm: 5.134 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      340/    1200 | consumed samples:        16320 | elapsed time per iteration (ms): 1052.3 | learning rate: 5.065E-06 | global batch size:    48 | lm loss: 6.134174E+00 | loss scale: 32768.0 | grad norm: 4.792 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      341/    1200 | consumed samples:        16368 | elapsed time per iteration (ms): 3098.8 | learning rate: 5.080E-06 | global batch size:    48 | lm loss: 7.121464E+00 | loss scale: 32768.0 | grad norm: 5.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      342/    1200 | consumed samples:        16416 | elapsed time per iteration (ms): 2686.5 | learning rate: 5.096E-06 | global batch size:    48 | lm loss: 7.117173E+00 | loss scale: 32768.0 | grad norm: 5.740 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      343/    1200 | consumed samples:        16464 | elapsed time per iteration (ms): 1982.5 | learning rate: 5.112E-06 | global batch size:    48 | lm loss: 7.112758E+00 | loss scale: 32768.0 | grad norm: 5.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      344/    1200 | consumed samples:        16512 | elapsed time per iteration (ms): 1773.4 | learning rate: 5.128E-06 | global batch size:    48 | lm loss: 7.108357E+00 | loss scale: 32768.0 | grad norm: 5.337 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      345/    1200 | consumed samples:        16560 | elapsed time per iteration (ms): 1842.9 | learning rate: 5.143E-06 | global batch size:    48 | lm loss: 7.103784E+00 | loss scale: 32768.0 | grad norm: 5.288 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      346/    1200 | consumed samples:        16608 | elapsed time per iteration (ms): 1985.9 | learning rate: 5.159E-06 | global batch size:    48 | lm loss: 7.098948E+00 | loss scale: 32768.0 | grad norm: 5.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      347/    1200 | consumed samples:        16656 | elapsed time per iteration (ms): 1754.0 | learning rate: 5.175E-06 | global batch size:    48 | lm loss: 7.094760E+00 | loss scale: 32768.0 | grad norm: 5.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      348/    1200 | consumed samples:        16704 | elapsed time per iteration (ms): 1983.8 | learning rate: 5.190E-06 | global batch size:    48 | lm loss: 7.090513E+00 | loss scale: 32768.0 | grad norm: 6.189 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      349/    1200 | consumed samples:        16752 | elapsed time per iteration (ms): 1922.9 | learning rate: 5.206E-06 | global batch size:    48 | lm loss: 7.085968E+00 | loss scale: 32768.0 | grad norm: 6.294 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      350/    1200 | consumed samples:        16800 | elapsed time per iteration (ms): 1777.8 | learning rate: 5.222E-06 | global batch size:    48 | lm loss: 7.081640E+00 | loss scale: 32768.0 | grad norm: 4.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      351/    1200 | consumed samples:        16848 | elapsed time per iteration (ms): 1827.4 | learning rate: 5.238E-06 | global batch size:    48 | lm loss: 7.077073E+00 | loss scale: 32768.0 | grad norm: 5.189 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      352/    1200 | consumed samples:        16896 | elapsed time per iteration (ms): 1798.7 | learning rate: 5.253E-06 | global batch size:    48 | lm loss: 7.072987E+00 | loss scale: 32768.0 | grad norm: 5.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      353/    1200 | consumed samples:        16944 | elapsed time per iteration (ms): 1830.0 | learning rate: 5.269E-06 | global batch size:    48 | lm loss: 7.068737E+00 | loss scale: 32768.0 | grad norm: 4.811 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      354/    1200 | consumed samples:        16992 | elapsed time per iteration (ms): 1881.7 | learning rate: 5.285E-06 | global batch size:    48 | lm loss: 7.064054E+00 | loss scale: 32768.0 | grad norm: 4.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      355/    1200 | consumed samples:        17040 | elapsed time per iteration (ms): 1806.9 | learning rate: 5.301E-06 | global batch size:    48 | lm loss: 7.059592E+00 | loss scale: 32768.0 | grad norm: 5.053 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      356/    1200 | consumed samples:        17088 | elapsed time per iteration (ms): 1969.0 | learning rate: 5.316E-06 | global batch size:    48 | lm loss: 7.055026E+00 | loss scale: 32768.0 | grad norm: 4.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      357/    1200 | consumed samples:        17136 | elapsed time per iteration (ms): 2149.8 | learning rate: 5.332E-06 | global batch size:    48 | lm loss: 7.050346E+00 | loss scale: 32768.0 | grad norm: 4.588 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      358/    1200 | consumed samples:        17184 | elapsed time per iteration (ms): 1911.7 | learning rate: 5.348E-06 | global batch size:    48 | lm loss: 7.045879E+00 | loss scale: 32768.0 | grad norm: 5.098 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      359/    1200 | consumed samples:        17232 | elapsed time per iteration (ms): 1843.1 | learning rate: 5.363E-06 | global batch size:    48 | lm loss: 7.041763E+00 | loss scale: 32768.0 | grad norm: 5.115 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      360/    1200 | consumed samples:        17280 | elapsed time per iteration (ms): 2185.9 | learning rate: 5.379E-06 | global batch size:    48 | lm loss: 7.037748E+00 | loss scale: 32768.0 | grad norm: 5.276 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      361/    1200 | consumed samples:        17328 | elapsed time per iteration (ms): 1883.6 | learning rate: 5.395E-06 | global batch size:    48 | lm loss: 7.033205E+00 | loss scale: 32768.0 | grad norm: 5.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      362/    1200 | consumed samples:        17376 | elapsed time per iteration (ms): 1970.7 | learning rate: 5.411E-06 | global batch size:    48 | lm loss: 7.028710E+00 | loss scale: 32768.0 | grad norm: 5.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      363/    1200 | consumed samples:        17424 | elapsed time per iteration (ms): 1790.6 | learning rate: 5.426E-06 | global batch size:    48 | lm loss: 7.024532E+00 | loss scale: 32768.0 | grad norm: 5.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      364/    1200 | consumed samples:        17472 | elapsed time per iteration (ms): 2221.2 | learning rate: 5.442E-06 | global batch size:    48 | lm loss: 7.020413E+00 | loss scale: 32768.0 | grad norm: 5.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      365/    1200 | consumed samples:        17520 | elapsed time per iteration (ms): 1721.3 | learning rate: 5.458E-06 | global batch size:    48 | lm loss: 7.016443E+00 | loss scale: 32768.0 | grad norm: 5.280 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      366/    1200 | consumed samples:        17568 | elapsed time per iteration (ms): 1879.5 | learning rate: 5.474E-06 | global batch size:    48 | lm loss: 7.012448E+00 | loss scale: 32768.0 | grad norm: 5.706 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      367/    1200 | consumed samples:        17616 | elapsed time per iteration (ms): 1859.1 | learning rate: 5.489E-06 | global batch size:    48 | lm loss: 7.008331E+00 | loss scale: 32768.0 | grad norm: 5.598 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      368/    1200 | consumed samples:        17664 | elapsed time per iteration (ms): 2048.9 | learning rate: 5.505E-06 | global batch size:    48 | lm loss: 7.004126E+00 | loss scale: 32768.0 | grad norm: 5.123 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      369/    1200 | consumed samples:        17712 | elapsed time per iteration (ms): 1707.6 | learning rate: 5.521E-06 | global batch size:    48 | lm loss: 7.000427E+00 | loss scale: 32768.0 | grad norm: 5.156 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      370/    1200 | consumed samples:        17760 | elapsed time per iteration (ms): 1877.1 | learning rate: 5.536E-06 | global batch size:    48 | lm loss: 6.997142E+00 | loss scale: 32768.0 | grad norm: 6.361 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      371/    1200 | consumed samples:        17808 | elapsed time per iteration (ms): 1972.9 | learning rate: 5.552E-06 | global batch size:    48 | lm loss: 6.993238E+00 | loss scale: 32768.0 | grad norm: 8.138 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      372/    1200 | consumed samples:        17856 | elapsed time per iteration (ms): 1982.5 | learning rate: 5.568E-06 | global batch size:    48 | lm loss: 6.989229E+00 | loss scale: 32768.0 | grad norm: 5.328 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      373/    1200 | consumed samples:        17904 | elapsed time per iteration (ms): 2072.9 | learning rate: 5.584E-06 | global batch size:    48 | lm loss: 6.985114E+00 | loss scale: 32768.0 | grad norm: 5.244 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      374/    1200 | consumed samples:        17952 | elapsed time per iteration (ms): 1714.3 | learning rate: 5.599E-06 | global batch size:    48 | lm loss: 6.981474E+00 | loss scale: 32768.0 | grad norm: 4.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      375/    1200 | consumed samples:        18000 | elapsed time per iteration (ms): 1874.6 | learning rate: 5.615E-06 | global batch size:    48 | lm loss: 6.977976E+00 | loss scale: 32768.0 | grad norm: 4.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      376/    1200 | consumed samples:        18048 | elapsed time per iteration (ms): 1772.5 | learning rate: 5.631E-06 | global batch size:    48 | lm loss: 6.974622E+00 | loss scale: 32768.0 | grad norm: 4.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      377/    1200 | consumed samples:        18096 | elapsed time per iteration (ms): 1741.6 | learning rate: 5.647E-06 | global batch size:    48 | lm loss: 6.970497E+00 | loss scale: 32768.0 | grad norm: 4.514 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      378/    1200 | consumed samples:        18144 | elapsed time per iteration (ms): 1819.1 | learning rate: 5.662E-06 | global batch size:    48 | lm loss: 6.966746E+00 | loss scale: 32768.0 | grad norm: 4.539 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      379/    1200 | consumed samples:        18192 | elapsed time per iteration (ms): 2209.1 | learning rate: 5.678E-06 | global batch size:    48 | lm loss: 6.962814E+00 | loss scale: 32768.0 | grad norm: 4.586 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      380/    1200 | consumed samples:        18240 | elapsed time per iteration (ms): 2026.2 | learning rate: 5.694E-06 | global batch size:    48 | lm loss: 6.959212E+00 | loss scale: 32768.0 | grad norm: 4.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      381/    1200 | consumed samples:        18288 | elapsed time per iteration (ms): 1805.4 | learning rate: 5.710E-06 | global batch size:    48 | lm loss: 6.955249E+00 | loss scale: 32768.0 | grad norm: 4.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      382/    1200 | consumed samples:        18336 | elapsed time per iteration (ms): 1851.3 | learning rate: 5.725E-06 | global batch size:    48 | lm loss: 6.951680E+00 | loss scale: 32768.0 | grad norm: 4.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      383/    1200 | consumed samples:        18384 | elapsed time per iteration (ms): 1688.1 | learning rate: 5.741E-06 | global batch size:    48 | lm loss: 6.947798E+00 | loss scale: 32768.0 | grad norm: 5.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      384/    1200 | consumed samples:        18432 | elapsed time per iteration (ms): 1761.8 | learning rate: 5.757E-06 | global batch size:    48 | lm loss: 6.944163E+00 | loss scale: 32768.0 | grad norm: 5.014 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      385/    1200 | consumed samples:        18480 | elapsed time per iteration (ms): 1705.8 | learning rate: 5.772E-06 | global batch size:    48 | lm loss: 6.940866E+00 | loss scale: 32768.0 | grad norm: 4.894 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      386/    1200 | consumed samples:        18528 | elapsed time per iteration (ms): 2197.1 | learning rate: 5.788E-06 | global batch size:    48 | lm loss: 6.937648E+00 | loss scale: 32768.0 | grad norm: 4.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      387/    1200 | consumed samples:        18576 | elapsed time per iteration (ms): 2116.7 | learning rate: 5.804E-06 | global batch size:    48 | lm loss: 6.934074E+00 | loss scale: 32768.0 | grad norm: 4.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      388/    1200 | consumed samples:        18624 | elapsed time per iteration (ms): 1965.9 | learning rate: 5.820E-06 | global batch size:    48 | lm loss: 6.930275E+00 | loss scale: 32768.0 | grad norm: 4.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      389/    1200 | consumed samples:        18672 | elapsed time per iteration (ms): 2099.2 | learning rate: 5.835E-06 | global batch size:    48 | lm loss: 6.926816E+00 | loss scale: 32768.0 | grad norm: 4.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      390/    1200 | consumed samples:        18720 | elapsed time per iteration (ms): 2149.1 | learning rate: 5.851E-06 | global batch size:    48 | lm loss: 6.923161E+00 | loss scale: 32768.0 | grad norm: 4.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      391/    1200 | consumed samples:        18768 | elapsed time per iteration (ms): 1715.9 | learning rate: 5.867E-06 | global batch size:    48 | lm loss: 6.919578E+00 | loss scale: 32768.0 | grad norm: 4.245 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      392/    1200 | consumed samples:        18816 | elapsed time per iteration (ms): 1912.6 | learning rate: 5.883E-06 | global batch size:    48 | lm loss: 6.915910E+00 | loss scale: 32768.0 | grad norm: 4.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      393/    1200 | consumed samples:        18864 | elapsed time per iteration (ms): 2083.8 | learning rate: 5.898E-06 | global batch size:    48 | lm loss: 6.912282E+00 | loss scale: 32768.0 | grad norm: 4.362 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      394/    1200 | consumed samples:        18912 | elapsed time per iteration (ms): 2015.6 | learning rate: 5.914E-06 | global batch size:    48 | lm loss: 6.909001E+00 | loss scale: 32768.0 | grad norm: 5.128 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      395/    1200 | consumed samples:        18960 | elapsed time per iteration (ms): 2161.3 | learning rate: 5.930E-06 | global batch size:    48 | lm loss: 6.905651E+00 | loss scale: 32768.0 | grad norm: 5.820 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      396/    1200 | consumed samples:        19008 | elapsed time per iteration (ms): 1763.1 | learning rate: 5.945E-06 | global batch size:    48 | lm loss: 6.902495E+00 | loss scale: 32768.0 | grad norm: 4.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      397/    1200 | consumed samples:        19056 | elapsed time per iteration (ms): 1776.1 | learning rate: 5.961E-06 | global batch size:    48 | lm loss: 6.898932E+00 | loss scale: 32768.0 | grad norm: 5.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      398/    1200 | consumed samples:        19104 | elapsed time per iteration (ms): 1809.7 | learning rate: 5.977E-06 | global batch size:    48 | lm loss: 6.895713E+00 | loss scale: 32768.0 | grad norm: 4.583 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      399/    1200 | consumed samples:        19152 | elapsed time per iteration (ms): 1903.4 | learning rate: 5.993E-06 | global batch size:    48 | lm loss: 6.892386E+00 | loss scale: 32768.0 | grad norm: 4.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      400/    1200 | consumed samples:        19200 | elapsed time per iteration (ms): 1711.5 | learning rate: 6.008E-06 | global batch size:    48 | lm loss: 6.889090E+00 | loss scale: 32768.0 | grad norm: 5.083 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      401/    1200 | consumed samples:        19248 | elapsed time per iteration (ms): 2276.9 | learning rate: 6.024E-06 | global batch size:    48 | lm loss: 6.885615E+00 | loss scale: 32768.0 | grad norm: 4.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      402/    1200 | consumed samples:        19296 | elapsed time per iteration (ms): 1963.1 | learning rate: 6.040E-06 | global batch size:    48 | lm loss: 6.882345E+00 | loss scale: 32768.0 | grad norm: 4.240 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      403/    1200 | consumed samples:        19344 | elapsed time per iteration (ms): 1921.1 | learning rate: 6.056E-06 | global batch size:    48 | lm loss: 6.879280E+00 | loss scale: 32768.0 | grad norm: 4.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      404/    1200 | consumed samples:        19392 | elapsed time per iteration (ms): 1809.3 | learning rate: 6.071E-06 | global batch size:    48 | lm loss: 6.876211E+00 | loss scale: 32768.0 | grad norm: 4.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      405/    1200 | consumed samples:        19440 | elapsed time per iteration (ms): 1902.2 | learning rate: 6.087E-06 | global batch size:    48 | lm loss: 6.873065E+00 | loss scale: 32768.0 | grad norm: 4.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      406/    1200 | consumed samples:        19488 | elapsed time per iteration (ms): 1871.2 | learning rate: 6.103E-06 | global batch size:    48 | lm loss: 6.869945E+00 | loss scale: 32768.0 | grad norm: 4.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      407/    1200 | consumed samples:        19536 | elapsed time per iteration (ms): 1753.9 | learning rate: 6.118E-06 | global batch size:    48 | lm loss: 6.867074E+00 | loss scale: 32768.0 | grad norm: 4.538 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      408/    1200 | consumed samples:        19584 | elapsed time per iteration (ms): 2110.3 | learning rate: 6.134E-06 | global batch size:    48 | lm loss: 6.864228E+00 | loss scale: 32768.0 | grad norm: 4.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      409/    1200 | consumed samples:        19632 | elapsed time per iteration (ms): 2181.0 | learning rate: 6.150E-06 | global batch size:    48 | lm loss: 6.861182E+00 | loss scale: 32768.0 | grad norm: 5.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      410/    1200 | consumed samples:        19680 | elapsed time per iteration (ms): 2097.6 | learning rate: 6.166E-06 | global batch size:    48 | lm loss: 6.857728E+00 | loss scale: 32768.0 | grad norm: 4.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      411/    1200 | consumed samples:        19728 | elapsed time per iteration (ms): 1997.8 | learning rate: 6.181E-06 | global batch size:    48 | lm loss: 6.854654E+00 | loss scale: 32768.0 | grad norm: 4.362 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      412/    1200 | consumed samples:        19776 | elapsed time per iteration (ms): 1110.5 | learning rate: 6.197E-06 | global batch size:    48 | lm loss: 5.954476E+00 | loss scale: 32768.0 | grad norm: 4.123 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      413/    1200 | consumed samples:        19824 | elapsed time per iteration (ms): 1329.6 | learning rate: 6.213E-06 | global batch size:    48 | lm loss: 5.905682E+00 | loss scale: 32768.0 | grad norm: 4.344 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      414/    1200 | consumed samples:        19872 | elapsed time per iteration (ms): 1388.2 | learning rate: 6.229E-06 | global batch size:    48 | lm loss: 6.063935E+00 | loss scale: 32768.0 | grad norm: 4.162 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      415/    1200 | consumed samples:        19920 | elapsed time per iteration (ms): 1055.5 | learning rate: 6.244E-06 | global batch size:    48 | lm loss: 5.926097E+00 | loss scale: 32768.0 | grad norm: 4.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      416/    1200 | consumed samples:        19968 | elapsed time per iteration (ms): 1195.4 | learning rate: 6.260E-06 | global batch size:    48 | lm loss: 5.964382E+00 | loss scale: 32768.0 | grad norm: 4.042 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      417/    1200 | consumed samples:        20016 | elapsed time per iteration (ms): 1272.0 | learning rate: 6.276E-06 | global batch size:    48 | lm loss: 5.897656E+00 | loss scale: 32768.0 | grad norm: 4.562 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      418/    1200 | consumed samples:        20064 | elapsed time per iteration (ms): 1023.9 | learning rate: 6.291E-06 | global batch size:    48 | lm loss: 5.960026E+00 | loss scale: 32768.0 | grad norm: 4.371 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      419/    1200 | consumed samples:        20112 | elapsed time per iteration (ms): 1270.8 | learning rate: 6.307E-06 | global batch size:    48 | lm loss: 5.993975E+00 | loss scale: 32768.0 | grad norm: 4.240 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      420/    1200 | consumed samples:        20160 | elapsed time per iteration (ms): 1165.8 | learning rate: 6.323E-06 | global batch size:    48 | lm loss: 5.978096E+00 | loss scale: 32768.0 | grad norm: 4.139 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      421/    1200 | consumed samples:        20208 | elapsed time per iteration (ms): 1086.8 | learning rate: 6.339E-06 | global batch size:    48 | lm loss: 6.070311E+00 | loss scale: 32768.0 | grad norm: 4.551 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      422/    1200 | consumed samples:        20256 | elapsed time per iteration (ms): 1393.3 | learning rate: 6.354E-06 | global batch size:    48 | lm loss: 5.807991E+00 | loss scale: 32768.0 | grad norm: 4.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      423/    1200 | consumed samples:        20304 | elapsed time per iteration (ms): 1283.3 | learning rate: 6.370E-06 | global batch size:    48 | lm loss: 5.942027E+00 | loss scale: 32768.0 | grad norm: 4.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      424/    1200 | consumed samples:        20352 | elapsed time per iteration (ms): 1209.3 | learning rate: 6.386E-06 | global batch size:    48 | lm loss: 5.908517E+00 | loss scale: 32768.0 | grad norm: 4.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      425/    1200 | consumed samples:        20400 | elapsed time per iteration (ms): 1302.9 | learning rate: 6.402E-06 | global batch size:    48 | lm loss: 5.916544E+00 | loss scale: 32768.0 | grad norm: 4.162 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      426/    1200 | consumed samples:        20448 | elapsed time per iteration (ms): 1160.1 | learning rate: 6.417E-06 | global batch size:    48 | lm loss: 6.016856E+00 | loss scale: 32768.0 | grad norm: 4.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      427/    1200 | consumed samples:        20496 | elapsed time per iteration (ms): 1235.4 | learning rate: 6.433E-06 | global batch size:    48 | lm loss: 5.998688E+00 | loss scale: 32768.0 | grad norm: 4.556 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      428/    1200 | consumed samples:        20544 | elapsed time per iteration (ms): 1218.7 | learning rate: 6.449E-06 | global batch size:    48 | lm loss: 6.072300E+00 | loss scale: 32768.0 | grad norm: 3.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      429/    1200 | consumed samples:        20592 | elapsed time per iteration (ms): 1346.3 | learning rate: 6.464E-06 | global batch size:    48 | lm loss: 5.974658E+00 | loss scale: 32768.0 | grad norm: 4.157 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      430/    1200 | consumed samples:        20640 | elapsed time per iteration (ms): 1217.8 | learning rate: 6.480E-06 | global batch size:    48 | lm loss: 5.875007E+00 | loss scale: 32768.0 | grad norm: 4.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      431/    1200 | consumed samples:        20688 | elapsed time per iteration (ms): 1091.6 | learning rate: 6.496E-06 | global batch size:    48 | lm loss: 5.959289E+00 | loss scale: 32768.0 | grad norm: 4.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      432/    1200 | consumed samples:        20736 | elapsed time per iteration (ms): 1308.0 | learning rate: 6.512E-06 | global batch size:    48 | lm loss: 5.988481E+00 | loss scale: 32768.0 | grad norm: 4.252 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      433/    1200 | consumed samples:        20784 | elapsed time per iteration (ms): 1239.1 | learning rate: 6.527E-06 | global batch size:    48 | lm loss: 5.819414E+00 | loss scale: 32768.0 | grad norm: 4.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      434/    1200 | consumed samples:        20832 | elapsed time per iteration (ms): 1168.1 | learning rate: 6.543E-06 | global batch size:    48 | lm loss: 6.011159E+00 | loss scale: 32768.0 | grad norm: 4.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      435/    1200 | consumed samples:        20880 | elapsed time per iteration (ms): 1414.8 | learning rate: 6.559E-06 | global batch size:    48 | lm loss: 5.930907E+00 | loss scale: 32768.0 | grad norm: 3.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      436/    1200 | consumed samples:        20928 | elapsed time per iteration (ms): 1221.6 | learning rate: 6.575E-06 | global batch size:    48 | lm loss: 5.941776E+00 | loss scale: 32768.0 | grad norm: 4.239 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      437/    1200 | consumed samples:        20976 | elapsed time per iteration (ms): 1231.5 | learning rate: 6.590E-06 | global batch size:    48 | lm loss: 5.900701E+00 | loss scale: 32768.0 | grad norm: 4.115 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      438/    1200 | consumed samples:        21024 | elapsed time per iteration (ms): 1094.3 | learning rate: 6.606E-06 | global batch size:    48 | lm loss: 5.937490E+00 | loss scale: 32768.0 | grad norm: 4.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      439/    1200 | consumed samples:        21072 | elapsed time per iteration (ms): 1221.1 | learning rate: 6.622E-06 | global batch size:    48 | lm loss: 5.918233E+00 | loss scale: 32768.0 | grad norm: 4.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      440/    1200 | consumed samples:        21120 | elapsed time per iteration (ms): 1146.1 | learning rate: 6.638E-06 | global batch size:    48 | lm loss: 5.988122E+00 | loss scale: 32768.0 | grad norm: 4.179 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      441/    1200 | consumed samples:        21168 | elapsed time per iteration (ms): 1146.8 | learning rate: 6.653E-06 | global batch size:    48 | lm loss: 6.070807E+00 | loss scale: 32768.0 | grad norm: 4.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      442/    1200 | consumed samples:        21216 | elapsed time per iteration (ms): 1081.5 | learning rate: 6.669E-06 | global batch size:    48 | lm loss: 6.000864E+00 | loss scale: 32768.0 | grad norm: 4.702 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      443/    1200 | consumed samples:        21264 | elapsed time per iteration (ms): 1428.9 | learning rate: 6.685E-06 | global batch size:    48 | lm loss: 5.825301E+00 | loss scale: 32768.0 | grad norm: 3.904 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      444/    1200 | consumed samples:        21312 | elapsed time per iteration (ms): 1406.2 | learning rate: 6.700E-06 | global batch size:    48 | lm loss: 5.953233E+00 | loss scale: 32768.0 | grad norm: 4.240 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      445/    1200 | consumed samples:        21360 | elapsed time per iteration (ms): 1079.6 | learning rate: 6.716E-06 | global batch size:    48 | lm loss: 6.032590E+00 | loss scale: 32768.0 | grad norm: 3.925 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      446/    1200 | consumed samples:        21408 | elapsed time per iteration (ms): 1021.9 | learning rate: 6.732E-06 | global batch size:    48 | lm loss: 5.958237E+00 | loss scale: 32768.0 | grad norm: 3.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      447/    1200 | consumed samples:        21456 | elapsed time per iteration (ms): 1309.9 | learning rate: 6.748E-06 | global batch size:    48 | lm loss: 6.008093E+00 | loss scale: 32768.0 | grad norm: 3.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      448/    1200 | consumed samples:        21504 | elapsed time per iteration (ms): 1174.3 | learning rate: 6.763E-06 | global batch size:    48 | lm loss: 5.916154E+00 | loss scale: 32768.0 | grad norm: 4.133 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      449/    1200 | consumed samples:        21552 | elapsed time per iteration (ms): 1191.6 | learning rate: 6.779E-06 | global batch size:    48 | lm loss: 5.928279E+00 | loss scale: 32768.0 | grad norm: 4.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      450/    1200 | consumed samples:        21600 | elapsed time per iteration (ms): 1145.1 | learning rate: 6.795E-06 | global batch size:    48 | lm loss: 5.953939E+00 | loss scale: 32768.0 | grad norm: 4.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      451/    1200 | consumed samples:        21648 | elapsed time per iteration (ms): 2894.3 | learning rate: 6.811E-06 | global batch size:    48 | lm loss: 6.851267E+00 | loss scale: 32768.0 | grad norm: 4.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      452/    1200 | consumed samples:        21696 | elapsed time per iteration (ms): 2754.1 | learning rate: 6.826E-06 | global batch size:    48 | lm loss: 6.848207E+00 | loss scale: 32768.0 | grad norm: 4.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      453/    1200 | consumed samples:        21744 | elapsed time per iteration (ms): 1666.5 | learning rate: 6.842E-06 | global batch size:    48 | lm loss: 6.844717E+00 | loss scale: 32768.0 | grad norm: 4.119 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      454/    1200 | consumed samples:        21792 | elapsed time per iteration (ms): 1741.4 | learning rate: 6.858E-06 | global batch size:    48 | lm loss: 6.841594E+00 | loss scale: 32768.0 | grad norm: 3.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      455/    1200 | consumed samples:        21840 | elapsed time per iteration (ms): 1654.7 | learning rate: 6.873E-06 | global batch size:    48 | lm loss: 6.838328E+00 | loss scale: 32768.0 | grad norm: 3.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      456/    1200 | consumed samples:        21888 | elapsed time per iteration (ms): 1650.7 | learning rate: 6.889E-06 | global batch size:    48 | lm loss: 6.835798E+00 | loss scale: 32768.0 | grad norm: 4.288 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      457/    1200 | consumed samples:        21936 | elapsed time per iteration (ms): 1795.7 | learning rate: 6.905E-06 | global batch size:    48 | lm loss: 6.832639E+00 | loss scale: 32768.0 | grad norm: 3.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      458/    1200 | consumed samples:        21984 | elapsed time per iteration (ms): 1868.3 | learning rate: 6.921E-06 | global batch size:    48 | lm loss: 6.829060E+00 | loss scale: 32768.0 | grad norm: 3.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      459/    1200 | consumed samples:        22032 | elapsed time per iteration (ms): 1896.6 | learning rate: 6.936E-06 | global batch size:    48 | lm loss: 6.825827E+00 | loss scale: 32768.0 | grad norm: 3.807 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      460/    1200 | consumed samples:        22080 | elapsed time per iteration (ms): 1982.5 | learning rate: 6.952E-06 | global batch size:    48 | lm loss: 6.822827E+00 | loss scale: 32768.0 | grad norm: 4.170 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      461/    1200 | consumed samples:        22128 | elapsed time per iteration (ms): 1748.2 | learning rate: 6.968E-06 | global batch size:    48 | lm loss: 6.819437E+00 | loss scale: 32768.0 | grad norm: 3.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      462/    1200 | consumed samples:        22176 | elapsed time per iteration (ms): 1698.9 | learning rate: 6.984E-06 | global batch size:    48 | lm loss: 6.816339E+00 | loss scale: 32768.0 | grad norm: 3.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      463/    1200 | consumed samples:        22224 | elapsed time per iteration (ms): 1702.1 | learning rate: 6.999E-06 | global batch size:    48 | lm loss: 6.813087E+00 | loss scale: 32768.0 | grad norm: 4.041 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      464/    1200 | consumed samples:        22272 | elapsed time per iteration (ms): 1972.5 | learning rate: 7.015E-06 | global batch size:    48 | lm loss: 6.810164E+00 | loss scale: 32768.0 | grad norm: 4.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      465/    1200 | consumed samples:        22320 | elapsed time per iteration (ms): 1574.4 | learning rate: 7.031E-06 | global batch size:    48 | lm loss: 6.807072E+00 | loss scale: 32768.0 | grad norm: 4.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      466/    1200 | consumed samples:        22368 | elapsed time per iteration (ms): 1818.6 | learning rate: 7.046E-06 | global batch size:    48 | lm loss: 6.804001E+00 | loss scale: 32768.0 | grad norm: 4.205 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      467/    1200 | consumed samples:        22416 | elapsed time per iteration (ms): 1854.9 | learning rate: 7.062E-06 | global batch size:    48 | lm loss: 6.801012E+00 | loss scale: 32768.0 | grad norm: 3.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      468/    1200 | consumed samples:        22464 | elapsed time per iteration (ms): 1794.5 | learning rate: 7.078E-06 | global batch size:    48 | lm loss: 6.798046E+00 | loss scale: 32768.0 | grad norm: 3.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      469/    1200 | consumed samples:        22512 | elapsed time per iteration (ms): 1541.4 | learning rate: 7.094E-06 | global batch size:    48 | lm loss: 6.795022E+00 | loss scale: 32768.0 | grad norm: 3.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      470/    1200 | consumed samples:        22560 | elapsed time per iteration (ms): 1981.7 | learning rate: 7.109E-06 | global batch size:    48 | lm loss: 6.792183E+00 | loss scale: 32768.0 | grad norm: 3.999 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      471/    1200 | consumed samples:        22608 | elapsed time per iteration (ms): 1731.3 | learning rate: 7.125E-06 | global batch size:    48 | lm loss: 6.788889E+00 | loss scale: 32768.0 | grad norm: 3.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      472/    1200 | consumed samples:        22656 | elapsed time per iteration (ms): 1826.1 | learning rate: 7.141E-06 | global batch size:    48 | lm loss: 6.785975E+00 | loss scale: 32768.0 | grad norm: 3.802 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      473/    1200 | consumed samples:        22704 | elapsed time per iteration (ms): 1677.2 | learning rate: 7.157E-06 | global batch size:    48 | lm loss: 6.783208E+00 | loss scale: 32768.0 | grad norm: 3.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      474/    1200 | consumed samples:        22752 | elapsed time per iteration (ms): 1740.7 | learning rate: 7.172E-06 | global batch size:    48 | lm loss: 6.780052E+00 | loss scale: 32768.0 | grad norm: 3.700 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      475/    1200 | consumed samples:        22800 | elapsed time per iteration (ms): 1746.7 | learning rate: 7.188E-06 | global batch size:    48 | lm loss: 6.777171E+00 | loss scale: 32768.0 | grad norm: 3.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      476/    1200 | consumed samples:        22848 | elapsed time per iteration (ms): 2019.9 | learning rate: 7.204E-06 | global batch size:    48 | lm loss: 6.774282E+00 | loss scale: 32768.0 | grad norm: 3.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      477/    1200 | consumed samples:        22896 | elapsed time per iteration (ms): 1663.1 | learning rate: 7.219E-06 | global batch size:    48 | lm loss: 6.771475E+00 | loss scale: 32768.0 | grad norm: 3.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      478/    1200 | consumed samples:        22944 | elapsed time per iteration (ms): 1742.3 | learning rate: 7.235E-06 | global batch size:    48 | lm loss: 6.768738E+00 | loss scale: 32768.0 | grad norm: 3.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      479/    1200 | consumed samples:        22992 | elapsed time per iteration (ms): 1628.2 | learning rate: 7.251E-06 | global batch size:    48 | lm loss: 6.766156E+00 | loss scale: 32768.0 | grad norm: 3.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      480/    1200 | consumed samples:        23040 | elapsed time per iteration (ms): 1694.8 | learning rate: 7.267E-06 | global batch size:    48 | lm loss: 6.763546E+00 | loss scale: 32768.0 | grad norm: 3.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      481/    1200 | consumed samples:        23088 | elapsed time per iteration (ms): 2013.3 | learning rate: 7.282E-06 | global batch size:    48 | lm loss: 6.760539E+00 | loss scale: 32768.0 | grad norm: 3.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      482/    1200 | consumed samples:        23136 | elapsed time per iteration (ms): 1859.1 | learning rate: 7.298E-06 | global batch size:    48 | lm loss: 6.757807E+00 | loss scale: 32768.0 | grad norm: 3.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      483/    1200 | consumed samples:        23184 | elapsed time per iteration (ms): 2267.4 | learning rate: 7.314E-06 | global batch size:    48 | lm loss: 6.754953E+00 | loss scale: 32768.0 | grad norm: 3.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      484/    1200 | consumed samples:        23232 | elapsed time per iteration (ms): 1725.3 | learning rate: 7.330E-06 | global batch size:    48 | lm loss: 6.752379E+00 | loss scale: 32768.0 | grad norm: 3.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      485/    1200 | consumed samples:        23280 | elapsed time per iteration (ms): 1876.2 | learning rate: 7.345E-06 | global batch size:    48 | lm loss: 6.749722E+00 | loss scale: 32768.0 | grad norm: 3.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      486/    1200 | consumed samples:        23328 | elapsed time per iteration (ms): 1544.0 | learning rate: 7.361E-06 | global batch size:    48 | lm loss: 6.746912E+00 | loss scale: 32768.0 | grad norm: 3.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      487/    1200 | consumed samples:        23376 | elapsed time per iteration (ms): 1712.4 | learning rate: 7.377E-06 | global batch size:    48 | lm loss: 6.744376E+00 | loss scale: 32768.0 | grad norm: 3.713 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      488/    1200 | consumed samples:        23424 | elapsed time per iteration (ms): 1848.6 | learning rate: 7.392E-06 | global batch size:    48 | lm loss: 6.741710E+00 | loss scale: 32768.0 | grad norm: 3.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      489/    1200 | consumed samples:        23472 | elapsed time per iteration (ms): 1531.7 | learning rate: 7.408E-06 | global batch size:    48 | lm loss: 6.738616E+00 | loss scale: 32768.0 | grad norm: 3.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      490/    1200 | consumed samples:        23520 | elapsed time per iteration (ms): 1547.0 | learning rate: 7.424E-06 | global batch size:    48 | lm loss: 6.735828E+00 | loss scale: 32768.0 | grad norm: 3.549 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      491/    1200 | consumed samples:        23568 | elapsed time per iteration (ms): 1939.0 | learning rate: 7.440E-06 | global batch size:    48 | lm loss: 6.733198E+00 | loss scale: 32768.0 | grad norm: 3.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      492/    1200 | consumed samples:        23616 | elapsed time per iteration (ms): 1926.8 | learning rate: 7.455E-06 | global batch size:    48 | lm loss: 6.730367E+00 | loss scale: 32768.0 | grad norm: 3.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      493/    1200 | consumed samples:        23664 | elapsed time per iteration (ms): 1806.3 | learning rate: 7.471E-06 | global batch size:    48 | lm loss: 6.727882E+00 | loss scale: 32768.0 | grad norm: 3.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      494/    1200 | consumed samples:        23712 | elapsed time per iteration (ms): 1910.3 | learning rate: 7.487E-06 | global batch size:    48 | lm loss: 6.725039E+00 | loss scale: 32768.0 | grad norm: 3.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      495/    1200 | consumed samples:        23760 | elapsed time per iteration (ms): 2272.5 | learning rate: 7.503E-06 | global batch size:    48 | lm loss: 6.722629E+00 | loss scale: 32768.0 | grad norm: 3.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      496/    1200 | consumed samples:        23808 | elapsed time per iteration (ms): 1683.3 | learning rate: 7.518E-06 | global batch size:    48 | lm loss: 6.720173E+00 | loss scale: 32768.0 | grad norm: 3.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      497/    1200 | consumed samples:        23856 | elapsed time per iteration (ms): 1753.9 | learning rate: 7.534E-06 | global batch size:    48 | lm loss: 6.717609E+00 | loss scale: 32768.0 | grad norm: 3.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      498/    1200 | consumed samples:        23904 | elapsed time per iteration (ms): 1632.0 | learning rate: 7.550E-06 | global batch size:    48 | lm loss: 6.715278E+00 | loss scale: 32768.0 | grad norm: 3.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      499/    1200 | consumed samples:        23952 | elapsed time per iteration (ms): 2069.4 | learning rate: 7.565E-06 | global batch size:    48 | lm loss: 6.712537E+00 | loss scale: 32768.0 | grad norm: 3.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      500/    1200 | consumed samples:        24000 | elapsed time per iteration (ms): 1782.8 | learning rate: 7.581E-06 | global batch size:    48 | lm loss: 6.709825E+00 | loss scale: 32768.0 | grad norm: 3.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      501/    1200 | consumed samples:        24048 | elapsed time per iteration (ms): 1817.8 | learning rate: 7.597E-06 | global batch size:    48 | lm loss: 6.707156E+00 | loss scale: 32768.0 | grad norm: 3.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      502/    1200 | consumed samples:        24096 | elapsed time per iteration (ms): 1788.7 | learning rate: 7.613E-06 | global batch size:    48 | lm loss: 6.704547E+00 | loss scale: 32768.0 | grad norm: 4.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      503/    1200 | consumed samples:        24144 | elapsed time per iteration (ms): 1680.1 | learning rate: 7.628E-06 | global batch size:    48 | lm loss: 6.702119E+00 | loss scale: 32768.0 | grad norm: 3.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      504/    1200 | consumed samples:        24192 | elapsed time per iteration (ms): 1567.8 | learning rate: 7.644E-06 | global batch size:    48 | lm loss: 6.699592E+00 | loss scale: 32768.0 | grad norm: 3.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      505/    1200 | consumed samples:        24240 | elapsed time per iteration (ms): 1546.8 | learning rate: 7.660E-06 | global batch size:    48 | lm loss: 6.697100E+00 | loss scale: 32768.0 | grad norm: 3.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      506/    1200 | consumed samples:        24288 | elapsed time per iteration (ms): 1938.6 | learning rate: 7.676E-06 | global batch size:    48 | lm loss: 6.694318E+00 | loss scale: 32768.0 | grad norm: 3.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      507/    1200 | consumed samples:        24336 | elapsed time per iteration (ms): 1804.1 | learning rate: 7.691E-06 | global batch size:    48 | lm loss: 6.691902E+00 | loss scale: 32768.0 | grad norm: 3.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      508/    1200 | consumed samples:        24384 | elapsed time per iteration (ms): 1588.2 | learning rate: 7.707E-06 | global batch size:    48 | lm loss: 6.689602E+00 | loss scale: 32768.0 | grad norm: 3.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      509/    1200 | consumed samples:        24432 | elapsed time per iteration (ms): 1891.4 | learning rate: 7.723E-06 | global batch size:    48 | lm loss: 6.687046E+00 | loss scale: 32768.0 | grad norm: 3.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      510/    1200 | consumed samples:        24480 | elapsed time per iteration (ms): 1903.3 | learning rate: 7.739E-06 | global batch size:    48 | lm loss: 6.684790E+00 | loss scale: 32768.0 | grad norm: 3.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      511/    1200 | consumed samples:        24528 | elapsed time per iteration (ms): 1583.2 | learning rate: 7.754E-06 | global batch size:    48 | lm loss: 6.682491E+00 | loss scale: 32768.0 | grad norm: 3.877 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      512/    1200 | consumed samples:        24576 | elapsed time per iteration (ms): 1825.4 | learning rate: 7.770E-06 | global batch size:    48 | lm loss: 6.679627E+00 | loss scale: 32768.0 | grad norm: 3.658 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      513/    1200 | consumed samples:        24624 | elapsed time per iteration (ms): 1596.2 | learning rate: 7.786E-06 | global batch size:    48 | lm loss: 6.677011E+00 | loss scale: 32768.0 | grad norm: 4.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      514/    1200 | consumed samples:        24672 | elapsed time per iteration (ms): 1826.7 | learning rate: 7.801E-06 | global batch size:    48 | lm loss: 6.674684E+00 | loss scale: 32768.0 | grad norm: 3.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      515/    1200 | consumed samples:        24720 | elapsed time per iteration (ms): 1776.7 | learning rate: 7.817E-06 | global batch size:    48 | lm loss: 6.672522E+00 | loss scale: 32768.0 | grad norm: 3.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      516/    1200 | consumed samples:        24768 | elapsed time per iteration (ms): 1793.2 | learning rate: 7.833E-06 | global batch size:    48 | lm loss: 6.670038E+00 | loss scale: 32768.0 | grad norm: 3.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      517/    1200 | consumed samples:        24816 | elapsed time per iteration (ms): 1615.2 | learning rate: 7.849E-06 | global batch size:    48 | lm loss: 6.667616E+00 | loss scale: 32768.0 | grad norm: 3.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      518/    1200 | consumed samples:        24864 | elapsed time per iteration (ms): 2024.8 | learning rate: 7.864E-06 | global batch size:    48 | lm loss: 6.665249E+00 | loss scale: 32768.0 | grad norm: 3.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      519/    1200 | consumed samples:        24912 | elapsed time per iteration (ms): 1610.4 | learning rate: 7.880E-06 | global batch size:    48 | lm loss: 6.663046E+00 | loss scale: 32768.0 | grad norm: 3.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      520/    1200 | consumed samples:        24960 | elapsed time per iteration (ms): 1975.9 | learning rate: 7.896E-06 | global batch size:    48 | lm loss: 6.660499E+00 | loss scale: 32768.0 | grad norm: 3.415 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      521/    1200 | consumed samples:        25008 | elapsed time per iteration (ms): 1905.8 | learning rate: 7.912E-06 | global batch size:    48 | lm loss: 6.658314E+00 | loss scale: 32768.0 | grad norm: 3.443 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      522/    1200 | consumed samples:        25056 | elapsed time per iteration (ms): 1112.6 | learning rate: 7.927E-06 | global batch size:    48 | lm loss: 5.751755E+00 | loss scale: 32768.0 | grad norm: 3.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      523/    1200 | consumed samples:        25104 | elapsed time per iteration (ms): 1530.6 | learning rate: 7.943E-06 | global batch size:    48 | lm loss: 5.820005E+00 | loss scale: 32768.0 | grad norm: 3.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      524/    1200 | consumed samples:        25152 | elapsed time per iteration (ms): 1232.1 | learning rate: 7.959E-06 | global batch size:    48 | lm loss: 5.739817E+00 | loss scale: 32768.0 | grad norm: 3.639 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      525/    1200 | consumed samples:        25200 | elapsed time per iteration (ms): 1085.9 | learning rate: 7.974E-06 | global batch size:    48 | lm loss: 5.908654E+00 | loss scale: 32768.0 | grad norm: 3.499 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      526/    1200 | consumed samples:        25248 | elapsed time per iteration (ms): 1195.0 | learning rate: 7.990E-06 | global batch size:    48 | lm loss: 5.883237E+00 | loss scale: 32768.0 | grad norm: 3.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      527/    1200 | consumed samples:        25296 | elapsed time per iteration (ms): 1014.1 | learning rate: 8.006E-06 | global batch size:    48 | lm loss: 5.891108E+00 | loss scale: 32768.0 | grad norm: 3.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      528/    1200 | consumed samples:        25344 | elapsed time per iteration (ms): 1211.1 | learning rate: 8.022E-06 | global batch size:    48 | lm loss: 5.766278E+00 | loss scale: 32768.0 | grad norm: 3.537 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      529/    1200 | consumed samples:        25392 | elapsed time per iteration (ms): 1442.4 | learning rate: 8.037E-06 | global batch size:    48 | lm loss: 5.864426E+00 | loss scale: 32768.0 | grad norm: 3.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      530/    1200 | consumed samples:        25440 | elapsed time per iteration (ms): 1352.6 | learning rate: 8.053E-06 | global batch size:    48 | lm loss: 5.842042E+00 | loss scale: 32768.0 | grad norm: 3.229 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      531/    1200 | consumed samples:        25488 | elapsed time per iteration (ms): 1131.1 | learning rate: 8.069E-06 | global batch size:    48 | lm loss: 5.797084E+00 | loss scale: 32768.0 | grad norm: 3.321 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      532/    1200 | consumed samples:        25536 | elapsed time per iteration (ms): 1221.4 | learning rate: 8.085E-06 | global batch size:    48 | lm loss: 5.801923E+00 | loss scale: 32768.0 | grad norm: 3.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      533/    1200 | consumed samples:        25584 | elapsed time per iteration (ms): 1188.4 | learning rate: 8.100E-06 | global batch size:    48 | lm loss: 5.651557E+00 | loss scale: 32768.0 | grad norm: 3.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      534/    1200 | consumed samples:        25632 | elapsed time per iteration (ms): 1009.3 | learning rate: 8.116E-06 | global batch size:    48 | lm loss: 5.730226E+00 | loss scale: 32768.0 | grad norm: 3.556 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      535/    1200 | consumed samples:        25680 | elapsed time per iteration (ms): 1148.5 | learning rate: 8.132E-06 | global batch size:    48 | lm loss: 5.767139E+00 | loss scale: 32768.0 | grad norm: 3.322 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      536/    1200 | consumed samples:        25728 | elapsed time per iteration (ms): 1234.5 | learning rate: 8.147E-06 | global batch size:    48 | lm loss: 5.860857E+00 | loss scale: 32768.0 | grad norm: 3.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      537/    1200 | consumed samples:        25776 | elapsed time per iteration (ms): 1151.2 | learning rate: 8.163E-06 | global batch size:    48 | lm loss: 5.810070E+00 | loss scale: 32768.0 | grad norm: 3.388 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      538/    1200 | consumed samples:        25824 | elapsed time per iteration (ms): 1257.8 | learning rate: 8.179E-06 | global batch size:    48 | lm loss: 5.745051E+00 | loss scale: 32768.0 | grad norm: 3.278 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      539/    1200 | consumed samples:        25872 | elapsed time per iteration (ms): 1233.3 | learning rate: 8.195E-06 | global batch size:    48 | lm loss: 5.764158E+00 | loss scale: 32768.0 | grad norm: 3.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      540/    1200 | consumed samples:        25920 | elapsed time per iteration (ms): 1231.9 | learning rate: 8.210E-06 | global batch size:    48 | lm loss: 5.871633E+00 | loss scale: 32768.0 | grad norm: 3.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      541/    1200 | consumed samples:        25968 | elapsed time per iteration (ms): 1464.7 | learning rate: 8.226E-06 | global batch size:    48 | lm loss: 5.847695E+00 | loss scale: 32768.0 | grad norm: 3.288 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      542/    1200 | consumed samples:        26016 | elapsed time per iteration (ms): 1009.1 | learning rate: 8.242E-06 | global batch size:    48 | lm loss: 5.824510E+00 | loss scale: 32768.0 | grad norm: 3.307 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      543/    1200 | consumed samples:        26064 | elapsed time per iteration (ms): 1171.0 | learning rate: 8.258E-06 | global batch size:    48 | lm loss: 5.993136E+00 | loss scale: 32768.0 | grad norm: 3.329 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      544/    1200 | consumed samples:        26112 | elapsed time per iteration (ms): 1204.0 | learning rate: 8.273E-06 | global batch size:    48 | lm loss: 5.767128E+00 | loss scale: 32768.0 | grad norm: 3.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      545/    1200 | consumed samples:        26160 | elapsed time per iteration (ms): 1436.3 | learning rate: 8.289E-06 | global batch size:    48 | lm loss: 5.677210E+00 | loss scale: 32768.0 | grad norm: 3.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      546/    1200 | consumed samples:        26208 | elapsed time per iteration (ms): 1133.3 | learning rate: 8.305E-06 | global batch size:    48 | lm loss: 5.729548E+00 | loss scale: 32768.0 | grad norm: 3.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      547/    1200 | consumed samples:        26256 | elapsed time per iteration (ms): 1021.0 | learning rate: 8.320E-06 | global batch size:    48 | lm loss: 5.752252E+00 | loss scale: 32768.0 | grad norm: 3.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      548/    1200 | consumed samples:        26304 | elapsed time per iteration (ms): 1216.1 | learning rate: 8.336E-06 | global batch size:    48 | lm loss: 5.767430E+00 | loss scale: 32768.0 | grad norm: 3.416 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      549/    1200 | consumed samples:        26352 | elapsed time per iteration (ms): 1313.7 | learning rate: 8.352E-06 | global batch size:    48 | lm loss: 5.753129E+00 | loss scale: 32768.0 | grad norm: 3.250 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      550/    1200 | consumed samples:        26400 | elapsed time per iteration (ms): 1160.4 | learning rate: 8.368E-06 | global batch size:    48 | lm loss: 5.789982E+00 | loss scale: 32768.0 | grad norm: 3.186 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      551/    1200 | consumed samples:        26448 | elapsed time per iteration (ms): 1085.2 | learning rate: 8.383E-06 | global batch size:    48 | lm loss: 5.709510E+00 | loss scale: 32768.0 | grad norm: 3.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      552/    1200 | consumed samples:        26496 | elapsed time per iteration (ms): 1172.7 | learning rate: 8.399E-06 | global batch size:    48 | lm loss: 5.863334E+00 | loss scale: 32768.0 | grad norm: 3.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      553/    1200 | consumed samples:        26544 | elapsed time per iteration (ms): 1498.3 | learning rate: 8.415E-06 | global batch size:    48 | lm loss: 5.709201E+00 | loss scale: 32768.0 | grad norm: 3.318 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      554/    1200 | consumed samples:        26592 | elapsed time per iteration (ms): 1272.6 | learning rate: 8.431E-06 | global batch size:    48 | lm loss: 5.737509E+00 | loss scale: 32768.0 | grad norm: 3.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      555/    1200 | consumed samples:        26640 | elapsed time per iteration (ms): 1019.6 | learning rate: 8.446E-06 | global batch size:    48 | lm loss: 5.878109E+00 | loss scale: 32768.0 | grad norm: 3.372 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      556/    1200 | consumed samples:        26688 | elapsed time per iteration (ms): 1020.4 | learning rate: 8.462E-06 | global batch size:    48 | lm loss: 5.716828E+00 | loss scale: 32768.0 | grad norm: 3.263 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      557/    1200 | consumed samples:        26736 | elapsed time per iteration (ms): 1245.4 | learning rate: 8.478E-06 | global batch size:    48 | lm loss: 5.897521E+00 | loss scale: 32768.0 | grad norm: 3.336 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      558/    1200 | consumed samples:        26784 | elapsed time per iteration (ms): 1166.3 | learning rate: 8.493E-06 | global batch size:    48 | lm loss: 5.698080E+00 | loss scale: 32768.0 | grad norm: 3.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      559/    1200 | consumed samples:        26832 | elapsed time per iteration (ms): 1330.2 | learning rate: 8.509E-06 | global batch size:    48 | lm loss: 5.670153E+00 | loss scale: 32768.0 | grad norm: 3.255 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      560/    1200 | consumed samples:        26880 | elapsed time per iteration (ms): 1206.8 | learning rate: 8.525E-06 | global batch size:    48 | lm loss: 5.782736E+00 | loss scale: 32768.0 | grad norm: 3.301 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      561/    1200 | consumed samples:        26928 | elapsed time per iteration (ms): 2610.4 | learning rate: 8.541E-06 | global batch size:    48 | lm loss: 6.655903E+00 | loss scale: 32768.0 | grad norm: 3.206 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      562/    1200 | consumed samples:        26976 | elapsed time per iteration (ms): 2606.1 | learning rate: 8.556E-06 | global batch size:    48 | lm loss: 6.653483E+00 | loss scale: 32768.0 | grad norm: 3.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      563/    1200 | consumed samples:        27024 | elapsed time per iteration (ms): 1729.8 | learning rate: 8.572E-06 | global batch size:    48 | lm loss: 6.650944E+00 | loss scale: 32768.0 | grad norm: 3.380 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      564/    1200 | consumed samples:        27072 | elapsed time per iteration (ms): 1785.2 | learning rate: 8.588E-06 | global batch size:    48 | lm loss: 6.648226E+00 | loss scale: 32768.0 | grad norm: 3.313 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      565/    1200 | consumed samples:        27120 | elapsed time per iteration (ms): 1816.5 | learning rate: 8.604E-06 | global batch size:    48 | lm loss: 6.645925E+00 | loss scale: 32768.0 | grad norm: 3.301 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      566/    1200 | consumed samples:        27168 | elapsed time per iteration (ms): 1886.1 | learning rate: 8.619E-06 | global batch size:    48 | lm loss: 6.643563E+00 | loss scale: 32768.0 | grad norm: 3.166 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      567/    1200 | consumed samples:        27216 | elapsed time per iteration (ms): 1794.4 | learning rate: 8.635E-06 | global batch size:    48 | lm loss: 6.641167E+00 | loss scale: 32768.0 | grad norm: 3.279 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      568/    1200 | consumed samples:        27264 | elapsed time per iteration (ms): 2406.0 | learning rate: 8.651E-06 | global batch size:    48 | lm loss: 6.638727E+00 | loss scale: 32768.0 | grad norm: 3.244 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      569/    1200 | consumed samples:        27312 | elapsed time per iteration (ms): 1856.1 | learning rate: 8.667E-06 | global batch size:    48 | lm loss: 6.636022E+00 | loss scale: 32768.0 | grad norm: 3.305 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      570/    1200 | consumed samples:        27360 | elapsed time per iteration (ms): 2061.3 | learning rate: 8.682E-06 | global batch size:    48 | lm loss: 6.633793E+00 | loss scale: 32768.0 | grad norm: 3.313 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      571/    1200 | consumed samples:        27408 | elapsed time per iteration (ms): 1796.5 | learning rate: 8.698E-06 | global batch size:    48 | lm loss: 6.631447E+00 | loss scale: 32768.0 | grad norm: 3.094 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      572/    1200 | consumed samples:        27456 | elapsed time per iteration (ms): 1828.7 | learning rate: 8.714E-06 | global batch size:    48 | lm loss: 6.629178E+00 | loss scale: 32768.0 | grad norm: 3.171 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      573/    1200 | consumed samples:        27504 | elapsed time per iteration (ms): 1829.9 | learning rate: 8.729E-06 | global batch size:    48 | lm loss: 6.626689E+00 | loss scale: 32768.0 | grad norm: 3.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      574/    1200 | consumed samples:        27552 | elapsed time per iteration (ms): 1883.1 | learning rate: 8.745E-06 | global batch size:    48 | lm loss: 6.624118E+00 | loss scale: 32768.0 | grad norm: 3.319 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      575/    1200 | consumed samples:        27600 | elapsed time per iteration (ms): 1793.4 | learning rate: 8.761E-06 | global batch size:    48 | lm loss: 6.621734E+00 | loss scale: 32768.0 | grad norm: 3.286 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      576/    1200 | consumed samples:        27648 | elapsed time per iteration (ms): 2196.4 | learning rate: 8.777E-06 | global batch size:    48 | lm loss: 6.619319E+00 | loss scale: 32768.0 | grad norm: 3.334 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      577/    1200 | consumed samples:        27696 | elapsed time per iteration (ms): 2169.5 | learning rate: 8.792E-06 | global batch size:    48 | lm loss: 6.617201E+00 | loss scale: 32768.0 | grad norm: 3.303 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      578/    1200 | consumed samples:        27744 | elapsed time per iteration (ms): 1709.7 | learning rate: 8.808E-06 | global batch size:    48 | lm loss: 6.614641E+00 | loss scale: 32768.0 | grad norm: 3.194 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      579/    1200 | consumed samples:        27792 | elapsed time per iteration (ms): 1765.2 | learning rate: 8.824E-06 | global batch size:    48 | lm loss: 6.611991E+00 | loss scale: 32768.0 | grad norm: 3.188 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      580/    1200 | consumed samples:        27840 | elapsed time per iteration (ms): 1938.8 | learning rate: 8.840E-06 | global batch size:    48 | lm loss: 6.609617E+00 | loss scale: 32768.0 | grad norm: 3.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      581/    1200 | consumed samples:        27888 | elapsed time per iteration (ms): 1869.6 | learning rate: 8.855E-06 | global batch size:    48 | lm loss: 6.607418E+00 | loss scale: 32768.0 | grad norm: 3.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      582/    1200 | consumed samples:        27936 | elapsed time per iteration (ms): 1850.1 | learning rate: 8.871E-06 | global batch size:    48 | lm loss: 6.605195E+00 | loss scale: 32768.0 | grad norm: 3.284 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      583/    1200 | consumed samples:        27984 | elapsed time per iteration (ms): 1884.7 | learning rate: 8.887E-06 | global batch size:    48 | lm loss: 6.602625E+00 | loss scale: 32768.0 | grad norm: 3.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      584/    1200 | consumed samples:        28032 | elapsed time per iteration (ms): 2083.0 | learning rate: 8.902E-06 | global batch size:    48 | lm loss: 6.600578E+00 | loss scale: 32768.0 | grad norm: 3.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      585/    1200 | consumed samples:        28080 | elapsed time per iteration (ms): 1661.7 | learning rate: 8.918E-06 | global batch size:    48 | lm loss: 6.598185E+00 | loss scale: 32768.0 | grad norm: 3.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      586/    1200 | consumed samples:        28128 | elapsed time per iteration (ms): 1809.0 | learning rate: 8.934E-06 | global batch size:    48 | lm loss: 6.595816E+00 | loss scale: 32768.0 | grad norm: 3.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      587/    1200 | consumed samples:        28176 | elapsed time per iteration (ms): 1728.8 | learning rate: 8.950E-06 | global batch size:    48 | lm loss: 6.593131E+00 | loss scale: 32768.0 | grad norm: 3.153 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      588/    1200 | consumed samples:        28224 | elapsed time per iteration (ms): 2098.9 | learning rate: 8.965E-06 | global batch size:    48 | lm loss: 6.591072E+00 | loss scale: 32768.0 | grad norm: 3.285 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      589/    1200 | consumed samples:        28272 | elapsed time per iteration (ms): 1825.5 | learning rate: 8.981E-06 | global batch size:    48 | lm loss: 6.588954E+00 | loss scale: 32768.0 | grad norm: 3.169 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      590/    1200 | consumed samples:        28320 | elapsed time per iteration (ms): 1790.7 | learning rate: 8.997E-06 | global batch size:    48 | lm loss: 6.586679E+00 | loss scale: 32768.0 | grad norm: 3.224 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      591/    1200 | consumed samples:        28368 | elapsed time per iteration (ms): 1671.5 | learning rate: 9.013E-06 | global batch size:    48 | lm loss: 6.584543E+00 | loss scale: 32768.0 | grad norm: 3.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      592/    1200 | consumed samples:        28416 | elapsed time per iteration (ms): 2348.3 | learning rate: 9.028E-06 | global batch size:    48 | lm loss: 6.582569E+00 | loss scale: 32768.0 | grad norm: 3.526 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      593/    1200 | consumed samples:        28464 | elapsed time per iteration (ms): 1845.2 | learning rate: 9.044E-06 | global batch size:    48 | lm loss: 6.580053E+00 | loss scale: 32768.0 | grad norm: 3.178 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      594/    1200 | consumed samples:        28512 | elapsed time per iteration (ms): 1714.5 | learning rate: 9.060E-06 | global batch size:    48 | lm loss: 6.577596E+00 | loss scale: 32768.0 | grad norm: 3.241 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      595/    1200 | consumed samples:        28560 | elapsed time per iteration (ms): 1757.3 | learning rate: 9.075E-06 | global batch size:    48 | lm loss: 6.575275E+00 | loss scale: 32768.0 | grad norm: 3.177 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      596/    1200 | consumed samples:        28608 | elapsed time per iteration (ms): 1695.3 | learning rate: 9.091E-06 | global batch size:    48 | lm loss: 6.573095E+00 | loss scale: 32768.0 | grad norm: 3.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      597/    1200 | consumed samples:        28656 | elapsed time per iteration (ms): 1943.8 | learning rate: 9.107E-06 | global batch size:    48 | lm loss: 6.570805E+00 | loss scale: 32768.0 | grad norm: 3.224 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      598/    1200 | consumed samples:        28704 | elapsed time per iteration (ms): 1908.7 | learning rate: 9.123E-06 | global batch size:    48 | lm loss: 6.568571E+00 | loss scale: 32768.0 | grad norm: 3.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      599/    1200 | consumed samples:        28752 | elapsed time per iteration (ms): 1898.2 | learning rate: 9.138E-06 | global batch size:    48 | lm loss: 6.566562E+00 | loss scale: 32768.0 | grad norm: 3.209 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      600/    1200 | consumed samples:        28800 | elapsed time per iteration (ms): 2256.9 | learning rate: 9.154E-06 | global batch size:    48 | lm loss: 6.564593E+00 | loss scale: 32768.0 | grad norm: 3.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      601/    1200 | consumed samples:        28848 | elapsed time per iteration (ms): 1651.5 | learning rate: 9.170E-06 | global batch size:    48 | lm loss: 6.562440E+00 | loss scale: 32768.0 | grad norm: 3.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      602/    1200 | consumed samples:        28896 | elapsed time per iteration (ms): 1785.5 | learning rate: 9.186E-06 | global batch size:    48 | lm loss: 6.560153E+00 | loss scale: 32768.0 | grad norm: 3.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      603/    1200 | consumed samples:        28944 | elapsed time per iteration (ms): 1679.7 | learning rate: 9.201E-06 | global batch size:    48 | lm loss: 6.557883E+00 | loss scale: 32768.0 | grad norm: 3.095 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      604/    1200 | consumed samples:        28992 | elapsed time per iteration (ms): 1940.4 | learning rate: 9.217E-06 | global batch size:    48 | lm loss: 6.555731E+00 | loss scale: 32768.0 | grad norm: 3.162 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      605/    1200 | consumed samples:        29040 | elapsed time per iteration (ms): 1821.5 | learning rate: 9.233E-06 | global batch size:    48 | lm loss: 6.553572E+00 | loss scale: 32768.0 | grad norm: 3.177 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      606/    1200 | consumed samples:        29088 | elapsed time per iteration (ms): 2053.9 | learning rate: 9.248E-06 | global batch size:    48 | lm loss: 6.551629E+00 | loss scale: 32768.0 | grad norm: 3.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      607/    1200 | consumed samples:        29136 | elapsed time per iteration (ms): 1781.9 | learning rate: 9.264E-06 | global batch size:    48 | lm loss: 6.549429E+00 | loss scale: 32768.0 | grad norm: 3.215 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      608/    1200 | consumed samples:        29184 | elapsed time per iteration (ms): 2284.8 | learning rate: 9.280E-06 | global batch size:    48 | lm loss: 6.547218E+00 | loss scale: 32768.0 | grad norm: 3.010 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      609/    1200 | consumed samples:        29232 | elapsed time per iteration (ms): 1789.6 | learning rate: 9.296E-06 | global batch size:    48 | lm loss: 6.544772E+00 | loss scale: 32768.0 | grad norm: 3.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      610/    1200 | consumed samples:        29280 | elapsed time per iteration (ms): 1702.3 | learning rate: 9.311E-06 | global batch size:    48 | lm loss: 6.542661E+00 | loss scale: 32768.0 | grad norm: 2.984 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      611/    1200 | consumed samples:        29328 | elapsed time per iteration (ms): 1981.2 | learning rate: 9.327E-06 | global batch size:    48 | lm loss: 6.540652E+00 | loss scale: 32768.0 | grad norm: 3.016 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      612/    1200 | consumed samples:        29376 | elapsed time per iteration (ms): 1800.1 | learning rate: 9.343E-06 | global batch size:    48 | lm loss: 6.538617E+00 | loss scale: 32768.0 | grad norm: 3.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      613/    1200 | consumed samples:        29424 | elapsed time per iteration (ms): 2232.1 | learning rate: 9.359E-06 | global batch size:    48 | lm loss: 6.536598E+00 | loss scale: 32768.0 | grad norm: 3.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      614/    1200 | consumed samples:        29472 | elapsed time per iteration (ms): 1800.2 | learning rate: 9.374E-06 | global batch size:    48 | lm loss: 6.534561E+00 | loss scale: 32768.0 | grad norm: 3.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      615/    1200 | consumed samples:        29520 | elapsed time per iteration (ms): 2175.1 | learning rate: 9.390E-06 | global batch size:    48 | lm loss: 6.532457E+00 | loss scale: 32768.0 | grad norm: 3.081 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      616/    1200 | consumed samples:        29568 | elapsed time per iteration (ms): 2133.1 | learning rate: 9.406E-06 | global batch size:    48 | lm loss: 6.530364E+00 | loss scale: 32768.0 | grad norm: 3.044 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      617/    1200 | consumed samples:        29616 | elapsed time per iteration (ms): 1861.6 | learning rate: 9.421E-06 | global batch size:    48 | lm loss: 6.528409E+00 | loss scale: 32768.0 | grad norm: 3.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      618/    1200 | consumed samples:        29664 | elapsed time per iteration (ms): 1804.0 | learning rate: 9.437E-06 | global batch size:    48 | lm loss: 6.526461E+00 | loss scale: 32768.0 | grad norm: 3.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      619/    1200 | consumed samples:        29712 | elapsed time per iteration (ms): 1789.7 | learning rate: 9.453E-06 | global batch size:    48 | lm loss: 6.524438E+00 | loss scale: 32768.0 | grad norm: 2.910 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      620/    1200 | consumed samples:        29760 | elapsed time per iteration (ms): 1932.0 | learning rate: 9.469E-06 | global batch size:    48 | lm loss: 6.522420E+00 | loss scale: 32768.0 | grad norm: 2.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      621/    1200 | consumed samples:        29808 | elapsed time per iteration (ms): 1786.8 | learning rate: 9.484E-06 | global batch size:    48 | lm loss: 6.520511E+00 | loss scale: 32768.0 | grad norm: 3.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      622/    1200 | consumed samples:        29856 | elapsed time per iteration (ms): 1789.9 | learning rate: 9.500E-06 | global batch size:    48 | lm loss: 6.518582E+00 | loss scale: 32768.0 | grad norm: 3.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      623/    1200 | consumed samples:        29904 | elapsed time per iteration (ms): 1741.0 | learning rate: 9.516E-06 | global batch size:    48 | lm loss: 6.516577E+00 | loss scale: 32768.0 | grad norm: 2.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      624/    1200 | consumed samples:        29952 | elapsed time per iteration (ms): 2066.4 | learning rate: 9.532E-06 | global batch size:    48 | lm loss: 6.514429E+00 | loss scale: 32768.0 | grad norm: 2.990 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      625/    1200 | consumed samples:        30000 | elapsed time per iteration (ms): 1887.2 | learning rate: 9.547E-06 | global batch size:    48 | lm loss: 6.512268E+00 | loss scale: 32768.0 | grad norm: 2.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      626/    1200 | consumed samples:        30048 | elapsed time per iteration (ms): 2312.6 | learning rate: 9.563E-06 | global batch size:    48 | lm loss: 6.510259E+00 | loss scale: 32768.0 | grad norm: 2.943 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      627/    1200 | consumed samples:        30096 | elapsed time per iteration (ms): 1711.9 | learning rate: 9.579E-06 | global batch size:    48 | lm loss: 6.508411E+00 | loss scale: 32768.0 | grad norm: 2.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      628/    1200 | consumed samples:        30144 | elapsed time per iteration (ms): 1771.7 | learning rate: 9.594E-06 | global batch size:    48 | lm loss: 6.506828E+00 | loss scale: 32768.0 | grad norm: 3.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      629/    1200 | consumed samples:        30192 | elapsed time per iteration (ms): 2083.3 | learning rate: 9.610E-06 | global batch size:    48 | lm loss: 6.504946E+00 | loss scale: 32768.0 | grad norm: 3.128 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      630/    1200 | consumed samples:        30240 | elapsed time per iteration (ms): 1653.4 | learning rate: 9.626E-06 | global batch size:    48 | lm loss: 6.503056E+00 | loss scale: 32768.0 | grad norm: 3.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      631/    1200 | consumed samples:        30288 | elapsed time per iteration (ms): 1659.8 | learning rate: 9.642E-06 | global batch size:    48 | lm loss: 6.501050E+00 | loss scale: 32768.0 | grad norm: 3.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      632/    1200 | consumed samples:        30336 | elapsed time per iteration (ms): 1326.6 | learning rate: 9.657E-06 | global batch size:    48 | lm loss: 5.602066E+00 | loss scale: 32768.0 | grad norm: 3.172 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      633/    1200 | consumed samples:        30384 | elapsed time per iteration (ms): 1246.4 | learning rate: 9.673E-06 | global batch size:    48 | lm loss: 5.736582E+00 | loss scale: 32768.0 | grad norm: 3.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      634/    1200 | consumed samples:        30432 | elapsed time per iteration (ms): 1205.0 | learning rate: 9.689E-06 | global batch size:    48 | lm loss: 5.725572E+00 | loss scale: 32768.0 | grad norm: 2.994 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      635/    1200 | consumed samples:        30480 | elapsed time per iteration (ms): 1141.8 | learning rate: 9.705E-06 | global batch size:    48 | lm loss: 5.639123E+00 | loss scale: 32768.0 | grad norm: 3.200 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      636/    1200 | consumed samples:        30528 | elapsed time per iteration (ms): 1290.6 | learning rate: 9.720E-06 | global batch size:    48 | lm loss: 5.707810E+00 | loss scale: 32768.0 | grad norm: 3.400 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      637/    1200 | consumed samples:        30576 | elapsed time per iteration (ms): 1178.6 | learning rate: 9.736E-06 | global batch size:    48 | lm loss: 5.737084E+00 | loss scale: 32768.0 | grad norm: 3.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      638/    1200 | consumed samples:        30624 | elapsed time per iteration (ms): 1188.0 | learning rate: 9.752E-06 | global batch size:    48 | lm loss: 5.661277E+00 | loss scale: 32768.0 | grad norm: 2.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      639/    1200 | consumed samples:        30672 | elapsed time per iteration (ms): 1366.2 | learning rate: 9.768E-06 | global batch size:    48 | lm loss: 5.669306E+00 | loss scale: 32768.0 | grad norm: 2.888 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      640/    1200 | consumed samples:        30720 | elapsed time per iteration (ms): 1388.4 | learning rate: 9.783E-06 | global batch size:    48 | lm loss: 5.718307E+00 | loss scale: 32768.0 | grad norm: 3.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      641/    1200 | consumed samples:        30768 | elapsed time per iteration (ms): 1215.0 | learning rate: 9.799E-06 | global batch size:    48 | lm loss: 5.744380E+00 | loss scale: 32768.0 | grad norm: 3.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      642/    1200 | consumed samples:        30816 | elapsed time per iteration (ms): 1264.7 | learning rate: 9.815E-06 | global batch size:    48 | lm loss: 5.636865E+00 | loss scale: 32768.0 | grad norm: 2.892 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      643/    1200 | consumed samples:        30864 | elapsed time per iteration (ms): 1394.4 | learning rate: 9.830E-06 | global batch size:    48 | lm loss: 5.695767E+00 | loss scale: 32768.0 | grad norm: 2.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      644/    1200 | consumed samples:        30912 | elapsed time per iteration (ms): 1099.9 | learning rate: 9.846E-06 | global batch size:    48 | lm loss: 5.662914E+00 | loss scale: 32768.0 | grad norm: 2.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      645/    1200 | consumed samples:        30960 | elapsed time per iteration (ms): 1098.3 | learning rate: 9.862E-06 | global batch size:    48 | lm loss: 5.683803E+00 | loss scale: 32768.0 | grad norm: 2.816 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      646/    1200 | consumed samples:        31008 | elapsed time per iteration (ms): 1130.4 | learning rate: 9.878E-06 | global batch size:    48 | lm loss: 5.829515E+00 | loss scale: 32768.0 | grad norm: 3.084 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      647/    1200 | consumed samples:        31056 | elapsed time per iteration (ms): 1160.4 | learning rate: 9.893E-06 | global batch size:    48 | lm loss: 5.636236E+00 | loss scale: 32768.0 | grad norm: 2.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      648/    1200 | consumed samples:        31104 | elapsed time per iteration (ms): 1389.1 | learning rate: 9.909E-06 | global batch size:    48 | lm loss: 5.646852E+00 | loss scale: 32768.0 | grad norm: 2.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      649/    1200 | consumed samples:        31152 | elapsed time per iteration (ms): 1110.4 | learning rate: 9.925E-06 | global batch size:    48 | lm loss: 5.596616E+00 | loss scale: 32768.0 | grad norm: 2.835 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      650/    1200 | consumed samples:        31200 | elapsed time per iteration (ms): 1220.7 | learning rate: 9.941E-06 | global batch size:    48 | lm loss: 5.670585E+00 | loss scale: 32768.0 | grad norm: 2.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      651/    1200 | consumed samples:        31248 | elapsed time per iteration (ms): 1404.2 | learning rate: 9.956E-06 | global batch size:    48 | lm loss: 5.636184E+00 | loss scale: 32768.0 | grad norm: 2.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      652/    1200 | consumed samples:        31296 | elapsed time per iteration (ms): 1413.9 | learning rate: 9.972E-06 | global batch size:    48 | lm loss: 5.602259E+00 | loss scale: 32768.0 | grad norm: 2.875 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      653/    1200 | consumed samples:        31344 | elapsed time per iteration (ms): 1097.5 | learning rate: 9.988E-06 | global batch size:    48 | lm loss: 5.625667E+00 | loss scale: 32768.0 | grad norm: 2.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      654/    1200 | consumed samples:        31392 | elapsed time per iteration (ms): 1202.9 | learning rate: 1.000E-05 | global batch size:    48 | lm loss: 5.680848E+00 | loss scale: 32768.0 | grad norm: 2.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      655/    1200 | consumed samples:        31440 | elapsed time per iteration (ms): 1132.4 | learning rate: 1.002E-05 | global batch size:    48 | lm loss: 5.542604E+00 | loss scale: 32768.0 | grad norm: 2.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      656/    1200 | consumed samples:        31488 | elapsed time per iteration (ms): 1161.1 | learning rate: 1.003E-05 | global batch size:    48 | lm loss: 5.590339E+00 | loss scale: 32768.0 | grad norm: 2.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      657/    1200 | consumed samples:        31536 | elapsed time per iteration (ms): 1374.8 | learning rate: 1.005E-05 | global batch size:    48 | lm loss: 5.602201E+00 | loss scale: 32768.0 | grad norm: 2.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      658/    1200 | consumed samples:        31584 | elapsed time per iteration (ms): 1021.0 | learning rate: 1.007E-05 | global batch size:    48 | lm loss: 5.693005E+00 | loss scale: 32768.0 | grad norm: 2.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      659/    1200 | consumed samples:        31632 | elapsed time per iteration (ms): 1238.4 | learning rate: 1.008E-05 | global batch size:    48 | lm loss: 5.727424E+00 | loss scale: 32768.0 | grad norm: 2.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      660/    1200 | consumed samples:        31680 | elapsed time per iteration (ms): 1593.9 | learning rate: 1.010E-05 | global batch size:    48 | lm loss: 5.665128E+00 | loss scale: 32768.0 | grad norm: 2.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      661/    1200 | consumed samples:        31728 | elapsed time per iteration (ms): 1271.0 | learning rate: 1.011E-05 | global batch size:    48 | lm loss: 5.654308E+00 | loss scale: 32768.0 | grad norm: 2.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      662/    1200 | consumed samples:        31776 | elapsed time per iteration (ms): 1209.0 | learning rate: 1.013E-05 | global batch size:    48 | lm loss: 5.560678E+00 | loss scale: 32768.0 | grad norm: 2.968 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      663/    1200 | consumed samples:        31824 | elapsed time per iteration (ms): 1093.2 | learning rate: 1.014E-05 | global batch size:    48 | lm loss: 5.650335E+00 | loss scale: 32768.0 | grad norm: 2.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      664/    1200 | consumed samples:        31872 | elapsed time per iteration (ms): 1017.9 | learning rate: 1.016E-05 | global batch size:    48 | lm loss: 5.633661E+00 | loss scale: 32768.0 | grad norm: 3.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      665/    1200 | consumed samples:        31920 | elapsed time per iteration (ms): 1330.6 | learning rate: 1.018E-05 | global batch size:    48 | lm loss: 5.605163E+00 | loss scale: 32768.0 | grad norm: 2.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      666/    1200 | consumed samples:        31968 | elapsed time per iteration (ms): 1208.7 | learning rate: 1.019E-05 | global batch size:    48 | lm loss: 5.602441E+00 | loss scale: 32768.0 | grad norm: 2.912 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      667/    1200 | consumed samples:        32016 | elapsed time per iteration (ms): 1244.8 | learning rate: 1.021E-05 | global batch size:    48 | lm loss: 5.546649E+00 | loss scale: 32768.0 | grad norm: 2.879 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      668/    1200 | consumed samples:        32064 | elapsed time per iteration (ms): 1184.0 | learning rate: 1.022E-05 | global batch size:    48 | lm loss: 5.560547E+00 | loss scale: 32768.0 | grad norm: 3.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      669/    1200 | consumed samples:        32112 | elapsed time per iteration (ms): 1352.8 | learning rate: 1.024E-05 | global batch size:    48 | lm loss: 5.506057E+00 | loss scale: 32768.0 | grad norm: 3.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      670/    1200 | consumed samples:        32160 | elapsed time per iteration (ms): 1428.4 | learning rate: 1.026E-05 | global batch size:    48 | lm loss: 5.611871E+00 | loss scale: 32768.0 | grad norm: 3.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      671/    1200 | consumed samples:        32208 | elapsed time per iteration (ms): 2254.7 | learning rate: 1.027E-05 | global batch size:    48 | lm loss: 6.498889E+00 | loss scale: 32768.0 | grad norm: 2.861 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      672/    1200 | consumed samples:        32256 | elapsed time per iteration (ms): 2276.3 | learning rate: 1.029E-05 | global batch size:    48 | lm loss: 6.496965E+00 | loss scale: 32768.0 | grad norm: 2.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      673/    1200 | consumed samples:        32304 | elapsed time per iteration (ms): 1776.8 | learning rate: 1.030E-05 | global batch size:    48 | lm loss: 6.494954E+00 | loss scale: 32768.0 | grad norm: 2.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      674/    1200 | consumed samples:        32352 | elapsed time per iteration (ms): 2189.7 | learning rate: 1.032E-05 | global batch size:    48 | lm loss: 6.492949E+00 | loss scale: 32768.0 | grad norm: 2.860 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      675/    1200 | consumed samples:        32400 | elapsed time per iteration (ms): 1619.9 | learning rate: 1.033E-05 | global batch size:    48 | lm loss: 6.490998E+00 | loss scale: 32768.0 | grad norm: 2.813 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      676/    1200 | consumed samples:        32448 | elapsed time per iteration (ms): 1988.2 | learning rate: 1.035E-05 | global batch size:    48 | lm loss: 6.488901E+00 | loss scale: 32768.0 | grad norm: 2.909 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      677/    1200 | consumed samples:        32496 | elapsed time per iteration (ms): 2139.4 | learning rate: 1.037E-05 | global batch size:    48 | lm loss: 6.486967E+00 | loss scale: 32768.0 | grad norm: 2.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      678/    1200 | consumed samples:        32544 | elapsed time per iteration (ms): 1656.5 | learning rate: 1.038E-05 | global batch size:    48 | lm loss: 6.484773E+00 | loss scale: 32768.0 | grad norm: 2.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      679/    1200 | consumed samples:        32592 | elapsed time per iteration (ms): 1768.7 | learning rate: 1.040E-05 | global batch size:    48 | lm loss: 6.482742E+00 | loss scale: 32768.0 | grad norm: 2.832 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      680/    1200 | consumed samples:        32640 | elapsed time per iteration (ms): 1909.7 | learning rate: 1.041E-05 | global batch size:    48 | lm loss: 6.480903E+00 | loss scale: 32768.0 | grad norm: 2.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      681/    1200 | consumed samples:        32688 | elapsed time per iteration (ms): 2101.8 | learning rate: 1.043E-05 | global batch size:    48 | lm loss: 6.478852E+00 | loss scale: 32768.0 | grad norm: 2.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      682/    1200 | consumed samples:        32736 | elapsed time per iteration (ms): 1934.8 | learning rate: 1.044E-05 | global batch size:    48 | lm loss: 6.476681E+00 | loss scale: 32768.0 | grad norm: 2.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      683/    1200 | consumed samples:        32784 | elapsed time per iteration (ms): 1794.3 | learning rate: 1.046E-05 | global batch size:    48 | lm loss: 6.474682E+00 | loss scale: 32768.0 | grad norm: 2.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      684/    1200 | consumed samples:        32832 | elapsed time per iteration (ms): 1700.6 | learning rate: 1.048E-05 | global batch size:    48 | lm loss: 6.472605E+00 | loss scale: 32768.0 | grad norm: 2.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      685/    1200 | consumed samples:        32880 | elapsed time per iteration (ms): 2105.6 | learning rate: 1.049E-05 | global batch size:    48 | lm loss: 6.470652E+00 | loss scale: 32768.0 | grad norm: 2.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      686/    1200 | consumed samples:        32928 | elapsed time per iteration (ms): 1695.2 | learning rate: 1.051E-05 | global batch size:    48 | lm loss: 6.468765E+00 | loss scale: 32768.0 | grad norm: 2.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      687/    1200 | consumed samples:        32976 | elapsed time per iteration (ms): 1700.5 | learning rate: 1.052E-05 | global batch size:    48 | lm loss: 6.466828E+00 | loss scale: 32768.0 | grad norm: 2.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      688/    1200 | consumed samples:        33024 | elapsed time per iteration (ms): 2203.5 | learning rate: 1.054E-05 | global batch size:    48 | lm loss: 6.464910E+00 | loss scale: 32768.0 | grad norm: 2.656 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      689/    1200 | consumed samples:        33072 | elapsed time per iteration (ms): 1787.7 | learning rate: 1.055E-05 | global batch size:    48 | lm loss: 6.463017E+00 | loss scale: 32768.0 | grad norm: 2.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      690/    1200 | consumed samples:        33120 | elapsed time per iteration (ms): 1846.0 | learning rate: 1.057E-05 | global batch size:    48 | lm loss: 6.461224E+00 | loss scale: 32768.0 | grad norm: 2.610 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      691/    1200 | consumed samples:        33168 | elapsed time per iteration (ms): 1990.6 | learning rate: 1.059E-05 | global batch size:    48 | lm loss: 6.459123E+00 | loss scale: 32768.0 | grad norm: 2.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      692/    1200 | consumed samples:        33216 | elapsed time per iteration (ms): 1850.4 | learning rate: 1.060E-05 | global batch size:    48 | lm loss: 6.457135E+00 | loss scale: 32768.0 | grad norm: 2.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      693/    1200 | consumed samples:        33264 | elapsed time per iteration (ms): 2086.7 | learning rate: 1.062E-05 | global batch size:    48 | lm loss: 6.454993E+00 | loss scale: 32768.0 | grad norm: 2.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      694/    1200 | consumed samples:        33312 | elapsed time per iteration (ms): 1776.7 | learning rate: 1.063E-05 | global batch size:    48 | lm loss: 6.453077E+00 | loss scale: 32768.0 | grad norm: 2.788 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      695/    1200 | consumed samples:        33360 | elapsed time per iteration (ms): 1580.1 | learning rate: 1.065E-05 | global batch size:    48 | lm loss: 6.451100E+00 | loss scale: 32768.0 | grad norm: 2.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      696/    1200 | consumed samples:        33408 | elapsed time per iteration (ms): 1662.1 | learning rate: 1.066E-05 | global batch size:    48 | lm loss: 6.449258E+00 | loss scale: 32768.0 | grad norm: 2.691 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      697/    1200 | consumed samples:        33456 | elapsed time per iteration (ms): 2185.1 | learning rate: 1.068E-05 | global batch size:    48 | lm loss: 6.447480E+00 | loss scale: 32768.0 | grad norm: 2.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      698/    1200 | consumed samples:        33504 | elapsed time per iteration (ms): 1934.6 | learning rate: 1.070E-05 | global batch size:    48 | lm loss: 6.445570E+00 | loss scale: 32768.0 | grad norm: 2.659 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      699/    1200 | consumed samples:        33552 | elapsed time per iteration (ms): 1658.1 | learning rate: 1.071E-05 | global batch size:    48 | lm loss: 6.443820E+00 | loss scale: 32768.0 | grad norm: 2.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      700/    1200 | consumed samples:        33600 | elapsed time per iteration (ms): 1746.7 | learning rate: 1.073E-05 | global batch size:    48 | lm loss: 6.441741E+00 | loss scale: 32768.0 | grad norm: 2.612 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      701/    1200 | consumed samples:        33648 | elapsed time per iteration (ms): 1892.0 | learning rate: 1.074E-05 | global batch size:    48 | lm loss: 6.439993E+00 | loss scale: 32768.0 | grad norm: 2.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      702/    1200 | consumed samples:        33696 | elapsed time per iteration (ms): 1809.3 | learning rate: 1.076E-05 | global batch size:    48 | lm loss: 6.438062E+00 | loss scale: 32768.0 | grad norm: 2.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      703/    1200 | consumed samples:        33744 | elapsed time per iteration (ms): 2187.0 | learning rate: 1.077E-05 | global batch size:    48 | lm loss: 6.436110E+00 | loss scale: 32768.0 | grad norm: 2.856 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      704/    1200 | consumed samples:        33792 | elapsed time per iteration (ms): 1705.3 | learning rate: 1.079E-05 | global batch size:    48 | lm loss: 6.434294E+00 | loss scale: 32768.0 | grad norm: 2.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      705/    1200 | consumed samples:        33840 | elapsed time per iteration (ms): 2114.6 | learning rate: 1.081E-05 | global batch size:    48 | lm loss: 6.432549E+00 | loss scale: 32768.0 | grad norm: 2.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      706/    1200 | consumed samples:        33888 | elapsed time per iteration (ms): 1718.5 | learning rate: 1.082E-05 | global batch size:    48 | lm loss: 6.430641E+00 | loss scale: 32768.0 | grad norm: 2.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      707/    1200 | consumed samples:        33936 | elapsed time per iteration (ms): 1685.1 | learning rate: 1.084E-05 | global batch size:    48 | lm loss: 6.428910E+00 | loss scale: 32768.0 | grad norm: 2.821 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      708/    1200 | consumed samples:        33984 | elapsed time per iteration (ms): 1917.7 | learning rate: 1.085E-05 | global batch size:    48 | lm loss: 6.427041E+00 | loss scale: 32768.0 | grad norm: 2.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      709/    1200 | consumed samples:        34032 | elapsed time per iteration (ms): 1841.8 | learning rate: 1.087E-05 | global batch size:    48 | lm loss: 6.425324E+00 | loss scale: 32768.0 | grad norm: 2.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      710/    1200 | consumed samples:        34080 | elapsed time per iteration (ms): 1939.5 | learning rate: 1.088E-05 | global batch size:    48 | lm loss: 6.423546E+00 | loss scale: 32768.0 | grad norm: 2.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      711/    1200 | consumed samples:        34128 | elapsed time per iteration (ms): 1762.3 | learning rate: 1.090E-05 | global batch size:    48 | lm loss: 6.421828E+00 | loss scale: 32768.0 | grad norm: 2.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      712/    1200 | consumed samples:        34176 | elapsed time per iteration (ms): 1976.4 | learning rate: 1.092E-05 | global batch size:    48 | lm loss: 6.420307E+00 | loss scale: 32768.0 | grad norm: 2.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      713/    1200 | consumed samples:        34224 | elapsed time per iteration (ms): 2060.4 | learning rate: 1.093E-05 | global batch size:    48 | lm loss: 6.418449E+00 | loss scale: 32768.0 | grad norm: 2.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      714/    1200 | consumed samples:        34272 | elapsed time per iteration (ms): 2082.1 | learning rate: 1.095E-05 | global batch size:    48 | lm loss: 6.416666E+00 | loss scale: 32768.0 | grad norm: 2.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      715/    1200 | consumed samples:        34320 | elapsed time per iteration (ms): 1837.4 | learning rate: 1.096E-05 | global batch size:    48 | lm loss: 6.414838E+00 | loss scale: 32768.0 | grad norm: 2.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      716/    1200 | consumed samples:        34368 | elapsed time per iteration (ms): 1801.1 | learning rate: 1.098E-05 | global batch size:    48 | lm loss: 6.412893E+00 | loss scale: 32768.0 | grad norm: 2.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      717/    1200 | consumed samples:        34416 | elapsed time per iteration (ms): 2026.9 | learning rate: 1.099E-05 | global batch size:    48 | lm loss: 6.411219E+00 | loss scale: 32768.0 | grad norm: 2.630 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      718/    1200 | consumed samples:        34464 | elapsed time per iteration (ms): 2099.8 | learning rate: 1.101E-05 | global batch size:    48 | lm loss: 6.409484E+00 | loss scale: 32768.0 | grad norm: 2.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      719/    1200 | consumed samples:        34512 | elapsed time per iteration (ms): 1615.3 | learning rate: 1.103E-05 | global batch size:    48 | lm loss: 6.407734E+00 | loss scale: 32768.0 | grad norm: 2.849 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      720/    1200 | consumed samples:        34560 | elapsed time per iteration (ms): 2053.8 | learning rate: 1.104E-05 | global batch size:    48 | lm loss: 6.405970E+00 | loss scale: 32768.0 | grad norm: 2.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      721/    1200 | consumed samples:        34608 | elapsed time per iteration (ms): 1840.3 | learning rate: 1.106E-05 | global batch size:    48 | lm loss: 6.404248E+00 | loss scale: 32768.0 | grad norm: 2.557 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      722/    1200 | consumed samples:        34656 | elapsed time per iteration (ms): 1830.0 | learning rate: 1.107E-05 | global batch size:    48 | lm loss: 6.402679E+00 | loss scale: 32768.0 | grad norm: 2.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      723/    1200 | consumed samples:        34704 | elapsed time per iteration (ms): 1942.4 | learning rate: 1.109E-05 | global batch size:    48 | lm loss: 6.400932E+00 | loss scale: 32768.0 | grad norm: 2.585 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      724/    1200 | consumed samples:        34752 | elapsed time per iteration (ms): 1796.8 | learning rate: 1.110E-05 | global batch size:    48 | lm loss: 6.399249E+00 | loss scale: 32768.0 | grad norm: 2.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      725/    1200 | consumed samples:        34800 | elapsed time per iteration (ms): 1893.9 | learning rate: 1.112E-05 | global batch size:    48 | lm loss: 6.397670E+00 | loss scale: 32768.0 | grad norm: 2.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      726/    1200 | consumed samples:        34848 | elapsed time per iteration (ms): 1865.1 | learning rate: 1.114E-05 | global batch size:    48 | lm loss: 6.395989E+00 | loss scale: 32768.0 | grad norm: 2.548 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      727/    1200 | consumed samples:        34896 | elapsed time per iteration (ms): 1755.9 | learning rate: 1.115E-05 | global batch size:    48 | lm loss: 6.394105E+00 | loss scale: 32768.0 | grad norm: 2.746 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      728/    1200 | consumed samples:        34944 | elapsed time per iteration (ms): 1844.1 | learning rate: 1.117E-05 | global batch size:    48 | lm loss: 6.392169E+00 | loss scale: 32768.0 | grad norm: 2.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      729/    1200 | consumed samples:        34992 | elapsed time per iteration (ms): 2206.6 | learning rate: 1.118E-05 | global batch size:    48 | lm loss: 6.390357E+00 | loss scale: 32768.0 | grad norm: 2.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      730/    1200 | consumed samples:        35040 | elapsed time per iteration (ms): 1948.6 | learning rate: 1.120E-05 | global batch size:    48 | lm loss: 6.388628E+00 | loss scale: 32768.0 | grad norm: 2.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      731/    1200 | consumed samples:        35088 | elapsed time per iteration (ms): 1851.7 | learning rate: 1.121E-05 | global batch size:    48 | lm loss: 6.386922E+00 | loss scale: 32768.0 | grad norm: 2.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      732/    1200 | consumed samples:        35136 | elapsed time per iteration (ms): 1774.5 | learning rate: 1.123E-05 | global batch size:    48 | lm loss: 6.385599E+00 | loss scale: 32768.0 | grad norm: 2.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      733/    1200 | consumed samples:        35184 | elapsed time per iteration (ms): 1716.1 | learning rate: 1.125E-05 | global batch size:    48 | lm loss: 6.383818E+00 | loss scale: 32768.0 | grad norm: 2.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      734/    1200 | consumed samples:        35232 | elapsed time per iteration (ms): 1670.6 | learning rate: 1.126E-05 | global batch size:    48 | lm loss: 6.382195E+00 | loss scale: 32768.0 | grad norm: 2.559 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      735/    1200 | consumed samples:        35280 | elapsed time per iteration (ms): 2199.3 | learning rate: 1.128E-05 | global batch size:    48 | lm loss: 6.380624E+00 | loss scale: 32768.0 | grad norm: 2.557 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      736/    1200 | consumed samples:        35328 | elapsed time per iteration (ms): 1957.7 | learning rate: 1.129E-05 | global batch size:    48 | lm loss: 6.378893E+00 | loss scale: 32768.0 | grad norm: 2.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      737/    1200 | consumed samples:        35376 | elapsed time per iteration (ms): 1980.7 | learning rate: 1.131E-05 | global batch size:    48 | lm loss: 6.377125E+00 | loss scale: 32768.0 | grad norm: 2.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      738/    1200 | consumed samples:        35424 | elapsed time per iteration (ms): 2051.6 | learning rate: 1.132E-05 | global batch size:    48 | lm loss: 6.375334E+00 | loss scale: 32768.0 | grad norm: 2.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      739/    1200 | consumed samples:        35472 | elapsed time per iteration (ms): 1874.3 | learning rate: 1.134E-05 | global batch size:    48 | lm loss: 6.373633E+00 | loss scale: 32768.0 | grad norm: 2.577 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      740/    1200 | consumed samples:        35520 | elapsed time per iteration (ms): 1839.6 | learning rate: 1.136E-05 | global batch size:    48 | lm loss: 6.371873E+00 | loss scale: 32768.0 | grad norm: 2.589 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      741/    1200 | consumed samples:        35568 | elapsed time per iteration (ms): 1832.1 | learning rate: 1.137E-05 | global batch size:    48 | lm loss: 6.370158E+00 | loss scale: 32768.0 | grad norm: 2.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      742/    1200 | consumed samples:        35616 | elapsed time per iteration (ms): 1301.9 | learning rate: 1.139E-05 | global batch size:    48 | lm loss: 5.436877E+00 | loss scale: 32768.0 | grad norm: 2.654 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      743/    1200 | consumed samples:        35664 | elapsed time per iteration (ms): 1203.6 | learning rate: 1.140E-05 | global batch size:    48 | lm loss: 5.512941E+00 | loss scale: 32768.0 | grad norm: 2.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      744/    1200 | consumed samples:        35712 | elapsed time per iteration (ms): 1025.6 | learning rate: 1.142E-05 | global batch size:    48 | lm loss: 5.542022E+00 | loss scale: 32768.0 | grad norm: 2.742 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      745/    1200 | consumed samples:        35760 | elapsed time per iteration (ms): 1509.1 | learning rate: 1.143E-05 | global batch size:    48 | lm loss: 5.604959E+00 | loss scale: 32768.0 | grad norm: 2.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      746/    1200 | consumed samples:        35808 | elapsed time per iteration (ms): 1194.8 | learning rate: 1.145E-05 | global batch size:    48 | lm loss: 5.490602E+00 | loss scale: 32768.0 | grad norm: 2.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      747/    1200 | consumed samples:        35856 | elapsed time per iteration (ms): 1186.6 | learning rate: 1.147E-05 | global batch size:    48 | lm loss: 5.524067E+00 | loss scale: 32768.0 | grad norm: 2.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      748/    1200 | consumed samples:        35904 | elapsed time per iteration (ms): 1179.2 | learning rate: 1.148E-05 | global batch size:    48 | lm loss: 5.519777E+00 | loss scale: 32768.0 | grad norm: 2.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      749/    1200 | consumed samples:        35952 | elapsed time per iteration (ms): 1179.8 | learning rate: 1.150E-05 | global batch size:    48 | lm loss: 5.493884E+00 | loss scale: 32768.0 | grad norm: 2.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      750/    1200 | consumed samples:        36000 | elapsed time per iteration (ms): 1254.5 | learning rate: 1.151E-05 | global batch size:    48 | lm loss: 5.471249E+00 | loss scale: 32768.0 | grad norm: 2.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      751/    1200 | consumed samples:        36048 | elapsed time per iteration (ms): 1403.6 | learning rate: 1.153E-05 | global batch size:    48 | lm loss: 5.485837E+00 | loss scale: 32768.0 | grad norm: 2.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      752/    1200 | consumed samples:        36096 | elapsed time per iteration (ms): 1025.2 | learning rate: 1.154E-05 | global batch size:    48 | lm loss: 5.508826E+00 | loss scale: 32768.0 | grad norm: 2.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      753/    1200 | consumed samples:        36144 | elapsed time per iteration (ms): 1406.8 | learning rate: 1.156E-05 | global batch size:    48 | lm loss: 5.596010E+00 | loss scale: 32768.0 | grad norm: 2.551 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      754/    1200 | consumed samples:        36192 | elapsed time per iteration (ms): 1215.3 | learning rate: 1.158E-05 | global batch size:    48 | lm loss: 5.545961E+00 | loss scale: 32768.0 | grad norm: 2.480 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      755/    1200 | consumed samples:        36240 | elapsed time per iteration (ms): 1039.5 | learning rate: 1.159E-05 | global batch size:    48 | lm loss: 5.463594E+00 | loss scale: 32768.0 | grad norm: 2.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      756/    1200 | consumed samples:        36288 | elapsed time per iteration (ms): 1223.8 | learning rate: 1.161E-05 | global batch size:    48 | lm loss: 5.513489E+00 | loss scale: 32768.0 | grad norm: 2.461 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      757/    1200 | consumed samples:        36336 | elapsed time per iteration (ms): 1187.4 | learning rate: 1.162E-05 | global batch size:    48 | lm loss: 5.461175E+00 | loss scale: 32768.0 | grad norm: 2.419 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      758/    1200 | consumed samples:        36384 | elapsed time per iteration (ms): 1305.8 | learning rate: 1.164E-05 | global batch size:    48 | lm loss: 5.466673E+00 | loss scale: 32768.0 | grad norm: 2.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      759/    1200 | consumed samples:        36432 | elapsed time per iteration (ms): 1224.1 | learning rate: 1.165E-05 | global batch size:    48 | lm loss: 5.422128E+00 | loss scale: 32768.0 | grad norm: 2.479 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      760/    1200 | consumed samples:        36480 | elapsed time per iteration (ms): 1283.4 | learning rate: 1.167E-05 | global batch size:    48 | lm loss: 5.494297E+00 | loss scale: 32768.0 | grad norm: 2.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      761/    1200 | consumed samples:        36528 | elapsed time per iteration (ms): 1021.5 | learning rate: 1.169E-05 | global batch size:    48 | lm loss: 5.542501E+00 | loss scale: 32768.0 | grad norm: 2.546 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      762/    1200 | consumed samples:        36576 | elapsed time per iteration (ms): 1372.9 | learning rate: 1.170E-05 | global batch size:    48 | lm loss: 5.574999E+00 | loss scale: 32768.0 | grad norm: 2.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      763/    1200 | consumed samples:        36624 | elapsed time per iteration (ms): 1549.9 | learning rate: 1.172E-05 | global batch size:    48 | lm loss: 5.549945E+00 | loss scale: 32768.0 | grad norm: 2.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      764/    1200 | consumed samples:        36672 | elapsed time per iteration (ms): 1096.0 | learning rate: 1.173E-05 | global batch size:    48 | lm loss: 5.543144E+00 | loss scale: 32768.0 | grad norm: 3.134 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      765/    1200 | consumed samples:        36720 | elapsed time per iteration (ms): 1213.7 | learning rate: 1.175E-05 | global batch size:    48 | lm loss: 5.534392E+00 | loss scale: 32768.0 | grad norm: 2.666 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      766/    1200 | consumed samples:        36768 | elapsed time per iteration (ms): 1277.0 | learning rate: 1.177E-05 | global batch size:    48 | lm loss: 5.540305E+00 | loss scale: 32768.0 | grad norm: 2.627 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      767/    1200 | consumed samples:        36816 | elapsed time per iteration (ms): 1293.0 | learning rate: 1.178E-05 | global batch size:    48 | lm loss: 5.512352E+00 | loss scale: 32768.0 | grad norm: 2.779 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      768/    1200 | consumed samples:        36864 | elapsed time per iteration (ms): 1236.1 | learning rate: 1.180E-05 | global batch size:    48 | lm loss: 5.454603E+00 | loss scale: 32768.0 | grad norm: 2.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      769/    1200 | consumed samples:        36912 | elapsed time per iteration (ms): 1252.8 | learning rate: 1.181E-05 | global batch size:    48 | lm loss: 5.493875E+00 | loss scale: 32768.0 | grad norm: 2.539 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      770/    1200 | consumed samples:        36960 | elapsed time per iteration (ms): 1099.5 | learning rate: 1.183E-05 | global batch size:    48 | lm loss: 5.493002E+00 | loss scale: 32768.0 | grad norm: 2.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      771/    1200 | consumed samples:        37008 | elapsed time per iteration (ms): 1097.2 | learning rate: 1.184E-05 | global batch size:    48 | lm loss: 5.461275E+00 | loss scale: 32768.0 | grad norm: 2.533 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      772/    1200 | consumed samples:        37056 | elapsed time per iteration (ms): 1386.2 | learning rate: 1.186E-05 | global batch size:    48 | lm loss: 5.569376E+00 | loss scale: 32768.0 | grad norm: 2.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      773/    1200 | consumed samples:        37104 | elapsed time per iteration (ms): 1211.4 | learning rate: 1.188E-05 | global batch size:    48 | lm loss: 5.613263E+00 | loss scale: 32768.0 | grad norm: 2.547 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      774/    1200 | consumed samples:        37152 | elapsed time per iteration (ms): 1176.0 | learning rate: 1.189E-05 | global batch size:    48 | lm loss: 5.517778E+00 | loss scale: 32768.0 | grad norm: 2.558 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      775/    1200 | consumed samples:        37200 | elapsed time per iteration (ms): 1313.4 | learning rate: 1.191E-05 | global batch size:    48 | lm loss: 5.564070E+00 | loss scale: 32768.0 | grad norm: 2.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      776/    1200 | consumed samples:        37248 | elapsed time per iteration (ms): 1288.4 | learning rate: 1.192E-05 | global batch size:    48 | lm loss: 5.635829E+00 | loss scale: 32768.0 | grad norm: 2.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      777/    1200 | consumed samples:        37296 | elapsed time per iteration (ms): 1289.5 | learning rate: 1.194E-05 | global batch size:    48 | lm loss: 5.485412E+00 | loss scale: 32768.0 | grad norm: 2.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      778/    1200 | consumed samples:        37344 | elapsed time per iteration (ms): 1116.9 | learning rate: 1.195E-05 | global batch size:    48 | lm loss: 5.417502E+00 | loss scale: 32768.0 | grad norm: 2.323 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      779/    1200 | consumed samples:        37392 | elapsed time per iteration (ms): 1120.2 | learning rate: 1.197E-05 | global batch size:    48 | lm loss: 5.585297E+00 | loss scale: 32768.0 | grad norm: 2.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      780/    1200 | consumed samples:        37440 | elapsed time per iteration (ms): 1251.6 | learning rate: 1.199E-05 | global batch size:    48 | lm loss: 5.462658E+00 | loss scale: 32768.0 | grad norm: 2.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      781/    1200 | consumed samples:        37488 | elapsed time per iteration (ms): 2900.3 | learning rate: 1.200E-05 | global batch size:    48 | lm loss: 6.368477E+00 | loss scale: 32768.0 | grad norm: 2.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      782/    1200 | consumed samples:        37536 | elapsed time per iteration (ms): 2697.7 | learning rate: 1.202E-05 | global batch size:    48 | lm loss: 6.366909E+00 | loss scale: 32768.0 | grad norm: 2.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      783/    1200 | consumed samples:        37584 | elapsed time per iteration (ms): 2096.3 | learning rate: 1.203E-05 | global batch size:    48 | lm loss: 6.365136E+00 | loss scale: 32768.0 | grad norm: 2.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      784/    1200 | consumed samples:        37632 | elapsed time per iteration (ms): 2193.5 | learning rate: 1.205E-05 | global batch size:    48 | lm loss: 6.363127E+00 | loss scale: 32768.0 | grad norm: 2.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      785/    1200 | consumed samples:        37680 | elapsed time per iteration (ms): 1965.5 | learning rate: 1.206E-05 | global batch size:    48 | lm loss: 6.361442E+00 | loss scale: 32768.0 | grad norm: 2.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      786/    1200 | consumed samples:        37728 | elapsed time per iteration (ms): 1948.7 | learning rate: 1.208E-05 | global batch size:    48 | lm loss: 6.359766E+00 | loss scale: 32768.0 | grad norm: 2.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      787/    1200 | consumed samples:        37776 | elapsed time per iteration (ms): 2026.3 | learning rate: 1.210E-05 | global batch size:    48 | lm loss: 6.358127E+00 | loss scale: 32768.0 | grad norm: 2.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      788/    1200 | consumed samples:        37824 | elapsed time per iteration (ms): 2193.7 | learning rate: 1.211E-05 | global batch size:    48 | lm loss: 6.356574E+00 | loss scale: 32768.0 | grad norm: 2.373 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      789/    1200 | consumed samples:        37872 | elapsed time per iteration (ms): 2034.4 | learning rate: 1.213E-05 | global batch size:    48 | lm loss: 6.354855E+00 | loss scale: 32768.0 | grad norm: 2.366 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      790/    1200 | consumed samples:        37920 | elapsed time per iteration (ms): 2351.4 | learning rate: 1.214E-05 | global batch size:    48 | lm loss: 6.353339E+00 | loss scale: 32768.0 | grad norm: 2.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      791/    1200 | consumed samples:        37968 | elapsed time per iteration (ms): 1769.2 | learning rate: 1.216E-05 | global batch size:    48 | lm loss: 6.351509E+00 | loss scale: 32768.0 | grad norm: 2.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      792/    1200 | consumed samples:        38016 | elapsed time per iteration (ms): 2399.2 | learning rate: 1.217E-05 | global batch size:    48 | lm loss: 6.349777E+00 | loss scale: 32768.0 | grad norm: 2.593 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      793/    1200 | consumed samples:        38064 | elapsed time per iteration (ms): 1860.1 | learning rate: 1.219E-05 | global batch size:    48 | lm loss: 6.348112E+00 | loss scale: 32768.0 | grad norm: 2.544 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      794/    1200 | consumed samples:        38112 | elapsed time per iteration (ms): 1874.2 | learning rate: 1.221E-05 | global batch size:    48 | lm loss: 6.346546E+00 | loss scale: 32768.0 | grad norm: 2.580 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      795/    1200 | consumed samples:        38160 | elapsed time per iteration (ms): 1924.2 | learning rate: 1.222E-05 | global batch size:    48 | lm loss: 6.344951E+00 | loss scale: 32768.0 | grad norm: 2.566 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      796/    1200 | consumed samples:        38208 | elapsed time per iteration (ms): 2041.3 | learning rate: 1.224E-05 | global batch size:    48 | lm loss: 6.343335E+00 | loss scale: 32768.0 | grad norm: 2.309 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      797/    1200 | consumed samples:        38256 | elapsed time per iteration (ms): 2179.7 | learning rate: 1.225E-05 | global batch size:    48 | lm loss: 6.341735E+00 | loss scale: 32768.0 | grad norm: 2.435 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      798/    1200 | consumed samples:        38304 | elapsed time per iteration (ms): 2538.4 | learning rate: 1.227E-05 | global batch size:    48 | lm loss: 6.340056E+00 | loss scale: 32768.0 | grad norm: 2.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      799/    1200 | consumed samples:        38352 | elapsed time per iteration (ms): 2136.8 | learning rate: 1.228E-05 | global batch size:    48 | lm loss: 6.338408E+00 | loss scale: 32768.0 | grad norm: 2.372 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      800/    1200 | consumed samples:        38400 | elapsed time per iteration (ms): 1990.0 | learning rate: 1.230E-05 | global batch size:    48 | lm loss: 6.336685E+00 | loss scale: 32768.0 | grad norm: 2.302 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      801/    1200 | consumed samples:        38448 | elapsed time per iteration (ms): 1953.8 | learning rate: 1.232E-05 | global batch size:    48 | lm loss: 6.334948E+00 | loss scale: 32768.0 | grad norm: 2.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      802/    1200 | consumed samples:        38496 | elapsed time per iteration (ms): 2131.6 | learning rate: 1.233E-05 | global batch size:    48 | lm loss: 6.333114E+00 | loss scale: 32768.0 | grad norm: 2.316 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      803/    1200 | consumed samples:        38544 | elapsed time per iteration (ms): 2340.6 | learning rate: 1.235E-05 | global batch size:    48 | lm loss: 6.331480E+00 | loss scale: 32768.0 | grad norm: 2.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      804/    1200 | consumed samples:        38592 | elapsed time per iteration (ms): 2201.2 | learning rate: 1.236E-05 | global batch size:    48 | lm loss: 6.329959E+00 | loss scale: 32768.0 | grad norm: 2.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      805/    1200 | consumed samples:        38640 | elapsed time per iteration (ms): 2128.8 | learning rate: 1.238E-05 | global batch size:    48 | lm loss: 6.328360E+00 | loss scale: 32768.0 | grad norm: 2.290 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      806/    1200 | consumed samples:        38688 | elapsed time per iteration (ms): 2100.5 | learning rate: 1.239E-05 | global batch size:    48 | lm loss: 6.326558E+00 | loss scale: 32768.0 | grad norm: 2.370 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      807/    1200 | consumed samples:        38736 | elapsed time per iteration (ms): 1859.4 | learning rate: 1.241E-05 | global batch size:    48 | lm loss: 6.325048E+00 | loss scale: 32768.0 | grad norm: 2.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      808/    1200 | consumed samples:        38784 | elapsed time per iteration (ms): 2312.8 | learning rate: 1.243E-05 | global batch size:    48 | lm loss: 6.323390E+00 | loss scale: 32768.0 | grad norm: 2.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      809/    1200 | consumed samples:        38832 | elapsed time per iteration (ms): 2309.7 | learning rate: 1.244E-05 | global batch size:    48 | lm loss: 6.321618E+00 | loss scale: 32768.0 | grad norm: 2.376 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      810/    1200 | consumed samples:        38880 | elapsed time per iteration (ms): 1926.0 | learning rate: 1.246E-05 | global batch size:    48 | lm loss: 6.319924E+00 | loss scale: 32768.0 | grad norm: 2.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      811/    1200 | consumed samples:        38928 | elapsed time per iteration (ms): 2017.2 | learning rate: 1.247E-05 | global batch size:    48 | lm loss: 6.318182E+00 | loss scale: 32768.0 | grad norm: 2.311 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      812/    1200 | consumed samples:        38976 | elapsed time per iteration (ms): 2135.0 | learning rate: 1.249E-05 | global batch size:    48 | lm loss: 6.316713E+00 | loss scale: 32768.0 | grad norm: 2.347 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      813/    1200 | consumed samples:        39024 | elapsed time per iteration (ms): 1918.7 | learning rate: 1.250E-05 | global batch size:    48 | lm loss: 6.315207E+00 | loss scale: 32768.0 | grad norm: 2.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      814/    1200 | consumed samples:        39072 | elapsed time per iteration (ms): 2091.0 | learning rate: 1.252E-05 | global batch size:    48 | lm loss: 6.313552E+00 | loss scale: 32768.0 | grad norm: 2.256 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      815/    1200 | consumed samples:        39120 | elapsed time per iteration (ms): 2102.4 | learning rate: 1.254E-05 | global batch size:    48 | lm loss: 6.311865E+00 | loss scale: 32768.0 | grad norm: 2.257 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      816/    1200 | consumed samples:        39168 | elapsed time per iteration (ms): 2339.0 | learning rate: 1.255E-05 | global batch size:    48 | lm loss: 6.310524E+00 | loss scale: 32768.0 | grad norm: 2.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      817/    1200 | consumed samples:        39216 | elapsed time per iteration (ms): 2010.9 | learning rate: 1.257E-05 | global batch size:    48 | lm loss: 6.308727E+00 | loss scale: 32768.0 | grad norm: 2.256 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      818/    1200 | consumed samples:        39264 | elapsed time per iteration (ms): 2024.5 | learning rate: 1.258E-05 | global batch size:    48 | lm loss: 6.307134E+00 | loss scale: 32768.0 | grad norm: 2.229 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      819/    1200 | consumed samples:        39312 | elapsed time per iteration (ms): 1850.0 | learning rate: 1.260E-05 | global batch size:    48 | lm loss: 6.305375E+00 | loss scale: 32768.0 | grad norm: 2.282 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      820/    1200 | consumed samples:        39360 | elapsed time per iteration (ms): 2028.6 | learning rate: 1.261E-05 | global batch size:    48 | lm loss: 6.303819E+00 | loss scale: 32768.0 | grad norm: 2.200 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      821/    1200 | consumed samples:        39408 | elapsed time per iteration (ms): 2244.8 | learning rate: 1.263E-05 | global batch size:    48 | lm loss: 6.302146E+00 | loss scale: 32768.0 | grad norm: 2.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      822/    1200 | consumed samples:        39456 | elapsed time per iteration (ms): 1884.8 | learning rate: 1.265E-05 | global batch size:    48 | lm loss: 6.300643E+00 | loss scale: 32768.0 | grad norm: 2.315 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      823/    1200 | consumed samples:        39504 | elapsed time per iteration (ms): 2061.9 | learning rate: 1.266E-05 | global batch size:    48 | lm loss: 6.299050E+00 | loss scale: 32768.0 | grad norm: 2.291 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      824/    1200 | consumed samples:        39552 | elapsed time per iteration (ms): 1899.1 | learning rate: 1.268E-05 | global batch size:    48 | lm loss: 6.297415E+00 | loss scale: 32768.0 | grad norm: 2.368 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      825/    1200 | consumed samples:        39600 | elapsed time per iteration (ms): 2183.9 | learning rate: 1.269E-05 | global batch size:    48 | lm loss: 6.296016E+00 | loss scale: 32768.0 | grad norm: 2.550 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      826/    1200 | consumed samples:        39648 | elapsed time per iteration (ms): 2024.4 | learning rate: 1.271E-05 | global batch size:    48 | lm loss: 6.294614E+00 | loss scale: 32768.0 | grad norm: 2.294 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      827/    1200 | consumed samples:        39696 | elapsed time per iteration (ms): 2223.2 | learning rate: 1.272E-05 | global batch size:    48 | lm loss: 6.293071E+00 | loss scale: 32768.0 | grad norm: 2.361 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      828/    1200 | consumed samples:        39744 | elapsed time per iteration (ms): 2069.4 | learning rate: 1.274E-05 | global batch size:    48 | lm loss: 6.291486E+00 | loss scale: 32768.0 | grad norm: 2.332 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      829/    1200 | consumed samples:        39792 | elapsed time per iteration (ms): 2263.4 | learning rate: 1.276E-05 | global batch size:    48 | lm loss: 6.289907E+00 | loss scale: 32768.0 | grad norm: 2.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      830/    1200 | consumed samples:        39840 | elapsed time per iteration (ms): 1954.7 | learning rate: 1.277E-05 | global batch size:    48 | lm loss: 6.288414E+00 | loss scale: 32768.0 | grad norm: 2.371 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      831/    1200 | consumed samples:        39888 | elapsed time per iteration (ms): 2269.1 | learning rate: 1.279E-05 | global batch size:    48 | lm loss: 6.287094E+00 | loss scale: 32768.0 | grad norm: 2.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      832/    1200 | consumed samples:        39936 | elapsed time per iteration (ms): 1929.3 | learning rate: 1.280E-05 | global batch size:    48 | lm loss: 6.285771E+00 | loss scale: 32768.0 | grad norm: 2.275 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      833/    1200 | consumed samples:        39984 | elapsed time per iteration (ms): 2175.7 | learning rate: 1.282E-05 | global batch size:    48 | lm loss: 6.284426E+00 | loss scale: 32768.0 | grad norm: 2.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      834/    1200 | consumed samples:        40032 | elapsed time per iteration (ms): 1869.0 | learning rate: 1.283E-05 | global batch size:    48 | lm loss: 6.282871E+00 | loss scale: 32768.0 | grad norm: 2.335 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      835/    1200 | consumed samples:        40080 | elapsed time per iteration (ms): 1902.0 | learning rate: 1.285E-05 | global batch size:    48 | lm loss: 6.281418E+00 | loss scale: 32768.0 | grad norm: 2.336 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      836/    1200 | consumed samples:        40128 | elapsed time per iteration (ms): 2001.2 | learning rate: 1.287E-05 | global batch size:    48 | lm loss: 6.279896E+00 | loss scale: 32768.0 | grad norm: 2.346 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      837/    1200 | consumed samples:        40176 | elapsed time per iteration (ms): 1992.9 | learning rate: 1.288E-05 | global batch size:    48 | lm loss: 6.278317E+00 | loss scale: 32768.0 | grad norm: 2.345 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      838/    1200 | consumed samples:        40224 | elapsed time per iteration (ms): 2549.4 | learning rate: 1.290E-05 | global batch size:    48 | lm loss: 6.276771E+00 | loss scale: 32768.0 | grad norm: 2.195 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      839/    1200 | consumed samples:        40272 | elapsed time per iteration (ms): 2650.1 | learning rate: 1.291E-05 | global batch size:    48 | lm loss: 6.275036E+00 | loss scale: 32768.0 | grad norm: 2.218 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      840/    1200 | consumed samples:        40320 | elapsed time per iteration (ms): 1931.8 | learning rate: 1.293E-05 | global batch size:    48 | lm loss: 6.273568E+00 | loss scale: 32768.0 | grad norm: 2.287 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      841/    1200 | consumed samples:        40368 | elapsed time per iteration (ms): 2149.8 | learning rate: 1.294E-05 | global batch size:    48 | lm loss: 6.271748E+00 | loss scale: 32768.0 | grad norm: 2.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      842/    1200 | consumed samples:        40416 | elapsed time per iteration (ms): 1778.3 | learning rate: 1.296E-05 | global batch size:    48 | lm loss: 6.270212E+00 | loss scale: 32768.0 | grad norm: 2.203 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      843/    1200 | consumed samples:        40464 | elapsed time per iteration (ms): 1802.3 | learning rate: 1.298E-05 | global batch size:    48 | lm loss: 6.268780E+00 | loss scale: 32768.0 | grad norm: 2.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      844/    1200 | consumed samples:        40512 | elapsed time per iteration (ms): 2214.3 | learning rate: 1.299E-05 | global batch size:    48 | lm loss: 6.267597E+00 | loss scale: 32768.0 | grad norm: 3.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      845/    1200 | consumed samples:        40560 | elapsed time per iteration (ms): 2240.3 | learning rate: 1.301E-05 | global batch size:    48 | lm loss: 6.266092E+00 | loss scale: 32768.0 | grad norm: 2.312 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      846/    1200 | consumed samples:        40608 | elapsed time per iteration (ms): 2611.6 | learning rate: 1.302E-05 | global batch size:    48 | lm loss: 6.264589E+00 | loss scale: 32768.0 | grad norm: 2.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      847/    1200 | consumed samples:        40656 | elapsed time per iteration (ms): 1946.7 | learning rate: 1.304E-05 | global batch size:    48 | lm loss: 6.263154E+00 | loss scale: 32768.0 | grad norm: 2.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      848/    1200 | consumed samples:        40704 | elapsed time per iteration (ms): 1862.3 | learning rate: 1.305E-05 | global batch size:    48 | lm loss: 6.261544E+00 | loss scale: 32768.0 | grad norm: 2.216 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      849/    1200 | consumed samples:        40752 | elapsed time per iteration (ms): 1981.1 | learning rate: 1.307E-05 | global batch size:    48 | lm loss: 6.259967E+00 | loss scale: 32768.0 | grad norm: 2.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      850/    1200 | consumed samples:        40800 | elapsed time per iteration (ms): 2291.5 | learning rate: 1.309E-05 | global batch size:    48 | lm loss: 6.258647E+00 | loss scale: 32768.0 | grad norm: 2.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      851/    1200 | consumed samples:        40848 | elapsed time per iteration (ms): 1982.9 | learning rate: 1.310E-05 | global batch size:    48 | lm loss: 6.257313E+00 | loss scale: 32768.0 | grad norm: 2.175 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      852/    1200 | consumed samples:        40896 | elapsed time per iteration (ms): 1302.6 | learning rate: 1.312E-05 | global batch size:    48 | lm loss: 5.354940E+00 | loss scale: 32768.0 | grad norm: 2.339 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      853/    1200 | consumed samples:        40944 | elapsed time per iteration (ms): 1269.1 | learning rate: 1.313E-05 | global batch size:    48 | lm loss: 5.386668E+00 | loss scale: 32768.0 | grad norm: 2.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      854/    1200 | consumed samples:        40992 | elapsed time per iteration (ms): 1448.9 | learning rate: 1.315E-05 | global batch size:    48 | lm loss: 5.416926E+00 | loss scale: 32768.0 | grad norm: 2.321 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      855/    1200 | consumed samples:        41040 | elapsed time per iteration (ms): 1178.9 | learning rate: 1.316E-05 | global batch size:    48 | lm loss: 5.418561E+00 | loss scale: 32768.0 | grad norm: 2.293 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      856/    1200 | consumed samples:        41088 | elapsed time per iteration (ms): 1063.6 | learning rate: 1.318E-05 | global batch size:    48 | lm loss: 5.489338E+00 | loss scale: 32768.0 | grad norm: 2.251 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      857/    1200 | consumed samples:        41136 | elapsed time per iteration (ms): 1265.9 | learning rate: 1.320E-05 | global batch size:    48 | lm loss: 5.479391E+00 | loss scale: 32768.0 | grad norm: 2.144 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      858/    1200 | consumed samples:        41184 | elapsed time per iteration (ms): 1289.6 | learning rate: 1.321E-05 | global batch size:    48 | lm loss: 5.409265E+00 | loss scale: 32768.0 | grad norm: 2.321 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      859/    1200 | consumed samples:        41232 | elapsed time per iteration (ms): 1448.3 | learning rate: 1.323E-05 | global batch size:    48 | lm loss: 5.469419E+00 | loss scale: 32768.0 | grad norm: 2.131 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      860/    1200 | consumed samples:        41280 | elapsed time per iteration (ms): 1268.0 | learning rate: 1.324E-05 | global batch size:    48 | lm loss: 5.433782E+00 | loss scale: 32768.0 | grad norm: 2.235 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      861/    1200 | consumed samples:        41328 | elapsed time per iteration (ms): 1352.2 | learning rate: 1.326E-05 | global batch size:    48 | lm loss: 5.369781E+00 | loss scale: 32768.0 | grad norm: 2.158 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      862/    1200 | consumed samples:        41376 | elapsed time per iteration (ms): 1241.0 | learning rate: 1.328E-05 | global batch size:    48 | lm loss: 5.464331E+00 | loss scale: 32768.0 | grad norm: 2.272 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      863/    1200 | consumed samples:        41424 | elapsed time per iteration (ms): 1186.6 | learning rate: 1.329E-05 | global batch size:    48 | lm loss: 5.434584E+00 | loss scale: 32768.0 | grad norm: 2.161 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      864/    1200 | consumed samples:        41472 | elapsed time per iteration (ms): 1123.8 | learning rate: 1.331E-05 | global batch size:    48 | lm loss: 5.402329E+00 | loss scale: 32768.0 | grad norm: 2.275 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      865/    1200 | consumed samples:        41520 | elapsed time per iteration (ms): 1111.6 | learning rate: 1.332E-05 | global batch size:    48 | lm loss: 5.372257E+00 | loss scale: 32768.0 | grad norm: 2.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      866/    1200 | consumed samples:        41568 | elapsed time per iteration (ms): 1405.7 | learning rate: 1.334E-05 | global batch size:    48 | lm loss: 5.355555E+00 | loss scale: 32768.0 | grad norm: 2.317 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      867/    1200 | consumed samples:        41616 | elapsed time per iteration (ms): 1219.9 | learning rate: 1.335E-05 | global batch size:    48 | lm loss: 5.283389E+00 | loss scale: 32768.0 | grad norm: 2.093 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      868/    1200 | consumed samples:        41664 | elapsed time per iteration (ms): 1200.3 | learning rate: 1.337E-05 | global batch size:    48 | lm loss: 5.330420E+00 | loss scale: 32768.0 | grad norm: 2.203 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      869/    1200 | consumed samples:        41712 | elapsed time per iteration (ms): 1250.2 | learning rate: 1.339E-05 | global batch size:    48 | lm loss: 5.442895E+00 | loss scale: 32768.0 | grad norm: 2.190 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      870/    1200 | consumed samples:        41760 | elapsed time per iteration (ms): 1245.0 | learning rate: 1.340E-05 | global batch size:    48 | lm loss: 5.442117E+00 | loss scale: 32768.0 | grad norm: 2.220 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      871/    1200 | consumed samples:        41808 | elapsed time per iteration (ms): 1016.7 | learning rate: 1.342E-05 | global batch size:    48 | lm loss: 5.459334E+00 | loss scale: 32768.0 | grad norm: 2.312 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      872/    1200 | consumed samples:        41856 | elapsed time per iteration (ms): 1249.1 | learning rate: 1.343E-05 | global batch size:    48 | lm loss: 5.378273E+00 | loss scale: 32768.0 | grad norm: 2.226 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      873/    1200 | consumed samples:        41904 | elapsed time per iteration (ms): 1248.0 | learning rate: 1.345E-05 | global batch size:    48 | lm loss: 5.368026E+00 | loss scale: 32768.0 | grad norm: 2.209 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      874/    1200 | consumed samples:        41952 | elapsed time per iteration (ms): 1154.6 | learning rate: 1.346E-05 | global batch size:    48 | lm loss: 5.417726E+00 | loss scale: 32768.0 | grad norm: 2.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      875/    1200 | consumed samples:        42000 | elapsed time per iteration (ms): 1187.1 | learning rate: 1.348E-05 | global batch size:    48 | lm loss: 5.389942E+00 | loss scale: 32768.0 | grad norm: 2.129 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      876/    1200 | consumed samples:        42048 | elapsed time per iteration (ms): 1268.4 | learning rate: 1.350E-05 | global batch size:    48 | lm loss: 5.443110E+00 | loss scale: 32768.0 | grad norm: 2.209 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      877/    1200 | consumed samples:        42096 | elapsed time per iteration (ms): 1451.9 | learning rate: 1.351E-05 | global batch size:    48 | lm loss: 5.337201E+00 | loss scale: 32768.0 | grad norm: 2.270 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      878/    1200 | consumed samples:        42144 | elapsed time per iteration (ms): 1131.8 | learning rate: 1.353E-05 | global batch size:    48 | lm loss: 5.377415E+00 | loss scale: 32768.0 | grad norm: 2.102 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      879/    1200 | consumed samples:        42192 | elapsed time per iteration (ms): 1224.8 | learning rate: 1.354E-05 | global batch size:    48 | lm loss: 5.346821E+00 | loss scale: 32768.0 | grad norm: 2.151 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      880/    1200 | consumed samples:        42240 | elapsed time per iteration (ms): 1143.5 | learning rate: 1.356E-05 | global batch size:    48 | lm loss: 5.368223E+00 | loss scale: 32768.0 | grad norm: 2.179 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      881/    1200 | consumed samples:        42288 | elapsed time per iteration (ms): 1167.0 | learning rate: 1.357E-05 | global batch size:    48 | lm loss: 5.389137E+00 | loss scale: 32768.0 | grad norm: 2.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      882/    1200 | consumed samples:        42336 | elapsed time per iteration (ms): 1404.0 | learning rate: 1.359E-05 | global batch size:    48 | lm loss: 5.418159E+00 | loss scale: 32768.0 | grad norm: 2.114 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      883/    1200 | consumed samples:        42384 | elapsed time per iteration (ms): 1112.9 | learning rate: 1.361E-05 | global batch size:    48 | lm loss: 5.389165E+00 | loss scale: 32768.0 | grad norm: 2.142 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      884/    1200 | consumed samples:        42432 | elapsed time per iteration (ms): 1307.0 | learning rate: 1.362E-05 | global batch size:    48 | lm loss: 5.349958E+00 | loss scale: 32768.0 | grad norm: 2.061 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      885/    1200 | consumed samples:        42480 | elapsed time per iteration (ms): 1188.9 | learning rate: 1.364E-05 | global batch size:    48 | lm loss: 5.366014E+00 | loss scale: 32768.0 | grad norm: 2.327 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      886/    1200 | consumed samples:        42528 | elapsed time per iteration (ms): 1335.9 | learning rate: 1.365E-05 | global batch size:    48 | lm loss: 5.392216E+00 | loss scale: 32768.0 | grad norm: 2.133 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      887/    1200 | consumed samples:        42576 | elapsed time per iteration (ms): 1135.6 | learning rate: 1.367E-05 | global batch size:    48 | lm loss: 5.429701E+00 | loss scale: 32768.0 | grad norm: 2.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      888/    1200 | consumed samples:        42624 | elapsed time per iteration (ms): 1289.0 | learning rate: 1.368E-05 | global batch size:    48 | lm loss: 5.314342E+00 | loss scale: 32768.0 | grad norm: 2.162 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      889/    1200 | consumed samples:        42672 | elapsed time per iteration (ms): 1050.7 | learning rate: 1.370E-05 | global batch size:    48 | lm loss: 5.427429E+00 | loss scale: 32768.0 | grad norm: 2.114 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      890/    1200 | consumed samples:        42720 | elapsed time per iteration (ms): 1204.2 | learning rate: 1.372E-05 | global batch size:    48 | lm loss: 5.373451E+00 | loss scale: 32768.0 | grad norm: 2.100 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      891/    1200 | consumed samples:        42768 | elapsed time per iteration (ms): 2789.4 | learning rate: 1.373E-05 | global batch size:    48 | lm loss: 6.255756E+00 | loss scale: 32768.0 | grad norm: 2.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      892/    1200 | consumed samples:        42816 | elapsed time per iteration (ms): 2717.6 | learning rate: 1.375E-05 | global batch size:    48 | lm loss: 6.254128E+00 | loss scale: 32768.0 | grad norm: 2.073 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      893/    1200 | consumed samples:        42864 | elapsed time per iteration (ms): 1854.6 | learning rate: 1.376E-05 | global batch size:    48 | lm loss: 6.252719E+00 | loss scale: 32768.0 | grad norm: 2.217 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      894/    1200 | consumed samples:        42912 | elapsed time per iteration (ms): 1963.4 | learning rate: 1.378E-05 | global batch size:    48 | lm loss: 6.251136E+00 | loss scale: 32768.0 | grad norm: 2.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      895/    1200 | consumed samples:        42960 | elapsed time per iteration (ms): 1957.4 | learning rate: 1.379E-05 | global batch size:    48 | lm loss: 6.249785E+00 | loss scale: 32768.0 | grad norm: 2.138 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      896/    1200 | consumed samples:        43008 | elapsed time per iteration (ms): 1663.3 | learning rate: 1.381E-05 | global batch size:    48 | lm loss: 6.248351E+00 | loss scale: 32768.0 | grad norm: 2.124 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      897/    1200 | consumed samples:        43056 | elapsed time per iteration (ms): 1902.5 | learning rate: 1.383E-05 | global batch size:    48 | lm loss: 6.246872E+00 | loss scale: 32768.0 | grad norm: 2.120 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      898/    1200 | consumed samples:        43104 | elapsed time per iteration (ms): 1813.7 | learning rate: 1.384E-05 | global batch size:    48 | lm loss: 6.245466E+00 | loss scale: 32768.0 | grad norm: 2.172 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      899/    1200 | consumed samples:        43152 | elapsed time per iteration (ms): 2077.1 | learning rate: 1.386E-05 | global batch size:    48 | lm loss: 6.244088E+00 | loss scale: 32768.0 | grad norm: 2.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      900/    1200 | consumed samples:        43200 | elapsed time per iteration (ms): 1817.9 | learning rate: 1.387E-05 | global batch size:    48 | lm loss: 6.242483E+00 | loss scale: 32768.0 | grad norm: 2.154 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      901/    1200 | consumed samples:        43248 | elapsed time per iteration (ms): 1966.4 | learning rate: 1.389E-05 | global batch size:    48 | lm loss: 6.240926E+00 | loss scale: 32768.0 | grad norm: 2.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      902/    1200 | consumed samples:        43296 | elapsed time per iteration (ms): 1684.7 | learning rate: 1.390E-05 | global batch size:    48 | lm loss: 6.239528E+00 | loss scale: 32768.0 | grad norm: 2.121 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      903/    1200 | consumed samples:        43344 | elapsed time per iteration (ms): 1700.9 | learning rate: 1.392E-05 | global batch size:    48 | lm loss: 6.238101E+00 | loss scale: 32768.0 | grad norm: 2.138 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      904/    1200 | consumed samples:        43392 | elapsed time per iteration (ms): 2023.6 | learning rate: 1.394E-05 | global batch size:    48 | lm loss: 6.236594E+00 | loss scale: 32768.0 | grad norm: 2.114 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      905/    1200 | consumed samples:        43440 | elapsed time per iteration (ms): 1893.5 | learning rate: 1.395E-05 | global batch size:    48 | lm loss: 6.235170E+00 | loss scale: 32768.0 | grad norm: 2.022 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      906/    1200 | consumed samples:        43488 | elapsed time per iteration (ms): 1854.2 | learning rate: 1.397E-05 | global batch size:    48 | lm loss: 6.233668E+00 | loss scale: 32768.0 | grad norm: 2.125 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      907/    1200 | consumed samples:        43536 | elapsed time per iteration (ms): 1713.4 | learning rate: 1.398E-05 | global batch size:    48 | lm loss: 6.232274E+00 | loss scale: 32768.0 | grad norm: 2.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      908/    1200 | consumed samples:        43584 | elapsed time per iteration (ms): 1765.0 | learning rate: 1.400E-05 | global batch size:    48 | lm loss: 6.230905E+00 | loss scale: 32768.0 | grad norm: 2.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      909/    1200 | consumed samples:        43632 | elapsed time per iteration (ms): 1759.3 | learning rate: 1.401E-05 | global batch size:    48 | lm loss: 6.229527E+00 | loss scale: 32768.0 | grad norm: 2.194 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      910/    1200 | consumed samples:        43680 | elapsed time per iteration (ms): 2070.4 | learning rate: 1.403E-05 | global batch size:    48 | lm loss: 6.228156E+00 | loss scale: 32768.0 | grad norm: 2.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      911/    1200 | consumed samples:        43728 | elapsed time per iteration (ms): 1676.1 | learning rate: 1.405E-05 | global batch size:    48 | lm loss: 6.226796E+00 | loss scale: 32768.0 | grad norm: 2.209 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      912/    1200 | consumed samples:        43776 | elapsed time per iteration (ms): 1731.8 | learning rate: 1.406E-05 | global batch size:    48 | lm loss: 6.225449E+00 | loss scale: 32768.0 | grad norm: 2.059 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      913/    1200 | consumed samples:        43824 | elapsed time per iteration (ms): 1672.5 | learning rate: 1.408E-05 | global batch size:    48 | lm loss: 6.224077E+00 | loss scale: 32768.0 | grad norm: 2.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      914/    1200 | consumed samples:        43872 | elapsed time per iteration (ms): 1800.8 | learning rate: 1.409E-05 | global batch size:    48 | lm loss: 6.222580E+00 | loss scale: 32768.0 | grad norm: 2.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      915/    1200 | consumed samples:        43920 | elapsed time per iteration (ms): 1912.3 | learning rate: 1.411E-05 | global batch size:    48 | lm loss: 6.221163E+00 | loss scale: 32768.0 | grad norm: 2.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      916/    1200 | consumed samples:        43968 | elapsed time per iteration (ms): 1871.1 | learning rate: 1.412E-05 | global batch size:    48 | lm loss: 6.219777E+00 | loss scale: 32768.0 | grad norm: 1.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      917/    1200 | consumed samples:        44016 | elapsed time per iteration (ms): 2372.6 | learning rate: 1.414E-05 | global batch size:    48 | lm loss: 6.218390E+00 | loss scale: 32768.0 | grad norm: 2.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      918/    1200 | consumed samples:        44064 | elapsed time per iteration (ms): 1859.9 | learning rate: 1.416E-05 | global batch size:    48 | lm loss: 6.216875E+00 | loss scale: 32768.0 | grad norm: 2.105 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      919/    1200 | consumed samples:        44112 | elapsed time per iteration (ms): 1699.0 | learning rate: 1.417E-05 | global batch size:    48 | lm loss: 6.215384E+00 | loss scale: 32768.0 | grad norm: 2.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      920/    1200 | consumed samples:        44160 | elapsed time per iteration (ms): 1677.6 | learning rate: 1.419E-05 | global batch size:    48 | lm loss: 6.213946E+00 | loss scale: 32768.0 | grad norm: 2.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      921/    1200 | consumed samples:        44208 | elapsed time per iteration (ms): 2000.0 | learning rate: 1.420E-05 | global batch size:    48 | lm loss: 6.212506E+00 | loss scale: 32768.0 | grad norm: 2.087 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      922/    1200 | consumed samples:        44256 | elapsed time per iteration (ms): 1724.2 | learning rate: 1.422E-05 | global batch size:    48 | lm loss: 6.211143E+00 | loss scale: 32768.0 | grad norm: 2.066 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      923/    1200 | consumed samples:        44304 | elapsed time per iteration (ms): 1965.8 | learning rate: 1.423E-05 | global batch size:    48 | lm loss: 6.209704E+00 | loss scale: 32768.0 | grad norm: 2.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      924/    1200 | consumed samples:        44352 | elapsed time per iteration (ms): 1898.9 | learning rate: 1.425E-05 | global batch size:    48 | lm loss: 6.208425E+00 | loss scale: 32768.0 | grad norm: 2.153 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      925/    1200 | consumed samples:        44400 | elapsed time per iteration (ms): 1747.3 | learning rate: 1.427E-05 | global batch size:    48 | lm loss: 6.206977E+00 | loss scale: 32768.0 | grad norm: 2.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      926/    1200 | consumed samples:        44448 | elapsed time per iteration (ms): 1671.3 | learning rate: 1.428E-05 | global batch size:    48 | lm loss: 6.205448E+00 | loss scale: 32768.0 | grad norm: 2.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      927/    1200 | consumed samples:        44496 | elapsed time per iteration (ms): 1706.3 | learning rate: 1.430E-05 | global batch size:    48 | lm loss: 6.204030E+00 | loss scale: 32768.0 | grad norm: 2.074 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      928/    1200 | consumed samples:        44544 | elapsed time per iteration (ms): 1859.3 | learning rate: 1.431E-05 | global batch size:    48 | lm loss: 6.202697E+00 | loss scale: 32768.0 | grad norm: 2.070 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      929/    1200 | consumed samples:        44592 | elapsed time per iteration (ms): 1807.9 | learning rate: 1.433E-05 | global batch size:    48 | lm loss: 6.201159E+00 | loss scale: 32768.0 | grad norm: 2.009 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      930/    1200 | consumed samples:        44640 | elapsed time per iteration (ms): 1745.2 | learning rate: 1.434E-05 | global batch size:    48 | lm loss: 6.199797E+00 | loss scale: 32768.0 | grad norm: 2.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      931/    1200 | consumed samples:        44688 | elapsed time per iteration (ms): 1880.8 | learning rate: 1.436E-05 | global batch size:    48 | lm loss: 6.198468E+00 | loss scale: 32768.0 | grad norm: 2.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      932/    1200 | consumed samples:        44736 | elapsed time per iteration (ms): 1855.4 | learning rate: 1.438E-05 | global batch size:    48 | lm loss: 6.197236E+00 | loss scale: 32768.0 | grad norm: 1.996 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      933/    1200 | consumed samples:        44784 | elapsed time per iteration (ms): 1819.2 | learning rate: 1.439E-05 | global batch size:    48 | lm loss: 6.195897E+00 | loss scale: 32768.0 | grad norm: 2.013 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      934/    1200 | consumed samples:        44832 | elapsed time per iteration (ms): 1700.3 | learning rate: 1.441E-05 | global batch size:    48 | lm loss: 6.194438E+00 | loss scale: 32768.0 | grad norm: 1.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      935/    1200 | consumed samples:        44880 | elapsed time per iteration (ms): 2103.9 | learning rate: 1.442E-05 | global batch size:    48 | lm loss: 6.193068E+00 | loss scale: 32768.0 | grad norm: 2.101 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      936/    1200 | consumed samples:        44928 | elapsed time per iteration (ms): 1765.3 | learning rate: 1.444E-05 | global batch size:    48 | lm loss: 6.191771E+00 | loss scale: 32768.0 | grad norm: 1.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      937/    1200 | consumed samples:        44976 | elapsed time per iteration (ms): 1849.7 | learning rate: 1.445E-05 | global batch size:    48 | lm loss: 6.190248E+00 | loss scale: 32768.0 | grad norm: 1.891 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      938/    1200 | consumed samples:        45024 | elapsed time per iteration (ms): 1799.1 | learning rate: 1.447E-05 | global batch size:    48 | lm loss: 6.188839E+00 | loss scale: 32768.0 | grad norm: 2.054 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      939/    1200 | consumed samples:        45072 | elapsed time per iteration (ms): 1931.3 | learning rate: 1.449E-05 | global batch size:    48 | lm loss: 6.187484E+00 | loss scale: 32768.0 | grad norm: 2.005 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      940/    1200 | consumed samples:        45120 | elapsed time per iteration (ms): 1715.0 | learning rate: 1.450E-05 | global batch size:    48 | lm loss: 6.186095E+00 | loss scale: 32768.0 | grad norm: 2.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      941/    1200 | consumed samples:        45168 | elapsed time per iteration (ms): 1833.2 | learning rate: 1.452E-05 | global batch size:    48 | lm loss: 6.184597E+00 | loss scale: 32768.0 | grad norm: 1.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      942/    1200 | consumed samples:        45216 | elapsed time per iteration (ms): 1815.1 | learning rate: 1.453E-05 | global batch size:    48 | lm loss: 6.183109E+00 | loss scale: 32768.0 | grad norm: 1.974 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      943/    1200 | consumed samples:        45264 | elapsed time per iteration (ms): 1779.4 | learning rate: 1.455E-05 | global batch size:    48 | lm loss: 6.181603E+00 | loss scale: 32768.0 | grad norm: 2.119 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      944/    1200 | consumed samples:        45312 | elapsed time per iteration (ms): 1673.5 | learning rate: 1.456E-05 | global batch size:    48 | lm loss: 6.180123E+00 | loss scale: 32768.0 | grad norm: 1.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      945/    1200 | consumed samples:        45360 | elapsed time per iteration (ms): 1674.1 | learning rate: 1.458E-05 | global batch size:    48 | lm loss: 6.178855E+00 | loss scale: 32768.0 | grad norm: 2.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      946/    1200 | consumed samples:        45408 | elapsed time per iteration (ms): 1780.3 | learning rate: 1.460E-05 | global batch size:    48 | lm loss: 6.177509E+00 | loss scale: 32768.0 | grad norm: 2.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      947/    1200 | consumed samples:        45456 | elapsed time per iteration (ms): 1692.1 | learning rate: 1.461E-05 | global batch size:    48 | lm loss: 6.176135E+00 | loss scale: 32768.0 | grad norm: 1.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      948/    1200 | consumed samples:        45504 | elapsed time per iteration (ms): 2117.5 | learning rate: 1.463E-05 | global batch size:    48 | lm loss: 6.174656E+00 | loss scale: 32768.0 | grad norm: 1.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      949/    1200 | consumed samples:        45552 | elapsed time per iteration (ms): 1726.3 | learning rate: 1.464E-05 | global batch size:    48 | lm loss: 6.173226E+00 | loss scale: 32768.0 | grad norm: 2.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      950/    1200 | consumed samples:        45600 | elapsed time per iteration (ms): 1768.2 | learning rate: 1.466E-05 | global batch size:    48 | lm loss: 6.171833E+00 | loss scale: 32768.0 | grad norm: 1.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      951/    1200 | consumed samples:        45648 | elapsed time per iteration (ms): 1829.2 | learning rate: 1.467E-05 | global batch size:    48 | lm loss: 6.170695E+00 | loss scale: 32768.0 | grad norm: 3.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      952/    1200 | consumed samples:        45696 | elapsed time per iteration (ms): 1670.4 | learning rate: 1.469E-05 | global batch size:    48 | lm loss: 6.169416E+00 | loss scale: 32768.0 | grad norm: 2.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      953/    1200 | consumed samples:        45744 | elapsed time per iteration (ms): 2143.8 | learning rate: 1.471E-05 | global batch size:    48 | lm loss: 6.167970E+00 | loss scale: 32768.0 | grad norm: 1.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      954/    1200 | consumed samples:        45792 | elapsed time per iteration (ms): 2270.2 | learning rate: 1.472E-05 | global batch size:    48 | lm loss: 6.166820E+00 | loss scale: 32768.0 | grad norm: 2.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      955/    1200 | consumed samples:        45840 | elapsed time per iteration (ms): 1702.7 | learning rate: 1.474E-05 | global batch size:    48 | lm loss: 6.165533E+00 | loss scale: 32768.0 | grad norm: 1.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      956/    1200 | consumed samples:        45888 | elapsed time per iteration (ms): 1702.7 | learning rate: 1.475E-05 | global batch size:    48 | lm loss: 6.164297E+00 | loss scale: 32768.0 | grad norm: 2.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      957/    1200 | consumed samples:        45936 | elapsed time per iteration (ms): 1952.4 | learning rate: 1.477E-05 | global batch size:    48 | lm loss: 6.162965E+00 | loss scale: 32768.0 | grad norm: 1.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      958/    1200 | consumed samples:        45984 | elapsed time per iteration (ms): 1667.1 | learning rate: 1.478E-05 | global batch size:    48 | lm loss: 6.161617E+00 | loss scale: 32768.0 | grad norm: 2.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      959/    1200 | consumed samples:        46032 | elapsed time per iteration (ms): 1831.3 | learning rate: 1.480E-05 | global batch size:    48 | lm loss: 6.160428E+00 | loss scale: 32768.0 | grad norm: 2.035 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      960/    1200 | consumed samples:        46080 | elapsed time per iteration (ms): 1898.5 | learning rate: 1.482E-05 | global batch size:    48 | lm loss: 6.159310E+00 | loss scale: 32768.0 | grad norm: 2.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      961/    1200 | consumed samples:        46128 | elapsed time per iteration (ms): 1827.0 | learning rate: 1.483E-05 | global batch size:    48 | lm loss: 6.158141E+00 | loss scale: 32768.0 | grad norm: 2.049 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      962/    1200 | consumed samples:        46176 | elapsed time per iteration (ms): 1257.8 | learning rate: 1.485E-05 | global batch size:    48 | lm loss: 5.287412E+00 | loss scale: 32768.0 | grad norm: 2.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      963/    1200 | consumed samples:        46224 | elapsed time per iteration (ms): 1318.0 | learning rate: 1.486E-05 | global batch size:    48 | lm loss: 5.287154E+00 | loss scale: 32768.0 | grad norm: 2.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      964/    1200 | consumed samples:        46272 | elapsed time per iteration (ms): 1019.4 | learning rate: 1.488E-05 | global batch size:    48 | lm loss: 5.311024E+00 | loss scale: 32768.0 | grad norm: 2.178 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      965/    1200 | consumed samples:        46320 | elapsed time per iteration (ms): 1462.6 | learning rate: 1.490E-05 | global batch size:    48 | lm loss: 5.268913E+00 | loss scale: 32768.0 | grad norm: 1.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      966/    1200 | consumed samples:        46368 | elapsed time per iteration (ms): 1166.1 | learning rate: 1.491E-05 | global batch size:    48 | lm loss: 5.377222E+00 | loss scale: 32768.0 | grad norm: 2.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      967/    1200 | consumed samples:        46416 | elapsed time per iteration (ms): 1168.2 | learning rate: 1.493E-05 | global batch size:    48 | lm loss: 5.234326E+00 | loss scale: 32768.0 | grad norm: 1.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      968/    1200 | consumed samples:        46464 | elapsed time per iteration (ms): 1198.5 | learning rate: 1.494E-05 | global batch size:    48 | lm loss: 5.238404E+00 | loss scale: 32768.0 | grad norm: 2.062 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      969/    1200 | consumed samples:        46512 | elapsed time per iteration (ms): 1204.1 | learning rate: 1.496E-05 | global batch size:    48 | lm loss: 5.334866E+00 | loss scale: 32768.0 | grad norm: 1.883 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      970/    1200 | consumed samples:        46560 | elapsed time per iteration (ms): 1317.8 | learning rate: 1.497E-05 | global batch size:    48 | lm loss: 5.222650E+00 | loss scale: 32768.0 | grad norm: 2.090 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      971/    1200 | consumed samples:        46608 | elapsed time per iteration (ms): 1353.8 | learning rate: 1.499E-05 | global batch size:    48 | lm loss: 5.226184E+00 | loss scale: 32768.0 | grad norm: 1.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      972/    1200 | consumed samples:        46656 | elapsed time per iteration (ms): 1346.1 | learning rate: 1.501E-05 | global batch size:    48 | lm loss: 5.388858E+00 | loss scale: 32768.0 | grad norm: 2.123 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      973/    1200 | consumed samples:        46704 | elapsed time per iteration (ms): 1237.1 | learning rate: 1.502E-05 | global batch size:    48 | lm loss: 5.287314E+00 | loss scale: 32768.0 | grad norm: 2.079 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      974/    1200 | consumed samples:        46752 | elapsed time per iteration (ms): 1260.6 | learning rate: 1.504E-05 | global batch size:    48 | lm loss: 5.312557E+00 | loss scale: 32768.0 | grad norm: 1.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      975/    1200 | consumed samples:        46800 | elapsed time per iteration (ms): 1153.0 | learning rate: 1.505E-05 | global batch size:    48 | lm loss: 5.326550E+00 | loss scale: 32768.0 | grad norm: 1.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      976/    1200 | consumed samples:        46848 | elapsed time per iteration (ms): 1293.9 | learning rate: 1.507E-05 | global batch size:    48 | lm loss: 5.301226E+00 | loss scale: 32768.0 | grad norm: 1.938 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      977/    1200 | consumed samples:        46896 | elapsed time per iteration (ms): 1227.0 | learning rate: 1.508E-05 | global batch size:    48 | lm loss: 5.403348E+00 | loss scale: 32768.0 | grad norm: 1.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      978/    1200 | consumed samples:        46944 | elapsed time per iteration (ms): 1185.3 | learning rate: 1.510E-05 | global batch size:    48 | lm loss: 5.256657E+00 | loss scale: 32768.0 | grad norm: 2.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      979/    1200 | consumed samples:        46992 | elapsed time per iteration (ms): 1268.5 | learning rate: 1.512E-05 | global batch size:    48 | lm loss: 5.223884E+00 | loss scale: 32768.0 | grad norm: 1.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      980/    1200 | consumed samples:        47040 | elapsed time per iteration (ms): 1269.9 | learning rate: 1.513E-05 | global batch size:    48 | lm loss: 5.327868E+00 | loss scale: 32768.0 | grad norm: 1.873 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      981/    1200 | consumed samples:        47088 | elapsed time per iteration (ms): 1237.1 | learning rate: 1.515E-05 | global batch size:    48 | lm loss: 5.228302E+00 | loss scale: 32768.0 | grad norm: 1.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      982/    1200 | consumed samples:        47136 | elapsed time per iteration (ms): 1249.4 | learning rate: 1.516E-05 | global batch size:    48 | lm loss: 5.225498E+00 | loss scale: 32768.0 | grad norm: 1.988 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      983/    1200 | consumed samples:        47184 | elapsed time per iteration (ms): 1365.8 | learning rate: 1.518E-05 | global batch size:    48 | lm loss: 5.244337E+00 | loss scale: 32768.0 | grad norm: 1.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      984/    1200 | consumed samples:        47232 | elapsed time per iteration (ms): 1348.8 | learning rate: 1.519E-05 | global batch size:    48 | lm loss: 5.329399E+00 | loss scale: 32768.0 | grad norm: 1.941 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      985/    1200 | consumed samples:        47280 | elapsed time per iteration (ms): 1352.5 | learning rate: 1.521E-05 | global batch size:    48 | lm loss: 5.240498E+00 | loss scale: 32768.0 | grad norm: 2.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      986/    1200 | consumed samples:        47328 | elapsed time per iteration (ms): 1211.1 | learning rate: 1.523E-05 | global batch size:    48 | lm loss: 5.356561E+00 | loss scale: 32768.0 | grad norm: 1.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      987/    1200 | consumed samples:        47376 | elapsed time per iteration (ms): 1121.8 | learning rate: 1.524E-05 | global batch size:    48 | lm loss: 5.310004E+00 | loss scale: 32768.0 | grad norm: 1.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      988/    1200 | consumed samples:        47424 | elapsed time per iteration (ms): 1086.3 | learning rate: 1.526E-05 | global batch size:    48 | lm loss: 5.312841E+00 | loss scale: 32768.0 | grad norm: 1.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      989/    1200 | consumed samples:        47472 | elapsed time per iteration (ms): 1115.8 | learning rate: 1.527E-05 | global batch size:    48 | lm loss: 5.305084E+00 | loss scale: 32768.0 | grad norm: 1.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      990/    1200 | consumed samples:        47520 | elapsed time per iteration (ms): 1024.5 | learning rate: 1.529E-05 | global batch size:    48 | lm loss: 5.324228E+00 | loss scale: 32768.0 | grad norm: 1.906 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      991/    1200 | consumed samples:        47568 | elapsed time per iteration (ms): 1166.6 | learning rate: 1.530E-05 | global batch size:    48 | lm loss: 5.387029E+00 | loss scale: 32768.0 | grad norm: 1.889 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      992/    1200 | consumed samples:        47616 | elapsed time per iteration (ms): 1327.4 | learning rate: 1.532E-05 | global batch size:    48 | lm loss: 5.310380E+00 | loss scale: 32768.0 | grad norm: 1.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      993/    1200 | consumed samples:        47664 | elapsed time per iteration (ms): 1569.6 | learning rate: 1.534E-05 | global batch size:    48 | lm loss: 5.309012E+00 | loss scale: 32768.0 | grad norm: 1.769 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      994/    1200 | consumed samples:        47712 | elapsed time per iteration (ms): 1261.2 | learning rate: 1.535E-05 | global batch size:    48 | lm loss: 5.375811E+00 | loss scale: 32768.0 | grad norm: 1.913 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      995/    1200 | consumed samples:        47760 | elapsed time per iteration (ms): 1265.8 | learning rate: 1.537E-05 | global batch size:    48 | lm loss: 5.276562E+00 | loss scale: 32768.0 | grad norm: 1.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      996/    1200 | consumed samples:        47808 | elapsed time per iteration (ms): 1088.7 | learning rate: 1.538E-05 | global batch size:    48 | lm loss: 5.203186E+00 | loss scale: 32768.0 | grad norm: 1.858 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      997/    1200 | consumed samples:        47856 | elapsed time per iteration (ms): 1145.5 | learning rate: 1.540E-05 | global batch size:    48 | lm loss: 5.360290E+00 | loss scale: 32768.0 | grad norm: 2.033 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      998/    1200 | consumed samples:        47904 | elapsed time per iteration (ms): 1108.5 | learning rate: 1.541E-05 | global batch size:    48 | lm loss: 5.257024E+00 | loss scale: 32768.0 | grad norm: 2.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      999/    1200 | consumed samples:        47952 | elapsed time per iteration (ms): 1109.6 | learning rate: 1.543E-05 | global batch size:    48 | lm loss: 5.257386E+00 | loss scale: 32768.0 | grad norm: 1.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1000/    1200 | consumed samples:        48000 | elapsed time per iteration (ms): 1151.3 | learning rate: 1.545E-05 | global batch size:    48 | lm loss: 5.303419E+00 | loss scale: 32768.0 | grad norm: 1.868 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1001/    1200 | consumed samples:        48048 | elapsed time per iteration (ms): 1311.7 | learning rate: 1.546E-05 | global batch size:    48 | lm loss: 5.249746E+00 | loss scale: 32768.0 | grad norm: 1.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1002/    1200 | consumed samples:        48096 | elapsed time per iteration (ms): 1492.4 | learning rate: 1.548E-05 | global batch size:    48 | lm loss: 5.203670E+00 | loss scale: 32768.0 | grad norm: 1.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1003/    1200 | consumed samples:        48144 | elapsed time per iteration (ms): 1300.7 | learning rate: 1.549E-05 | global batch size:    48 | lm loss: 5.240518E+00 | loss scale: 32768.0 | grad norm: 1.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1004/    1200 | consumed samples:        48192 | elapsed time per iteration (ms): 1187.0 | learning rate: 1.551E-05 | global batch size:    48 | lm loss: 5.250306E+00 | loss scale: 32768.0 | grad norm: 1.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1005/    1200 | consumed samples:        48240 | elapsed time per iteration (ms): 1027.8 | learning rate: 1.552E-05 | global batch size:    48 | lm loss: 5.246065E+00 | loss scale: 32768.0 | grad norm: 1.942 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1006/    1200 | consumed samples:        48288 | elapsed time per iteration (ms): 1218.3 | learning rate: 1.554E-05 | global batch size:    48 | lm loss: 5.261241E+00 | loss scale: 32768.0 | grad norm: 1.905 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1007/    1200 | consumed samples:        48336 | elapsed time per iteration (ms): 1232.3 | learning rate: 1.556E-05 | global batch size:    48 | lm loss: 5.311317E+00 | loss scale: 32768.0 | grad norm: 1.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1008/    1200 | consumed samples:        48384 | elapsed time per iteration (ms): 1189.2 | learning rate: 1.557E-05 | global batch size:    48 | lm loss: 5.279305E+00 | loss scale: 32768.0 | grad norm: 1.957 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1009/    1200 | consumed samples:        48432 | elapsed time per iteration (ms): 1405.8 | learning rate: 1.559E-05 | global batch size:    48 | lm loss: 5.284955E+00 | loss scale: 32768.0 | grad norm: 1.818 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1010/    1200 | consumed samples:        48480 | elapsed time per iteration (ms): 1346.4 | learning rate: 1.560E-05 | global batch size:    48 | lm loss: 5.213619E+00 | loss scale: 32768.0 | grad norm: 1.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1011/    1200 | consumed samples:        48528 | elapsed time per iteration (ms): 1422.1 | learning rate: 1.562E-05 | global batch size:    48 | lm loss: 5.193797E+00 | loss scale: 32768.0 | grad norm: 1.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1012/    1200 | consumed samples:        48576 | elapsed time per iteration (ms): 1105.9 | learning rate: 1.563E-05 | global batch size:    48 | lm loss: 5.294280E+00 | loss scale: 32768.0 | grad norm: 1.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1013/    1200 | consumed samples:        48624 | elapsed time per iteration (ms): 1297.1 | learning rate: 1.565E-05 | global batch size:    48 | lm loss: 5.256775E+00 | loss scale: 32768.0 | grad norm: 1.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1014/    1200 | consumed samples:        48672 | elapsed time per iteration (ms): 1026.0 | learning rate: 1.567E-05 | global batch size:    48 | lm loss: 5.229557E+00 | loss scale: 32768.0 | grad norm: 1.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1015/    1200 | consumed samples:        48720 | elapsed time per iteration (ms): 1206.6 | learning rate: 1.568E-05 | global batch size:    48 | lm loss: 5.252547E+00 | loss scale: 32768.0 | grad norm: 1.830 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1016/    1200 | consumed samples:        48768 | elapsed time per iteration (ms): 1293.6 | learning rate: 1.570E-05 | global batch size:    48 | lm loss: 5.325073E+00 | loss scale: 32768.0 | grad norm: 1.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1017/    1200 | consumed samples:        48816 | elapsed time per iteration (ms): 1135.9 | learning rate: 1.571E-05 | global batch size:    48 | lm loss: 5.190529E+00 | loss scale: 32768.0 | grad norm: 1.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1018/    1200 | consumed samples:        48864 | elapsed time per iteration (ms): 1287.5 | learning rate: 1.573E-05 | global batch size:    48 | lm loss: 5.233419E+00 | loss scale: 32768.0 | grad norm: 1.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1019/    1200 | consumed samples:        48912 | elapsed time per iteration (ms): 1236.3 | learning rate: 1.574E-05 | global batch size:    48 | lm loss: 5.387687E+00 | loss scale: 32768.0 | grad norm: 1.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1020/    1200 | consumed samples:        48960 | elapsed time per iteration (ms): 1281.0 | learning rate: 1.576E-05 | global batch size:    48 | lm loss: 5.218439E+00 | loss scale: 32768.0 | grad norm: 1.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1021/    1200 | consumed samples:        49008 | elapsed time per iteration (ms): 1186.2 | learning rate: 1.578E-05 | global batch size:    48 | lm loss: 5.310602E+00 | loss scale: 32768.0 | grad norm: 1.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1022/    1200 | consumed samples:        49056 | elapsed time per iteration (ms): 1125.9 | learning rate: 1.579E-05 | global batch size:    48 | lm loss: 5.184072E+00 | loss scale: 32768.0 | grad norm: 1.793 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1023/    1200 | consumed samples:        49104 | elapsed time per iteration (ms): 1263.6 | learning rate: 1.581E-05 | global batch size:    48 | lm loss: 5.249812E+00 | loss scale: 65536.0 | grad norm: 1.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1024/    1200 | consumed samples:        49152 | elapsed time per iteration (ms): 1262.7 | learning rate: 1.582E-05 | global batch size:    48 | lm loss: 5.306619E+00 | loss scale: 65536.0 | grad norm: 1.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1025/    1200 | consumed samples:        49200 | elapsed time per iteration (ms): 1217.8 | learning rate: 1.584E-05 | global batch size:    48 | lm loss: 5.236625E+00 | loss scale: 65536.0 | grad norm: 1.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1026/    1200 | consumed samples:        49248 | elapsed time per iteration (ms): 1226.1 | learning rate: 1.585E-05 | global batch size:    48 | lm loss: 5.264395E+00 | loss scale: 65536.0 | grad norm: 1.799 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1027/    1200 | consumed samples:        49296 | elapsed time per iteration (ms): 1312.9 | learning rate: 1.587E-05 | global batch size:    48 | lm loss: 5.273537E+00 | loss scale: 65536.0 | grad norm: 1.741 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1028/    1200 | consumed samples:        49344 | elapsed time per iteration (ms): 1260.8 | learning rate: 1.589E-05 | global batch size:    48 | lm loss: 5.139912E+00 | loss scale: 65536.0 | grad norm: 1.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1029/    1200 | consumed samples:        49392 | elapsed time per iteration (ms): 1310.8 | learning rate: 1.590E-05 | global batch size:    48 | lm loss: 5.416408E+00 | loss scale: 65536.0 | grad norm: 1.852 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1030/    1200 | consumed samples:        49440 | elapsed time per iteration (ms): 1111.4 | learning rate: 1.592E-05 | global batch size:    48 | lm loss: 5.254686E+00 | loss scale: 65536.0 | grad norm: 1.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1031/    1200 | consumed samples:        49488 | elapsed time per iteration (ms): 2341.4 | learning rate: 1.593E-05 | global batch size:    48 | lm loss: 6.156738E+00 | loss scale: 65536.0 | grad norm: 1.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1032/    1200 | consumed samples:        49536 | elapsed time per iteration (ms): 1791.5 | learning rate: 1.595E-05 | global batch size:    48 | lm loss: 6.155145E+00 | loss scale: 65536.0 | grad norm: 1.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1033/    1200 | consumed samples:        49584 | elapsed time per iteration (ms): 2120.9 | learning rate: 1.596E-05 | global batch size:    48 | lm loss: 6.153780E+00 | loss scale: 65536.0 | grad norm: 1.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1034/    1200 | consumed samples:        49632 | elapsed time per iteration (ms): 1883.1 | learning rate: 1.598E-05 | global batch size:    48 | lm loss: 6.152433E+00 | loss scale: 65536.0 | grad norm: 1.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1035/    1200 | consumed samples:        49680 | elapsed time per iteration (ms): 1958.4 | learning rate: 1.600E-05 | global batch size:    48 | lm loss: 6.150931E+00 | loss scale: 65536.0 | grad norm: 1.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1036/    1200 | consumed samples:        49728 | elapsed time per iteration (ms): 1994.1 | learning rate: 1.601E-05 | global batch size:    48 | lm loss: 6.149582E+00 | loss scale: 65536.0 | grad norm: 1.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1037/    1200 | consumed samples:        49776 | elapsed time per iteration (ms): 1872.9 | learning rate: 1.603E-05 | global batch size:    48 | lm loss: 6.148314E+00 | loss scale: 65536.0 | grad norm: 1.784 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1038/    1200 | consumed samples:        49824 | elapsed time per iteration (ms): 1706.7 | learning rate: 1.604E-05 | global batch size:    48 | lm loss: 6.146810E+00 | loss scale: 65536.0 | grad norm: 1.771 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1039/    1200 | consumed samples:        49872 | elapsed time per iteration (ms): 2125.7 | learning rate: 1.606E-05 | global batch size:    48 | lm loss: 6.145387E+00 | loss scale: 65536.0 | grad norm: 1.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1040/    1200 | consumed samples:        49920 | elapsed time per iteration (ms): 1664.0 | learning rate: 1.607E-05 | global batch size:    48 | lm loss: 6.143949E+00 | loss scale: 65536.0 | grad norm: 1.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1041/    1200 | consumed samples:        49968 | elapsed time per iteration (ms): 2171.2 | learning rate: 1.609E-05 | global batch size:    48 | lm loss: 6.142527E+00 | loss scale: 65536.0 | grad norm: 1.959 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1042/    1200 | consumed samples:        50016 | elapsed time per iteration (ms): 2075.0 | learning rate: 1.611E-05 | global batch size:    48 | lm loss: 6.141274E+00 | loss scale: 65536.0 | grad norm: 1.743 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1043/    1200 | consumed samples:        50064 | elapsed time per iteration (ms): 1739.3 | learning rate: 1.612E-05 | global batch size:    48 | lm loss: 6.139878E+00 | loss scale: 65536.0 | grad norm: 2.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1044/    1200 | consumed samples:        50112 | elapsed time per iteration (ms): 2054.5 | learning rate: 1.614E-05 | global batch size:    48 | lm loss: 6.138664E+00 | loss scale: 65536.0 | grad norm: 1.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1045/    1200 | consumed samples:        50160 | elapsed time per iteration (ms): 1934.7 | learning rate: 1.615E-05 | global batch size:    48 | lm loss: 6.137231E+00 | loss scale: 65536.0 | grad norm: 1.750 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1046/    1200 | consumed samples:        50208 | elapsed time per iteration (ms): 1814.2 | learning rate: 1.617E-05 | global batch size:    48 | lm loss: 6.135765E+00 | loss scale: 65536.0 | grad norm: 1.783 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1047/    1200 | consumed samples:        50256 | elapsed time per iteration (ms): 2026.2 | learning rate: 1.618E-05 | global batch size:    48 | lm loss: 6.134554E+00 | loss scale: 65536.0 | grad norm: 1.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1048/    1200 | consumed samples:        50304 | elapsed time per iteration (ms): 1808.9 | learning rate: 1.620E-05 | global batch size:    48 | lm loss: 6.133152E+00 | loss scale: 65536.0 | grad norm: 1.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1049/    1200 | consumed samples:        50352 | elapsed time per iteration (ms): 1836.3 | learning rate: 1.622E-05 | global batch size:    48 | lm loss: 6.131772E+00 | loss scale: 65536.0 | grad norm: 1.786 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1050/    1200 | consumed samples:        50400 | elapsed time per iteration (ms): 2244.2 | learning rate: 1.623E-05 | global batch size:    48 | lm loss: 6.130293E+00 | loss scale: 65536.0 | grad norm: 1.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1051/    1200 | consumed samples:        50448 | elapsed time per iteration (ms): 1777.1 | learning rate: 1.625E-05 | global batch size:    48 | lm loss: 6.128927E+00 | loss scale: 65536.0 | grad norm: 1.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1052/    1200 | consumed samples:        50496 | elapsed time per iteration (ms): 1868.9 | learning rate: 1.626E-05 | global batch size:    48 | lm loss: 6.127700E+00 | loss scale: 65536.0 | grad norm: 1.827 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1053/    1200 | consumed samples:        50544 | elapsed time per iteration (ms): 1797.5 | learning rate: 1.628E-05 | global batch size:    48 | lm loss: 6.126346E+00 | loss scale: 65536.0 | grad norm: 1.956 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1054/    1200 | consumed samples:        50592 | elapsed time per iteration (ms): 2061.6 | learning rate: 1.629E-05 | global batch size:    48 | lm loss: 6.124931E+00 | loss scale: 65536.0 | grad norm: 1.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1055/    1200 | consumed samples:        50640 | elapsed time per iteration (ms): 1883.4 | learning rate: 1.631E-05 | global batch size:    48 | lm loss: 6.123424E+00 | loss scale: 65536.0 | grad norm: 1.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1056/    1200 | consumed samples:        50688 | elapsed time per iteration (ms): 1986.4 | learning rate: 1.633E-05 | global batch size:    48 | lm loss: 6.122171E+00 | loss scale: 65536.0 | grad norm: 1.882 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1057/    1200 | consumed samples:        50736 | elapsed time per iteration (ms): 1946.5 | learning rate: 1.634E-05 | global batch size:    48 | lm loss: 6.120878E+00 | loss scale: 65536.0 | grad norm: 1.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1058/    1200 | consumed samples:        50784 | elapsed time per iteration (ms): 1672.2 | learning rate: 1.636E-05 | global batch size:    48 | lm loss: 6.119429E+00 | loss scale: 65536.0 | grad norm: 1.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1059/    1200 | consumed samples:        50832 | elapsed time per iteration (ms): 1808.6 | learning rate: 1.637E-05 | global batch size:    48 | lm loss: 6.118114E+00 | loss scale: 65536.0 | grad norm: 1.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1060/    1200 | consumed samples:        50880 | elapsed time per iteration (ms): 1557.1 | learning rate: 1.639E-05 | global batch size:    48 | lm loss: 6.116702E+00 | loss scale: 65536.0 | grad norm: 1.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1061/    1200 | consumed samples:        50928 | elapsed time per iteration (ms): 2005.3 | learning rate: 1.641E-05 | global batch size:    48 | lm loss: 6.115320E+00 | loss scale: 65536.0 | grad norm: 1.837 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1062/    1200 | consumed samples:        50976 | elapsed time per iteration (ms): 1747.4 | learning rate: 1.642E-05 | global batch size:    48 | lm loss: 6.113969E+00 | loss scale: 65536.0 | grad norm: 1.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1063/    1200 | consumed samples:        51024 | elapsed time per iteration (ms): 1729.5 | learning rate: 1.644E-05 | global batch size:    48 | lm loss: 6.112669E+00 | loss scale: 65536.0 | grad norm: 1.730 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1064/    1200 | consumed samples:        51072 | elapsed time per iteration (ms): 2109.7 | learning rate: 1.645E-05 | global batch size:    48 | lm loss: 6.111428E+00 | loss scale: 65536.0 | grad norm: 1.833 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1065/    1200 | consumed samples:        51120 | elapsed time per iteration (ms): 1777.8 | learning rate: 1.647E-05 | global batch size:    48 | lm loss: 6.110095E+00 | loss scale: 65536.0 | grad norm: 1.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1066/    1200 | consumed samples:        51168 | elapsed time per iteration (ms): 2100.5 | learning rate: 1.648E-05 | global batch size:    48 | lm loss: 6.108942E+00 | loss scale: 65536.0 | grad norm: 1.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1067/    1200 | consumed samples:        51216 | elapsed time per iteration (ms): 1861.6 | learning rate: 1.650E-05 | global batch size:    48 | lm loss: 6.107704E+00 | loss scale: 65536.0 | grad norm: 1.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1068/    1200 | consumed samples:        51264 | elapsed time per iteration (ms): 2037.3 | learning rate: 1.652E-05 | global batch size:    48 | lm loss: 6.106349E+00 | loss scale: 65536.0 | grad norm: 1.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1069/    1200 | consumed samples:        51312 | elapsed time per iteration (ms): 1943.6 | learning rate: 1.653E-05 | global batch size:    48 | lm loss: 6.104887E+00 | loss scale: 65536.0 | grad norm: 1.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1070/    1200 | consumed samples:        51360 | elapsed time per iteration (ms): 1916.7 | learning rate: 1.655E-05 | global batch size:    48 | lm loss: 6.103670E+00 | loss scale: 65536.0 | grad norm: 1.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1071/    1200 | consumed samples:        51408 | elapsed time per iteration (ms): 1842.9 | learning rate: 1.656E-05 | global batch size:    48 | lm loss: 6.102491E+00 | loss scale: 65536.0 | grad norm: 1.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1072/    1200 | consumed samples:        51456 | elapsed time per iteration (ms): 1773.6 | learning rate: 1.658E-05 | global batch size:    48 | lm loss: 6.101201E+00 | loss scale: 65536.0 | grad norm: 1.727 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1073/    1200 | consumed samples:        51504 | elapsed time per iteration (ms): 1683.0 | learning rate: 1.659E-05 | global batch size:    48 | lm loss: 6.099904E+00 | loss scale: 65536.0 | grad norm: 1.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1074/    1200 | consumed samples:        51552 | elapsed time per iteration (ms): 1709.2 | learning rate: 1.661E-05 | global batch size:    48 | lm loss: 6.098589E+00 | loss scale: 65536.0 | grad norm: 1.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1075/    1200 | consumed samples:        51600 | elapsed time per iteration (ms): 1975.2 | learning rate: 1.663E-05 | global batch size:    48 | lm loss: 6.097322E+00 | loss scale: 65536.0 | grad norm: 1.778 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1076/    1200 | consumed samples:        51648 | elapsed time per iteration (ms): 1635.7 | learning rate: 1.664E-05 | global batch size:    48 | lm loss: 6.096155E+00 | loss scale: 65536.0 | grad norm: 1.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1077/    1200 | consumed samples:        51696 | elapsed time per iteration (ms): 2206.5 | learning rate: 1.666E-05 | global batch size:    48 | lm loss: 6.094884E+00 | loss scale: 65536.0 | grad norm: 1.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1078/    1200 | consumed samples:        51744 | elapsed time per iteration (ms): 1778.3 | learning rate: 1.667E-05 | global batch size:    48 | lm loss: 6.093644E+00 | loss scale: 65536.0 | grad norm: 1.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1079/    1200 | consumed samples:        51792 | elapsed time per iteration (ms): 1731.3 | learning rate: 1.669E-05 | global batch size:    48 | lm loss: 6.092380E+00 | loss scale: 65536.0 | grad norm: 1.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1080/    1200 | consumed samples:        51840 | elapsed time per iteration (ms): 2068.5 | learning rate: 1.670E-05 | global batch size:    48 | lm loss: 6.091260E+00 | loss scale: 65536.0 | grad norm: 1.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1081/    1200 | consumed samples:        51888 | elapsed time per iteration (ms): 1753.6 | learning rate: 1.672E-05 | global batch size:    48 | lm loss: 6.090018E+00 | loss scale: 65536.0 | grad norm: 1.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1082/    1200 | consumed samples:        51936 | elapsed time per iteration (ms): 1898.1 | learning rate: 1.674E-05 | global batch size:    48 | lm loss: 6.088802E+00 | loss scale: 65536.0 | grad norm: 1.739 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1083/    1200 | consumed samples:        51984 | elapsed time per iteration (ms): 2082.9 | learning rate: 1.675E-05 | global batch size:    48 | lm loss: 6.087563E+00 | loss scale: 65536.0 | grad norm: 1.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1084/    1200 | consumed samples:        52032 | elapsed time per iteration (ms): 1908.4 | learning rate: 1.677E-05 | global batch size:    48 | lm loss: 6.086160E+00 | loss scale: 65536.0 | grad norm: 1.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1085/    1200 | consumed samples:        52080 | elapsed time per iteration (ms): 1819.6 | learning rate: 1.678E-05 | global batch size:    48 | lm loss: 6.084872E+00 | loss scale: 65536.0 | grad norm: 1.716 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1086/    1200 | consumed samples:        52128 | elapsed time per iteration (ms): 1860.1 | learning rate: 1.680E-05 | global batch size:    48 | lm loss: 6.083634E+00 | loss scale: 65536.0 | grad norm: 1.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1087/    1200 | consumed samples:        52176 | elapsed time per iteration (ms): 1881.3 | learning rate: 1.681E-05 | global batch size:    48 | lm loss: 6.082472E+00 | loss scale: 65536.0 | grad norm: 1.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1088/    1200 | consumed samples:        52224 | elapsed time per iteration (ms): 1936.8 | learning rate: 1.683E-05 | global batch size:    48 | lm loss: 6.081200E+00 | loss scale: 65536.0 | grad norm: 1.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1089/    1200 | consumed samples:        52272 | elapsed time per iteration (ms): 2040.5 | learning rate: 1.685E-05 | global batch size:    48 | lm loss: 6.079875E+00 | loss scale: 65536.0 | grad norm: 1.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1090/    1200 | consumed samples:        52320 | elapsed time per iteration (ms): 1979.0 | learning rate: 1.686E-05 | global batch size:    48 | lm loss: 6.078640E+00 | loss scale: 65536.0 | grad norm: 1.776 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1091/    1200 | consumed samples:        52368 | elapsed time per iteration (ms): 1730.8 | learning rate: 1.688E-05 | global batch size:    48 | lm loss: 6.077368E+00 | loss scale: 65536.0 | grad norm: 1.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1092/    1200 | consumed samples:        52416 | elapsed time per iteration (ms): 1957.4 | learning rate: 1.689E-05 | global batch size:    48 | lm loss: 6.076046E+00 | loss scale: 65536.0 | grad norm: 1.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1093/    1200 | consumed samples:        52464 | elapsed time per iteration (ms): 1754.9 | learning rate: 1.691E-05 | global batch size:    48 | lm loss: 6.074818E+00 | loss scale: 65536.0 | grad norm: 1.633 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1094/    1200 | consumed samples:        52512 | elapsed time per iteration (ms): 2050.9 | learning rate: 1.692E-05 | global batch size:    48 | lm loss: 6.073607E+00 | loss scale: 65536.0 | grad norm: 1.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1095/    1200 | consumed samples:        52560 | elapsed time per iteration (ms): 1780.5 | learning rate: 1.694E-05 | global batch size:    48 | lm loss: 6.072312E+00 | loss scale: 65536.0 | grad norm: 1.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1096/    1200 | consumed samples:        52608 | elapsed time per iteration (ms): 1757.5 | learning rate: 1.696E-05 | global batch size:    48 | lm loss: 6.071108E+00 | loss scale: 65536.0 | grad norm: 1.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1097/    1200 | consumed samples:        52656 | elapsed time per iteration (ms): 2501.6 | learning rate: 1.697E-05 | global batch size:    48 | lm loss: 6.069928E+00 | loss scale: 65536.0 | grad norm: 1.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1098/    1200 | consumed samples:        52704 | elapsed time per iteration (ms): 1964.7 | learning rate: 1.699E-05 | global batch size:    48 | lm loss: 6.068729E+00 | loss scale: 65536.0 | grad norm: 1.572 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1099/    1200 | consumed samples:        52752 | elapsed time per iteration (ms): 2038.3 | learning rate: 1.700E-05 | global batch size:    48 | lm loss: 6.067514E+00 | loss scale: 65536.0 | grad norm: 1.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1100/    1200 | consumed samples:        52800 | elapsed time per iteration (ms): 1899.6 | learning rate: 1.702E-05 | global batch size:    48 | lm loss: 6.066246E+00 | loss scale: 65536.0 | grad norm: 1.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1101/    1200 | consumed samples:        52848 | elapsed time per iteration (ms): 1836.8 | learning rate: 1.703E-05 | global batch size:    48 | lm loss: 6.065003E+00 | loss scale: 65536.0 | grad norm: 1.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1102/    1200 | consumed samples:        52896 | elapsed time per iteration (ms): 1899.7 | learning rate: 1.705E-05 | global batch size:    48 | lm loss: 6.063784E+00 | loss scale: 65536.0 | grad norm: 1.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1103/    1200 | consumed samples:        52944 | elapsed time per iteration (ms): 1697.6 | learning rate: 1.707E-05 | global batch size:    48 | lm loss: 6.062601E+00 | loss scale: 65536.0 | grad norm: 1.647 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1104/    1200 | consumed samples:        52992 | elapsed time per iteration (ms): 2084.0 | learning rate: 1.708E-05 | global batch size:    48 | lm loss: 6.061437E+00 | loss scale: 65536.0 | grad norm: 1.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1105/    1200 | consumed samples:        53040 | elapsed time per iteration (ms): 1903.2 | learning rate: 1.710E-05 | global batch size:    48 | lm loss: 6.060225E+00 | loss scale: 65536.0 | grad norm: 1.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1106/    1200 | consumed samples:        53088 | elapsed time per iteration (ms): 2029.7 | learning rate: 1.711E-05 | global batch size:    48 | lm loss: 6.058904E+00 | loss scale: 65536.0 | grad norm: 1.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1107/    1200 | consumed samples:        53136 | elapsed time per iteration (ms): 1747.9 | learning rate: 1.713E-05 | global batch size:    48 | lm loss: 6.057499E+00 | loss scale: 65536.0 | grad norm: 1.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1108/    1200 | consumed samples:        53184 | elapsed time per iteration (ms): 2033.6 | learning rate: 1.714E-05 | global batch size:    48 | lm loss: 6.056337E+00 | loss scale: 65536.0 | grad norm: 1.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1109/    1200 | consumed samples:        53232 | elapsed time per iteration (ms): 1817.9 | learning rate: 1.716E-05 | global batch size:    48 | lm loss: 6.055073E+00 | loss scale: 65536.0 | grad norm: 1.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1110/    1200 | consumed samples:        53280 | elapsed time per iteration (ms): 1777.4 | learning rate: 1.718E-05 | global batch size:    48 | lm loss: 6.053781E+00 | loss scale: 65536.0 | grad norm: 1.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1111/    1200 | consumed samples:        53328 | elapsed time per iteration (ms): 1830.0 | learning rate: 1.719E-05 | global batch size:    48 | lm loss: 6.052579E+00 | loss scale: 65536.0 | grad norm: 1.668 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1112/    1200 | consumed samples:        53376 | elapsed time per iteration (ms): 2460.7 | learning rate: 1.721E-05 | global batch size:    48 | lm loss: 6.051314E+00 | loss scale: 65536.0 | grad norm: 1.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1113/    1200 | consumed samples:        53424 | elapsed time per iteration (ms): 1984.2 | learning rate: 1.722E-05 | global batch size:    48 | lm loss: 6.050101E+00 | loss scale: 65536.0 | grad norm: 1.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1114/    1200 | consumed samples:        53472 | elapsed time per iteration (ms): 1927.0 | learning rate: 1.724E-05 | global batch size:    48 | lm loss: 6.048693E+00 | loss scale: 65536.0 | grad norm: 1.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1115/    1200 | consumed samples:        53520 | elapsed time per iteration (ms): 1633.7 | learning rate: 1.725E-05 | global batch size:    48 | lm loss: 6.047493E+00 | loss scale: 65536.0 | grad norm: 1.721 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1116/    1200 | consumed samples:        53568 | elapsed time per iteration (ms): 1739.5 | learning rate: 1.727E-05 | global batch size:    48 | lm loss: 6.046340E+00 | loss scale: 65536.0 | grad norm: 1.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1117/    1200 | consumed samples:        53616 | elapsed time per iteration (ms): 1695.9 | learning rate: 1.729E-05 | global batch size:    48 | lm loss: 6.045114E+00 | loss scale: 65536.0 | grad norm: 1.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1118/    1200 | consumed samples:        53664 | elapsed time per iteration (ms): 1979.0 | learning rate: 1.730E-05 | global batch size:    48 | lm loss: 6.044002E+00 | loss scale: 65536.0 | grad norm: 1.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1119/    1200 | consumed samples:        53712 | elapsed time per iteration (ms): 2238.6 | learning rate: 1.732E-05 | global batch size:    48 | lm loss: 6.042719E+00 | loss scale: 65536.0 | grad norm: 1.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1120/    1200 | consumed samples:        53760 | elapsed time per iteration (ms): 1876.3 | learning rate: 1.733E-05 | global batch size:    48 | lm loss: 6.041658E+00 | loss scale: 65536.0 | grad norm: 1.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1121/    1200 | consumed samples:        53808 | elapsed time per iteration (ms): 1858.2 | learning rate: 1.735E-05 | global batch size:    48 | lm loss: 6.040450E+00 | loss scale: 65536.0 | grad norm: 1.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1122/    1200 | consumed samples:        53856 | elapsed time per iteration (ms): 1876.8 | learning rate: 1.736E-05 | global batch size:    48 | lm loss: 6.039314E+00 | loss scale: 65536.0 | grad norm: 1.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1123/    1200 | consumed samples:        53904 | elapsed time per iteration (ms): 1631.6 | learning rate: 1.738E-05 | global batch size:    48 | lm loss: 6.038202E+00 | loss scale: 65536.0 | grad norm: 1.587 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1124/    1200 | consumed samples:        53952 | elapsed time per iteration (ms): 1647.0 | learning rate: 1.740E-05 | global batch size:    48 | lm loss: 6.036906E+00 | loss scale: 65536.0 | grad norm: 1.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1125/    1200 | consumed samples:        54000 | elapsed time per iteration (ms): 2160.9 | learning rate: 1.741E-05 | global batch size:    48 | lm loss: 6.035593E+00 | loss scale: 65536.0 | grad norm: 1.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1126/    1200 | consumed samples:        54048 | elapsed time per iteration (ms): 2286.3 | learning rate: 1.743E-05 | global batch size:    48 | lm loss: 6.034328E+00 | loss scale: 65536.0 | grad norm: 1.629 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1127/    1200 | consumed samples:        54096 | elapsed time per iteration (ms): 1883.1 | learning rate: 1.744E-05 | global batch size:    48 | lm loss: 6.033194E+00 | loss scale: 65536.0 | grad norm: 1.689 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1128/    1200 | consumed samples:        54144 | elapsed time per iteration (ms): 1935.4 | learning rate: 1.746E-05 | global batch size:    48 | lm loss: 6.031958E+00 | loss scale: 65536.0 | grad norm: 1.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1129/    1200 | consumed samples:        54192 | elapsed time per iteration (ms): 1724.6 | learning rate: 1.747E-05 | global batch size:    48 | lm loss: 6.030787E+00 | loss scale: 65536.0 | grad norm: 1.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1130/    1200 | consumed samples:        54240 | elapsed time per iteration (ms): 1761.7 | learning rate: 1.749E-05 | global batch size:    48 | lm loss: 6.029659E+00 | loss scale: 65536.0 | grad norm: 1.575 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1131/    1200 | consumed samples:        54288 | elapsed time per iteration (ms): 1807.0 | learning rate: 1.751E-05 | global batch size:    48 | lm loss: 6.028879E+00 | loss scale: 65536.0 | grad norm: 2.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1132/    1200 | consumed samples:        54336 | elapsed time per iteration (ms): 1666.0 | learning rate: 1.752E-05 | global batch size:    48 | lm loss: 6.027755E+00 | loss scale: 65536.0 | grad norm: 1.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1133/    1200 | consumed samples:        54384 | elapsed time per iteration (ms): 1782.8 | learning rate: 1.754E-05 | global batch size:    48 | lm loss: 6.026759E+00 | loss scale: 65536.0 | grad norm: 1.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1134/    1200 | consumed samples:        54432 | elapsed time per iteration (ms): 2097.2 | learning rate: 1.755E-05 | global batch size:    48 | lm loss: 6.025559E+00 | loss scale: 65536.0 | grad norm: 1.674 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1135/    1200 | consumed samples:        54480 | elapsed time per iteration (ms): 2241.4 | learning rate: 1.757E-05 | global batch size:    48 | lm loss: 6.024434E+00 | loss scale: 65536.0 | grad norm: 1.678 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1136/    1200 | consumed samples:        54528 | elapsed time per iteration (ms): 1939.1 | learning rate: 1.758E-05 | global batch size:    48 | lm loss: 6.023333E+00 | loss scale: 65536.0 | grad norm: 1.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1137/    1200 | consumed samples:        54576 | elapsed time per iteration (ms): 2143.6 | learning rate: 1.760E-05 | global batch size:    48 | lm loss: 6.021940E+00 | loss scale: 65536.0 | grad norm: 1.577 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1138/    1200 | consumed samples:        54624 | elapsed time per iteration (ms): 2124.1 | learning rate: 1.762E-05 | global batch size:    48 | lm loss: 6.020671E+00 | loss scale: 65536.0 | grad norm: 1.580 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1139/    1200 | consumed samples:        54672 | elapsed time per iteration (ms): 1702.1 | learning rate: 1.763E-05 | global batch size:    48 | lm loss: 6.019393E+00 | loss scale: 65536.0 | grad norm: 1.542 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1140/    1200 | consumed samples:        54720 | elapsed time per iteration (ms): 2139.6 | learning rate: 1.765E-05 | global batch size:    48 | lm loss: 6.018224E+00 | loss scale: 65536.0 | grad norm: 1.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1141/    1200 | consumed samples:        54768 | elapsed time per iteration (ms): 1810.0 | learning rate: 1.766E-05 | global batch size:    48 | lm loss: 6.016932E+00 | loss scale: 65536.0 | grad norm: 1.589 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1142/    1200 | consumed samples:        54816 | elapsed time per iteration (ms): 1910.3 | learning rate: 1.768E-05 | global batch size:    48 | lm loss: 6.015895E+00 | loss scale: 65536.0 | grad norm: 1.610 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1143/    1200 | consumed samples:        54864 | elapsed time per iteration (ms): 1822.6 | learning rate: 1.769E-05 | global batch size:    48 | lm loss: 6.014716E+00 | loss scale: 65536.0 | grad norm: 1.681 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1144/    1200 | consumed samples:        54912 | elapsed time per iteration (ms): 1965.5 | learning rate: 1.771E-05 | global batch size:    48 | lm loss: 6.013615E+00 | loss scale: 65536.0 | grad norm: 1.626 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1145/    1200 | consumed samples:        54960 | elapsed time per iteration (ms): 1846.8 | learning rate: 1.773E-05 | global batch size:    48 | lm loss: 6.012569E+00 | loss scale: 65536.0 | grad norm: 1.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1146/    1200 | consumed samples:        55008 | elapsed time per iteration (ms): 1712.0 | learning rate: 1.774E-05 | global batch size:    48 | lm loss: 6.011337E+00 | loss scale: 65536.0 | grad norm: 1.571 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1147/    1200 | consumed samples:        55056 | elapsed time per iteration (ms): 1817.8 | learning rate: 1.776E-05 | global batch size:    48 | lm loss: 6.010101E+00 | loss scale: 65536.0 | grad norm: 1.577 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1148/    1200 | consumed samples:        55104 | elapsed time per iteration (ms): 2165.2 | learning rate: 1.777E-05 | global batch size:    48 | lm loss: 6.009083E+00 | loss scale: 65536.0 | grad norm: 1.583 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1149/    1200 | consumed samples:        55152 | elapsed time per iteration (ms): 2092.5 | learning rate: 1.779E-05 | global batch size:    48 | lm loss: 6.007976E+00 | loss scale: 65536.0 | grad norm: 1.522 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1150/    1200 | consumed samples:        55200 | elapsed time per iteration (ms): 1939.2 | learning rate: 1.780E-05 | global batch size:    48 | lm loss: 6.006823E+00 | loss scale: 65536.0 | grad norm: 1.591 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1151/    1200 | consumed samples:        55248 | elapsed time per iteration (ms): 1808.7 | learning rate: 1.782E-05 | global batch size:    48 | lm loss: 6.005670E+00 | loss scale: 65536.0 | grad norm: 1.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1152/    1200 | consumed samples:        55296 | elapsed time per iteration (ms): 1862.6 | learning rate: 1.784E-05 | global batch size:    48 | lm loss: 6.004642E+00 | loss scale: 65536.0 | grad norm: 1.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1153/    1200 | consumed samples:        55344 | elapsed time per iteration (ms): 1902.9 | learning rate: 1.785E-05 | global batch size:    48 | lm loss: 6.003549E+00 | loss scale: 65536.0 | grad norm: 1.582 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1154/    1200 | consumed samples:        55392 | elapsed time per iteration (ms): 1714.1 | learning rate: 1.787E-05 | global batch size:    48 | lm loss: 6.002497E+00 | loss scale: 65536.0 | grad norm: 1.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1155/    1200 | consumed samples:        55440 | elapsed time per iteration (ms): 2289.6 | learning rate: 1.788E-05 | global batch size:    48 | lm loss: 6.001359E+00 | loss scale: 65536.0 | grad norm: 1.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1156/    1200 | consumed samples:        55488 | elapsed time per iteration (ms): 1859.2 | learning rate: 1.790E-05 | global batch size:    48 | lm loss: 6.000141E+00 | loss scale: 65536.0 | grad norm: 1.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1157/    1200 | consumed samples:        55536 | elapsed time per iteration (ms): 1724.4 | learning rate: 1.791E-05 | global batch size:    48 | lm loss: 5.999138E+00 | loss scale: 65536.0 | grad norm: 1.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1158/    1200 | consumed samples:        55584 | elapsed time per iteration (ms): 1875.0 | learning rate: 1.793E-05 | global batch size:    48 | lm loss: 5.997971E+00 | loss scale: 65536.0 | grad norm: 1.556 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1159/    1200 | consumed samples:        55632 | elapsed time per iteration (ms): 1941.0 | learning rate: 1.795E-05 | global batch size:    48 | lm loss: 5.996783E+00 | loss scale: 65536.0 | grad norm: 1.555 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1160/    1200 | consumed samples:        55680 | elapsed time per iteration (ms): 1921.9 | learning rate: 1.796E-05 | global batch size:    48 | lm loss: 5.995717E+00 | loss scale: 65536.0 | grad norm: 1.597 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1161/    1200 | consumed samples:        55728 | elapsed time per iteration (ms): 1855.1 | learning rate: 1.798E-05 | global batch size:    48 | lm loss: 5.994577E+00 | loss scale: 65536.0 | grad norm: 1.537 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1162/    1200 | consumed samples:        55776 | elapsed time per iteration (ms): 2187.2 | learning rate: 1.799E-05 | global batch size:    48 | lm loss: 5.993525E+00 | loss scale: 65536.0 | grad norm: 1.610 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1163/    1200 | consumed samples:        55824 | elapsed time per iteration (ms): 1588.1 | learning rate: 1.801E-05 | global batch size:    48 | lm loss: 5.992384E+00 | loss scale: 65536.0 | grad norm: 1.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1164/    1200 | consumed samples:        55872 | elapsed time per iteration (ms): 1899.1 | learning rate: 1.803E-05 | global batch size:    48 | lm loss: 5.991223E+00 | loss scale: 65536.0 | grad norm: 1.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1165/    1200 | consumed samples:        55920 | elapsed time per iteration (ms): 1597.0 | learning rate: 1.804E-05 | global batch size:    48 | lm loss: 5.990102E+00 | loss scale: 65536.0 | grad norm: 1.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1166/    1200 | consumed samples:        55968 | elapsed time per iteration (ms): 1836.9 | learning rate: 1.806E-05 | global batch size:    48 | lm loss: 5.988894E+00 | loss scale: 65536.0 | grad norm: 1.554 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1167/    1200 | consumed samples:        56016 | elapsed time per iteration (ms): 2222.0 | learning rate: 1.807E-05 | global batch size:    48 | lm loss: 5.987771E+00 | loss scale: 65536.0 | grad norm: 1.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1168/    1200 | consumed samples:        56064 | elapsed time per iteration (ms): 1838.5 | learning rate: 1.809E-05 | global batch size:    48 | lm loss: 5.986763E+00 | loss scale: 65536.0 | grad norm: 1.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1169/    1200 | consumed samples:        56112 | elapsed time per iteration (ms): 1850.6 | learning rate: 1.810E-05 | global batch size:    48 | lm loss: 5.985575E+00 | loss scale: 65536.0 | grad norm: 1.601 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1170/    1200 | consumed samples:        56160 | elapsed time per iteration (ms): 1826.9 | learning rate: 1.812E-05 | global batch size:    48 | lm loss: 5.984424E+00 | loss scale: 65536.0 | grad norm: 1.623 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1171/    1200 | consumed samples:        56208 | elapsed time per iteration (ms): 1804.7 | learning rate: 1.814E-05 | global batch size:    48 | lm loss: 5.983246E+00 | loss scale: 65536.0 | grad norm: 1.632 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1172/    1200 | consumed samples:        56256 | elapsed time per iteration (ms): 1589.6 | learning rate: 1.815E-05 | global batch size:    48 | lm loss: 5.982125E+00 | loss scale: 65536.0 | grad norm: 1.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1173/    1200 | consumed samples:        56304 | elapsed time per iteration (ms): 2073.8 | learning rate: 1.817E-05 | global batch size:    48 | lm loss: 5.980922E+00 | loss scale: 65536.0 | grad norm: 1.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1174/    1200 | consumed samples:        56352 | elapsed time per iteration (ms): 1854.7 | learning rate: 1.818E-05 | global batch size:    48 | lm loss: 5.979838E+00 | loss scale: 65536.0 | grad norm: 1.540 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1175/    1200 | consumed samples:        56400 | elapsed time per iteration (ms): 1933.8 | learning rate: 1.820E-05 | global batch size:    48 | lm loss: 5.978852E+00 | loss scale: 65536.0 | grad norm: 1.655 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1176/    1200 | consumed samples:        56448 | elapsed time per iteration (ms): 2046.9 | learning rate: 1.821E-05 | global batch size:    48 | lm loss: 5.977688E+00 | loss scale: 65536.0 | grad norm: 1.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1177/    1200 | consumed samples:        56496 | elapsed time per iteration (ms): 1971.7 | learning rate: 1.823E-05 | global batch size:    48 | lm loss: 5.976606E+00 | loss scale: 65536.0 | grad norm: 1.578 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1178/    1200 | consumed samples:        56544 | elapsed time per iteration (ms): 1841.4 | learning rate: 1.825E-05 | global batch size:    48 | lm loss: 5.975502E+00 | loss scale: 65536.0 | grad norm: 1.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1179/    1200 | consumed samples:        56592 | elapsed time per iteration (ms): 1867.8 | learning rate: 1.826E-05 | global batch size:    48 | lm loss: 5.974526E+00 | loss scale: 65536.0 | grad norm: 1.583 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1180/    1200 | consumed samples:        56640 | elapsed time per iteration (ms): 1649.3 | learning rate: 1.828E-05 | global batch size:    48 | lm loss: 5.973369E+00 | loss scale: 65536.0 | grad norm: 1.567 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1181/    1200 | consumed samples:        56688 | elapsed time per iteration (ms): 1904.9 | learning rate: 1.829E-05 | global batch size:    48 | lm loss: 5.972220E+00 | loss scale: 65536.0 | grad norm: 1.591 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1182/    1200 | consumed samples:        56736 | elapsed time per iteration (ms): 2213.3 | learning rate: 1.831E-05 | global batch size:    48 | lm loss: 5.971141E+00 | loss scale: 65536.0 | grad norm: 1.578 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1183/    1200 | consumed samples:        56784 | elapsed time per iteration (ms): 1696.2 | learning rate: 1.832E-05 | global batch size:    48 | lm loss: 5.970107E+00 | loss scale: 65536.0 | grad norm: 1.504 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1184/    1200 | consumed samples:        56832 | elapsed time per iteration (ms): 2045.7 | learning rate: 1.834E-05 | global batch size:    48 | lm loss: 5.969049E+00 | loss scale: 65536.0 | grad norm: 1.523 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1185/    1200 | consumed samples:        56880 | elapsed time per iteration (ms): 1680.1 | learning rate: 1.836E-05 | global batch size:    48 | lm loss: 5.968040E+00 | loss scale: 65536.0 | grad norm: 1.545 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1186/    1200 | consumed samples:        56928 | elapsed time per iteration (ms): 1732.3 | learning rate: 1.837E-05 | global batch size:    48 | lm loss: 5.966986E+00 | loss scale: 65536.0 | grad norm: 1.491 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1187/    1200 | consumed samples:        56976 | elapsed time per iteration (ms): 1672.4 | learning rate: 1.839E-05 | global batch size:    48 | lm loss: 5.965817E+00 | loss scale: 65536.0 | grad norm: 1.457 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1188/    1200 | consumed samples:        57024 | elapsed time per iteration (ms): 1871.8 | learning rate: 1.840E-05 | global batch size:    48 | lm loss: 5.964793E+00 | loss scale: 65536.0 | grad norm: 1.560 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1189/    1200 | consumed samples:        57072 | elapsed time per iteration (ms): 1822.4 | learning rate: 1.842E-05 | global batch size:    48 | lm loss: 5.963867E+00 | loss scale: 65536.0 | grad norm: 1.555 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1190/    1200 | consumed samples:        57120 | elapsed time per iteration (ms): 2365.0 | learning rate: 1.843E-05 | global batch size:    48 | lm loss: 5.962740E+00 | loss scale: 65536.0 | grad norm: 1.574 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1191/    1200 | consumed samples:        57168 | elapsed time per iteration (ms): 1985.5 | learning rate: 1.845E-05 | global batch size:    48 | lm loss: 5.961539E+00 | loss scale: 65536.0 | grad norm: 1.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1192/    1200 | consumed samples:        57216 | elapsed time per iteration (ms): 1836.9 | learning rate: 1.847E-05 | global batch size:    48 | lm loss: 5.960496E+00 | loss scale: 65536.0 | grad norm: 1.591 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1193/    1200 | consumed samples:        57264 | elapsed time per iteration (ms): 2005.3 | learning rate: 1.848E-05 | global batch size:    48 | lm loss: 5.959515E+00 | loss scale: 65536.0 | grad norm: 1.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1194/    1200 | consumed samples:        57312 | elapsed time per iteration (ms): 1854.6 | learning rate: 1.850E-05 | global batch size:    48 | lm loss: 5.958547E+00 | loss scale: 65536.0 | grad norm: 1.551 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1195/    1200 | consumed samples:        57360 | elapsed time per iteration (ms): 2003.4 | learning rate: 1.851E-05 | global batch size:    48 | lm loss: 5.957483E+00 | loss scale: 65536.0 | grad norm: 1.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1196/    1200 | consumed samples:        57408 | elapsed time per iteration (ms): 2002.1 | learning rate: 1.853E-05 | global batch size:    48 | lm loss: 5.956613E+00 | loss scale: 65536.0 | grad norm: 1.796 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1197/    1200 | consumed samples:        57456 | elapsed time per iteration (ms): 1989.0 | learning rate: 1.854E-05 | global batch size:    48 | lm loss: 5.955636E+00 | loss scale: 65536.0 | grad norm: 1.597 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1198/    1200 | consumed samples:        57504 | elapsed time per iteration (ms): 1879.1 | learning rate: 1.856E-05 | global batch size:    48 | lm loss: 5.954618E+00 | loss scale: 65536.0 | grad norm: 1.613 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1199/    1200 | consumed samples:        57552 | elapsed time per iteration (ms): 1864.8 | learning rate: 1.858E-05 | global batch size:    48 | lm loss: 5.953474E+00 | loss scale: 65536.0 | grad norm: 1.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1200/    1200 | consumed samples:        57600 | elapsed time per iteration (ms): 1943.8 | learning rate: 1.859E-05 | global batch size:    48 | lm loss: 5.952415E+00 | loss scale: 65536.0 | grad norm: 1.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
