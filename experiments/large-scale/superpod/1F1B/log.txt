 iteration        1/    1200 | consumed samples:           48 | elapsed time per iteration (ms): 88966.1 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4294967296.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        2/    1200 | consumed samples:           96 | elapsed time per iteration (ms): 1851.0 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2147483648.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        3/    1200 | consumed samples:          144 | elapsed time per iteration (ms): 1385.3 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1073741824.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        4/    1200 | consumed samples:          192 | elapsed time per iteration (ms): 1406.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 536870912.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        5/    1200 | consumed samples:          240 | elapsed time per iteration (ms): 1411.3 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        6/    1200 | consumed samples:          288 | elapsed time per iteration (ms): 1406.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 134217728.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        7/    1200 | consumed samples:          336 | elapsed time per iteration (ms): 1405.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 67108864.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        8/    1200 | consumed samples:          384 | elapsed time per iteration (ms): 1403.7 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 33554432.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        9/    1200 | consumed samples:          432 | elapsed time per iteration (ms): 1412.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 16777216.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       10/    1200 | consumed samples:          480 | elapsed time per iteration (ms): 1405.6 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 8388608.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       11/    1200 | consumed samples:          528 | elapsed time per iteration (ms): 1403.7 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4194304.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       12/    1200 | consumed samples:          576 | elapsed time per iteration (ms): 1405.0 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       13/    1200 | consumed samples:          624 | elapsed time per iteration (ms): 1410.3 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       14/    1200 | consumed samples:          672 | elapsed time per iteration (ms): 1403.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 524288.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       15/    1200 | consumed samples:          720 | elapsed time per iteration (ms): 1403.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       16/    1200 | consumed samples:          768 | elapsed time per iteration (ms): 1563.7 | learning rate: 1.573E-08 | global batch size:    48 | lm loss: 1.065781E+01 | loss scale: 262144.0 | grad norm: 157.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       17/    1200 | consumed samples:          816 | elapsed time per iteration (ms): 2911.2 | learning rate: 3.146E-08 | global batch size:    48 | lm loss: 1.065981E+01 | loss scale: 262144.0 | grad norm: 164.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       18/    1200 | consumed samples:          864 | elapsed time per iteration (ms): 2679.7 | learning rate: 4.719E-08 | global batch size:    48 | lm loss: 1.065036E+01 | loss scale: 262144.0 | grad norm: 159.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       19/    1200 | consumed samples:          912 | elapsed time per iteration (ms): 2680.6 | learning rate: 6.291E-08 | global batch size:    48 | lm loss: 1.042427E+01 | loss scale: 262144.0 | grad norm: 159.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       20/    1200 | consumed samples:          960 | elapsed time per iteration (ms): 2681.1 | learning rate: 7.864E-08 | global batch size:    48 | lm loss: 9.801708E+00 | loss scale: 262144.0 | grad norm: 138.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       21/    1200 | consumed samples:         1008 | elapsed time per iteration (ms): 2639.8 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 131072.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       22/    1200 | consumed samples:         1056 | elapsed time per iteration (ms): 2639.4 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       23/    1200 | consumed samples:         1104 | elapsed time per iteration (ms): 2639.1 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       24/    1200 | consumed samples:         1152 | elapsed time per iteration (ms): 2679.8 | learning rate: 9.437E-08 | global batch size:    48 | lm loss: 1.047623E+01 | loss scale: 32768.0 | grad norm: 789.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       25/    1200 | consumed samples:         1200 | elapsed time per iteration (ms): 2680.0 | learning rate: 1.101E-07 | global batch size:    48 | lm loss: 1.015672E+01 | loss scale: 32768.0 | grad norm: 711.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       26/    1200 | consumed samples:         1248 | elapsed time per iteration (ms): 2675.9 | learning rate: 1.258E-07 | global batch size:    48 | lm loss: 9.398643E+00 | loss scale: 32768.0 | grad norm: 298.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       27/    1200 | consumed samples:         1296 | elapsed time per iteration (ms): 2677.5 | learning rate: 1.416E-07 | global batch size:    48 | lm loss: 9.068604E+00 | loss scale: 32768.0 | grad norm: 205.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       28/    1200 | consumed samples:         1344 | elapsed time per iteration (ms): 2676.6 | learning rate: 1.573E-07 | global batch size:    48 | lm loss: 8.798186E+00 | loss scale: 32768.0 | grad norm: 62.547 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       29/    1200 | consumed samples:         1392 | elapsed time per iteration (ms): 2675.7 | learning rate: 1.730E-07 | global batch size:    48 | lm loss: 8.744461E+00 | loss scale: 32768.0 | grad norm: 73.582 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       30/    1200 | consumed samples:         1440 | elapsed time per iteration (ms): 2674.3 | learning rate: 1.887E-07 | global batch size:    48 | lm loss: 8.688231E+00 | loss scale: 32768.0 | grad norm: 52.181 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       31/    1200 | consumed samples:         1488 | elapsed time per iteration (ms): 2672.1 | learning rate: 2.045E-07 | global batch size:    48 | lm loss: 8.584795E+00 | loss scale: 32768.0 | grad norm: 144.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       32/    1200 | consumed samples:         1536 | elapsed time per iteration (ms): 2678.6 | learning rate: 2.202E-07 | global batch size:    48 | lm loss: 8.453249E+00 | loss scale: 32768.0 | grad norm: 76.355 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       33/    1200 | consumed samples:         1584 | elapsed time per iteration (ms): 2673.1 | learning rate: 2.359E-07 | global batch size:    48 | lm loss: 8.406470E+00 | loss scale: 32768.0 | grad norm: 53.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       34/    1200 | consumed samples:         1632 | elapsed time per iteration (ms): 2672.9 | learning rate: 2.517E-07 | global batch size:    48 | lm loss: 8.353151E+00 | loss scale: 32768.0 | grad norm: 47.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       35/    1200 | consumed samples:         1680 | elapsed time per iteration (ms): 2708.6 | learning rate: 2.674E-07 | global batch size:    48 | lm loss: 8.301533E+00 | loss scale: 32768.0 | grad norm: 56.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       36/    1200 | consumed samples:         1728 | elapsed time per iteration (ms): 2672.6 | learning rate: 2.831E-07 | global batch size:    48 | lm loss: 8.239415E+00 | loss scale: 32768.0 | grad norm: 46.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       37/    1200 | consumed samples:         1776 | elapsed time per iteration (ms): 2680.1 | learning rate: 2.988E-07 | global batch size:    48 | lm loss: 8.239269E+00 | loss scale: 32768.0 | grad norm: 32.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       38/    1200 | consumed samples:         1824 | elapsed time per iteration (ms): 2675.2 | learning rate: 3.146E-07 | global batch size:    48 | lm loss: 8.143072E+00 | loss scale: 32768.0 | grad norm: 27.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       39/    1200 | consumed samples:         1872 | elapsed time per iteration (ms): 2670.7 | learning rate: 3.303E-07 | global batch size:    48 | lm loss: 8.125022E+00 | loss scale: 32768.0 | grad norm: 34.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       40/    1200 | consumed samples:         1920 | elapsed time per iteration (ms): 2679.3 | learning rate: 3.460E-07 | global batch size:    48 | lm loss: 8.162258E+00 | loss scale: 32768.0 | grad norm: 64.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       41/    1200 | consumed samples:         1968 | elapsed time per iteration (ms): 2677.0 | learning rate: 3.618E-07 | global batch size:    48 | lm loss: 8.111242E+00 | loss scale: 32768.0 | grad norm: 25.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       42/    1200 | consumed samples:         2016 | elapsed time per iteration (ms): 2708.8 | learning rate: 3.775E-07 | global batch size:    48 | lm loss: 8.016221E+00 | loss scale: 32768.0 | grad norm: 28.157 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       43/    1200 | consumed samples:         2064 | elapsed time per iteration (ms): 2672.4 | learning rate: 3.932E-07 | global batch size:    48 | lm loss: 8.029202E+00 | loss scale: 32768.0 | grad norm: 36.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       44/    1200 | consumed samples:         2112 | elapsed time per iteration (ms): 2678.5 | learning rate: 4.089E-07 | global batch size:    48 | lm loss: 8.044934E+00 | loss scale: 32768.0 | grad norm: 44.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       45/    1200 | consumed samples:         2160 | elapsed time per iteration (ms): 2675.9 | learning rate: 4.247E-07 | global batch size:    48 | lm loss: 7.920192E+00 | loss scale: 32768.0 | grad norm: 24.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       46/    1200 | consumed samples:         2208 | elapsed time per iteration (ms): 2672.0 | learning rate: 4.404E-07 | global batch size:    48 | lm loss: 8.004175E+00 | loss scale: 32768.0 | grad norm: 49.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       47/    1200 | consumed samples:         2256 | elapsed time per iteration (ms): 2676.7 | learning rate: 4.561E-07 | global batch size:    48 | lm loss: 8.005824E+00 | loss scale: 32768.0 | grad norm: 37.329 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       48/    1200 | consumed samples:         2304 | elapsed time per iteration (ms): 2673.6 | learning rate: 4.719E-07 | global batch size:    48 | lm loss: 7.914961E+00 | loss scale: 32768.0 | grad norm: 18.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       49/    1200 | consumed samples:         2352 | elapsed time per iteration (ms): 2675.1 | learning rate: 4.876E-07 | global batch size:    48 | lm loss: 7.940005E+00 | loss scale: 32768.0 | grad norm: 32.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       50/    1200 | consumed samples:         2400 | elapsed time per iteration (ms): 2679.7 | learning rate: 5.033E-07 | global batch size:    48 | lm loss: 7.899236E+00 | loss scale: 32768.0 | grad norm: 19.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       51/    1200 | consumed samples:         2448 | elapsed time per iteration (ms): 2675.8 | learning rate: 5.190E-07 | global batch size:    48 | lm loss: 7.903930E+00 | loss scale: 32768.0 | grad norm: 30.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       52/    1200 | consumed samples:         2496 | elapsed time per iteration (ms): 2670.8 | learning rate: 5.348E-07 | global batch size:    48 | lm loss: 7.944133E+00 | loss scale: 32768.0 | grad norm: 27.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       53/    1200 | consumed samples:         2544 | elapsed time per iteration (ms): 2671.3 | learning rate: 5.505E-07 | global batch size:    48 | lm loss: 7.817269E+00 | loss scale: 32768.0 | grad norm: 14.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       54/    1200 | consumed samples:         2592 | elapsed time per iteration (ms): 2675.1 | learning rate: 5.662E-07 | global batch size:    48 | lm loss: 7.822289E+00 | loss scale: 32768.0 | grad norm: 64.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       55/    1200 | consumed samples:         2640 | elapsed time per iteration (ms): 2671.7 | learning rate: 5.820E-07 | global batch size:    48 | lm loss: 7.954288E+00 | loss scale: 32768.0 | grad norm: 62.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       56/    1200 | consumed samples:         2688 | elapsed time per iteration (ms): 2756.2 | learning rate: 5.977E-07 | global batch size:    48 | lm loss: 7.893144E+00 | loss scale: 32768.0 | grad norm: 24.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       57/    1200 | consumed samples:         2736 | elapsed time per iteration (ms): 2677.1 | learning rate: 6.134E-07 | global batch size:    48 | lm loss: 7.804148E+00 | loss scale: 32768.0 | grad norm: 20.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       58/    1200 | consumed samples:         2784 | elapsed time per iteration (ms): 2678.6 | learning rate: 6.291E-07 | global batch size:    48 | lm loss: 8.038012E+00 | loss scale: 32768.0 | grad norm: 122.185 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       59/    1200 | consumed samples:         2832 | elapsed time per iteration (ms): 2671.2 | learning rate: 6.449E-07 | global batch size:    48 | lm loss: 7.895634E+00 | loss scale: 32768.0 | grad norm: 54.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       60/    1200 | consumed samples:         2880 | elapsed time per iteration (ms): 2669.4 | learning rate: 6.606E-07 | global batch size:    48 | lm loss: 7.813709E+00 | loss scale: 32768.0 | grad norm: 19.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       61/    1200 | consumed samples:         2928 | elapsed time per iteration (ms): 2675.9 | learning rate: 6.763E-07 | global batch size:    48 | lm loss: 7.746299E+00 | loss scale: 32768.0 | grad norm: 19.158 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       62/    1200 | consumed samples:         2976 | elapsed time per iteration (ms): 2675.8 | learning rate: 6.921E-07 | global batch size:    48 | lm loss: 7.763969E+00 | loss scale: 32768.0 | grad norm: 22.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       63/    1200 | consumed samples:         3024 | elapsed time per iteration (ms): 2677.9 | learning rate: 7.078E-07 | global batch size:    48 | lm loss: 7.722938E+00 | loss scale: 32768.0 | grad norm: 75.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       64/    1200 | consumed samples:         3072 | elapsed time per iteration (ms): 2670.0 | learning rate: 7.235E-07 | global batch size:    48 | lm loss: 7.647756E+00 | loss scale: 32768.0 | grad norm: 23.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       65/    1200 | consumed samples:         3120 | elapsed time per iteration (ms): 2674.9 | learning rate: 7.392E-07 | global batch size:    48 | lm loss: 7.665687E+00 | loss scale: 32768.0 | grad norm: 19.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       66/    1200 | consumed samples:         3168 | elapsed time per iteration (ms): 2675.3 | learning rate: 7.550E-07 | global batch size:    48 | lm loss: 7.702944E+00 | loss scale: 32768.0 | grad norm: 17.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       67/    1200 | consumed samples:         3216 | elapsed time per iteration (ms): 2675.6 | learning rate: 7.707E-07 | global batch size:    48 | lm loss: 7.670463E+00 | loss scale: 32768.0 | grad norm: 39.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       68/    1200 | consumed samples:         3264 | elapsed time per iteration (ms): 2680.1 | learning rate: 7.864E-07 | global batch size:    48 | lm loss: 7.657525E+00 | loss scale: 32768.0 | grad norm: 39.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       69/    1200 | consumed samples:         3312 | elapsed time per iteration (ms): 2679.6 | learning rate: 8.022E-07 | global batch size:    48 | lm loss: 7.680553E+00 | loss scale: 32768.0 | grad norm: 26.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       70/    1200 | consumed samples:         3360 | elapsed time per iteration (ms): 2670.3 | learning rate: 8.179E-07 | global batch size:    48 | lm loss: 7.669929E+00 | loss scale: 32768.0 | grad norm: 18.246 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       71/    1200 | consumed samples:         3408 | elapsed time per iteration (ms): 2674.6 | learning rate: 8.336E-07 | global batch size:    48 | lm loss: 7.642608E+00 | loss scale: 32768.0 | grad norm: 20.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       72/    1200 | consumed samples:         3456 | elapsed time per iteration (ms): 2672.1 | learning rate: 8.493E-07 | global batch size:    48 | lm loss: 7.609447E+00 | loss scale: 32768.0 | grad norm: 18.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       73/    1200 | consumed samples:         3504 | elapsed time per iteration (ms): 2676.9 | learning rate: 8.651E-07 | global batch size:    48 | lm loss: 7.620540E+00 | loss scale: 32768.0 | grad norm: 34.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       74/    1200 | consumed samples:         3552 | elapsed time per iteration (ms): 2673.0 | learning rate: 8.808E-07 | global batch size:    48 | lm loss: 7.624036E+00 | loss scale: 32768.0 | grad norm: 30.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       75/    1200 | consumed samples:         3600 | elapsed time per iteration (ms): 2676.8 | learning rate: 8.965E-07 | global batch size:    48 | lm loss: 7.543097E+00 | loss scale: 32768.0 | grad norm: 15.242 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       76/    1200 | consumed samples:         3648 | elapsed time per iteration (ms): 2667.3 | learning rate: 9.123E-07 | global batch size:    48 | lm loss: 7.549984E+00 | loss scale: 32768.0 | grad norm: 17.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       77/    1200 | consumed samples:         3696 | elapsed time per iteration (ms): 2674.7 | learning rate: 9.280E-07 | global batch size:    48 | lm loss: 7.516418E+00 | loss scale: 32768.0 | grad norm: 17.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       78/    1200 | consumed samples:         3744 | elapsed time per iteration (ms): 2675.6 | learning rate: 9.437E-07 | global batch size:    48 | lm loss: 7.521658E+00 | loss scale: 32768.0 | grad norm: 12.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       79/    1200 | consumed samples:         3792 | elapsed time per iteration (ms): 2674.4 | learning rate: 9.594E-07 | global batch size:    48 | lm loss: 7.360420E+00 | loss scale: 32768.0 | grad norm: 11.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       80/    1200 | consumed samples:         3840 | elapsed time per iteration (ms): 2670.2 | learning rate: 9.752E-07 | global batch size:    48 | lm loss: 7.396046E+00 | loss scale: 32768.0 | grad norm: 18.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       81/    1200 | consumed samples:         3888 | elapsed time per iteration (ms): 2682.2 | learning rate: 9.909E-07 | global batch size:    48 | lm loss: 7.360001E+00 | loss scale: 32768.0 | grad norm: 19.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       82/    1200 | consumed samples:         3936 | elapsed time per iteration (ms): 2676.9 | learning rate: 1.007E-06 | global batch size:    48 | lm loss: 7.494289E+00 | loss scale: 32768.0 | grad norm: 27.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       83/    1200 | consumed samples:         3984 | elapsed time per iteration (ms): 2672.9 | learning rate: 1.022E-06 | global batch size:    48 | lm loss: 7.420578E+00 | loss scale: 32768.0 | grad norm: 12.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       84/    1200 | consumed samples:         4032 | elapsed time per iteration (ms): 2670.3 | learning rate: 1.038E-06 | global batch size:    48 | lm loss: 7.352755E+00 | loss scale: 32768.0 | grad norm: 14.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       85/    1200 | consumed samples:         4080 | elapsed time per iteration (ms): 2679.3 | learning rate: 1.054E-06 | global batch size:    48 | lm loss: 7.374402E+00 | loss scale: 32768.0 | grad norm: 17.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       86/    1200 | consumed samples:         4128 | elapsed time per iteration (ms): 1815.9 | learning rate: 1.070E-06 | global batch size:    48 | lm loss: 7.310581E+00 | loss scale: 32768.0 | grad norm: 13.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       87/    1200 | consumed samples:         4176 | elapsed time per iteration (ms): 1443.4 | learning rate: 1.085E-06 | global batch size:    48 | lm loss: 7.289821E+00 | loss scale: 32768.0 | grad norm: 12.305 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       88/    1200 | consumed samples:         4224 | elapsed time per iteration (ms): 1445.4 | learning rate: 1.101E-06 | global batch size:    48 | lm loss: 7.309093E+00 | loss scale: 32768.0 | grad norm: 22.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       89/    1200 | consumed samples:         4272 | elapsed time per iteration (ms): 1446.3 | learning rate: 1.117E-06 | global batch size:    48 | lm loss: 7.299557E+00 | loss scale: 32768.0 | grad norm: 11.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       90/    1200 | consumed samples:         4320 | elapsed time per iteration (ms): 1445.0 | learning rate: 1.132E-06 | global batch size:    48 | lm loss: 7.264783E+00 | loss scale: 32768.0 | grad norm: 18.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       91/    1200 | consumed samples:         4368 | elapsed time per iteration (ms): 1443.9 | learning rate: 1.148E-06 | global batch size:    48 | lm loss: 7.266624E+00 | loss scale: 32768.0 | grad norm: 10.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       92/    1200 | consumed samples:         4416 | elapsed time per iteration (ms): 1441.8 | learning rate: 1.164E-06 | global batch size:    48 | lm loss: 7.272981E+00 | loss scale: 32768.0 | grad norm: 14.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       93/    1200 | consumed samples:         4464 | elapsed time per iteration (ms): 1449.7 | learning rate: 1.180E-06 | global batch size:    48 | lm loss: 7.215261E+00 | loss scale: 32768.0 | grad norm: 11.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       94/    1200 | consumed samples:         4512 | elapsed time per iteration (ms): 1444.9 | learning rate: 1.195E-06 | global batch size:    48 | lm loss: 7.183052E+00 | loss scale: 32768.0 | grad norm: 10.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       95/    1200 | consumed samples:         4560 | elapsed time per iteration (ms): 1446.2 | learning rate: 1.211E-06 | global batch size:    48 | lm loss: 7.250178E+00 | loss scale: 32768.0 | grad norm: 12.542 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       96/    1200 | consumed samples:         4608 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.227E-06 | global batch size:    48 | lm loss: 7.103675E+00 | loss scale: 32768.0 | grad norm: 25.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       97/    1200 | consumed samples:         4656 | elapsed time per iteration (ms): 1450.4 | learning rate: 1.243E-06 | global batch size:    48 | lm loss: 7.210084E+00 | loss scale: 32768.0 | grad norm: 11.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       98/    1200 | consumed samples:         4704 | elapsed time per iteration (ms): 1444.2 | learning rate: 1.258E-06 | global batch size:    48 | lm loss: 7.219209E+00 | loss scale: 32768.0 | grad norm: 12.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       99/    1200 | consumed samples:         4752 | elapsed time per iteration (ms): 1444.5 | learning rate: 1.274E-06 | global batch size:    48 | lm loss: 7.175226E+00 | loss scale: 32768.0 | grad norm: 15.135 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      100/    1200 | consumed samples:         4800 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.290E-06 | global batch size:    48 | lm loss: 7.184348E+00 | loss scale: 32768.0 | grad norm: 9.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      101/    1200 | consumed samples:         4848 | elapsed time per iteration (ms): 1448.8 | learning rate: 1.305E-06 | global batch size:    48 | lm loss: 7.160148E+00 | loss scale: 32768.0 | grad norm: 9.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      102/    1200 | consumed samples:         4896 | elapsed time per iteration (ms): 1442.0 | learning rate: 1.321E-06 | global batch size:    48 | lm loss: 7.013313E+00 | loss scale: 32768.0 | grad norm: 9.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      103/    1200 | consumed samples:         4944 | elapsed time per iteration (ms): 1444.4 | learning rate: 1.337E-06 | global batch size:    48 | lm loss: 7.052917E+00 | loss scale: 32768.0 | grad norm: 14.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      104/    1200 | consumed samples:         4992 | elapsed time per iteration (ms): 1442.6 | learning rate: 1.353E-06 | global batch size:    48 | lm loss: 7.137936E+00 | loss scale: 32768.0 | grad norm: 19.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      105/    1200 | consumed samples:         5040 | elapsed time per iteration (ms): 1566.4 | learning rate: 1.368E-06 | global batch size:    48 | lm loss: 7.164827E+00 | loss scale: 32768.0 | grad norm: 17.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      106/    1200 | consumed samples:         5088 | elapsed time per iteration (ms): 1442.6 | learning rate: 1.384E-06 | global batch size:    48 | lm loss: 7.075429E+00 | loss scale: 32768.0 | grad norm: 8.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      107/    1200 | consumed samples:         5136 | elapsed time per iteration (ms): 1445.5 | learning rate: 1.400E-06 | global batch size:    48 | lm loss: 7.101547E+00 | loss scale: 32768.0 | grad norm: 13.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      108/    1200 | consumed samples:         5184 | elapsed time per iteration (ms): 1442.5 | learning rate: 1.416E-06 | global batch size:    48 | lm loss: 7.068012E+00 | loss scale: 32768.0 | grad norm: 14.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      109/    1200 | consumed samples:         5232 | elapsed time per iteration (ms): 1449.5 | learning rate: 1.431E-06 | global batch size:    48 | lm loss: 7.079152E+00 | loss scale: 32768.0 | grad norm: 10.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      110/    1200 | consumed samples:         5280 | elapsed time per iteration (ms): 1442.3 | learning rate: 1.447E-06 | global batch size:    48 | lm loss: 7.017496E+00 | loss scale: 32768.0 | grad norm: 11.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      111/    1200 | consumed samples:         5328 | elapsed time per iteration (ms): 1443.0 | learning rate: 1.463E-06 | global batch size:    48 | lm loss: 7.066458E+00 | loss scale: 32768.0 | grad norm: 9.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      112/    1200 | consumed samples:         5376 | elapsed time per iteration (ms): 1442.8 | learning rate: 1.478E-06 | global batch size:    48 | lm loss: 7.059348E+00 | loss scale: 32768.0 | grad norm: 12.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      113/    1200 | consumed samples:         5424 | elapsed time per iteration (ms): 1449.2 | learning rate: 1.494E-06 | global batch size:    48 | lm loss: 6.929554E+00 | loss scale: 32768.0 | grad norm: 8.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      114/    1200 | consumed samples:         5472 | elapsed time per iteration (ms): 1444.8 | learning rate: 1.510E-06 | global batch size:    48 | lm loss: 6.947205E+00 | loss scale: 32768.0 | grad norm: 19.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      115/    1200 | consumed samples:         5520 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.526E-06 | global batch size:    48 | lm loss: 7.013575E+00 | loss scale: 32768.0 | grad norm: 12.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      116/    1200 | consumed samples:         5568 | elapsed time per iteration (ms): 1448.4 | learning rate: 1.541E-06 | global batch size:    48 | lm loss: 7.014450E+00 | loss scale: 32768.0 | grad norm: 12.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      117/    1200 | consumed samples:         5616 | elapsed time per iteration (ms): 1450.4 | learning rate: 1.557E-06 | global batch size:    48 | lm loss: 6.933110E+00 | loss scale: 32768.0 | grad norm: 10.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      118/    1200 | consumed samples:         5664 | elapsed time per iteration (ms): 1440.8 | learning rate: 1.573E-06 | global batch size:    48 | lm loss: 6.910919E+00 | loss scale: 32768.0 | grad norm: 17.253 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      119/    1200 | consumed samples:         5712 | elapsed time per iteration (ms): 1444.7 | learning rate: 1.589E-06 | global batch size:    48 | lm loss: 6.975500E+00 | loss scale: 32768.0 | grad norm: 11.309 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      120/    1200 | consumed samples:         5760 | elapsed time per iteration (ms): 1441.7 | learning rate: 1.604E-06 | global batch size:    48 | lm loss: 6.943404E+00 | loss scale: 32768.0 | grad norm: 10.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      121/    1200 | consumed samples:         5808 | elapsed time per iteration (ms): 2686.2 | learning rate: 1.620E-06 | global batch size:    48 | lm loss: 6.917996E+00 | loss scale: 32768.0 | grad norm: 12.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      122/    1200 | consumed samples:         5856 | elapsed time per iteration (ms): 2517.3 | learning rate: 1.636E-06 | global batch size:    48 | lm loss: 6.839823E+00 | loss scale: 32768.0 | grad norm: 10.541 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      123/    1200 | consumed samples:         5904 | elapsed time per iteration (ms): 2507.0 | learning rate: 1.652E-06 | global batch size:    48 | lm loss: 6.870667E+00 | loss scale: 32768.0 | grad norm: 6.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      124/    1200 | consumed samples:         5952 | elapsed time per iteration (ms): 2506.4 | learning rate: 1.667E-06 | global batch size:    48 | lm loss: 6.816160E+00 | loss scale: 32768.0 | grad norm: 6.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      125/    1200 | consumed samples:         6000 | elapsed time per iteration (ms): 2513.9 | learning rate: 1.683E-06 | global batch size:    48 | lm loss: 6.807645E+00 | loss scale: 32768.0 | grad norm: 9.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      126/    1200 | consumed samples:         6048 | elapsed time per iteration (ms): 2504.8 | learning rate: 1.699E-06 | global batch size:    48 | lm loss: 6.829272E+00 | loss scale: 32768.0 | grad norm: 7.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      127/    1200 | consumed samples:         6096 | elapsed time per iteration (ms): 2506.3 | learning rate: 1.714E-06 | global batch size:    48 | lm loss: 6.810949E+00 | loss scale: 32768.0 | grad norm: 6.576 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      128/    1200 | consumed samples:         6144 | elapsed time per iteration (ms): 2503.1 | learning rate: 1.730E-06 | global batch size:    48 | lm loss: 6.806122E+00 | loss scale: 32768.0 | grad norm: 7.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      129/    1200 | consumed samples:         6192 | elapsed time per iteration (ms): 2519.5 | learning rate: 1.746E-06 | global batch size:    48 | lm loss: 6.732492E+00 | loss scale: 32768.0 | grad norm: 12.127 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      130/    1200 | consumed samples:         6240 | elapsed time per iteration (ms): 2516.8 | learning rate: 1.762E-06 | global batch size:    48 | lm loss: 6.827133E+00 | loss scale: 32768.0 | grad norm: 10.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      131/    1200 | consumed samples:         6288 | elapsed time per iteration (ms): 2506.6 | learning rate: 1.777E-06 | global batch size:    48 | lm loss: 6.708465E+00 | loss scale: 32768.0 | grad norm: 7.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      132/    1200 | consumed samples:         6336 | elapsed time per iteration (ms): 2516.6 | learning rate: 1.793E-06 | global batch size:    48 | lm loss: 6.779068E+00 | loss scale: 32768.0 | grad norm: 11.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      133/    1200 | consumed samples:         6384 | elapsed time per iteration (ms): 2511.1 | learning rate: 1.809E-06 | global batch size:    48 | lm loss: 6.751063E+00 | loss scale: 32768.0 | grad norm: 6.343 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      134/    1200 | consumed samples:         6432 | elapsed time per iteration (ms): 2513.9 | learning rate: 1.825E-06 | global batch size:    48 | lm loss: 6.773484E+00 | loss scale: 32768.0 | grad norm: 13.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      135/    1200 | consumed samples:         6480 | elapsed time per iteration (ms): 2514.9 | learning rate: 1.840E-06 | global batch size:    48 | lm loss: 6.725053E+00 | loss scale: 32768.0 | grad norm: 8.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      136/    1200 | consumed samples:         6528 | elapsed time per iteration (ms): 2508.7 | learning rate: 1.856E-06 | global batch size:    48 | lm loss: 6.668398E+00 | loss scale: 32768.0 | grad norm: 8.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      137/    1200 | consumed samples:         6576 | elapsed time per iteration (ms): 2523.2 | learning rate: 1.872E-06 | global batch size:    48 | lm loss: 6.681416E+00 | loss scale: 32768.0 | grad norm: 8.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      138/    1200 | consumed samples:         6624 | elapsed time per iteration (ms): 2513.8 | learning rate: 1.887E-06 | global batch size:    48 | lm loss: 6.706676E+00 | loss scale: 32768.0 | grad norm: 8.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      139/    1200 | consumed samples:         6672 | elapsed time per iteration (ms): 2517.4 | learning rate: 1.903E-06 | global batch size:    48 | lm loss: 6.785660E+00 | loss scale: 32768.0 | grad norm: 8.148 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      140/    1200 | consumed samples:         6720 | elapsed time per iteration (ms): 2514.5 | learning rate: 1.919E-06 | global batch size:    48 | lm loss: 6.638913E+00 | loss scale: 32768.0 | grad norm: 11.220 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      141/    1200 | consumed samples:         6768 | elapsed time per iteration (ms): 2514.8 | learning rate: 1.935E-06 | global batch size:    48 | lm loss: 6.691549E+00 | loss scale: 32768.0 | grad norm: 12.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      142/    1200 | consumed samples:         6816 | elapsed time per iteration (ms): 2506.1 | learning rate: 1.950E-06 | global batch size:    48 | lm loss: 6.646757E+00 | loss scale: 32768.0 | grad norm: 6.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      143/    1200 | consumed samples:         6864 | elapsed time per iteration (ms): 2511.8 | learning rate: 1.966E-06 | global batch size:    48 | lm loss: 6.661151E+00 | loss scale: 32768.0 | grad norm: 8.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      144/    1200 | consumed samples:         6912 | elapsed time per iteration (ms): 2511.4 | learning rate: 1.982E-06 | global batch size:    48 | lm loss: 6.640087E+00 | loss scale: 32768.0 | grad norm: 15.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      145/    1200 | consumed samples:         6960 | elapsed time per iteration (ms): 2514.4 | learning rate: 1.998E-06 | global batch size:    48 | lm loss: 6.558360E+00 | loss scale: 32768.0 | grad norm: 8.589 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      146/    1200 | consumed samples:         7008 | elapsed time per iteration (ms): 2512.4 | learning rate: 2.013E-06 | global batch size:    48 | lm loss: 6.656762E+00 | loss scale: 32768.0 | grad norm: 8.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      147/    1200 | consumed samples:         7056 | elapsed time per iteration (ms): 2516.4 | learning rate: 2.029E-06 | global batch size:    48 | lm loss: 6.615575E+00 | loss scale: 32768.0 | grad norm: 11.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      148/    1200 | consumed samples:         7104 | elapsed time per iteration (ms): 2603.3 | learning rate: 2.045E-06 | global batch size:    48 | lm loss: 6.564539E+00 | loss scale: 32768.0 | grad norm: 10.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      149/    1200 | consumed samples:         7152 | elapsed time per iteration (ms): 2521.4 | learning rate: 2.060E-06 | global batch size:    48 | lm loss: 6.616283E+00 | loss scale: 32768.0 | grad norm: 10.248 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      150/    1200 | consumed samples:         7200 | elapsed time per iteration (ms): 2510.8 | learning rate: 2.076E-06 | global batch size:    48 | lm loss: 6.474820E+00 | loss scale: 32768.0 | grad norm: 6.304 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      151/    1200 | consumed samples:         7248 | elapsed time per iteration (ms): 2509.5 | learning rate: 2.092E-06 | global batch size:    48 | lm loss: 6.589240E+00 | loss scale: 32768.0 | grad norm: 10.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      152/    1200 | consumed samples:         7296 | elapsed time per iteration (ms): 2515.4 | learning rate: 2.108E-06 | global batch size:    48 | lm loss: 6.531324E+00 | loss scale: 32768.0 | grad norm: 9.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      153/    1200 | consumed samples:         7344 | elapsed time per iteration (ms): 2511.5 | learning rate: 2.123E-06 | global batch size:    48 | lm loss: 6.586135E+00 | loss scale: 32768.0 | grad norm: 7.173 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      154/    1200 | consumed samples:         7392 | elapsed time per iteration (ms): 2508.8 | learning rate: 2.139E-06 | global batch size:    48 | lm loss: 6.527660E+00 | loss scale: 32768.0 | grad norm: 6.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      155/    1200 | consumed samples:         7440 | elapsed time per iteration (ms): 2515.1 | learning rate: 2.155E-06 | global batch size:    48 | lm loss: 6.537187E+00 | loss scale: 32768.0 | grad norm: 8.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      156/    1200 | consumed samples:         7488 | elapsed time per iteration (ms): 2513.7 | learning rate: 2.171E-06 | global batch size:    48 | lm loss: 6.605680E+00 | loss scale: 32768.0 | grad norm: 12.265 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      157/    1200 | consumed samples:         7536 | elapsed time per iteration (ms): 2516.0 | learning rate: 2.186E-06 | global batch size:    48 | lm loss: 6.532893E+00 | loss scale: 32768.0 | grad norm: 7.251 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      158/    1200 | consumed samples:         7584 | elapsed time per iteration (ms): 2512.1 | learning rate: 2.202E-06 | global batch size:    48 | lm loss: 6.554538E+00 | loss scale: 32768.0 | grad norm: 10.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      159/    1200 | consumed samples:         7632 | elapsed time per iteration (ms): 2510.7 | learning rate: 2.218E-06 | global batch size:    48 | lm loss: 6.523364E+00 | loss scale: 32768.0 | grad norm: 6.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      160/    1200 | consumed samples:         7680 | elapsed time per iteration (ms): 2508.5 | learning rate: 2.233E-06 | global batch size:    48 | lm loss: 6.499016E+00 | loss scale: 32768.0 | grad norm: 7.162 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      161/    1200 | consumed samples:         7728 | elapsed time per iteration (ms): 2514.4 | learning rate: 2.249E-06 | global batch size:    48 | lm loss: 6.488636E+00 | loss scale: 32768.0 | grad norm: 7.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      162/    1200 | consumed samples:         7776 | elapsed time per iteration (ms): 2512.7 | learning rate: 2.265E-06 | global batch size:    48 | lm loss: 6.402086E+00 | loss scale: 32768.0 | grad norm: 8.321 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      163/    1200 | consumed samples:         7824 | elapsed time per iteration (ms): 2510.9 | learning rate: 2.281E-06 | global batch size:    48 | lm loss: 6.453182E+00 | loss scale: 32768.0 | grad norm: 6.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      164/    1200 | consumed samples:         7872 | elapsed time per iteration (ms): 2507.8 | learning rate: 2.296E-06 | global batch size:    48 | lm loss: 6.574172E+00 | loss scale: 32768.0 | grad norm: 6.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      165/    1200 | consumed samples:         7920 | elapsed time per iteration (ms): 2511.1 | learning rate: 2.312E-06 | global batch size:    48 | lm loss: 6.555213E+00 | loss scale: 32768.0 | grad norm: 7.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      166/    1200 | consumed samples:         7968 | elapsed time per iteration (ms): 2513.6 | learning rate: 2.328E-06 | global batch size:    48 | lm loss: 6.525514E+00 | loss scale: 32768.0 | grad norm: 9.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      167/    1200 | consumed samples:         8016 | elapsed time per iteration (ms): 2513.8 | learning rate: 2.344E-06 | global batch size:    48 | lm loss: 6.441551E+00 | loss scale: 32768.0 | grad norm: 12.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      168/    1200 | consumed samples:         8064 | elapsed time per iteration (ms): 2510.6 | learning rate: 2.359E-06 | global batch size:    48 | lm loss: 6.435333E+00 | loss scale: 32768.0 | grad norm: 11.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      169/    1200 | consumed samples:         8112 | elapsed time per iteration (ms): 2510.6 | learning rate: 2.375E-06 | global batch size:    48 | lm loss: 6.447063E+00 | loss scale: 32768.0 | grad norm: 7.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      170/    1200 | consumed samples:         8160 | elapsed time per iteration (ms): 2516.1 | learning rate: 2.391E-06 | global batch size:    48 | lm loss: 6.496104E+00 | loss scale: 32768.0 | grad norm: 10.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      171/    1200 | consumed samples:         8208 | elapsed time per iteration (ms): 2516.0 | learning rate: 2.406E-06 | global batch size:    48 | lm loss: 6.501842E+00 | loss scale: 32768.0 | grad norm: 10.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      172/    1200 | consumed samples:         8256 | elapsed time per iteration (ms): 2511.2 | learning rate: 2.422E-06 | global batch size:    48 | lm loss: 6.410518E+00 | loss scale: 32768.0 | grad norm: 5.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      173/    1200 | consumed samples:         8304 | elapsed time per iteration (ms): 2516.7 | learning rate: 2.438E-06 | global batch size:    48 | lm loss: 6.406030E+00 | loss scale: 32768.0 | grad norm: 9.304 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      174/    1200 | consumed samples:         8352 | elapsed time per iteration (ms): 2610.2 | learning rate: 2.454E-06 | global batch size:    48 | lm loss: 6.368234E+00 | loss scale: 32768.0 | grad norm: 7.327 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      175/    1200 | consumed samples:         8400 | elapsed time per iteration (ms): 2516.0 | learning rate: 2.469E-06 | global batch size:    48 | lm loss: 6.364482E+00 | loss scale: 32768.0 | grad norm: 8.289 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      176/    1200 | consumed samples:         8448 | elapsed time per iteration (ms): 2506.6 | learning rate: 2.485E-06 | global batch size:    48 | lm loss: 6.365047E+00 | loss scale: 32768.0 | grad norm: 6.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      177/    1200 | consumed samples:         8496 | elapsed time per iteration (ms): 2684.0 | learning rate: 2.501E-06 | global batch size:    48 | lm loss: 6.427409E+00 | loss scale: 32768.0 | grad norm: 7.355 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      178/    1200 | consumed samples:         8544 | elapsed time per iteration (ms): 2512.0 | learning rate: 2.517E-06 | global batch size:    48 | lm loss: 6.352920E+00 | loss scale: 32768.0 | grad norm: 5.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      179/    1200 | consumed samples:         8592 | elapsed time per iteration (ms): 2504.3 | learning rate: 2.532E-06 | global batch size:    48 | lm loss: 6.382558E+00 | loss scale: 32768.0 | grad norm: 6.237 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      180/    1200 | consumed samples:         8640 | elapsed time per iteration (ms): 2503.6 | learning rate: 2.548E-06 | global batch size:    48 | lm loss: 6.397189E+00 | loss scale: 32768.0 | grad norm: 5.043 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      181/    1200 | consumed samples:         8688 | elapsed time per iteration (ms): 2511.8 | learning rate: 2.564E-06 | global batch size:    48 | lm loss: 6.372642E+00 | loss scale: 32768.0 | grad norm: 5.712 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      182/    1200 | consumed samples:         8736 | elapsed time per iteration (ms): 2505.9 | learning rate: 2.580E-06 | global batch size:    48 | lm loss: 6.292591E+00 | loss scale: 32768.0 | grad norm: 5.971 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      183/    1200 | consumed samples:         8784 | elapsed time per iteration (ms): 2503.8 | learning rate: 2.595E-06 | global batch size:    48 | lm loss: 6.356360E+00 | loss scale: 32768.0 | grad norm: 6.244 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      184/    1200 | consumed samples:         8832 | elapsed time per iteration (ms): 2531.2 | learning rate: 2.611E-06 | global batch size:    48 | lm loss: 6.328367E+00 | loss scale: 32768.0 | grad norm: 5.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      185/    1200 | consumed samples:         8880 | elapsed time per iteration (ms): 2513.5 | learning rate: 2.627E-06 | global batch size:    48 | lm loss: 6.324722E+00 | loss scale: 32768.0 | grad norm: 6.269 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      186/    1200 | consumed samples:         8928 | elapsed time per iteration (ms): 2503.5 | learning rate: 2.642E-06 | global batch size:    48 | lm loss: 6.376919E+00 | loss scale: 32768.0 | grad norm: 5.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      187/    1200 | consumed samples:         8976 | elapsed time per iteration (ms): 2502.8 | learning rate: 2.658E-06 | global batch size:    48 | lm loss: 6.324995E+00 | loss scale: 32768.0 | grad norm: 6.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      188/    1200 | consumed samples:         9024 | elapsed time per iteration (ms): 2508.8 | learning rate: 2.674E-06 | global batch size:    48 | lm loss: 6.324950E+00 | loss scale: 32768.0 | grad norm: 6.527 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      189/    1200 | consumed samples:         9072 | elapsed time per iteration (ms): 2514.9 | learning rate: 2.690E-06 | global batch size:    48 | lm loss: 6.251019E+00 | loss scale: 32768.0 | grad norm: 5.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      190/    1200 | consumed samples:         9120 | elapsed time per iteration (ms): 2506.7 | learning rate: 2.705E-06 | global batch size:    48 | lm loss: 6.290689E+00 | loss scale: 32768.0 | grad norm: 7.252 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      191/    1200 | consumed samples:         9168 | elapsed time per iteration (ms): 2228.3 | learning rate: 2.721E-06 | global batch size:    48 | lm loss: 6.356312E+00 | loss scale: 32768.0 | grad norm: 7.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      192/    1200 | consumed samples:         9216 | elapsed time per iteration (ms): 2148.6 | learning rate: 2.737E-06 | global batch size:    48 | lm loss: 6.279025E+00 | loss scale: 32768.0 | grad norm: 6.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      193/    1200 | consumed samples:         9264 | elapsed time per iteration (ms): 1442.7 | learning rate: 2.753E-06 | global batch size:    48 | lm loss: 6.285343E+00 | loss scale: 32768.0 | grad norm: 6.182 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      194/    1200 | consumed samples:         9312 | elapsed time per iteration (ms): 1443.2 | learning rate: 2.768E-06 | global batch size:    48 | lm loss: 6.412189E+00 | loss scale: 32768.0 | grad norm: 8.525 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      195/    1200 | consumed samples:         9360 | elapsed time per iteration (ms): 1437.6 | learning rate: 2.784E-06 | global batch size:    48 | lm loss: 6.300478E+00 | loss scale: 32768.0 | grad norm: 7.452 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      196/    1200 | consumed samples:         9408 | elapsed time per iteration (ms): 1442.7 | learning rate: 2.800E-06 | global batch size:    48 | lm loss: 6.366922E+00 | loss scale: 32768.0 | grad norm: 11.926 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      197/    1200 | consumed samples:         9456 | elapsed time per iteration (ms): 1448.8 | learning rate: 2.815E-06 | global batch size:    48 | lm loss: 6.444289E+00 | loss scale: 32768.0 | grad norm: 18.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      198/    1200 | consumed samples:         9504 | elapsed time per iteration (ms): 1440.9 | learning rate: 2.831E-06 | global batch size:    48 | lm loss: 6.408941E+00 | loss scale: 32768.0 | grad norm: 5.606 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      199/    1200 | consumed samples:         9552 | elapsed time per iteration (ms): 1442.9 | learning rate: 2.847E-06 | global batch size:    48 | lm loss: 6.376432E+00 | loss scale: 32768.0 | grad norm: 12.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      200/    1200 | consumed samples:         9600 | elapsed time per iteration (ms): 1441.9 | learning rate: 2.863E-06 | global batch size:    48 | lm loss: 6.268194E+00 | loss scale: 32768.0 | grad norm: 8.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      201/    1200 | consumed samples:         9648 | elapsed time per iteration (ms): 1450.2 | learning rate: 2.878E-06 | global batch size:    48 | lm loss: 6.214344E+00 | loss scale: 32768.0 | grad norm: 10.274 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      202/    1200 | consumed samples:         9696 | elapsed time per iteration (ms): 1442.3 | learning rate: 2.894E-06 | global batch size:    48 | lm loss: 6.304132E+00 | loss scale: 32768.0 | grad norm: 4.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      203/    1200 | consumed samples:         9744 | elapsed time per iteration (ms): 1441.9 | learning rate: 2.910E-06 | global batch size:    48 | lm loss: 6.296124E+00 | loss scale: 32768.0 | grad norm: 6.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      204/    1200 | consumed samples:         9792 | elapsed time per iteration (ms): 1436.8 | learning rate: 2.926E-06 | global batch size:    48 | lm loss: 6.325944E+00 | loss scale: 32768.0 | grad norm: 7.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      205/    1200 | consumed samples:         9840 | elapsed time per iteration (ms): 1444.2 | learning rate: 2.941E-06 | global batch size:    48 | lm loss: 6.315384E+00 | loss scale: 32768.0 | grad norm: 7.483 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      206/    1200 | consumed samples:         9888 | elapsed time per iteration (ms): 1442.2 | learning rate: 2.957E-06 | global batch size:    48 | lm loss: 6.222211E+00 | loss scale: 32768.0 | grad norm: 10.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      207/    1200 | consumed samples:         9936 | elapsed time per iteration (ms): 1469.7 | learning rate: 2.973E-06 | global batch size:    48 | lm loss: 6.294320E+00 | loss scale: 32768.0 | grad norm: 7.565 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      208/    1200 | consumed samples:         9984 | elapsed time per iteration (ms): 1444.9 | learning rate: 2.988E-06 | global batch size:    48 | lm loss: 6.309316E+00 | loss scale: 32768.0 | grad norm: 11.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      209/    1200 | consumed samples:        10032 | elapsed time per iteration (ms): 1448.5 | learning rate: 3.004E-06 | global batch size:    48 | lm loss: 6.284218E+00 | loss scale: 32768.0 | grad norm: 10.344 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      210/    1200 | consumed samples:        10080 | elapsed time per iteration (ms): 1439.6 | learning rate: 3.020E-06 | global batch size:    48 | lm loss: 6.253360E+00 | loss scale: 32768.0 | grad norm: 5.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      211/    1200 | consumed samples:        10128 | elapsed time per iteration (ms): 1438.8 | learning rate: 3.036E-06 | global batch size:    48 | lm loss: 6.251384E+00 | loss scale: 32768.0 | grad norm: 5.970 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      212/    1200 | consumed samples:        10176 | elapsed time per iteration (ms): 1437.4 | learning rate: 3.051E-06 | global batch size:    48 | lm loss: 6.235586E+00 | loss scale: 32768.0 | grad norm: 5.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      213/    1200 | consumed samples:        10224 | elapsed time per iteration (ms): 1441.0 | learning rate: 3.067E-06 | global batch size:    48 | lm loss: 6.259884E+00 | loss scale: 32768.0 | grad norm: 5.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      214/    1200 | consumed samples:        10272 | elapsed time per iteration (ms): 1505.7 | learning rate: 3.083E-06 | global batch size:    48 | lm loss: 6.206426E+00 | loss scale: 32768.0 | grad norm: 5.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      215/    1200 | consumed samples:        10320 | elapsed time per iteration (ms): 1440.4 | learning rate: 3.099E-06 | global batch size:    48 | lm loss: 6.203533E+00 | loss scale: 32768.0 | grad norm: 5.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      216/    1200 | consumed samples:        10368 | elapsed time per iteration (ms): 1526.3 | learning rate: 3.114E-06 | global batch size:    48 | lm loss: 6.135100E+00 | loss scale: 32768.0 | grad norm: 4.324 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      217/    1200 | consumed samples:        10416 | elapsed time per iteration (ms): 1443.3 | learning rate: 3.130E-06 | global batch size:    48 | lm loss: 6.177822E+00 | loss scale: 32768.0 | grad norm: 5.643 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      218/    1200 | consumed samples:        10464 | elapsed time per iteration (ms): 1442.9 | learning rate: 3.146E-06 | global batch size:    48 | lm loss: 6.248650E+00 | loss scale: 32768.0 | grad norm: 6.365 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      219/    1200 | consumed samples:        10512 | elapsed time per iteration (ms): 1439.7 | learning rate: 3.161E-06 | global batch size:    48 | lm loss: 6.210133E+00 | loss scale: 32768.0 | grad norm: 5.253 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      220/    1200 | consumed samples:        10560 | elapsed time per iteration (ms): 1439.2 | learning rate: 3.177E-06 | global batch size:    48 | lm loss: 6.228437E+00 | loss scale: 32768.0 | grad norm: 4.277 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      221/    1200 | consumed samples:        10608 | elapsed time per iteration (ms): 1443.4 | learning rate: 3.193E-06 | global batch size:    48 | lm loss: 6.151637E+00 | loss scale: 32768.0 | grad norm: 5.370 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      222/    1200 | consumed samples:        10656 | elapsed time per iteration (ms): 1438.0 | learning rate: 3.209E-06 | global batch size:    48 | lm loss: 6.175426E+00 | loss scale: 32768.0 | grad norm: 6.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      223/    1200 | consumed samples:        10704 | elapsed time per iteration (ms): 1438.9 | learning rate: 3.224E-06 | global batch size:    48 | lm loss: 6.167981E+00 | loss scale: 32768.0 | grad norm: 5.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      224/    1200 | consumed samples:        10752 | elapsed time per iteration (ms): 1437.7 | learning rate: 3.240E-06 | global batch size:    48 | lm loss: 6.113436E+00 | loss scale: 32768.0 | grad norm: 4.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      225/    1200 | consumed samples:        10800 | elapsed time per iteration (ms): 1447.6 | learning rate: 3.256E-06 | global batch size:    48 | lm loss: 6.168806E+00 | loss scale: 32768.0 | grad norm: 4.330 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      226/    1200 | consumed samples:        10848 | elapsed time per iteration (ms): 1437.6 | learning rate: 3.272E-06 | global batch size:    48 | lm loss: 6.113297E+00 | loss scale: 32768.0 | grad norm: 5.235 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      227/    1200 | consumed samples:        10896 | elapsed time per iteration (ms): 1440.4 | learning rate: 3.287E-06 | global batch size:    48 | lm loss: 6.086957E+00 | loss scale: 32768.0 | grad norm: 5.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      228/    1200 | consumed samples:        10944 | elapsed time per iteration (ms): 1437.1 | learning rate: 3.303E-06 | global batch size:    48 | lm loss: 6.159265E+00 | loss scale: 32768.0 | grad norm: 7.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      229/    1200 | consumed samples:        10992 | elapsed time per iteration (ms): 1443.8 | learning rate: 3.319E-06 | global batch size:    48 | lm loss: 6.129413E+00 | loss scale: 32768.0 | grad norm: 6.617 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      230/    1200 | consumed samples:        11040 | elapsed time per iteration (ms): 1438.8 | learning rate: 3.334E-06 | global batch size:    48 | lm loss: 6.174271E+00 | loss scale: 32768.0 | grad norm: 5.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      231/    1200 | consumed samples:        11088 | elapsed time per iteration (ms): 1566.5 | learning rate: 3.350E-06 | global batch size:    48 | lm loss: 6.123535E+00 | loss scale: 32768.0 | grad norm: 4.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      232/    1200 | consumed samples:        11136 | elapsed time per iteration (ms): 1859.7 | learning rate: 3.366E-06 | global batch size:    48 | lm loss: 6.152833E+00 | loss scale: 32768.0 | grad norm: 5.050 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      233/    1200 | consumed samples:        11184 | elapsed time per iteration (ms): 1949.2 | learning rate: 3.382E-06 | global batch size:    48 | lm loss: 6.070405E+00 | loss scale: 32768.0 | grad norm: 5.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      234/    1200 | consumed samples:        11232 | elapsed time per iteration (ms): 1899.5 | learning rate: 3.397E-06 | global batch size:    48 | lm loss: 6.124052E+00 | loss scale: 32768.0 | grad norm: 6.869 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      235/    1200 | consumed samples:        11280 | elapsed time per iteration (ms): 1897.5 | learning rate: 3.413E-06 | global batch size:    48 | lm loss: 6.040794E+00 | loss scale: 32768.0 | grad norm: 5.080 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      236/    1200 | consumed samples:        11328 | elapsed time per iteration (ms): 1899.8 | learning rate: 3.429E-06 | global batch size:    48 | lm loss: 6.048243E+00 | loss scale: 32768.0 | grad norm: 4.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      237/    1200 | consumed samples:        11376 | elapsed time per iteration (ms): 1899.5 | learning rate: 3.445E-06 | global batch size:    48 | lm loss: 6.070652E+00 | loss scale: 32768.0 | grad norm: 4.225 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      238/    1200 | consumed samples:        11424 | elapsed time per iteration (ms): 1899.3 | learning rate: 3.460E-06 | global batch size:    48 | lm loss: 6.084604E+00 | loss scale: 32768.0 | grad norm: 3.638 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      239/    1200 | consumed samples:        11472 | elapsed time per iteration (ms): 1901.7 | learning rate: 3.476E-06 | global batch size:    48 | lm loss: 6.058610E+00 | loss scale: 32768.0 | grad norm: 4.293 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      240/    1200 | consumed samples:        11520 | elapsed time per iteration (ms): 1897.7 | learning rate: 3.492E-06 | global batch size:    48 | lm loss: 6.064327E+00 | loss scale: 32768.0 | grad norm: 6.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      241/    1200 | consumed samples:        11568 | elapsed time per iteration (ms): 1906.3 | learning rate: 3.507E-06 | global batch size:    48 | lm loss: 6.101375E+00 | loss scale: 32768.0 | grad norm: 8.551 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      242/    1200 | consumed samples:        11616 | elapsed time per iteration (ms): 1895.8 | learning rate: 3.523E-06 | global batch size:    48 | lm loss: 6.098775E+00 | loss scale: 32768.0 | grad norm: 6.566 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      243/    1200 | consumed samples:        11664 | elapsed time per iteration (ms): 1897.8 | learning rate: 3.539E-06 | global batch size:    48 | lm loss: 6.120929E+00 | loss scale: 32768.0 | grad norm: 6.704 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      244/    1200 | consumed samples:        11712 | elapsed time per iteration (ms): 1897.9 | learning rate: 3.555E-06 | global batch size:    48 | lm loss: 6.089368E+00 | loss scale: 32768.0 | grad norm: 5.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      245/    1200 | consumed samples:        11760 | elapsed time per iteration (ms): 1901.8 | learning rate: 3.570E-06 | global batch size:    48 | lm loss: 6.004448E+00 | loss scale: 32768.0 | grad norm: 6.155 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      246/    1200 | consumed samples:        11808 | elapsed time per iteration (ms): 1905.3 | learning rate: 3.586E-06 | global batch size:    48 | lm loss: 6.116600E+00 | loss scale: 32768.0 | grad norm: 9.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      247/    1200 | consumed samples:        11856 | elapsed time per iteration (ms): 1902.9 | learning rate: 3.602E-06 | global batch size:    48 | lm loss: 6.171491E+00 | loss scale: 32768.0 | grad norm: 9.125 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      248/    1200 | consumed samples:        11904 | elapsed time per iteration (ms): 1896.5 | learning rate: 3.618E-06 | global batch size:    48 | lm loss: 6.139465E+00 | loss scale: 32768.0 | grad norm: 4.781 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      249/    1200 | consumed samples:        11952 | elapsed time per iteration (ms): 1905.3 | learning rate: 3.633E-06 | global batch size:    48 | lm loss: 6.052494E+00 | loss scale: 32768.0 | grad norm: 5.222 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      250/    1200 | consumed samples:        12000 | elapsed time per iteration (ms): 1899.7 | learning rate: 3.649E-06 | global batch size:    48 | lm loss: 6.121558E+00 | loss scale: 32768.0 | grad norm: 5.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      251/    1200 | consumed samples:        12048 | elapsed time per iteration (ms): 1899.8 | learning rate: 3.665E-06 | global batch size:    48 | lm loss: 6.098868E+00 | loss scale: 32768.0 | grad norm: 6.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      252/    1200 | consumed samples:        12096 | elapsed time per iteration (ms): 1903.0 | learning rate: 3.681E-06 | global batch size:    48 | lm loss: 6.131411E+00 | loss scale: 32768.0 | grad norm: 11.226 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      253/    1200 | consumed samples:        12144 | elapsed time per iteration (ms): 1915.5 | learning rate: 3.696E-06 | global batch size:    48 | lm loss: 6.091784E+00 | loss scale: 32768.0 | grad norm: 10.915 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      254/    1200 | consumed samples:        12192 | elapsed time per iteration (ms): 1896.9 | learning rate: 3.712E-06 | global batch size:    48 | lm loss: 6.112297E+00 | loss scale: 32768.0 | grad norm: 5.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      255/    1200 | consumed samples:        12240 | elapsed time per iteration (ms): 1896.2 | learning rate: 3.728E-06 | global batch size:    48 | lm loss: 6.090653E+00 | loss scale: 32768.0 | grad norm: 7.108 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      256/    1200 | consumed samples:        12288 | elapsed time per iteration (ms): 1900.2 | learning rate: 3.743E-06 | global batch size:    48 | lm loss: 6.071641E+00 | loss scale: 32768.0 | grad norm: 7.834 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      257/    1200 | consumed samples:        12336 | elapsed time per iteration (ms): 1898.2 | learning rate: 3.759E-06 | global batch size:    48 | lm loss: 6.094011E+00 | loss scale: 32768.0 | grad norm: 6.921 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      258/    1200 | consumed samples:        12384 | elapsed time per iteration (ms): 1899.5 | learning rate: 3.775E-06 | global batch size:    48 | lm loss: 6.039844E+00 | loss scale: 32768.0 | grad norm: 6.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      259/    1200 | consumed samples:        12432 | elapsed time per iteration (ms): 1900.3 | learning rate: 3.791E-06 | global batch size:    48 | lm loss: 6.096912E+00 | loss scale: 32768.0 | grad norm: 7.231 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      260/    1200 | consumed samples:        12480 | elapsed time per iteration (ms): 1899.6 | learning rate: 3.806E-06 | global batch size:    48 | lm loss: 6.096464E+00 | loss scale: 32768.0 | grad norm: 6.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      261/    1200 | consumed samples:        12528 | elapsed time per iteration (ms): 1900.5 | learning rate: 3.822E-06 | global batch size:    48 | lm loss: 6.040856E+00 | loss scale: 32768.0 | grad norm: 5.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      262/    1200 | consumed samples:        12576 | elapsed time per iteration (ms): 1898.9 | learning rate: 3.838E-06 | global batch size:    48 | lm loss: 6.034122E+00 | loss scale: 32768.0 | grad norm: 4.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      263/    1200 | consumed samples:        12624 | elapsed time per iteration (ms): 1896.9 | learning rate: 3.854E-06 | global batch size:    48 | lm loss: 6.054517E+00 | loss scale: 32768.0 | grad norm: 4.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      264/    1200 | consumed samples:        12672 | elapsed time per iteration (ms): 1899.8 | learning rate: 3.869E-06 | global batch size:    48 | lm loss: 6.017873E+00 | loss scale: 32768.0 | grad norm: 4.371 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      265/    1200 | consumed samples:        12720 | elapsed time per iteration (ms): 1905.3 | learning rate: 3.885E-06 | global batch size:    48 | lm loss: 6.104542E+00 | loss scale: 32768.0 | grad norm: 4.363 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      266/    1200 | consumed samples:        12768 | elapsed time per iteration (ms): 1899.7 | learning rate: 3.901E-06 | global batch size:    48 | lm loss: 5.953461E+00 | loss scale: 32768.0 | grad norm: 4.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      267/    1200 | consumed samples:        12816 | elapsed time per iteration (ms): 1899.5 | learning rate: 3.916E-06 | global batch size:    48 | lm loss: 5.941144E+00 | loss scale: 32768.0 | grad norm: 3.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      268/    1200 | consumed samples:        12864 | elapsed time per iteration (ms): 1898.8 | learning rate: 3.932E-06 | global batch size:    48 | lm loss: 6.012745E+00 | loss scale: 32768.0 | grad norm: 3.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      269/    1200 | consumed samples:        12912 | elapsed time per iteration (ms): 2167.0 | learning rate: 3.948E-06 | global batch size:    48 | lm loss: 5.973140E+00 | loss scale: 32768.0 | grad norm: 4.050 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      270/    1200 | consumed samples:        12960 | elapsed time per iteration (ms): 1895.4 | learning rate: 3.964E-06 | global batch size:    48 | lm loss: 6.036755E+00 | loss scale: 32768.0 | grad norm: 4.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      271/    1200 | consumed samples:        13008 | elapsed time per iteration (ms): 1899.6 | learning rate: 3.979E-06 | global batch size:    48 | lm loss: 6.071637E+00 | loss scale: 32768.0 | grad norm: 5.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      272/    1200 | consumed samples:        13056 | elapsed time per iteration (ms): 1897.5 | learning rate: 3.995E-06 | global batch size:    48 | lm loss: 6.062474E+00 | loss scale: 32768.0 | grad norm: 5.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      273/    1200 | consumed samples:        13104 | elapsed time per iteration (ms): 1904.3 | learning rate: 4.011E-06 | global batch size:    48 | lm loss: 5.944879E+00 | loss scale: 32768.0 | grad norm: 5.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      274/    1200 | consumed samples:        13152 | elapsed time per iteration (ms): 1902.5 | learning rate: 4.027E-06 | global batch size:    48 | lm loss: 5.912902E+00 | loss scale: 32768.0 | grad norm: 5.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      275/    1200 | consumed samples:        13200 | elapsed time per iteration (ms): 1899.9 | learning rate: 4.042E-06 | global batch size:    48 | lm loss: 5.989179E+00 | loss scale: 32768.0 | grad norm: 4.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      276/    1200 | consumed samples:        13248 | elapsed time per iteration (ms): 1902.3 | learning rate: 4.058E-06 | global batch size:    48 | lm loss: 5.928495E+00 | loss scale: 32768.0 | grad norm: 4.987 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      277/    1200 | consumed samples:        13296 | elapsed time per iteration (ms): 1900.8 | learning rate: 4.074E-06 | global batch size:    48 | lm loss: 5.956337E+00 | loss scale: 32768.0 | grad norm: 4.056 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      278/    1200 | consumed samples:        13344 | elapsed time per iteration (ms): 1898.5 | learning rate: 4.089E-06 | global batch size:    48 | lm loss: 6.052391E+00 | loss scale: 32768.0 | grad norm: 4.351 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      279/    1200 | consumed samples:        13392 | elapsed time per iteration (ms): 1894.0 | learning rate: 4.105E-06 | global batch size:    48 | lm loss: 5.949574E+00 | loss scale: 32768.0 | grad norm: 5.354 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      280/    1200 | consumed samples:        13440 | elapsed time per iteration (ms): 1898.1 | learning rate: 4.121E-06 | global batch size:    48 | lm loss: 5.952845E+00 | loss scale: 32768.0 | grad norm: 5.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      281/    1200 | consumed samples:        13488 | elapsed time per iteration (ms): 1902.1 | learning rate: 4.137E-06 | global batch size:    48 | lm loss: 5.926060E+00 | loss scale: 32768.0 | grad norm: 6.293 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      282/    1200 | consumed samples:        13536 | elapsed time per iteration (ms): 1901.0 | learning rate: 4.152E-06 | global batch size:    48 | lm loss: 5.984989E+00 | loss scale: 32768.0 | grad norm: 7.546 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      283/    1200 | consumed samples:        13584 | elapsed time per iteration (ms): 1908.4 | learning rate: 4.168E-06 | global batch size:    48 | lm loss: 5.974937E+00 | loss scale: 32768.0 | grad norm: 9.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      284/    1200 | consumed samples:        13632 | elapsed time per iteration (ms): 1898.0 | learning rate: 4.184E-06 | global batch size:    48 | lm loss: 6.096160E+00 | loss scale: 32768.0 | grad norm: 6.077 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      285/    1200 | consumed samples:        13680 | elapsed time per iteration (ms): 1902.7 | learning rate: 4.200E-06 | global batch size:    48 | lm loss: 5.927379E+00 | loss scale: 32768.0 | grad norm: 5.631 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      286/    1200 | consumed samples:        13728 | elapsed time per iteration (ms): 1894.4 | learning rate: 4.215E-06 | global batch size:    48 | lm loss: 5.960001E+00 | loss scale: 32768.0 | grad norm: 7.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      287/    1200 | consumed samples:        13776 | elapsed time per iteration (ms): 1897.4 | learning rate: 4.231E-06 | global batch size:    48 | lm loss: 5.947647E+00 | loss scale: 32768.0 | grad norm: 7.307 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      288/    1200 | consumed samples:        13824 | elapsed time per iteration (ms): 1896.7 | learning rate: 4.247E-06 | global batch size:    48 | lm loss: 5.954735E+00 | loss scale: 32768.0 | grad norm: 5.819 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      289/    1200 | consumed samples:        13872 | elapsed time per iteration (ms): 1902.8 | learning rate: 4.262E-06 | global batch size:    48 | lm loss: 5.981758E+00 | loss scale: 32768.0 | grad norm: 5.172 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      290/    1200 | consumed samples:        13920 | elapsed time per iteration (ms): 1899.5 | learning rate: 4.278E-06 | global batch size:    48 | lm loss: 5.901371E+00 | loss scale: 32768.0 | grad norm: 3.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      291/    1200 | consumed samples:        13968 | elapsed time per iteration (ms): 1900.7 | learning rate: 4.294E-06 | global batch size:    48 | lm loss: 5.962683E+00 | loss scale: 32768.0 | grad norm: 4.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      292/    1200 | consumed samples:        14016 | elapsed time per iteration (ms): 1900.2 | learning rate: 4.310E-06 | global batch size:    48 | lm loss: 5.985707E+00 | loss scale: 32768.0 | grad norm: 4.747 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      293/    1200 | consumed samples:        14064 | elapsed time per iteration (ms): 1908.3 | learning rate: 4.325E-06 | global batch size:    48 | lm loss: 5.844438E+00 | loss scale: 32768.0 | grad norm: 5.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      294/    1200 | consumed samples:        14112 | elapsed time per iteration (ms): 1897.1 | learning rate: 4.341E-06 | global batch size:    48 | lm loss: 5.918741E+00 | loss scale: 32768.0 | grad norm: 5.436 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      295/    1200 | consumed samples:        14160 | elapsed time per iteration (ms): 1897.2 | learning rate: 4.357E-06 | global batch size:    48 | lm loss: 5.915321E+00 | loss scale: 32768.0 | grad norm: 4.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      296/    1200 | consumed samples:        14208 | elapsed time per iteration (ms): 1896.6 | learning rate: 4.373E-06 | global batch size:    48 | lm loss: 5.893447E+00 | loss scale: 32768.0 | grad norm: 4.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      297/    1200 | consumed samples:        14256 | elapsed time per iteration (ms): 1903.0 | learning rate: 4.388E-06 | global batch size:    48 | lm loss: 5.950523E+00 | loss scale: 32768.0 | grad norm: 4.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      298/    1200 | consumed samples:        14304 | elapsed time per iteration (ms): 1895.5 | learning rate: 4.404E-06 | global batch size:    48 | lm loss: 5.911525E+00 | loss scale: 32768.0 | grad norm: 3.389 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      299/    1200 | consumed samples:        14352 | elapsed time per iteration (ms): 1899.4 | learning rate: 4.420E-06 | global batch size:    48 | lm loss: 5.950067E+00 | loss scale: 32768.0 | grad norm: 4.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      300/    1200 | consumed samples:        14400 | elapsed time per iteration (ms): 1897.6 | learning rate: 4.435E-06 | global batch size:    48 | lm loss: 5.925467E+00 | loss scale: 32768.0 | grad norm: 4.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      301/    1200 | consumed samples:        14448 | elapsed time per iteration (ms): 1821.8 | learning rate: 4.451E-06 | global batch size:    48 | lm loss: 5.907159E+00 | loss scale: 32768.0 | grad norm: 4.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      302/    1200 | consumed samples:        14496 | elapsed time per iteration (ms): 1563.5 | learning rate: 4.467E-06 | global batch size:    48 | lm loss: 5.872791E+00 | loss scale: 32768.0 | grad norm: 5.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      303/    1200 | consumed samples:        14544 | elapsed time per iteration (ms): 1443.0 | learning rate: 4.483E-06 | global batch size:    48 | lm loss: 5.899029E+00 | loss scale: 32768.0 | grad norm: 4.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      304/    1200 | consumed samples:        14592 | elapsed time per iteration (ms): 1436.0 | learning rate: 4.498E-06 | global batch size:    48 | lm loss: 5.927730E+00 | loss scale: 32768.0 | grad norm: 4.292 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      305/    1200 | consumed samples:        14640 | elapsed time per iteration (ms): 1448.1 | learning rate: 4.514E-06 | global batch size:    48 | lm loss: 5.797363E+00 | loss scale: 32768.0 | grad norm: 4.148 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      306/    1200 | consumed samples:        14688 | elapsed time per iteration (ms): 1437.9 | learning rate: 4.530E-06 | global batch size:    48 | lm loss: 5.889336E+00 | loss scale: 32768.0 | grad norm: 4.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      307/    1200 | consumed samples:        14736 | elapsed time per iteration (ms): 1438.5 | learning rate: 4.546E-06 | global batch size:    48 | lm loss: 5.836386E+00 | loss scale: 32768.0 | grad norm: 4.106 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      308/    1200 | consumed samples:        14784 | elapsed time per iteration (ms): 1439.0 | learning rate: 4.561E-06 | global batch size:    48 | lm loss: 5.897586E+00 | loss scale: 32768.0 | grad norm: 4.012 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      309/    1200 | consumed samples:        14832 | elapsed time per iteration (ms): 1444.1 | learning rate: 4.577E-06 | global batch size:    48 | lm loss: 5.887231E+00 | loss scale: 32768.0 | grad norm: 3.496 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      310/    1200 | consumed samples:        14880 | elapsed time per iteration (ms): 1443.4 | learning rate: 4.593E-06 | global batch size:    48 | lm loss: 5.834555E+00 | loss scale: 32768.0 | grad norm: 3.528 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      311/    1200 | consumed samples:        14928 | elapsed time per iteration (ms): 1443.4 | learning rate: 4.609E-06 | global batch size:    48 | lm loss: 5.808273E+00 | loss scale: 32768.0 | grad norm: 3.375 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      312/    1200 | consumed samples:        14976 | elapsed time per iteration (ms): 1439.1 | learning rate: 4.624E-06 | global batch size:    48 | lm loss: 5.859552E+00 | loss scale: 32768.0 | grad norm: 3.520 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      313/    1200 | consumed samples:        15024 | elapsed time per iteration (ms): 1443.3 | learning rate: 4.640E-06 | global batch size:    48 | lm loss: 5.908733E+00 | loss scale: 32768.0 | grad norm: 4.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      314/    1200 | consumed samples:        15072 | elapsed time per iteration (ms): 1440.2 | learning rate: 4.656E-06 | global batch size:    48 | lm loss: 5.834089E+00 | loss scale: 32768.0 | grad norm: 4.936 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      315/    1200 | consumed samples:        15120 | elapsed time per iteration (ms): 1439.5 | learning rate: 4.671E-06 | global batch size:    48 | lm loss: 5.975460E+00 | loss scale: 32768.0 | grad norm: 5.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      316/    1200 | consumed samples:        15168 | elapsed time per iteration (ms): 1438.6 | learning rate: 4.687E-06 | global batch size:    48 | lm loss: 5.813978E+00 | loss scale: 32768.0 | grad norm: 5.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      317/    1200 | consumed samples:        15216 | elapsed time per iteration (ms): 1442.3 | learning rate: 4.703E-06 | global batch size:    48 | lm loss: 5.804312E+00 | loss scale: 32768.0 | grad norm: 4.719 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      318/    1200 | consumed samples:        15264 | elapsed time per iteration (ms): 1439.6 | learning rate: 4.719E-06 | global batch size:    48 | lm loss: 5.821070E+00 | loss scale: 32768.0 | grad norm: 5.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      319/    1200 | consumed samples:        15312 | elapsed time per iteration (ms): 1438.9 | learning rate: 4.734E-06 | global batch size:    48 | lm loss: 5.843206E+00 | loss scale: 32768.0 | grad norm: 5.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      320/    1200 | consumed samples:        15360 | elapsed time per iteration (ms): 1438.4 | learning rate: 4.750E-06 | global batch size:    48 | lm loss: 5.839746E+00 | loss scale: 32768.0 | grad norm: 4.920 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      321/    1200 | consumed samples:        15408 | elapsed time per iteration (ms): 1443.7 | learning rate: 4.766E-06 | global batch size:    48 | lm loss: 5.827675E+00 | loss scale: 32768.0 | grad norm: 5.050 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      322/    1200 | consumed samples:        15456 | elapsed time per iteration (ms): 1438.8 | learning rate: 4.782E-06 | global batch size:    48 | lm loss: 5.800811E+00 | loss scale: 32768.0 | grad norm: 4.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      323/    1200 | consumed samples:        15504 | elapsed time per iteration (ms): 1441.7 | learning rate: 4.797E-06 | global batch size:    48 | lm loss: 5.842760E+00 | loss scale: 32768.0 | grad norm: 3.798 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      324/    1200 | consumed samples:        15552 | elapsed time per iteration (ms): 1438.2 | learning rate: 4.813E-06 | global batch size:    48 | lm loss: 5.867542E+00 | loss scale: 32768.0 | grad norm: 4.855 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      325/    1200 | consumed samples:        15600 | elapsed time per iteration (ms): 1445.7 | learning rate: 4.829E-06 | global batch size:    48 | lm loss: 5.811225E+00 | loss scale: 32768.0 | grad norm: 5.144 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      326/    1200 | consumed samples:        15648 | elapsed time per iteration (ms): 1441.2 | learning rate: 4.844E-06 | global batch size:    48 | lm loss: 5.833304E+00 | loss scale: 32768.0 | grad norm: 5.541 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      327/    1200 | consumed samples:        15696 | elapsed time per iteration (ms): 1439.9 | learning rate: 4.860E-06 | global batch size:    48 | lm loss: 5.824872E+00 | loss scale: 32768.0 | grad norm: 4.055 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      328/    1200 | consumed samples:        15744 | elapsed time per iteration (ms): 1441.7 | learning rate: 4.876E-06 | global batch size:    48 | lm loss: 5.856164E+00 | loss scale: 32768.0 | grad norm: 4.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      329/    1200 | consumed samples:        15792 | elapsed time per iteration (ms): 1442.3 | learning rate: 4.892E-06 | global batch size:    48 | lm loss: 5.825955E+00 | loss scale: 32768.0 | grad norm: 4.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      330/    1200 | consumed samples:        15840 | elapsed time per iteration (ms): 1438.2 | learning rate: 4.907E-06 | global batch size:    48 | lm loss: 5.877368E+00 | loss scale: 32768.0 | grad norm: 5.725 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      331/    1200 | consumed samples:        15888 | elapsed time per iteration (ms): 1439.3 | learning rate: 4.923E-06 | global batch size:    48 | lm loss: 5.823345E+00 | loss scale: 32768.0 | grad norm: 5.111 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      332/    1200 | consumed samples:        15936 | elapsed time per iteration (ms): 1435.0 | learning rate: 4.939E-06 | global batch size:    48 | lm loss: 5.853574E+00 | loss scale: 32768.0 | grad norm: 4.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      333/    1200 | consumed samples:        15984 | elapsed time per iteration (ms): 1441.9 | learning rate: 4.955E-06 | global batch size:    48 | lm loss: 5.753589E+00 | loss scale: 32768.0 | grad norm: 4.294 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      334/    1200 | consumed samples:        16032 | elapsed time per iteration (ms): 1436.2 | learning rate: 4.970E-06 | global batch size:    48 | lm loss: 5.879999E+00 | loss scale: 32768.0 | grad norm: 3.651 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      335/    1200 | consumed samples:        16080 | elapsed time per iteration (ms): 1438.9 | learning rate: 4.986E-06 | global batch size:    48 | lm loss: 5.821210E+00 | loss scale: 32768.0 | grad norm: 3.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      336/    1200 | consumed samples:        16128 | elapsed time per iteration (ms): 1438.2 | learning rate: 5.002E-06 | global batch size:    48 | lm loss: 5.813470E+00 | loss scale: 32768.0 | grad norm: 3.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      337/    1200 | consumed samples:        16176 | elapsed time per iteration (ms): 1446.8 | learning rate: 5.017E-06 | global batch size:    48 | lm loss: 5.814229E+00 | loss scale: 32768.0 | grad norm: 3.951 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      338/    1200 | consumed samples:        16224 | elapsed time per iteration (ms): 1443.5 | learning rate: 5.033E-06 | global batch size:    48 | lm loss: 5.825589E+00 | loss scale: 32768.0 | grad norm: 5.161 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      339/    1200 | consumed samples:        16272 | elapsed time per iteration (ms): 1437.6 | learning rate: 5.049E-06 | global batch size:    48 | lm loss: 5.867177E+00 | loss scale: 32768.0 | grad norm: 4.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      340/    1200 | consumed samples:        16320 | elapsed time per iteration (ms): 1446.3 | learning rate: 5.065E-06 | global batch size:    48 | lm loss: 5.879012E+00 | loss scale: 32768.0 | grad norm: 4.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      341/    1200 | consumed samples:        16368 | elapsed time per iteration (ms): 3856.6 | learning rate: 5.080E-06 | global batch size:    48 | lm loss: 5.816304E+00 | loss scale: 32768.0 | grad norm: 4.377 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      342/    1200 | consumed samples:        16416 | elapsed time per iteration (ms): 3819.7 | learning rate: 5.096E-06 | global batch size:    48 | lm loss: 5.843323E+00 | loss scale: 32768.0 | grad norm: 4.929 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      343/    1200 | consumed samples:        16464 | elapsed time per iteration (ms): 3829.5 | learning rate: 5.112E-06 | global batch size:    48 | lm loss: 5.799352E+00 | loss scale: 32768.0 | grad norm: 4.222 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      344/    1200 | consumed samples:        16512 | elapsed time per iteration (ms): 3832.3 | learning rate: 5.128E-06 | global batch size:    48 | lm loss: 5.823757E+00 | loss scale: 32768.0 | grad norm: 4.355 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      345/    1200 | consumed samples:        16560 | elapsed time per iteration (ms): 3836.3 | learning rate: 5.143E-06 | global batch size:    48 | lm loss: 5.770958E+00 | loss scale: 32768.0 | grad norm: 4.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      346/    1200 | consumed samples:        16608 | elapsed time per iteration (ms): 3833.6 | learning rate: 5.159E-06 | global batch size:    48 | lm loss: 5.869867E+00 | loss scale: 32768.0 | grad norm: 4.143 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      347/    1200 | consumed samples:        16656 | elapsed time per iteration (ms): 3830.4 | learning rate: 5.175E-06 | global batch size:    48 | lm loss: 5.764000E+00 | loss scale: 32768.0 | grad norm: 3.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      348/    1200 | consumed samples:        16704 | elapsed time per iteration (ms): 3837.5 | learning rate: 5.190E-06 | global batch size:    48 | lm loss: 5.789070E+00 | loss scale: 32768.0 | grad norm: 3.337 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      349/    1200 | consumed samples:        16752 | elapsed time per iteration (ms): 3836.6 | learning rate: 5.206E-06 | global batch size:    48 | lm loss: 5.696212E+00 | loss scale: 32768.0 | grad norm: 3.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      350/    1200 | consumed samples:        16800 | elapsed time per iteration (ms): 3829.3 | learning rate: 5.222E-06 | global batch size:    48 | lm loss: 5.731609E+00 | loss scale: 32768.0 | grad norm: 3.500 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      351/    1200 | consumed samples:        16848 | elapsed time per iteration (ms): 3830.6 | learning rate: 5.238E-06 | global batch size:    48 | lm loss: 5.782121E+00 | loss scale: 32768.0 | grad norm: 3.460 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      352/    1200 | consumed samples:        16896 | elapsed time per iteration (ms): 3831.9 | learning rate: 5.253E-06 | global batch size:    48 | lm loss: 5.790254E+00 | loss scale: 32768.0 | grad norm: 3.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      353/    1200 | consumed samples:        16944 | elapsed time per iteration (ms): 3842.3 | learning rate: 5.269E-06 | global batch size:    48 | lm loss: 5.735473E+00 | loss scale: 32768.0 | grad norm: 3.263 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      354/    1200 | consumed samples:        16992 | elapsed time per iteration (ms): 3866.6 | learning rate: 5.285E-06 | global batch size:    48 | lm loss: 5.738227E+00 | loss scale: 32768.0 | grad norm: 3.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      355/    1200 | consumed samples:        17040 | elapsed time per iteration (ms): 3833.7 | learning rate: 5.301E-06 | global batch size:    48 | lm loss: 5.755273E+00 | loss scale: 32768.0 | grad norm: 4.112 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      356/    1200 | consumed samples:        17088 | elapsed time per iteration (ms): 3832.5 | learning rate: 5.316E-06 | global batch size:    48 | lm loss: 5.810371E+00 | loss scale: 32768.0 | grad norm: 3.764 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      357/    1200 | consumed samples:        17136 | elapsed time per iteration (ms): 3833.7 | learning rate: 5.332E-06 | global batch size:    48 | lm loss: 5.722843E+00 | loss scale: 32768.0 | grad norm: 4.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      358/    1200 | consumed samples:        17184 | elapsed time per iteration (ms): 3832.2 | learning rate: 5.348E-06 | global batch size:    48 | lm loss: 5.794830E+00 | loss scale: 32768.0 | grad norm: 6.139 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      359/    1200 | consumed samples:        17232 | elapsed time per iteration (ms): 3832.7 | learning rate: 5.363E-06 | global batch size:    48 | lm loss: 5.773038E+00 | loss scale: 32768.0 | grad norm: 4.787 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      360/    1200 | consumed samples:        17280 | elapsed time per iteration (ms): 3830.8 | learning rate: 5.379E-06 | global batch size:    48 | lm loss: 5.757912E+00 | loss scale: 32768.0 | grad norm: 3.770 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      361/    1200 | consumed samples:        17328 | elapsed time per iteration (ms): 3837.8 | learning rate: 5.395E-06 | global batch size:    48 | lm loss: 5.783825E+00 | loss scale: 32768.0 | grad norm: 3.516 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      362/    1200 | consumed samples:        17376 | elapsed time per iteration (ms): 3834.8 | learning rate: 5.411E-06 | global batch size:    48 | lm loss: 5.707795E+00 | loss scale: 32768.0 | grad norm: 4.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      363/    1200 | consumed samples:        17424 | elapsed time per iteration (ms): 3828.1 | learning rate: 5.426E-06 | global batch size:    48 | lm loss: 5.724976E+00 | loss scale: 32768.0 | grad norm: 3.902 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      364/    1200 | consumed samples:        17472 | elapsed time per iteration (ms): 3853.7 | learning rate: 5.442E-06 | global batch size:    48 | lm loss: 5.725680E+00 | loss scale: 32768.0 | grad norm: 3.593 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      365/    1200 | consumed samples:        17520 | elapsed time per iteration (ms): 3833.9 | learning rate: 5.458E-06 | global batch size:    48 | lm loss: 5.758311E+00 | loss scale: 32768.0 | grad norm: 3.597 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      366/    1200 | consumed samples:        17568 | elapsed time per iteration (ms): 3835.3 | learning rate: 5.474E-06 | global batch size:    48 | lm loss: 5.705781E+00 | loss scale: 32768.0 | grad norm: 4.150 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      367/    1200 | consumed samples:        17616 | elapsed time per iteration (ms): 3904.3 | learning rate: 5.489E-06 | global batch size:    48 | lm loss: 5.739178E+00 | loss scale: 32768.0 | grad norm: 4.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      368/    1200 | consumed samples:        17664 | elapsed time per iteration (ms): 3832.5 | learning rate: 5.505E-06 | global batch size:    48 | lm loss: 5.806935E+00 | loss scale: 32768.0 | grad norm: 4.091 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      369/    1200 | consumed samples:        17712 | elapsed time per iteration (ms): 3835.7 | learning rate: 5.521E-06 | global batch size:    48 | lm loss: 5.813251E+00 | loss scale: 32768.0 | grad norm: 3.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      370/    1200 | consumed samples:        17760 | elapsed time per iteration (ms): 3830.8 | learning rate: 5.536E-06 | global batch size:    48 | lm loss: 5.690470E+00 | loss scale: 32768.0 | grad norm: 3.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      371/    1200 | consumed samples:        17808 | elapsed time per iteration (ms): 3835.5 | learning rate: 5.552E-06 | global batch size:    48 | lm loss: 5.733400E+00 | loss scale: 32768.0 | grad norm: 3.257 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      372/    1200 | consumed samples:        17856 | elapsed time per iteration (ms): 3824.7 | learning rate: 5.568E-06 | global batch size:    48 | lm loss: 5.695306E+00 | loss scale: 32768.0 | grad norm: 3.235 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      373/    1200 | consumed samples:        17904 | elapsed time per iteration (ms): 3834.1 | learning rate: 5.584E-06 | global batch size:    48 | lm loss: 5.724460E+00 | loss scale: 32768.0 | grad norm: 3.322 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      374/    1200 | consumed samples:        17952 | elapsed time per iteration (ms): 3830.0 | learning rate: 5.599E-06 | global batch size:    48 | lm loss: 5.771717E+00 | loss scale: 32768.0 | grad norm: 3.572 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      375/    1200 | consumed samples:        18000 | elapsed time per iteration (ms): 3824.7 | learning rate: 5.615E-06 | global batch size:    48 | lm loss: 5.711411E+00 | loss scale: 32768.0 | grad norm: 3.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      376/    1200 | consumed samples:        18048 | elapsed time per iteration (ms): 3831.4 | learning rate: 5.631E-06 | global batch size:    48 | lm loss: 5.714411E+00 | loss scale: 32768.0 | grad norm: 3.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      377/    1200 | consumed samples:        18096 | elapsed time per iteration (ms): 3834.2 | learning rate: 5.647E-06 | global batch size:    48 | lm loss: 5.744404E+00 | loss scale: 32768.0 | grad norm: 3.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      378/    1200 | consumed samples:        18144 | elapsed time per iteration (ms): 3831.7 | learning rate: 5.662E-06 | global batch size:    48 | lm loss: 5.728218E+00 | loss scale: 32768.0 | grad norm: 3.824 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      379/    1200 | consumed samples:        18192 | elapsed time per iteration (ms): 3827.7 | learning rate: 5.678E-06 | global batch size:    48 | lm loss: 5.655318E+00 | loss scale: 32768.0 | grad norm: 3.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      380/    1200 | consumed samples:        18240 | elapsed time per iteration (ms): 3827.8 | learning rate: 5.694E-06 | global batch size:    48 | lm loss: 5.673652E+00 | loss scale: 32768.0 | grad norm: 3.782 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      381/    1200 | consumed samples:        18288 | elapsed time per iteration (ms): 3833.7 | learning rate: 5.710E-06 | global batch size:    48 | lm loss: 5.715662E+00 | loss scale: 32768.0 | grad norm: 4.368 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      382/    1200 | consumed samples:        18336 | elapsed time per iteration (ms): 3835.1 | learning rate: 5.725E-06 | global batch size:    48 | lm loss: 5.725752E+00 | loss scale: 32768.0 | grad norm: 4.146 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      383/    1200 | consumed samples:        18384 | elapsed time per iteration (ms): 3827.6 | learning rate: 5.741E-06 | global batch size:    48 | lm loss: 5.736157E+00 | loss scale: 32768.0 | grad norm: 3.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      384/    1200 | consumed samples:        18432 | elapsed time per iteration (ms): 3834.5 | learning rate: 5.757E-06 | global batch size:    48 | lm loss: 5.767841E+00 | loss scale: 32768.0 | grad norm: 2.928 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      385/    1200 | consumed samples:        18480 | elapsed time per iteration (ms): 3838.1 | learning rate: 5.772E-06 | global batch size:    48 | lm loss: 5.803384E+00 | loss scale: 32768.0 | grad norm: 3.283 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      386/    1200 | consumed samples:        18528 | elapsed time per iteration (ms): 3832.5 | learning rate: 5.788E-06 | global batch size:    48 | lm loss: 5.690155E+00 | loss scale: 32768.0 | grad norm: 3.556 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      387/    1200 | consumed samples:        18576 | elapsed time per iteration (ms): 3828.7 | learning rate: 5.804E-06 | global batch size:    48 | lm loss: 5.744367E+00 | loss scale: 32768.0 | grad norm: 3.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      388/    1200 | consumed samples:        18624 | elapsed time per iteration (ms): 3829.6 | learning rate: 5.820E-06 | global batch size:    48 | lm loss: 5.752934E+00 | loss scale: 32768.0 | grad norm: 4.030 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      389/    1200 | consumed samples:        18672 | elapsed time per iteration (ms): 3834.4 | learning rate: 5.835E-06 | global batch size:    48 | lm loss: 5.760572E+00 | loss scale: 32768.0 | grad norm: 4.271 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      390/    1200 | consumed samples:        18720 | elapsed time per iteration (ms): 3828.6 | learning rate: 5.851E-06 | global batch size:    48 | lm loss: 5.821915E+00 | loss scale: 32768.0 | grad norm: 3.040 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      391/    1200 | consumed samples:        18768 | elapsed time per iteration (ms): 3831.4 | learning rate: 5.867E-06 | global batch size:    48 | lm loss: 5.686707E+00 | loss scale: 32768.0 | grad norm: 3.380 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      392/    1200 | consumed samples:        18816 | elapsed time per iteration (ms): 3831.3 | learning rate: 5.883E-06 | global batch size:    48 | lm loss: 5.688040E+00 | loss scale: 32768.0 | grad norm: 3.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      393/    1200 | consumed samples:        18864 | elapsed time per iteration (ms): 3832.1 | learning rate: 5.898E-06 | global batch size:    48 | lm loss: 5.653856E+00 | loss scale: 32768.0 | grad norm: 3.375 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      394/    1200 | consumed samples:        18912 | elapsed time per iteration (ms): 3830.7 | learning rate: 5.914E-06 | global batch size:    48 | lm loss: 5.720714E+00 | loss scale: 32768.0 | grad norm: 3.559 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      395/    1200 | consumed samples:        18960 | elapsed time per iteration (ms): 3827.3 | learning rate: 5.930E-06 | global batch size:    48 | lm loss: 5.697584E+00 | loss scale: 32768.0 | grad norm: 3.753 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      396/    1200 | consumed samples:        19008 | elapsed time per iteration (ms): 3829.1 | learning rate: 5.945E-06 | global batch size:    48 | lm loss: 5.647975E+00 | loss scale: 32768.0 | grad norm: 3.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      397/    1200 | consumed samples:        19056 | elapsed time per iteration (ms): 3833.6 | learning rate: 5.961E-06 | global batch size:    48 | lm loss: 5.672589E+00 | loss scale: 32768.0 | grad norm: 4.351 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      398/    1200 | consumed samples:        19104 | elapsed time per iteration (ms): 3829.2 | learning rate: 5.977E-06 | global batch size:    48 | lm loss: 5.754165E+00 | loss scale: 32768.0 | grad norm: 4.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      399/    1200 | consumed samples:        19152 | elapsed time per iteration (ms): 3825.6 | learning rate: 5.993E-06 | global batch size:    48 | lm loss: 5.731679E+00 | loss scale: 32768.0 | grad norm: 4.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      400/    1200 | consumed samples:        19200 | elapsed time per iteration (ms): 3825.1 | learning rate: 6.008E-06 | global batch size:    48 | lm loss: 5.745016E+00 | loss scale: 32768.0 | grad norm: 3.749 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      401/    1200 | consumed samples:        19248 | elapsed time per iteration (ms): 3835.0 | learning rate: 6.024E-06 | global batch size:    48 | lm loss: 5.729112E+00 | loss scale: 32768.0 | grad norm: 3.495 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      402/    1200 | consumed samples:        19296 | elapsed time per iteration (ms): 3830.8 | learning rate: 6.040E-06 | global batch size:    48 | lm loss: 5.661695E+00 | loss scale: 32768.0 | grad norm: 3.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      403/    1200 | consumed samples:        19344 | elapsed time per iteration (ms): 3829.9 | learning rate: 6.056E-06 | global batch size:    48 | lm loss: 5.679279E+00 | loss scale: 32768.0 | grad norm: 2.733 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      404/    1200 | consumed samples:        19392 | elapsed time per iteration (ms): 3827.7 | learning rate: 6.071E-06 | global batch size:    48 | lm loss: 5.716458E+00 | loss scale: 32768.0 | grad norm: 3.211 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      405/    1200 | consumed samples:        19440 | elapsed time per iteration (ms): 3836.6 | learning rate: 6.087E-06 | global batch size:    48 | lm loss: 5.635450E+00 | loss scale: 32768.0 | grad norm: 2.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      406/    1200 | consumed samples:        19488 | elapsed time per iteration (ms): 3827.1 | learning rate: 6.103E-06 | global batch size:    48 | lm loss: 5.703502E+00 | loss scale: 32768.0 | grad norm: 3.337 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      407/    1200 | consumed samples:        19536 | elapsed time per iteration (ms): 3829.7 | learning rate: 6.118E-06 | global batch size:    48 | lm loss: 5.692499E+00 | loss scale: 32768.0 | grad norm: 2.939 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      408/    1200 | consumed samples:        19584 | elapsed time per iteration (ms): 3832.5 | learning rate: 6.134E-06 | global batch size:    48 | lm loss: 5.624832E+00 | loss scale: 32768.0 | grad norm: 3.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      409/    1200 | consumed samples:        19632 | elapsed time per iteration (ms): 3831.2 | learning rate: 6.150E-06 | global batch size:    48 | lm loss: 5.607938E+00 | loss scale: 32768.0 | grad norm: 3.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      410/    1200 | consumed samples:        19680 | elapsed time per iteration (ms): 3829.6 | learning rate: 6.166E-06 | global batch size:    48 | lm loss: 5.652136E+00 | loss scale: 32768.0 | grad norm: 2.809 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      411/    1200 | consumed samples:        19728 | elapsed time per iteration (ms): 3025.2 | learning rate: 6.181E-06 | global batch size:    48 | lm loss: 5.682523E+00 | loss scale: 32768.0 | grad norm: 2.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      412/    1200 | consumed samples:        19776 | elapsed time per iteration (ms): 1436.2 | learning rate: 6.197E-06 | global batch size:    48 | lm loss: 5.678947E+00 | loss scale: 32768.0 | grad norm: 2.940 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      413/    1200 | consumed samples:        19824 | elapsed time per iteration (ms): 1441.1 | learning rate: 6.213E-06 | global batch size:    48 | lm loss: 5.684196E+00 | loss scale: 32768.0 | grad norm: 3.021 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      414/    1200 | consumed samples:        19872 | elapsed time per iteration (ms): 1438.7 | learning rate: 6.229E-06 | global batch size:    48 | lm loss: 5.666877E+00 | loss scale: 32768.0 | grad norm: 3.309 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      415/    1200 | consumed samples:        19920 | elapsed time per iteration (ms): 1435.5 | learning rate: 6.244E-06 | global batch size:    48 | lm loss: 5.646106E+00 | loss scale: 32768.0 | grad norm: 3.451 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      416/    1200 | consumed samples:        19968 | elapsed time per iteration (ms): 1436.5 | learning rate: 6.260E-06 | global batch size:    48 | lm loss: 5.730768E+00 | loss scale: 32768.0 | grad norm: 3.172 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      417/    1200 | consumed samples:        20016 | elapsed time per iteration (ms): 1442.3 | learning rate: 6.276E-06 | global batch size:    48 | lm loss: 5.645908E+00 | loss scale: 32768.0 | grad norm: 4.057 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      418/    1200 | consumed samples:        20064 | elapsed time per iteration (ms): 1439.4 | learning rate: 6.291E-06 | global batch size:    48 | lm loss: 5.720718E+00 | loss scale: 32768.0 | grad norm: 3.923 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      419/    1200 | consumed samples:        20112 | elapsed time per iteration (ms): 1440.7 | learning rate: 6.307E-06 | global batch size:    48 | lm loss: 5.628225E+00 | loss scale: 32768.0 | grad norm: 2.924 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      420/    1200 | consumed samples:        20160 | elapsed time per iteration (ms): 1435.2 | learning rate: 6.323E-06 | global batch size:    48 | lm loss: 5.623701E+00 | loss scale: 32768.0 | grad norm: 2.853 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      421/    1200 | consumed samples:        20208 | elapsed time per iteration (ms): 1442.8 | learning rate: 6.339E-06 | global batch size:    48 | lm loss: 5.704160E+00 | loss scale: 32768.0 | grad norm: 2.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      422/    1200 | consumed samples:        20256 | elapsed time per iteration (ms): 1442.0 | learning rate: 6.354E-06 | global batch size:    48 | lm loss: 5.701680E+00 | loss scale: 32768.0 | grad norm: 2.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      423/    1200 | consumed samples:        20304 | elapsed time per iteration (ms): 1438.8 | learning rate: 6.370E-06 | global batch size:    48 | lm loss: 5.588583E+00 | loss scale: 32768.0 | grad norm: 3.063 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      424/    1200 | consumed samples:        20352 | elapsed time per iteration (ms): 1443.4 | learning rate: 6.386E-06 | global batch size:    48 | lm loss: 5.714014E+00 | loss scale: 32768.0 | grad norm: 3.166 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      425/    1200 | consumed samples:        20400 | elapsed time per iteration (ms): 1448.8 | learning rate: 6.402E-06 | global batch size:    48 | lm loss: 5.707849E+00 | loss scale: 32768.0 | grad norm: 3.570 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      426/    1200 | consumed samples:        20448 | elapsed time per iteration (ms): 1437.9 | learning rate: 6.417E-06 | global batch size:    48 | lm loss: 5.686821E+00 | loss scale: 32768.0 | grad norm: 3.147 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      427/    1200 | consumed samples:        20496 | elapsed time per iteration (ms): 1437.4 | learning rate: 6.433E-06 | global batch size:    48 | lm loss: 5.672740E+00 | loss scale: 32768.0 | grad norm: 3.230 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      428/    1200 | consumed samples:        20544 | elapsed time per iteration (ms): 1435.3 | learning rate: 6.449E-06 | global batch size:    48 | lm loss: 5.694137E+00 | loss scale: 32768.0 | grad norm: 4.285 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      429/    1200 | consumed samples:        20592 | elapsed time per iteration (ms): 1441.3 | learning rate: 6.464E-06 | global batch size:    48 | lm loss: 5.645247E+00 | loss scale: 32768.0 | grad norm: 4.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      430/    1200 | consumed samples:        20640 | elapsed time per iteration (ms): 1443.2 | learning rate: 6.480E-06 | global batch size:    48 | lm loss: 5.662036E+00 | loss scale: 32768.0 | grad norm: 3.175 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      431/    1200 | consumed samples:        20688 | elapsed time per iteration (ms): 1440.2 | learning rate: 6.496E-06 | global batch size:    48 | lm loss: 5.690090E+00 | loss scale: 32768.0 | grad norm: 2.763 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      432/    1200 | consumed samples:        20736 | elapsed time per iteration (ms): 1437.6 | learning rate: 6.512E-06 | global batch size:    48 | lm loss: 5.634439E+00 | loss scale: 32768.0 | grad norm: 3.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      433/    1200 | consumed samples:        20784 | elapsed time per iteration (ms): 1441.0 | learning rate: 6.527E-06 | global batch size:    48 | lm loss: 5.641184E+00 | loss scale: 32768.0 | grad norm: 2.777 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      434/    1200 | consumed samples:        20832 | elapsed time per iteration (ms): 1435.8 | learning rate: 6.543E-06 | global batch size:    48 | lm loss: 5.628600E+00 | loss scale: 32768.0 | grad norm: 2.667 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      435/    1200 | consumed samples:        20880 | elapsed time per iteration (ms): 1436.8 | learning rate: 6.559E-06 | global batch size:    48 | lm loss: 5.640873E+00 | loss scale: 32768.0 | grad norm: 2.583 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      436/    1200 | consumed samples:        20928 | elapsed time per iteration (ms): 1437.1 | learning rate: 6.575E-06 | global batch size:    48 | lm loss: 5.625315E+00 | loss scale: 32768.0 | grad norm: 2.429 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      437/    1200 | consumed samples:        20976 | elapsed time per iteration (ms): 1441.6 | learning rate: 6.590E-06 | global batch size:    48 | lm loss: 5.604040E+00 | loss scale: 32768.0 | grad norm: 2.340 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      438/    1200 | consumed samples:        21024 | elapsed time per iteration (ms): 1442.2 | learning rate: 6.606E-06 | global batch size:    48 | lm loss: 5.630689E+00 | loss scale: 32768.0 | grad norm: 2.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      439/    1200 | consumed samples:        21072 | elapsed time per iteration (ms): 1440.3 | learning rate: 6.622E-06 | global batch size:    48 | lm loss: 5.651751E+00 | loss scale: 32768.0 | grad norm: 3.269 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      440/    1200 | consumed samples:        21120 | elapsed time per iteration (ms): 1433.4 | learning rate: 6.638E-06 | global batch size:    48 | lm loss: 5.646007E+00 | loss scale: 32768.0 | grad norm: 3.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      441/    1200 | consumed samples:        21168 | elapsed time per iteration (ms): 1446.3 | learning rate: 6.653E-06 | global batch size:    48 | lm loss: 5.626797E+00 | loss scale: 32768.0 | grad norm: 4.195 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      442/    1200 | consumed samples:        21216 | elapsed time per iteration (ms): 1438.9 | learning rate: 6.669E-06 | global batch size:    48 | lm loss: 5.603151E+00 | loss scale: 32768.0 | grad norm: 3.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      443/    1200 | consumed samples:        21264 | elapsed time per iteration (ms): 1437.2 | learning rate: 6.685E-06 | global batch size:    48 | lm loss: 5.713499E+00 | loss scale: 32768.0 | grad norm: 3.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      444/    1200 | consumed samples:        21312 | elapsed time per iteration (ms): 1438.2 | learning rate: 6.700E-06 | global batch size:    48 | lm loss: 5.659294E+00 | loss scale: 32768.0 | grad norm: 3.168 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      445/    1200 | consumed samples:        21360 | elapsed time per iteration (ms): 1443.1 | learning rate: 6.716E-06 | global batch size:    48 | lm loss: 5.628641E+00 | loss scale: 32768.0 | grad norm: 3.262 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      446/    1200 | consumed samples:        21408 | elapsed time per iteration (ms): 1438.4 | learning rate: 6.732E-06 | global batch size:    48 | lm loss: 5.628781E+00 | loss scale: 32768.0 | grad norm: 2.898 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      447/    1200 | consumed samples:        21456 | elapsed time per iteration (ms): 1439.6 | learning rate: 6.748E-06 | global batch size:    48 | lm loss: 5.576871E+00 | loss scale: 32768.0 | grad norm: 2.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      448/    1200 | consumed samples:        21504 | elapsed time per iteration (ms): 1442.9 | learning rate: 6.763E-06 | global batch size:    48 | lm loss: 5.574460E+00 | loss scale: 32768.0 | grad norm: 2.992 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      449/    1200 | consumed samples:        21552 | elapsed time per iteration (ms): 1444.8 | learning rate: 6.779E-06 | global batch size:    48 | lm loss: 5.617723E+00 | loss scale: 32768.0 | grad norm: 2.792 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      450/    1200 | consumed samples:        21600 | elapsed time per iteration (ms): 1439.3 | learning rate: 6.795E-06 | global batch size:    48 | lm loss: 5.598690E+00 | loss scale: 32768.0 | grad norm: 2.555 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      451/    1200 | consumed samples:        21648 | elapsed time per iteration (ms): 1960.2 | learning rate: 6.811E-06 | global batch size:    48 | lm loss: 5.574014E+00 | loss scale: 32768.0 | grad norm: 2.755 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      452/    1200 | consumed samples:        21696 | elapsed time per iteration (ms): 2956.8 | learning rate: 6.826E-06 | global batch size:    48 | lm loss: 5.576641E+00 | loss scale: 32768.0 | grad norm: 2.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      453/    1200 | consumed samples:        21744 | elapsed time per iteration (ms): 2954.9 | learning rate: 6.842E-06 | global batch size:    48 | lm loss: 5.611227E+00 | loss scale: 32768.0 | grad norm: 2.817 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      454/    1200 | consumed samples:        21792 | elapsed time per iteration (ms): 2955.4 | learning rate: 6.858E-06 | global batch size:    48 | lm loss: 5.610435E+00 | loss scale: 32768.0 | grad norm: 2.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      455/    1200 | consumed samples:        21840 | elapsed time per iteration (ms): 2950.0 | learning rate: 6.873E-06 | global batch size:    48 | lm loss: 5.513263E+00 | loss scale: 32768.0 | grad norm: 2.754 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      456/    1200 | consumed samples:        21888 | elapsed time per iteration (ms): 2949.0 | learning rate: 6.889E-06 | global batch size:    48 | lm loss: 5.616284E+00 | loss scale: 32768.0 | grad norm: 2.866 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      457/    1200 | consumed samples:        21936 | elapsed time per iteration (ms): 2958.0 | learning rate: 6.905E-06 | global batch size:    48 | lm loss: 5.599335E+00 | loss scale: 32768.0 | grad norm: 2.591 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      458/    1200 | consumed samples:        21984 | elapsed time per iteration (ms): 2950.7 | learning rate: 6.921E-06 | global batch size:    48 | lm loss: 5.673486E+00 | loss scale: 32768.0 | grad norm: 3.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      459/    1200 | consumed samples:        22032 | elapsed time per iteration (ms): 2951.3 | learning rate: 6.936E-06 | global batch size:    48 | lm loss: 5.591667E+00 | loss scale: 32768.0 | grad norm: 2.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      460/    1200 | consumed samples:        22080 | elapsed time per iteration (ms): 2946.2 | learning rate: 6.952E-06 | global batch size:    48 | lm loss: 5.603834E+00 | loss scale: 32768.0 | grad norm: 2.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      461/    1200 | consumed samples:        22128 | elapsed time per iteration (ms): 2956.7 | learning rate: 6.968E-06 | global batch size:    48 | lm loss: 5.555145E+00 | loss scale: 32768.0 | grad norm: 2.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      462/    1200 | consumed samples:        22176 | elapsed time per iteration (ms): 2948.4 | learning rate: 6.984E-06 | global batch size:    48 | lm loss: 5.576209E+00 | loss scale: 32768.0 | grad norm: 3.184 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      463/    1200 | consumed samples:        22224 | elapsed time per iteration (ms): 2951.0 | learning rate: 6.999E-06 | global batch size:    48 | lm loss: 5.635021E+00 | loss scale: 32768.0 | grad norm: 2.800 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      464/    1200 | consumed samples:        22272 | elapsed time per iteration (ms): 2951.4 | learning rate: 7.015E-06 | global batch size:    48 | lm loss: 5.611012E+00 | loss scale: 32768.0 | grad norm: 2.775 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      465/    1200 | consumed samples:        22320 | elapsed time per iteration (ms): 2952.0 | learning rate: 7.031E-06 | global batch size:    48 | lm loss: 5.510139E+00 | loss scale: 32768.0 | grad norm: 2.328 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      466/    1200 | consumed samples:        22368 | elapsed time per iteration (ms): 2951.6 | learning rate: 7.046E-06 | global batch size:    48 | lm loss: 5.563522E+00 | loss scale: 32768.0 | grad norm: 2.772 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      467/    1200 | consumed samples:        22416 | elapsed time per iteration (ms): 2952.5 | learning rate: 7.062E-06 | global batch size:    48 | lm loss: 5.586092E+00 | loss scale: 32768.0 | grad norm: 2.728 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      468/    1200 | consumed samples:        22464 | elapsed time per iteration (ms): 2951.4 | learning rate: 7.078E-06 | global batch size:    48 | lm loss: 5.626607E+00 | loss scale: 32768.0 | grad norm: 2.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      469/    1200 | consumed samples:        22512 | elapsed time per iteration (ms): 2953.0 | learning rate: 7.094E-06 | global batch size:    48 | lm loss: 5.591762E+00 | loss scale: 32768.0 | grad norm: 2.386 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      470/    1200 | consumed samples:        22560 | elapsed time per iteration (ms): 2955.5 | learning rate: 7.109E-06 | global batch size:    48 | lm loss: 5.538215E+00 | loss scale: 32768.0 | grad norm: 2.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      471/    1200 | consumed samples:        22608 | elapsed time per iteration (ms): 2949.0 | learning rate: 7.125E-06 | global batch size:    48 | lm loss: 5.580388E+00 | loss scale: 32768.0 | grad norm: 2.890 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      472/    1200 | consumed samples:        22656 | elapsed time per iteration (ms): 2952.5 | learning rate: 7.141E-06 | global batch size:    48 | lm loss: 5.506944E+00 | loss scale: 32768.0 | grad norm: 2.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      473/    1200 | consumed samples:        22704 | elapsed time per iteration (ms): 2954.3 | learning rate: 7.157E-06 | global batch size:    48 | lm loss: 5.559358E+00 | loss scale: 32768.0 | grad norm: 2.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      474/    1200 | consumed samples:        22752 | elapsed time per iteration (ms): 2951.0 | learning rate: 7.172E-06 | global batch size:    48 | lm loss: 5.601879E+00 | loss scale: 32768.0 | grad norm: 2.791 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      475/    1200 | consumed samples:        22800 | elapsed time per iteration (ms): 2951.0 | learning rate: 7.188E-06 | global batch size:    48 | lm loss: 5.537947E+00 | loss scale: 32768.0 | grad norm: 2.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      476/    1200 | consumed samples:        22848 | elapsed time per iteration (ms): 2949.8 | learning rate: 7.204E-06 | global batch size:    48 | lm loss: 5.581597E+00 | loss scale: 32768.0 | grad norm: 2.216 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      477/    1200 | consumed samples:        22896 | elapsed time per iteration (ms): 2959.7 | learning rate: 7.219E-06 | global batch size:    48 | lm loss: 5.540847E+00 | loss scale: 32768.0 | grad norm: 2.247 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      478/    1200 | consumed samples:        22944 | elapsed time per iteration (ms): 2962.9 | learning rate: 7.235E-06 | global batch size:    48 | lm loss: 5.606577E+00 | loss scale: 32768.0 | grad norm: 2.329 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      479/    1200 | consumed samples:        22992 | elapsed time per iteration (ms): 2960.3 | learning rate: 7.251E-06 | global batch size:    48 | lm loss: 5.624497E+00 | loss scale: 32768.0 | grad norm: 2.259 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      480/    1200 | consumed samples:        23040 | elapsed time per iteration (ms): 2950.6 | learning rate: 7.267E-06 | global batch size:    48 | lm loss: 5.541713E+00 | loss scale: 32768.0 | grad norm: 2.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      481/    1200 | consumed samples:        23088 | elapsed time per iteration (ms): 2957.9 | learning rate: 7.282E-06 | global batch size:    48 | lm loss: 5.580543E+00 | loss scale: 32768.0 | grad norm: 2.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      482/    1200 | consumed samples:        23136 | elapsed time per iteration (ms): 2950.5 | learning rate: 7.298E-06 | global batch size:    48 | lm loss: 5.530124E+00 | loss scale: 32768.0 | grad norm: 2.188 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      483/    1200 | consumed samples:        23184 | elapsed time per iteration (ms): 2959.8 | learning rate: 7.314E-06 | global batch size:    48 | lm loss: 5.604270E+00 | loss scale: 32768.0 | grad norm: 2.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      484/    1200 | consumed samples:        23232 | elapsed time per iteration (ms): 2948.9 | learning rate: 7.330E-06 | global batch size:    48 | lm loss: 5.567405E+00 | loss scale: 32768.0 | grad norm: 2.555 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      485/    1200 | consumed samples:        23280 | elapsed time per iteration (ms): 2951.2 | learning rate: 7.345E-06 | global batch size:    48 | lm loss: 5.516803E+00 | loss scale: 32768.0 | grad norm: 2.332 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      486/    1200 | consumed samples:        23328 | elapsed time per iteration (ms): 2952.6 | learning rate: 7.361E-06 | global batch size:    48 | lm loss: 5.580444E+00 | loss scale: 32768.0 | grad norm: 2.156 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      487/    1200 | consumed samples:        23376 | elapsed time per iteration (ms): 2950.4 | learning rate: 7.377E-06 | global batch size:    48 | lm loss: 5.505378E+00 | loss scale: 32768.0 | grad norm: 2.218 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      488/    1200 | consumed samples:        23424 | elapsed time per iteration (ms): 2952.2 | learning rate: 7.392E-06 | global batch size:    48 | lm loss: 5.592422E+00 | loss scale: 32768.0 | grad norm: 2.204 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      489/    1200 | consumed samples:        23472 | elapsed time per iteration (ms): 2954.9 | learning rate: 7.408E-06 | global batch size:    48 | lm loss: 5.569568E+00 | loss scale: 32768.0 | grad norm: 2.169 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      490/    1200 | consumed samples:        23520 | elapsed time per iteration (ms): 2953.9 | learning rate: 7.424E-06 | global batch size:    48 | lm loss: 5.495521E+00 | loss scale: 32768.0 | grad norm: 2.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      491/    1200 | consumed samples:        23568 | elapsed time per iteration (ms): 2955.7 | learning rate: 7.440E-06 | global batch size:    48 | lm loss: 5.601617E+00 | loss scale: 32768.0 | grad norm: 2.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      492/    1200 | consumed samples:        23616 | elapsed time per iteration (ms): 2943.9 | learning rate: 7.455E-06 | global batch size:    48 | lm loss: 5.492599E+00 | loss scale: 32768.0 | grad norm: 2.724 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      493/    1200 | consumed samples:        23664 | elapsed time per iteration (ms): 2953.3 | learning rate: 7.471E-06 | global batch size:    48 | lm loss: 5.610180E+00 | loss scale: 32768.0 | grad norm: 2.705 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      494/    1200 | consumed samples:        23712 | elapsed time per iteration (ms): 2948.4 | learning rate: 7.487E-06 | global batch size:    48 | lm loss: 5.510631E+00 | loss scale: 32768.0 | grad norm: 2.445 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      495/    1200 | consumed samples:        23760 | elapsed time per iteration (ms): 2948.9 | learning rate: 7.503E-06 | global batch size:    48 | lm loss: 5.587091E+00 | loss scale: 32768.0 | grad norm: 2.314 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      496/    1200 | consumed samples:        23808 | elapsed time per iteration (ms): 2950.3 | learning rate: 7.518E-06 | global batch size:    48 | lm loss: 5.539518E+00 | loss scale: 32768.0 | grad norm: 2.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      497/    1200 | consumed samples:        23856 | elapsed time per iteration (ms): 2955.3 | learning rate: 7.534E-06 | global batch size:    48 | lm loss: 5.557510E+00 | loss scale: 32768.0 | grad norm: 2.259 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      498/    1200 | consumed samples:        23904 | elapsed time per iteration (ms): 2948.4 | learning rate: 7.550E-06 | global batch size:    48 | lm loss: 5.476506E+00 | loss scale: 32768.0 | grad norm: 2.352 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      499/    1200 | consumed samples:        23952 | elapsed time per iteration (ms): 2950.0 | learning rate: 7.565E-06 | global batch size:    48 | lm loss: 5.582995E+00 | loss scale: 32768.0 | grad norm: 2.438 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      500/    1200 | consumed samples:        24000 | elapsed time per iteration (ms): 2946.8 | learning rate: 7.581E-06 | global batch size:    48 | lm loss: 5.551681E+00 | loss scale: 32768.0 | grad norm: 2.259 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      501/    1200 | consumed samples:        24048 | elapsed time per iteration (ms): 2951.1 | learning rate: 7.597E-06 | global batch size:    48 | lm loss: 5.547090E+00 | loss scale: 32768.0 | grad norm: 2.356 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      502/    1200 | consumed samples:        24096 | elapsed time per iteration (ms): 2949.5 | learning rate: 7.613E-06 | global batch size:    48 | lm loss: 5.554676E+00 | loss scale: 32768.0 | grad norm: 2.766 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      503/    1200 | consumed samples:        24144 | elapsed time per iteration (ms): 2945.7 | learning rate: 7.628E-06 | global batch size:    48 | lm loss: 5.503694E+00 | loss scale: 32768.0 | grad norm: 3.218 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      504/    1200 | consumed samples:        24192 | elapsed time per iteration (ms): 2948.5 | learning rate: 7.644E-06 | global batch size:    48 | lm loss: 5.540314E+00 | loss scale: 32768.0 | grad norm: 2.722 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      505/    1200 | consumed samples:        24240 | elapsed time per iteration (ms): 2956.1 | learning rate: 7.660E-06 | global batch size:    48 | lm loss: 5.548652E+00 | loss scale: 32768.0 | grad norm: 2.245 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      506/    1200 | consumed samples:        24288 | elapsed time per iteration (ms): 2950.5 | learning rate: 7.676E-06 | global batch size:    48 | lm loss: 5.477430E+00 | loss scale: 32768.0 | grad norm: 2.166 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      507/    1200 | consumed samples:        24336 | elapsed time per iteration (ms): 2953.4 | learning rate: 7.691E-06 | global batch size:    48 | lm loss: 5.505935E+00 | loss scale: 32768.0 | grad norm: 2.179 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      508/    1200 | consumed samples:        24384 | elapsed time per iteration (ms): 2946.6 | learning rate: 7.707E-06 | global batch size:    48 | lm loss: 5.579793E+00 | loss scale: 32768.0 | grad norm: 2.185 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      509/    1200 | consumed samples:        24432 | elapsed time per iteration (ms): 2954.4 | learning rate: 7.723E-06 | global batch size:    48 | lm loss: 5.543115E+00 | loss scale: 32768.0 | grad norm: 2.347 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      510/    1200 | consumed samples:        24480 | elapsed time per iteration (ms): 2948.9 | learning rate: 7.739E-06 | global batch size:    48 | lm loss: 5.548204E+00 | loss scale: 32768.0 | grad norm: 2.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      511/    1200 | consumed samples:        24528 | elapsed time per iteration (ms): 2950.9 | learning rate: 7.754E-06 | global batch size:    48 | lm loss: 5.453847E+00 | loss scale: 32768.0 | grad norm: 2.432 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      512/    1200 | consumed samples:        24576 | elapsed time per iteration (ms): 2954.3 | learning rate: 7.770E-06 | global batch size:    48 | lm loss: 5.537197E+00 | loss scale: 32768.0 | grad norm: 2.238 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      513/    1200 | consumed samples:        24624 | elapsed time per iteration (ms): 2954.9 | learning rate: 7.786E-06 | global batch size:    48 | lm loss: 5.481262E+00 | loss scale: 32768.0 | grad norm: 2.485 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      514/    1200 | consumed samples:        24672 | elapsed time per iteration (ms): 2948.3 | learning rate: 7.801E-06 | global batch size:    48 | lm loss: 5.646551E+00 | loss scale: 32768.0 | grad norm: 2.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      515/    1200 | consumed samples:        24720 | elapsed time per iteration (ms): 2954.8 | learning rate: 7.817E-06 | global batch size:    48 | lm loss: 5.506584E+00 | loss scale: 32768.0 | grad norm: 2.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      516/    1200 | consumed samples:        24768 | elapsed time per iteration (ms): 2952.0 | learning rate: 7.833E-06 | global batch size:    48 | lm loss: 5.556300E+00 | loss scale: 32768.0 | grad norm: 2.262 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      517/    1200 | consumed samples:        24816 | elapsed time per iteration (ms): 2952.2 | learning rate: 7.849E-06 | global batch size:    48 | lm loss: 5.565569E+00 | loss scale: 32768.0 | grad norm: 2.088 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      518/    1200 | consumed samples:        24864 | elapsed time per iteration (ms): 2955.7 | learning rate: 7.864E-06 | global batch size:    48 | lm loss: 5.460568E+00 | loss scale: 32768.0 | grad norm: 2.412 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      519/    1200 | consumed samples:        24912 | elapsed time per iteration (ms): 2952.0 | learning rate: 7.880E-06 | global batch size:    48 | lm loss: 5.516277E+00 | loss scale: 32768.0 | grad norm: 2.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      520/    1200 | consumed samples:        24960 | elapsed time per iteration (ms): 2948.7 | learning rate: 7.896E-06 | global batch size:    48 | lm loss: 5.550084E+00 | loss scale: 32768.0 | grad norm: 2.015 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      521/    1200 | consumed samples:        25008 | elapsed time per iteration (ms): 1447.1 | learning rate: 7.912E-06 | global batch size:    48 | lm loss: 5.497179E+00 | loss scale: 32768.0 | grad norm: 2.140 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      522/    1200 | consumed samples:        25056 | elapsed time per iteration (ms): 1434.4 | learning rate: 7.927E-06 | global batch size:    48 | lm loss: 5.607591E+00 | loss scale: 32768.0 | grad norm: 2.060 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      523/    1200 | consumed samples:        25104 | elapsed time per iteration (ms): 1440.0 | learning rate: 7.943E-06 | global batch size:    48 | lm loss: 5.437740E+00 | loss scale: 32768.0 | grad norm: 2.158 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      524/    1200 | consumed samples:        25152 | elapsed time per iteration (ms): 1439.3 | learning rate: 7.959E-06 | global batch size:    48 | lm loss: 5.538715E+00 | loss scale: 32768.0 | grad norm: 2.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      525/    1200 | consumed samples:        25200 | elapsed time per iteration (ms): 1454.5 | learning rate: 7.974E-06 | global batch size:    48 | lm loss: 5.504448E+00 | loss scale: 32768.0 | grad norm: 2.212 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      526/    1200 | consumed samples:        25248 | elapsed time per iteration (ms): 1436.8 | learning rate: 7.990E-06 | global batch size:    48 | lm loss: 5.444273E+00 | loss scale: 32768.0 | grad norm: 2.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      527/    1200 | consumed samples:        25296 | elapsed time per iteration (ms): 1439.9 | learning rate: 8.006E-06 | global batch size:    48 | lm loss: 5.496395E+00 | loss scale: 32768.0 | grad norm: 2.371 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      528/    1200 | consumed samples:        25344 | elapsed time per iteration (ms): 1437.4 | learning rate: 8.022E-06 | global batch size:    48 | lm loss: 5.487802E+00 | loss scale: 32768.0 | grad norm: 2.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      529/    1200 | consumed samples:        25392 | elapsed time per iteration (ms): 1442.0 | learning rate: 8.037E-06 | global batch size:    48 | lm loss: 5.450439E+00 | loss scale: 32768.0 | grad norm: 2.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      530/    1200 | consumed samples:        25440 | elapsed time per iteration (ms): 1437.2 | learning rate: 8.053E-06 | global batch size:    48 | lm loss: 5.533634E+00 | loss scale: 32768.0 | grad norm: 2.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      531/    1200 | consumed samples:        25488 | elapsed time per iteration (ms): 1437.2 | learning rate: 8.069E-06 | global batch size:    48 | lm loss: 5.517597E+00 | loss scale: 32768.0 | grad norm: 1.969 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      532/    1200 | consumed samples:        25536 | elapsed time per iteration (ms): 1436.3 | learning rate: 8.085E-06 | global batch size:    48 | lm loss: 5.546638E+00 | loss scale: 32768.0 | grad norm: 1.930 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      533/    1200 | consumed samples:        25584 | elapsed time per iteration (ms): 1441.5 | learning rate: 8.100E-06 | global batch size:    48 | lm loss: 5.573899E+00 | loss scale: 32768.0 | grad norm: 2.143 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      534/    1200 | consumed samples:        25632 | elapsed time per iteration (ms): 1437.2 | learning rate: 8.116E-06 | global batch size:    48 | lm loss: 5.491554E+00 | loss scale: 32768.0 | grad norm: 2.512 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      535/    1200 | consumed samples:        25680 | elapsed time per iteration (ms): 1439.4 | learning rate: 8.132E-06 | global batch size:    48 | lm loss: 5.517940E+00 | loss scale: 32768.0 | grad norm: 2.103 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      536/    1200 | consumed samples:        25728 | elapsed time per iteration (ms): 1437.0 | learning rate: 8.147E-06 | global batch size:    48 | lm loss: 5.472960E+00 | loss scale: 32768.0 | grad norm: 2.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      537/    1200 | consumed samples:        25776 | elapsed time per iteration (ms): 1442.6 | learning rate: 8.163E-06 | global batch size:    48 | lm loss: 5.446199E+00 | loss scale: 32768.0 | grad norm: 2.475 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      538/    1200 | consumed samples:        25824 | elapsed time per iteration (ms): 1437.9 | learning rate: 8.179E-06 | global batch size:    48 | lm loss: 5.429674E+00 | loss scale: 32768.0 | grad norm: 2.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      539/    1200 | consumed samples:        25872 | elapsed time per iteration (ms): 1437.9 | learning rate: 8.195E-06 | global batch size:    48 | lm loss: 5.525222E+00 | loss scale: 32768.0 | grad norm: 2.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      540/    1200 | consumed samples:        25920 | elapsed time per iteration (ms): 1442.7 | learning rate: 8.210E-06 | global batch size:    48 | lm loss: 5.562256E+00 | loss scale: 32768.0 | grad norm: 2.276 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      541/    1200 | consumed samples:        25968 | elapsed time per iteration (ms): 1450.0 | learning rate: 8.226E-06 | global batch size:    48 | lm loss: 5.496074E+00 | loss scale: 32768.0 | grad norm: 2.274 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      542/    1200 | consumed samples:        26016 | elapsed time per iteration (ms): 1507.7 | learning rate: 8.242E-06 | global batch size:    48 | lm loss: 5.498337E+00 | loss scale: 32768.0 | grad norm: 2.132 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      543/    1200 | consumed samples:        26064 | elapsed time per iteration (ms): 1445.3 | learning rate: 8.258E-06 | global batch size:    48 | lm loss: 5.553152E+00 | loss scale: 32768.0 | grad norm: 2.188 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      544/    1200 | consumed samples:        26112 | elapsed time per iteration (ms): 1436.7 | learning rate: 8.273E-06 | global batch size:    48 | lm loss: 5.502098E+00 | loss scale: 32768.0 | grad norm: 2.198 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      545/    1200 | consumed samples:        26160 | elapsed time per iteration (ms): 1440.3 | learning rate: 8.289E-06 | global batch size:    48 | lm loss: 5.620945E+00 | loss scale: 32768.0 | grad norm: 2.209 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      546/    1200 | consumed samples:        26208 | elapsed time per iteration (ms): 1438.8 | learning rate: 8.305E-06 | global batch size:    48 | lm loss: 5.451147E+00 | loss scale: 32768.0 | grad norm: 1.960 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      547/    1200 | consumed samples:        26256 | elapsed time per iteration (ms): 1471.0 | learning rate: 8.320E-06 | global batch size:    48 | lm loss: 5.531240E+00 | loss scale: 32768.0 | grad norm: 1.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      548/    1200 | consumed samples:        26304 | elapsed time per iteration (ms): 1438.3 | learning rate: 8.336E-06 | global batch size:    48 | lm loss: 5.507005E+00 | loss scale: 32768.0 | grad norm: 1.919 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      549/    1200 | consumed samples:        26352 | elapsed time per iteration (ms): 1439.5 | learning rate: 8.352E-06 | global batch size:    48 | lm loss: 5.461117E+00 | loss scale: 32768.0 | grad norm: 2.180 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      550/    1200 | consumed samples:        26400 | elapsed time per iteration (ms): 1437.7 | learning rate: 8.368E-06 | global batch size:    48 | lm loss: 5.487824E+00 | loss scale: 32768.0 | grad norm: 2.000 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      551/    1200 | consumed samples:        26448 | elapsed time per iteration (ms): 1437.5 | learning rate: 8.383E-06 | global batch size:    48 | lm loss: 5.441448E+00 | loss scale: 32768.0 | grad norm: 2.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      552/    1200 | consumed samples:        26496 | elapsed time per iteration (ms): 1501.2 | learning rate: 8.399E-06 | global batch size:    48 | lm loss: 5.563377E+00 | loss scale: 32768.0 | grad norm: 2.019 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      553/    1200 | consumed samples:        26544 | elapsed time per iteration (ms): 1444.8 | learning rate: 8.415E-06 | global batch size:    48 | lm loss: 5.500787E+00 | loss scale: 32768.0 | grad norm: 1.955 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      554/    1200 | consumed samples:        26592 | elapsed time per iteration (ms): 1438.4 | learning rate: 8.431E-06 | global batch size:    48 | lm loss: 5.497921E+00 | loss scale: 32768.0 | grad norm: 2.437 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      555/    1200 | consumed samples:        26640 | elapsed time per iteration (ms): 1438.2 | learning rate: 8.446E-06 | global batch size:    48 | lm loss: 5.434900E+00 | loss scale: 32768.0 | grad norm: 1.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      556/    1200 | consumed samples:        26688 | elapsed time per iteration (ms): 1438.0 | learning rate: 8.462E-06 | global batch size:    48 | lm loss: 5.513769E+00 | loss scale: 32768.0 | grad norm: 2.117 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      557/    1200 | consumed samples:        26736 | elapsed time per iteration (ms): 1439.7 | learning rate: 8.478E-06 | global batch size:    48 | lm loss: 5.474628E+00 | loss scale: 32768.0 | grad norm: 1.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      558/    1200 | consumed samples:        26784 | elapsed time per iteration (ms): 1436.5 | learning rate: 8.493E-06 | global batch size:    48 | lm loss: 5.409360E+00 | loss scale: 32768.0 | grad norm: 2.023 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      559/    1200 | consumed samples:        26832 | elapsed time per iteration (ms): 1438.6 | learning rate: 8.509E-06 | global batch size:    48 | lm loss: 5.436053E+00 | loss scale: 32768.0 | grad norm: 2.052 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      560/    1200 | consumed samples:        26880 | elapsed time per iteration (ms): 1502.4 | learning rate: 8.525E-06 | global batch size:    48 | lm loss: 5.410121E+00 | loss scale: 32768.0 | grad norm: 2.085 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      561/    1200 | consumed samples:        26928 | elapsed time per iteration (ms): 2966.6 | learning rate: 8.541E-06 | global batch size:    48 | lm loss: 5.413889E+00 | loss scale: 32768.0 | grad norm: 2.045 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      562/    1200 | consumed samples:        26976 | elapsed time per iteration (ms): 2961.3 | learning rate: 8.556E-06 | global batch size:    48 | lm loss: 5.362567E+00 | loss scale: 32768.0 | grad norm: 2.310 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      563/    1200 | consumed samples:        27024 | elapsed time per iteration (ms): 2958.5 | learning rate: 8.572E-06 | global batch size:    48 | lm loss: 5.500846E+00 | loss scale: 32768.0 | grad norm: 2.458 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      564/    1200 | consumed samples:        27072 | elapsed time per iteration (ms): 2962.1 | learning rate: 8.588E-06 | global batch size:    48 | lm loss: 5.460346E+00 | loss scale: 32768.0 | grad norm: 2.034 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      565/    1200 | consumed samples:        27120 | elapsed time per iteration (ms): 2964.6 | learning rate: 8.604E-06 | global batch size:    48 | lm loss: 5.436244E+00 | loss scale: 32768.0 | grad norm: 2.153 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      566/    1200 | consumed samples:        27168 | elapsed time per iteration (ms): 2962.3 | learning rate: 8.619E-06 | global batch size:    48 | lm loss: 5.446551E+00 | loss scale: 32768.0 | grad norm: 1.962 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      567/    1200 | consumed samples:        27216 | elapsed time per iteration (ms): 2958.7 | learning rate: 8.635E-06 | global batch size:    48 | lm loss: 5.475076E+00 | loss scale: 32768.0 | grad norm: 1.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      568/    1200 | consumed samples:        27264 | elapsed time per iteration (ms): 2963.7 | learning rate: 8.651E-06 | global batch size:    48 | lm loss: 5.465275E+00 | loss scale: 32768.0 | grad norm: 1.797 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      569/    1200 | consumed samples:        27312 | elapsed time per iteration (ms): 2963.4 | learning rate: 8.667E-06 | global batch size:    48 | lm loss: 5.461612E+00 | loss scale: 32768.0 | grad norm: 1.947 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      570/    1200 | consumed samples:        27360 | elapsed time per iteration (ms): 2959.5 | learning rate: 8.682E-06 | global batch size:    48 | lm loss: 5.453542E+00 | loss scale: 32768.0 | grad norm: 2.026 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      571/    1200 | consumed samples:        27408 | elapsed time per iteration (ms): 2960.0 | learning rate: 8.698E-06 | global batch size:    48 | lm loss: 5.477018E+00 | loss scale: 32768.0 | grad norm: 1.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      572/    1200 | consumed samples:        27456 | elapsed time per iteration (ms): 2958.8 | learning rate: 8.714E-06 | global batch size:    48 | lm loss: 5.465738E+00 | loss scale: 32768.0 | grad norm: 1.842 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      573/    1200 | consumed samples:        27504 | elapsed time per iteration (ms): 2959.7 | learning rate: 8.729E-06 | global batch size:    48 | lm loss: 5.434595E+00 | loss scale: 32768.0 | grad norm: 1.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      574/    1200 | consumed samples:        27552 | elapsed time per iteration (ms): 2960.4 | learning rate: 8.745E-06 | global batch size:    48 | lm loss: 5.463510E+00 | loss scale: 32768.0 | grad norm: 1.874 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      575/    1200 | consumed samples:        27600 | elapsed time per iteration (ms): 2960.4 | learning rate: 8.761E-06 | global batch size:    48 | lm loss: 5.401178E+00 | loss scale: 32768.0 | grad norm: 1.978 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      576/    1200 | consumed samples:        27648 | elapsed time per iteration (ms): 2955.4 | learning rate: 8.777E-06 | global batch size:    48 | lm loss: 5.431064E+00 | loss scale: 32768.0 | grad norm: 2.113 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      577/    1200 | consumed samples:        27696 | elapsed time per iteration (ms): 2966.5 | learning rate: 8.792E-06 | global batch size:    48 | lm loss: 5.429685E+00 | loss scale: 32768.0 | grad norm: 1.972 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      578/    1200 | consumed samples:        27744 | elapsed time per iteration (ms): 2962.7 | learning rate: 8.808E-06 | global batch size:    48 | lm loss: 5.462465E+00 | loss scale: 32768.0 | grad norm: 1.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      579/    1200 | consumed samples:        27792 | elapsed time per iteration (ms): 2960.6 | learning rate: 8.824E-06 | global batch size:    48 | lm loss: 5.444051E+00 | loss scale: 32768.0 | grad norm: 1.911 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      580/    1200 | consumed samples:        27840 | elapsed time per iteration (ms): 2955.8 | learning rate: 8.840E-06 | global batch size:    48 | lm loss: 5.367260E+00 | loss scale: 32768.0 | grad norm: 2.156 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      581/    1200 | consumed samples:        27888 | elapsed time per iteration (ms): 2961.6 | learning rate: 8.855E-06 | global batch size:    48 | lm loss: 5.353781E+00 | loss scale: 32768.0 | grad norm: 2.126 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      582/    1200 | consumed samples:        27936 | elapsed time per iteration (ms): 2961.0 | learning rate: 8.871E-06 | global batch size:    48 | lm loss: 5.467159E+00 | loss scale: 32768.0 | grad norm: 2.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      583/    1200 | consumed samples:        27984 | elapsed time per iteration (ms): 2956.7 | learning rate: 8.887E-06 | global batch size:    48 | lm loss: 5.431954E+00 | loss scale: 32768.0 | grad norm: 1.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      584/    1200 | consumed samples:        28032 | elapsed time per iteration (ms): 2960.0 | learning rate: 8.902E-06 | global batch size:    48 | lm loss: 5.394954E+00 | loss scale: 32768.0 | grad norm: 2.003 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      585/    1200 | consumed samples:        28080 | elapsed time per iteration (ms): 2966.4 | learning rate: 8.918E-06 | global batch size:    48 | lm loss: 5.469614E+00 | loss scale: 32768.0 | grad norm: 1.903 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      586/    1200 | consumed samples:        28128 | elapsed time per iteration (ms): 2956.5 | learning rate: 8.934E-06 | global batch size:    48 | lm loss: 5.423135E+00 | loss scale: 32768.0 | grad norm: 1.862 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      587/    1200 | consumed samples:        28176 | elapsed time per iteration (ms): 2958.0 | learning rate: 8.950E-06 | global batch size:    48 | lm loss: 5.392987E+00 | loss scale: 32768.0 | grad norm: 1.751 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      588/    1200 | consumed samples:        28224 | elapsed time per iteration (ms): 2957.1 | learning rate: 8.965E-06 | global batch size:    48 | lm loss: 5.407043E+00 | loss scale: 32768.0 | grad norm: 1.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      589/    1200 | consumed samples:        28272 | elapsed time per iteration (ms): 2963.4 | learning rate: 8.981E-06 | global batch size:    48 | lm loss: 5.440837E+00 | loss scale: 32768.0 | grad norm: 1.916 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      590/    1200 | consumed samples:        28320 | elapsed time per iteration (ms): 2956.1 | learning rate: 8.997E-06 | global batch size:    48 | lm loss: 5.438184E+00 | loss scale: 32768.0 | grad norm: 2.228 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      591/    1200 | consumed samples:        28368 | elapsed time per iteration (ms): 2955.9 | learning rate: 9.013E-06 | global batch size:    48 | lm loss: 5.456333E+00 | loss scale: 32768.0 | grad norm: 2.243 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      592/    1200 | consumed samples:        28416 | elapsed time per iteration (ms): 2957.8 | learning rate: 9.028E-06 | global batch size:    48 | lm loss: 5.464595E+00 | loss scale: 32768.0 | grad norm: 1.964 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      593/    1200 | consumed samples:        28464 | elapsed time per iteration (ms): 2966.9 | learning rate: 9.044E-06 | global batch size:    48 | lm loss: 5.438242E+00 | loss scale: 32768.0 | grad norm: 1.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      594/    1200 | consumed samples:        28512 | elapsed time per iteration (ms): 2959.2 | learning rate: 9.060E-06 | global batch size:    48 | lm loss: 5.438622E+00 | loss scale: 32768.0 | grad norm: 1.914 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      595/    1200 | consumed samples:        28560 | elapsed time per iteration (ms): 2963.0 | learning rate: 9.075E-06 | global batch size:    48 | lm loss: 5.418504E+00 | loss scale: 32768.0 | grad norm: 1.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      596/    1200 | consumed samples:        28608 | elapsed time per iteration (ms): 2959.1 | learning rate: 9.091E-06 | global batch size:    48 | lm loss: 5.391889E+00 | loss scale: 32768.0 | grad norm: 1.982 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      597/    1200 | consumed samples:        28656 | elapsed time per iteration (ms): 2962.2 | learning rate: 9.107E-06 | global batch size:    48 | lm loss: 5.442462E+00 | loss scale: 32768.0 | grad norm: 1.859 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      598/    1200 | consumed samples:        28704 | elapsed time per iteration (ms): 2965.3 | learning rate: 9.123E-06 | global batch size:    48 | lm loss: 5.416012E+00 | loss scale: 32768.0 | grad norm: 1.785 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      599/    1200 | consumed samples:        28752 | elapsed time per iteration (ms): 2961.1 | learning rate: 9.138E-06 | global batch size:    48 | lm loss: 5.370384E+00 | loss scale: 32768.0 | grad norm: 2.065 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      600/    1200 | consumed samples:        28800 | elapsed time per iteration (ms): 2957.9 | learning rate: 9.154E-06 | global batch size:    48 | lm loss: 5.450733E+00 | loss scale: 32768.0 | grad norm: 2.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      601/    1200 | consumed samples:        28848 | elapsed time per iteration (ms): 2962.4 | learning rate: 9.170E-06 | global batch size:    48 | lm loss: 5.383464E+00 | loss scale: 32768.0 | grad norm: 2.046 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      602/    1200 | consumed samples:        28896 | elapsed time per iteration (ms): 2960.6 | learning rate: 9.186E-06 | global batch size:    48 | lm loss: 5.395994E+00 | loss scale: 32768.0 | grad norm: 1.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      603/    1200 | consumed samples:        28944 | elapsed time per iteration (ms): 2961.8 | learning rate: 9.201E-06 | global batch size:    48 | lm loss: 5.451582E+00 | loss scale: 32768.0 | grad norm: 1.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      604/    1200 | consumed samples:        28992 | elapsed time per iteration (ms): 2961.2 | learning rate: 9.217E-06 | global batch size:    48 | lm loss: 5.335550E+00 | loss scale: 32768.0 | grad norm: 1.850 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      605/    1200 | consumed samples:        29040 | elapsed time per iteration (ms): 2966.2 | learning rate: 9.233E-06 | global batch size:    48 | lm loss: 5.404255E+00 | loss scale: 32768.0 | grad norm: 1.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      606/    1200 | consumed samples:        29088 | elapsed time per iteration (ms): 2961.3 | learning rate: 9.248E-06 | global batch size:    48 | lm loss: 5.410604E+00 | loss scale: 32768.0 | grad norm: 1.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      607/    1200 | consumed samples:        29136 | elapsed time per iteration (ms): 2958.1 | learning rate: 9.264E-06 | global batch size:    48 | lm loss: 5.448564E+00 | loss scale: 32768.0 | grad norm: 1.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      608/    1200 | consumed samples:        29184 | elapsed time per iteration (ms): 2958.0 | learning rate: 9.280E-06 | global batch size:    48 | lm loss: 5.471355E+00 | loss scale: 32768.0 | grad norm: 1.729 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      609/    1200 | consumed samples:        29232 | elapsed time per iteration (ms): 2963.1 | learning rate: 9.296E-06 | global batch size:    48 | lm loss: 5.300415E+00 | loss scale: 32768.0 | grad norm: 1.694 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      610/    1200 | consumed samples:        29280 | elapsed time per iteration (ms): 3040.4 | learning rate: 9.311E-06 | global batch size:    48 | lm loss: 5.389006E+00 | loss scale: 32768.0 | grad norm: 1.660 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      611/    1200 | consumed samples:        29328 | elapsed time per iteration (ms): 2958.7 | learning rate: 9.327E-06 | global batch size:    48 | lm loss: 5.365156E+00 | loss scale: 32768.0 | grad norm: 1.731 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      612/    1200 | consumed samples:        29376 | elapsed time per iteration (ms): 2960.3 | learning rate: 9.343E-06 | global batch size:    48 | lm loss: 5.414995E+00 | loss scale: 32768.0 | grad norm: 1.756 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      613/    1200 | consumed samples:        29424 | elapsed time per iteration (ms): 2962.5 | learning rate: 9.359E-06 | global batch size:    48 | lm loss: 5.403717E+00 | loss scale: 32768.0 | grad norm: 1.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      614/    1200 | consumed samples:        29472 | elapsed time per iteration (ms): 2958.7 | learning rate: 9.374E-06 | global batch size:    48 | lm loss: 5.416802E+00 | loss scale: 32768.0 | grad norm: 1.738 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      615/    1200 | consumed samples:        29520 | elapsed time per iteration (ms): 2959.0 | learning rate: 9.390E-06 | global batch size:    48 | lm loss: 5.409369E+00 | loss scale: 32768.0 | grad norm: 1.710 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      616/    1200 | consumed samples:        29568 | elapsed time per iteration (ms): 2958.4 | learning rate: 9.406E-06 | global batch size:    48 | lm loss: 5.402284E+00 | loss scale: 32768.0 | grad norm: 1.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      617/    1200 | consumed samples:        29616 | elapsed time per iteration (ms): 2967.1 | learning rate: 9.421E-06 | global batch size:    48 | lm loss: 5.427941E+00 | loss scale: 32768.0 | grad norm: 1.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      618/    1200 | consumed samples:        29664 | elapsed time per iteration (ms): 2956.7 | learning rate: 9.437E-06 | global batch size:    48 | lm loss: 5.443668E+00 | loss scale: 32768.0 | grad norm: 1.794 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      619/    1200 | consumed samples:        29712 | elapsed time per iteration (ms): 2962.3 | learning rate: 9.453E-06 | global batch size:    48 | lm loss: 5.475767E+00 | loss scale: 32768.0 | grad norm: 1.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      620/    1200 | consumed samples:        29760 | elapsed time per iteration (ms): 2959.7 | learning rate: 9.469E-06 | global batch size:    48 | lm loss: 5.442257E+00 | loss scale: 32768.0 | grad norm: 1.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      621/    1200 | consumed samples:        29808 | elapsed time per iteration (ms): 2966.4 | learning rate: 9.484E-06 | global batch size:    48 | lm loss: 5.420871E+00 | loss scale: 32768.0 | grad norm: 1.645 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      622/    1200 | consumed samples:        29856 | elapsed time per iteration (ms): 2959.8 | learning rate: 9.500E-06 | global batch size:    48 | lm loss: 5.366947E+00 | loss scale: 32768.0 | grad norm: 1.961 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      623/    1200 | consumed samples:        29904 | elapsed time per iteration (ms): 2964.1 | learning rate: 9.516E-06 | global batch size:    48 | lm loss: 5.415380E+00 | loss scale: 32768.0 | grad norm: 2.051 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      624/    1200 | consumed samples:        29952 | elapsed time per iteration (ms): 2960.5 | learning rate: 9.532E-06 | global batch size:    48 | lm loss: 5.411081E+00 | loss scale: 32768.0 | grad norm: 1.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      625/    1200 | consumed samples:        30000 | elapsed time per iteration (ms): 2961.5 | learning rate: 9.547E-06 | global batch size:    48 | lm loss: 5.368420E+00 | loss scale: 32768.0 | grad norm: 1.677 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      626/    1200 | consumed samples:        30048 | elapsed time per iteration (ms): 2965.8 | learning rate: 9.563E-06 | global batch size:    48 | lm loss: 5.412148E+00 | loss scale: 32768.0 | grad norm: 1.848 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      627/    1200 | consumed samples:        30096 | elapsed time per iteration (ms): 2959.1 | learning rate: 9.579E-06 | global batch size:    48 | lm loss: 5.374525E+00 | loss scale: 32768.0 | grad norm: 1.679 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      628/    1200 | consumed samples:        30144 | elapsed time per iteration (ms): 2964.3 | learning rate: 9.594E-06 | global batch size:    48 | lm loss: 5.333106E+00 | loss scale: 32768.0 | grad norm: 1.744 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      629/    1200 | consumed samples:        30192 | elapsed time per iteration (ms): 2967.2 | learning rate: 9.610E-06 | global batch size:    48 | lm loss: 5.359655E+00 | loss scale: 32768.0 | grad norm: 1.672 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      630/    1200 | consumed samples:        30240 | elapsed time per iteration (ms): 2959.8 | learning rate: 9.626E-06 | global batch size:    48 | lm loss: 5.350567E+00 | loss scale: 32768.0 | grad norm: 1.864 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      631/    1200 | consumed samples:        30288 | elapsed time per iteration (ms): 2943.9 | learning rate: 9.642E-06 | global batch size:    48 | lm loss: 5.393679E+00 | loss scale: 32768.0 | grad norm: 1.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      632/    1200 | consumed samples:        30336 | elapsed time per iteration (ms): 2792.1 | learning rate: 9.657E-06 | global batch size:    48 | lm loss: 5.376534E+00 | loss scale: 32768.0 | grad norm: 1.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      633/    1200 | consumed samples:        30384 | elapsed time per iteration (ms): 1442.6 | learning rate: 9.673E-06 | global batch size:    48 | lm loss: 5.366853E+00 | loss scale: 32768.0 | grad norm: 2.118 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      634/    1200 | consumed samples:        30432 | elapsed time per iteration (ms): 1437.2 | learning rate: 9.689E-06 | global batch size:    48 | lm loss: 5.424659E+00 | loss scale: 32768.0 | grad norm: 2.361 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      635/    1200 | consumed samples:        30480 | elapsed time per iteration (ms): 1440.2 | learning rate: 9.705E-06 | global batch size:    48 | lm loss: 5.411553E+00 | loss scale: 32768.0 | grad norm: 2.151 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      636/    1200 | consumed samples:        30528 | elapsed time per iteration (ms): 1434.1 | learning rate: 9.720E-06 | global batch size:    48 | lm loss: 5.266012E+00 | loss scale: 32768.0 | grad norm: 1.993 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      637/    1200 | consumed samples:        30576 | elapsed time per iteration (ms): 1439.3 | learning rate: 9.736E-06 | global batch size:    48 | lm loss: 5.436311E+00 | loss scale: 32768.0 | grad norm: 1.831 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      638/    1200 | consumed samples:        30624 | elapsed time per iteration (ms): 1440.3 | learning rate: 9.752E-06 | global batch size:    48 | lm loss: 5.382148E+00 | loss scale: 32768.0 | grad norm: 1.836 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      639/    1200 | consumed samples:        30672 | elapsed time per iteration (ms): 1437.5 | learning rate: 9.768E-06 | global batch size:    48 | lm loss: 5.342964E+00 | loss scale: 32768.0 | grad norm: 1.886 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      640/    1200 | consumed samples:        30720 | elapsed time per iteration (ms): 1435.6 | learning rate: 9.783E-06 | global batch size:    48 | lm loss: 5.397603E+00 | loss scale: 32768.0 | grad norm: 2.145 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      641/    1200 | consumed samples:        30768 | elapsed time per iteration (ms): 1446.4 | learning rate: 9.799E-06 | global batch size:    48 | lm loss: 5.347290E+00 | loss scale: 32768.0 | grad norm: 1.760 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      642/    1200 | consumed samples:        30816 | elapsed time per iteration (ms): 1480.1 | learning rate: 9.815E-06 | global batch size:    48 | lm loss: 5.371192E+00 | loss scale: 32768.0 | grad norm: 1.829 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      643/    1200 | consumed samples:        30864 | elapsed time per iteration (ms): 1439.1 | learning rate: 9.830E-06 | global batch size:    48 | lm loss: 5.353459E+00 | loss scale: 32768.0 | grad norm: 1.810 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      644/    1200 | consumed samples:        30912 | elapsed time per iteration (ms): 1433.9 | learning rate: 9.846E-06 | global batch size:    48 | lm loss: 5.418758E+00 | loss scale: 32768.0 | grad norm: 2.204 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      645/    1200 | consumed samples:        30960 | elapsed time per iteration (ms): 1439.1 | learning rate: 9.862E-06 | global batch size:    48 | lm loss: 5.446883E+00 | loss scale: 32768.0 | grad norm: 1.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      646/    1200 | consumed samples:        31008 | elapsed time per iteration (ms): 1437.3 | learning rate: 9.878E-06 | global batch size:    48 | lm loss: 5.387145E+00 | loss scale: 32768.0 | grad norm: 1.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      647/    1200 | consumed samples:        31056 | elapsed time per iteration (ms): 1439.4 | learning rate: 9.893E-06 | global batch size:    48 | lm loss: 5.343081E+00 | loss scale: 32768.0 | grad norm: 1.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      648/    1200 | consumed samples:        31104 | elapsed time per iteration (ms): 1457.4 | learning rate: 9.909E-06 | global batch size:    48 | lm loss: 5.316885E+00 | loss scale: 32768.0 | grad norm: 1.671 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      649/    1200 | consumed samples:        31152 | elapsed time per iteration (ms): 1440.6 | learning rate: 9.925E-06 | global batch size:    48 | lm loss: 5.304056E+00 | loss scale: 32768.0 | grad norm: 1.815 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      650/    1200 | consumed samples:        31200 | elapsed time per iteration (ms): 1435.1 | learning rate: 9.941E-06 | global batch size:    48 | lm loss: 5.418199E+00 | loss scale: 32768.0 | grad norm: 1.588 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      651/    1200 | consumed samples:        31248 | elapsed time per iteration (ms): 1437.1 | learning rate: 9.956E-06 | global batch size:    48 | lm loss: 5.364061E+00 | loss scale: 32768.0 | grad norm: 1.568 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      652/    1200 | consumed samples:        31296 | elapsed time per iteration (ms): 1436.3 | learning rate: 9.972E-06 | global batch size:    48 | lm loss: 5.399503E+00 | loss scale: 32768.0 | grad norm: 1.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      653/    1200 | consumed samples:        31344 | elapsed time per iteration (ms): 1440.9 | learning rate: 9.988E-06 | global batch size:    48 | lm loss: 5.350257E+00 | loss scale: 32768.0 | grad norm: 1.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      654/    1200 | consumed samples:        31392 | elapsed time per iteration (ms): 1438.4 | learning rate: 1.000E-05 | global batch size:    48 | lm loss: 5.341614E+00 | loss scale: 32768.0 | grad norm: 1.709 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      655/    1200 | consumed samples:        31440 | elapsed time per iteration (ms): 1440.8 | learning rate: 1.002E-05 | global batch size:    48 | lm loss: 5.376506E+00 | loss scale: 32768.0 | grad norm: 1.609 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      656/    1200 | consumed samples:        31488 | elapsed time per iteration (ms): 1444.1 | learning rate: 1.003E-05 | global batch size:    48 | lm loss: 5.366937E+00 | loss scale: 32768.0 | grad norm: 1.649 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      657/    1200 | consumed samples:        31536 | elapsed time per iteration (ms): 1443.0 | learning rate: 1.005E-05 | global batch size:    48 | lm loss: 5.352073E+00 | loss scale: 32768.0 | grad norm: 1.653 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      658/    1200 | consumed samples:        31584 | elapsed time per iteration (ms): 1437.4 | learning rate: 1.007E-05 | global batch size:    48 | lm loss: 5.285151E+00 | loss scale: 32768.0 | grad norm: 1.635 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      659/    1200 | consumed samples:        31632 | elapsed time per iteration (ms): 1438.5 | learning rate: 1.008E-05 | global batch size:    48 | lm loss: 5.308590E+00 | loss scale: 32768.0 | grad norm: 1.717 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      660/    1200 | consumed samples:        31680 | elapsed time per iteration (ms): 1435.9 | learning rate: 1.010E-05 | global batch size:    48 | lm loss: 5.353479E+00 | loss scale: 32768.0 | grad norm: 1.640 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      661/    1200 | consumed samples:        31728 | elapsed time per iteration (ms): 1440.2 | learning rate: 1.011E-05 | global batch size:    48 | lm loss: 5.369196E+00 | loss scale: 32768.0 | grad norm: 1.620 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      662/    1200 | consumed samples:        31776 | elapsed time per iteration (ms): 1434.3 | learning rate: 1.013E-05 | global batch size:    48 | lm loss: 5.348896E+00 | loss scale: 32768.0 | grad norm: 1.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      663/    1200 | consumed samples:        31824 | elapsed time per iteration (ms): 1437.9 | learning rate: 1.014E-05 | global batch size:    48 | lm loss: 5.339928E+00 | loss scale: 32768.0 | grad norm: 1.845 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      664/    1200 | consumed samples:        31872 | elapsed time per iteration (ms): 1439.8 | learning rate: 1.016E-05 | global batch size:    48 | lm loss: 5.350933E+00 | loss scale: 32768.0 | grad norm: 1.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      665/    1200 | consumed samples:        31920 | elapsed time per iteration (ms): 1442.3 | learning rate: 1.018E-05 | global batch size:    48 | lm loss: 5.328270E+00 | loss scale: 32768.0 | grad norm: 1.593 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      666/    1200 | consumed samples:        31968 | elapsed time per iteration (ms): 1438.4 | learning rate: 1.019E-05 | global batch size:    48 | lm loss: 5.301854E+00 | loss scale: 32768.0 | grad norm: 1.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      667/    1200 | consumed samples:        32016 | elapsed time per iteration (ms): 1437.6 | learning rate: 1.021E-05 | global batch size:    48 | lm loss: 5.376196E+00 | loss scale: 32768.0 | grad norm: 1.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      668/    1200 | consumed samples:        32064 | elapsed time per iteration (ms): 1437.2 | learning rate: 1.022E-05 | global batch size:    48 | lm loss: 5.384512E+00 | loss scale: 32768.0 | grad norm: 1.548 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      669/    1200 | consumed samples:        32112 | elapsed time per iteration (ms): 1439.4 | learning rate: 1.024E-05 | global batch size:    48 | lm loss: 5.350711E+00 | loss scale: 32768.0 | grad norm: 1.604 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      670/    1200 | consumed samples:        32160 | elapsed time per iteration (ms): 1435.8 | learning rate: 1.026E-05 | global batch size:    48 | lm loss: 5.376247E+00 | loss scale: 32768.0 | grad norm: 1.735 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      671/    1200 | consumed samples:        32208 | elapsed time per iteration (ms): 1599.5 | learning rate: 1.027E-05 | global batch size:    48 | lm loss: 5.273447E+00 | loss scale: 32768.0 | grad norm: 1.695 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      672/    1200 | consumed samples:        32256 | elapsed time per iteration (ms): 1898.8 | learning rate: 1.029E-05 | global batch size:    48 | lm loss: 5.288458E+00 | loss scale: 32768.0 | grad norm: 1.644 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      673/    1200 | consumed samples:        32304 | elapsed time per iteration (ms): 1923.9 | learning rate: 1.030E-05 | global batch size:    48 | lm loss: 5.370089E+00 | loss scale: 32768.0 | grad norm: 1.670 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      674/    1200 | consumed samples:        32352 | elapsed time per iteration (ms): 1916.1 | learning rate: 1.032E-05 | global batch size:    48 | lm loss: 5.361071E+00 | loss scale: 32768.0 | grad norm: 1.673 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      675/    1200 | consumed samples:        32400 | elapsed time per iteration (ms): 1914.7 | learning rate: 1.033E-05 | global batch size:    48 | lm loss: 5.295797E+00 | loss scale: 32768.0 | grad norm: 1.814 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      676/    1200 | consumed samples:        32448 | elapsed time per iteration (ms): 1914.2 | learning rate: 1.035E-05 | global batch size:    48 | lm loss: 5.297402E+00 | loss scale: 32768.0 | grad norm: 1.745 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      677/    1200 | consumed samples:        32496 | elapsed time per iteration (ms): 1920.0 | learning rate: 1.037E-05 | global batch size:    48 | lm loss: 5.301384E+00 | loss scale: 32768.0 | grad norm: 1.768 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      678/    1200 | consumed samples:        32544 | elapsed time per iteration (ms): 1915.9 | learning rate: 1.038E-05 | global batch size:    48 | lm loss: 5.393627E+00 | loss scale: 32768.0 | grad norm: 2.082 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      679/    1200 | consumed samples:        32592 | elapsed time per iteration (ms): 1918.0 | learning rate: 1.040E-05 | global batch size:    48 | lm loss: 5.363311E+00 | loss scale: 32768.0 | grad norm: 2.269 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      680/    1200 | consumed samples:        32640 | elapsed time per iteration (ms): 1915.4 | learning rate: 1.041E-05 | global batch size:    48 | lm loss: 5.294801E+00 | loss scale: 32768.0 | grad norm: 1.933 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      681/    1200 | consumed samples:        32688 | elapsed time per iteration (ms): 1923.0 | learning rate: 1.043E-05 | global batch size:    48 | lm loss: 5.345228E+00 | loss scale: 32768.0 | grad norm: 1.736 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      682/    1200 | consumed samples:        32736 | elapsed time per iteration (ms): 1919.5 | learning rate: 1.044E-05 | global batch size:    48 | lm loss: 5.290208E+00 | loss scale: 32768.0 | grad norm: 1.685 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      683/    1200 | consumed samples:        32784 | elapsed time per iteration (ms): 1919.3 | learning rate: 1.046E-05 | global batch size:    48 | lm loss: 5.373189E+00 | loss scale: 32768.0 | grad norm: 1.767 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      684/    1200 | consumed samples:        32832 | elapsed time per iteration (ms): 1914.7 | learning rate: 1.048E-05 | global batch size:    48 | lm loss: 5.410896E+00 | loss scale: 32768.0 | grad norm: 1.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      685/    1200 | consumed samples:        32880 | elapsed time per iteration (ms): 1925.7 | learning rate: 1.049E-05 | global batch size:    48 | lm loss: 5.365775E+00 | loss scale: 32768.0 | grad norm: 2.172 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      686/    1200 | consumed samples:        32928 | elapsed time per iteration (ms): 1978.7 | learning rate: 1.051E-05 | global batch size:    48 | lm loss: 5.316832E+00 | loss scale: 32768.0 | grad norm: 1.907 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      687/    1200 | consumed samples:        32976 | elapsed time per iteration (ms): 1913.5 | learning rate: 1.052E-05 | global batch size:    48 | lm loss: 5.301531E+00 | loss scale: 32768.0 | grad norm: 1.804 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      688/    1200 | consumed samples:        33024 | elapsed time per iteration (ms): 1916.6 | learning rate: 1.054E-05 | global batch size:    48 | lm loss: 5.265699E+00 | loss scale: 32768.0 | grad norm: 1.641 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      689/    1200 | consumed samples:        33072 | elapsed time per iteration (ms): 1924.8 | learning rate: 1.055E-05 | global batch size:    48 | lm loss: 5.312648E+00 | loss scale: 32768.0 | grad norm: 1.563 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      690/    1200 | consumed samples:        33120 | elapsed time per iteration (ms): 1915.0 | learning rate: 1.057E-05 | global batch size:    48 | lm loss: 5.334326E+00 | loss scale: 32768.0 | grad norm: 1.546 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      691/    1200 | consumed samples:        33168 | elapsed time per iteration (ms): 1915.0 | learning rate: 1.059E-05 | global batch size:    48 | lm loss: 5.321775E+00 | loss scale: 32768.0 | grad norm: 1.509 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      692/    1200 | consumed samples:        33216 | elapsed time per iteration (ms): 1917.7 | learning rate: 1.060E-05 | global batch size:    48 | lm loss: 5.349709E+00 | loss scale: 32768.0 | grad norm: 1.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      693/    1200 | consumed samples:        33264 | elapsed time per iteration (ms): 1919.2 | learning rate: 1.062E-05 | global batch size:    48 | lm loss: 5.290004E+00 | loss scale: 32768.0 | grad norm: 1.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      694/    1200 | consumed samples:        33312 | elapsed time per iteration (ms): 1914.6 | learning rate: 1.063E-05 | global batch size:    48 | lm loss: 5.294722E+00 | loss scale: 32768.0 | grad norm: 1.616 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      695/    1200 | consumed samples:        33360 | elapsed time per iteration (ms): 1912.5 | learning rate: 1.065E-05 | global batch size:    48 | lm loss: 5.281979E+00 | loss scale: 32768.0 | grad norm: 1.625 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      696/    1200 | consumed samples:        33408 | elapsed time per iteration (ms): 1916.7 | learning rate: 1.066E-05 | global batch size:    48 | lm loss: 5.306229E+00 | loss scale: 32768.0 | grad norm: 1.720 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      697/    1200 | consumed samples:        33456 | elapsed time per iteration (ms): 1921.3 | learning rate: 1.068E-05 | global batch size:    48 | lm loss: 5.252285E+00 | loss scale: 32768.0 | grad norm: 1.663 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      698/    1200 | consumed samples:        33504 | elapsed time per iteration (ms): 1919.0 | learning rate: 1.070E-05 | global batch size:    48 | lm loss: 5.303554E+00 | loss scale: 32768.0 | grad norm: 1.759 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      699/    1200 | consumed samples:        33552 | elapsed time per iteration (ms): 1916.8 | learning rate: 1.071E-05 | global batch size:    48 | lm loss: 5.262516E+00 | loss scale: 32768.0 | grad norm: 1.594 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      700/    1200 | consumed samples:        33600 | elapsed time per iteration (ms): 2007.2 | learning rate: 1.073E-05 | global batch size:    48 | lm loss: 5.306134E+00 | loss scale: 32768.0 | grad norm: 1.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      701/    1200 | consumed samples:        33648 | elapsed time per iteration (ms): 1917.2 | learning rate: 1.074E-05 | global batch size:    48 | lm loss: 5.268571E+00 | loss scale: 32768.0 | grad norm: 1.585 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      702/    1200 | consumed samples:        33696 | elapsed time per iteration (ms): 1918.2 | learning rate: 1.076E-05 | global batch size:    48 | lm loss: 5.284335E+00 | loss scale: 32768.0 | grad norm: 1.535 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      703/    1200 | consumed samples:        33744 | elapsed time per iteration (ms): 1958.8 | learning rate: 1.077E-05 | global batch size:    48 | lm loss: 5.264311E+00 | loss scale: 32768.0 | grad norm: 1.513 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      704/    1200 | consumed samples:        33792 | elapsed time per iteration (ms): 1916.9 | learning rate: 1.079E-05 | global batch size:    48 | lm loss: 5.262866E+00 | loss scale: 32768.0 | grad norm: 1.556 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      705/    1200 | consumed samples:        33840 | elapsed time per iteration (ms): 1923.0 | learning rate: 1.081E-05 | global batch size:    48 | lm loss: 5.210929E+00 | loss scale: 32768.0 | grad norm: 1.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      706/    1200 | consumed samples:        33888 | elapsed time per iteration (ms): 1919.0 | learning rate: 1.082E-05 | global batch size:    48 | lm loss: 5.290936E+00 | loss scale: 32768.0 | grad norm: 1.567 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      707/    1200 | consumed samples:        33936 | elapsed time per iteration (ms): 1918.8 | learning rate: 1.084E-05 | global batch size:    48 | lm loss: 5.279535E+00 | loss scale: 32768.0 | grad norm: 1.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      708/    1200 | consumed samples:        33984 | elapsed time per iteration (ms): 1914.0 | learning rate: 1.085E-05 | global batch size:    48 | lm loss: 5.313623E+00 | loss scale: 32768.0 | grad norm: 1.538 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      709/    1200 | consumed samples:        34032 | elapsed time per iteration (ms): 1919.9 | learning rate: 1.087E-05 | global batch size:    48 | lm loss: 5.282271E+00 | loss scale: 32768.0 | grad norm: 1.470 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      710/    1200 | consumed samples:        34080 | elapsed time per iteration (ms): 1918.5 | learning rate: 1.088E-05 | global batch size:    48 | lm loss: 5.319443E+00 | loss scale: 32768.0 | grad norm: 1.553 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      711/    1200 | consumed samples:        34128 | elapsed time per iteration (ms): 1925.8 | learning rate: 1.090E-05 | global batch size:    48 | lm loss: 5.225879E+00 | loss scale: 32768.0 | grad norm: 1.634 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      712/    1200 | consumed samples:        34176 | elapsed time per iteration (ms): 1913.2 | learning rate: 1.092E-05 | global batch size:    48 | lm loss: 5.196040E+00 | loss scale: 32768.0 | grad norm: 1.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      713/    1200 | consumed samples:        34224 | elapsed time per iteration (ms): 1925.1 | learning rate: 1.093E-05 | global batch size:    48 | lm loss: 5.240556E+00 | loss scale: 32768.0 | grad norm: 1.823 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      714/    1200 | consumed samples:        34272 | elapsed time per iteration (ms): 1916.4 | learning rate: 1.095E-05 | global batch size:    48 | lm loss: 5.321823E+00 | loss scale: 32768.0 | grad norm: 1.825 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      715/    1200 | consumed samples:        34320 | elapsed time per iteration (ms): 1916.1 | learning rate: 1.096E-05 | global batch size:    48 | lm loss: 5.264046E+00 | loss scale: 32768.0 | grad norm: 1.684 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      716/    1200 | consumed samples:        34368 | elapsed time per iteration (ms): 1915.8 | learning rate: 1.098E-05 | global batch size:    48 | lm loss: 5.292698E+00 | loss scale: 32768.0 | grad norm: 2.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      717/    1200 | consumed samples:        34416 | elapsed time per iteration (ms): 1921.1 | learning rate: 1.099E-05 | global batch size:    48 | lm loss: 5.242422E+00 | loss scale: 32768.0 | grad norm: 1.566 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      718/    1200 | consumed samples:        34464 | elapsed time per iteration (ms): 1915.9 | learning rate: 1.101E-05 | global batch size:    48 | lm loss: 5.226022E+00 | loss scale: 32768.0 | grad norm: 1.665 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      719/    1200 | consumed samples:        34512 | elapsed time per iteration (ms): 1915.2 | learning rate: 1.103E-05 | global batch size:    48 | lm loss: 5.312698E+00 | loss scale: 32768.0 | grad norm: 1.642 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      720/    1200 | consumed samples:        34560 | elapsed time per iteration (ms): 1913.9 | learning rate: 1.104E-05 | global batch size:    48 | lm loss: 5.208157E+00 | loss scale: 32768.0 | grad norm: 1.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      721/    1200 | consumed samples:        34608 | elapsed time per iteration (ms): 1922.7 | learning rate: 1.106E-05 | global batch size:    48 | lm loss: 5.257973E+00 | loss scale: 32768.0 | grad norm: 1.624 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      722/    1200 | consumed samples:        34656 | elapsed time per iteration (ms): 1915.4 | learning rate: 1.107E-05 | global batch size:    48 | lm loss: 5.167590E+00 | loss scale: 32768.0 | grad norm: 1.783 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      723/    1200 | consumed samples:        34704 | elapsed time per iteration (ms): 1914.9 | learning rate: 1.109E-05 | global batch size:    48 | lm loss: 5.270230E+00 | loss scale: 32768.0 | grad norm: 1.664 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      724/    1200 | consumed samples:        34752 | elapsed time per iteration (ms): 1915.0 | learning rate: 1.110E-05 | global batch size:    48 | lm loss: 5.229977E+00 | loss scale: 32768.0 | grad norm: 1.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      725/    1200 | consumed samples:        34800 | elapsed time per iteration (ms): 1916.8 | learning rate: 1.112E-05 | global batch size:    48 | lm loss: 5.204496E+00 | loss scale: 32768.0 | grad norm: 1.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      726/    1200 | consumed samples:        34848 | elapsed time per iteration (ms): 1920.0 | learning rate: 1.114E-05 | global batch size:    48 | lm loss: 5.273711E+00 | loss scale: 32768.0 | grad norm: 1.692 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      727/    1200 | consumed samples:        34896 | elapsed time per iteration (ms): 2025.6 | learning rate: 1.115E-05 | global batch size:    48 | lm loss: 5.251173E+00 | loss scale: 32768.0 | grad norm: 1.515 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      728/    1200 | consumed samples:        34944 | elapsed time per iteration (ms): 1949.7 | learning rate: 1.117E-05 | global batch size:    48 | lm loss: 5.264058E+00 | loss scale: 32768.0 | grad norm: 1.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      729/    1200 | consumed samples:        34992 | elapsed time per iteration (ms): 1919.0 | learning rate: 1.118E-05 | global batch size:    48 | lm loss: 5.242090E+00 | loss scale: 32768.0 | grad norm: 1.571 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      730/    1200 | consumed samples:        35040 | elapsed time per iteration (ms): 1918.3 | learning rate: 1.120E-05 | global batch size:    48 | lm loss: 5.179298E+00 | loss scale: 32768.0 | grad norm: 1.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      731/    1200 | consumed samples:        35088 | elapsed time per iteration (ms): 1915.2 | learning rate: 1.121E-05 | global batch size:    48 | lm loss: 5.197062E+00 | loss scale: 32768.0 | grad norm: 1.614 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      732/    1200 | consumed samples:        35136 | elapsed time per iteration (ms): 1915.1 | learning rate: 1.123E-05 | global batch size:    48 | lm loss: 5.177234E+00 | loss scale: 32768.0 | grad norm: 1.531 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      733/    1200 | consumed samples:        35184 | elapsed time per iteration (ms): 1920.1 | learning rate: 1.125E-05 | global batch size:    48 | lm loss: 5.303034E+00 | loss scale: 32768.0 | grad norm: 1.519 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      734/    1200 | consumed samples:        35232 | elapsed time per iteration (ms): 1916.7 | learning rate: 1.126E-05 | global batch size:    48 | lm loss: 5.210860E+00 | loss scale: 32768.0 | grad norm: 1.577 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      735/    1200 | consumed samples:        35280 | elapsed time per iteration (ms): 1914.1 | learning rate: 1.128E-05 | global batch size:    48 | lm loss: 5.183703E+00 | loss scale: 32768.0 | grad norm: 1.524 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      736/    1200 | consumed samples:        35328 | elapsed time per iteration (ms): 1917.9 | learning rate: 1.129E-05 | global batch size:    48 | lm loss: 5.181653E+00 | loss scale: 32768.0 | grad norm: 1.555 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      737/    1200 | consumed samples:        35376 | elapsed time per iteration (ms): 1923.5 | learning rate: 1.131E-05 | global batch size:    48 | lm loss: 5.201513E+00 | loss scale: 32768.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      738/    1200 | consumed samples:        35424 | elapsed time per iteration (ms): 1914.6 | learning rate: 1.132E-05 | global batch size:    48 | lm loss: 5.216150E+00 | loss scale: 32768.0 | grad norm: 1.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      739/    1200 | consumed samples:        35472 | elapsed time per iteration (ms): 1918.5 | learning rate: 1.134E-05 | global batch size:    48 | lm loss: 5.194566E+00 | loss scale: 32768.0 | grad norm: 1.459 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      740/    1200 | consumed samples:        35520 | elapsed time per iteration (ms): 1914.2 | learning rate: 1.136E-05 | global batch size:    48 | lm loss: 5.258451E+00 | loss scale: 32768.0 | grad norm: 1.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      741/    1200 | consumed samples:        35568 | elapsed time per iteration (ms): 1705.1 | learning rate: 1.137E-05 | global batch size:    48 | lm loss: 5.169336E+00 | loss scale: 32768.0 | grad norm: 1.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      742/    1200 | consumed samples:        35616 | elapsed time per iteration (ms): 1456.2 | learning rate: 1.139E-05 | global batch size:    48 | lm loss: 5.170043E+00 | loss scale: 32768.0 | grad norm: 1.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      743/    1200 | consumed samples:        35664 | elapsed time per iteration (ms): 1437.2 | learning rate: 1.140E-05 | global batch size:    48 | lm loss: 5.231086E+00 | loss scale: 32768.0 | grad norm: 1.552 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      744/    1200 | consumed samples:        35712 | elapsed time per iteration (ms): 1437.0 | learning rate: 1.142E-05 | global batch size:    48 | lm loss: 5.176496E+00 | loss scale: 32768.0 | grad norm: 1.618 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      745/    1200 | consumed samples:        35760 | elapsed time per iteration (ms): 1446.5 | learning rate: 1.143E-05 | global batch size:    48 | lm loss: 5.207023E+00 | loss scale: 32768.0 | grad norm: 1.715 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      746/    1200 | consumed samples:        35808 | elapsed time per iteration (ms): 1439.9 | learning rate: 1.145E-05 | global batch size:    48 | lm loss: 5.145947E+00 | loss scale: 32768.0 | grad norm: 1.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      747/    1200 | consumed samples:        35856 | elapsed time per iteration (ms): 1484.7 | learning rate: 1.147E-05 | global batch size:    48 | lm loss: 5.219966E+00 | loss scale: 32768.0 | grad norm: 1.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      748/    1200 | consumed samples:        35904 | elapsed time per iteration (ms): 1437.7 | learning rate: 1.148E-05 | global batch size:    48 | lm loss: 5.206339E+00 | loss scale: 32768.0 | grad norm: 1.650 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      749/    1200 | consumed samples:        35952 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.150E-05 | global batch size:    48 | lm loss: 5.190179E+00 | loss scale: 32768.0 | grad norm: 1.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      750/    1200 | consumed samples:        36000 | elapsed time per iteration (ms): 1445.2 | learning rate: 1.151E-05 | global batch size:    48 | lm loss: 5.222949E+00 | loss scale: 32768.0 | grad norm: 1.870 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      751/    1200 | consumed samples:        36048 | elapsed time per iteration (ms): 1436.6 | learning rate: 1.153E-05 | global batch size:    48 | lm loss: 5.259317E+00 | loss scale: 32768.0 | grad norm: 1.595 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      752/    1200 | consumed samples:        36096 | elapsed time per iteration (ms): 1437.4 | learning rate: 1.154E-05 | global batch size:    48 | lm loss: 5.194521E+00 | loss scale: 32768.0 | grad norm: 1.648 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      753/    1200 | consumed samples:        36144 | elapsed time per iteration (ms): 1441.5 | learning rate: 1.156E-05 | global batch size:    48 | lm loss: 5.106750E+00 | loss scale: 32768.0 | grad norm: 1.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      754/    1200 | consumed samples:        36192 | elapsed time per iteration (ms): 1437.4 | learning rate: 1.158E-05 | global batch size:    48 | lm loss: 5.188655E+00 | loss scale: 32768.0 | grad norm: 1.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      755/    1200 | consumed samples:        36240 | elapsed time per iteration (ms): 1441.2 | learning rate: 1.159E-05 | global batch size:    48 | lm loss: 5.201596E+00 | loss scale: 32768.0 | grad norm: 1.506 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      756/    1200 | consumed samples:        36288 | elapsed time per iteration (ms): 1439.1 | learning rate: 1.161E-05 | global batch size:    48 | lm loss: 5.306081E+00 | loss scale: 32768.0 | grad norm: 1.552 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      757/    1200 | consumed samples:        36336 | elapsed time per iteration (ms): 1441.5 | learning rate: 1.162E-05 | global batch size:    48 | lm loss: 5.231027E+00 | loss scale: 32768.0 | grad norm: 1.608 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      758/    1200 | consumed samples:        36384 | elapsed time per iteration (ms): 1439.0 | learning rate: 1.164E-05 | global batch size:    48 | lm loss: 5.206639E+00 | loss scale: 32768.0 | grad norm: 1.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      759/    1200 | consumed samples:        36432 | elapsed time per iteration (ms): 1442.7 | learning rate: 1.165E-05 | global batch size:    48 | lm loss: 5.190211E+00 | loss scale: 32768.0 | grad norm: 1.600 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      760/    1200 | consumed samples:        36480 | elapsed time per iteration (ms): 1436.9 | learning rate: 1.167E-05 | global batch size:    48 | lm loss: 5.184835E+00 | loss scale: 32768.0 | grad norm: 1.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      761/    1200 | consumed samples:        36528 | elapsed time per iteration (ms): 1441.9 | learning rate: 1.169E-05 | global batch size:    48 | lm loss: 5.196326E+00 | loss scale: 32768.0 | grad norm: 1.592 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      762/    1200 | consumed samples:        36576 | elapsed time per iteration (ms): 1437.7 | learning rate: 1.170E-05 | global batch size:    48 | lm loss: 5.135199E+00 | loss scale: 32768.0 | grad norm: 1.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      763/    1200 | consumed samples:        36624 | elapsed time per iteration (ms): 1438.1 | learning rate: 1.172E-05 | global batch size:    48 | lm loss: 5.123138E+00 | loss scale: 32768.0 | grad norm: 1.806 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      764/    1200 | consumed samples:        36672 | elapsed time per iteration (ms): 1435.1 | learning rate: 1.173E-05 | global batch size:    48 | lm loss: 5.244646E+00 | loss scale: 32768.0 | grad norm: 1.541 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      765/    1200 | consumed samples:        36720 | elapsed time per iteration (ms): 1439.6 | learning rate: 1.175E-05 | global batch size:    48 | lm loss: 5.214551E+00 | loss scale: 32768.0 | grad norm: 1.507 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      766/    1200 | consumed samples:        36768 | elapsed time per iteration (ms): 1515.6 | learning rate: 1.177E-05 | global batch size:    48 | lm loss: 5.177900E+00 | loss scale: 32768.0 | grad norm: 1.477 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      767/    1200 | consumed samples:        36816 | elapsed time per iteration (ms): 1442.2 | learning rate: 1.178E-05 | global batch size:    48 | lm loss: 5.153563E+00 | loss scale: 32768.0 | grad norm: 1.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      768/    1200 | consumed samples:        36864 | elapsed time per iteration (ms): 1441.1 | learning rate: 1.180E-05 | global batch size:    48 | lm loss: 5.203459E+00 | loss scale: 32768.0 | grad norm: 1.615 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      769/    1200 | consumed samples:        36912 | elapsed time per iteration (ms): 1444.8 | learning rate: 1.181E-05 | global batch size:    48 | lm loss: 5.191826E+00 | loss scale: 32768.0 | grad norm: 1.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      770/    1200 | consumed samples:        36960 | elapsed time per iteration (ms): 1435.8 | learning rate: 1.183E-05 | global batch size:    48 | lm loss: 5.243004E+00 | loss scale: 32768.0 | grad norm: 1.636 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      771/    1200 | consumed samples:        37008 | elapsed time per iteration (ms): 1438.6 | learning rate: 1.184E-05 | global batch size:    48 | lm loss: 5.185817E+00 | loss scale: 32768.0 | grad norm: 1.584 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      772/    1200 | consumed samples:        37056 | elapsed time per iteration (ms): 1444.5 | learning rate: 1.186E-05 | global batch size:    48 | lm loss: 5.252524E+00 | loss scale: 32768.0 | grad norm: 1.657 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      773/    1200 | consumed samples:        37104 | elapsed time per iteration (ms): 1443.4 | learning rate: 1.188E-05 | global batch size:    48 | lm loss: 5.116811E+00 | loss scale: 32768.0 | grad norm: 1.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      774/    1200 | consumed samples:        37152 | elapsed time per iteration (ms): 1442.3 | learning rate: 1.189E-05 | global batch size:    48 | lm loss: 5.262764E+00 | loss scale: 32768.0 | grad norm: 2.216 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      775/    1200 | consumed samples:        37200 | elapsed time per iteration (ms): 1440.6 | learning rate: 1.191E-05 | global batch size:    48 | lm loss: 5.179281E+00 | loss scale: 32768.0 | grad norm: 1.808 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      776/    1200 | consumed samples:        37248 | elapsed time per iteration (ms): 1435.9 | learning rate: 1.192E-05 | global batch size:    48 | lm loss: 5.200644E+00 | loss scale: 32768.0 | grad norm: 1.758 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      777/    1200 | consumed samples:        37296 | elapsed time per iteration (ms): 1446.8 | learning rate: 1.194E-05 | global batch size:    48 | lm loss: 5.156401E+00 | loss scale: 32768.0 | grad norm: 1.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      778/    1200 | consumed samples:        37344 | elapsed time per iteration (ms): 1438.1 | learning rate: 1.195E-05 | global batch size:    48 | lm loss: 5.103696E+00 | loss scale: 32768.0 | grad norm: 1.476 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      779/    1200 | consumed samples:        37392 | elapsed time per iteration (ms): 1440.4 | learning rate: 1.197E-05 | global batch size:    48 | lm loss: 5.114364E+00 | loss scale: 32768.0 | grad norm: 1.498 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      780/    1200 | consumed samples:        37440 | elapsed time per iteration (ms): 1438.2 | learning rate: 1.199E-05 | global batch size:    48 | lm loss: 5.132414E+00 | loss scale: 32768.0 | grad norm: 1.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      781/    1200 | consumed samples:        37488 | elapsed time per iteration (ms): 3237.0 | learning rate: 1.200E-05 | global batch size:    48 | lm loss: 5.167222E+00 | loss scale: 32768.0 | grad norm: 1.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      782/    1200 | consumed samples:        37536 | elapsed time per iteration (ms): 3232.2 | learning rate: 1.202E-05 | global batch size:    48 | lm loss: 5.199588E+00 | loss scale: 32768.0 | grad norm: 1.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      783/    1200 | consumed samples:        37584 | elapsed time per iteration (ms): 3276.3 | learning rate: 1.203E-05 | global batch size:    48 | lm loss: 5.091784E+00 | loss scale: 32768.0 | grad norm: 1.463 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      784/    1200 | consumed samples:        37632 | elapsed time per iteration (ms): 3277.3 | learning rate: 1.205E-05 | global batch size:    48 | lm loss: 5.180663E+00 | loss scale: 32768.0 | grad norm: 1.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      785/    1200 | consumed samples:        37680 | elapsed time per iteration (ms): 3273.0 | learning rate: 1.206E-05 | global batch size:    48 | lm loss: 5.225652E+00 | loss scale: 32768.0 | grad norm: 1.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      786/    1200 | consumed samples:        37728 | elapsed time per iteration (ms): 3274.2 | learning rate: 1.208E-05 | global batch size:    48 | lm loss: 5.184580E+00 | loss scale: 32768.0 | grad norm: 1.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      787/    1200 | consumed samples:        37776 | elapsed time per iteration (ms): 3271.8 | learning rate: 1.210E-05 | global batch size:    48 | lm loss: 5.165221E+00 | loss scale: 32768.0 | grad norm: 1.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      788/    1200 | consumed samples:        37824 | elapsed time per iteration (ms): 3274.0 | learning rate: 1.211E-05 | global batch size:    48 | lm loss: 5.147855E+00 | loss scale: 32768.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      789/    1200 | consumed samples:        37872 | elapsed time per iteration (ms): 3270.0 | learning rate: 1.213E-05 | global batch size:    48 | lm loss: 5.110720E+00 | loss scale: 32768.0 | grad norm: 1.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      790/    1200 | consumed samples:        37920 | elapsed time per iteration (ms): 3271.8 | learning rate: 1.214E-05 | global batch size:    48 | lm loss: 5.210227E+00 | loss scale: 32768.0 | grad norm: 1.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      791/    1200 | consumed samples:        37968 | elapsed time per iteration (ms): 3271.2 | learning rate: 1.216E-05 | global batch size:    48 | lm loss: 5.129107E+00 | loss scale: 32768.0 | grad norm: 1.565 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      792/    1200 | consumed samples:        38016 | elapsed time per iteration (ms): 3272.7 | learning rate: 1.217E-05 | global batch size:    48 | lm loss: 5.126693E+00 | loss scale: 32768.0 | grad norm: 1.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      793/    1200 | consumed samples:        38064 | elapsed time per iteration (ms): 3276.8 | learning rate: 1.219E-05 | global batch size:    48 | lm loss: 5.204866E+00 | loss scale: 32768.0 | grad norm: 1.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      794/    1200 | consumed samples:        38112 | elapsed time per iteration (ms): 3272.9 | learning rate: 1.221E-05 | global batch size:    48 | lm loss: 5.154094E+00 | loss scale: 32768.0 | grad norm: 1.574 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      795/    1200 | consumed samples:        38160 | elapsed time per iteration (ms): 3270.9 | learning rate: 1.222E-05 | global batch size:    48 | lm loss: 5.195463E+00 | loss scale: 32768.0 | grad norm: 1.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      796/    1200 | consumed samples:        38208 | elapsed time per iteration (ms): 3268.1 | learning rate: 1.224E-05 | global batch size:    48 | lm loss: 5.116821E+00 | loss scale: 32768.0 | grad norm: 1.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      797/    1200 | consumed samples:        38256 | elapsed time per iteration (ms): 3269.6 | learning rate: 1.225E-05 | global batch size:    48 | lm loss: 5.066711E+00 | loss scale: 32768.0 | grad norm: 1.621 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      798/    1200 | consumed samples:        38304 | elapsed time per iteration (ms): 3267.9 | learning rate: 1.227E-05 | global batch size:    48 | lm loss: 5.110004E+00 | loss scale: 32768.0 | grad norm: 1.652 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      799/    1200 | consumed samples:        38352 | elapsed time per iteration (ms): 3342.2 | learning rate: 1.228E-05 | global batch size:    48 | lm loss: 5.142541E+00 | loss scale: 32768.0 | grad norm: 1.543 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      800/    1200 | consumed samples:        38400 | elapsed time per iteration (ms): 3270.0 | learning rate: 1.230E-05 | global batch size:    48 | lm loss: 5.085388E+00 | loss scale: 32768.0 | grad norm: 1.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      801/    1200 | consumed samples:        38448 | elapsed time per iteration (ms): 3276.9 | learning rate: 1.232E-05 | global batch size:    48 | lm loss: 5.092017E+00 | loss scale: 32768.0 | grad norm: 1.449 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      802/    1200 | consumed samples:        38496 | elapsed time per iteration (ms): 3278.7 | learning rate: 1.233E-05 | global batch size:    48 | lm loss: 5.202808E+00 | loss scale: 32768.0 | grad norm: 11.367 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      803/    1200 | consumed samples:        38544 | elapsed time per iteration (ms): 3275.3 | learning rate: 1.235E-05 | global batch size:    48 | lm loss: 5.193107E+00 | loss scale: 32768.0 | grad norm: 1.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      804/    1200 | consumed samples:        38592 | elapsed time per iteration (ms): 3272.6 | learning rate: 1.236E-05 | global batch size:    48 | lm loss: 5.130709E+00 | loss scale: 32768.0 | grad norm: 1.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      805/    1200 | consumed samples:        38640 | elapsed time per iteration (ms): 3279.4 | learning rate: 1.238E-05 | global batch size:    48 | lm loss: 5.178802E+00 | loss scale: 32768.0 | grad norm: 2.214 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      806/    1200 | consumed samples:        38688 | elapsed time per iteration (ms): 3273.5 | learning rate: 1.239E-05 | global batch size:    48 | lm loss: 5.201657E+00 | loss scale: 32768.0 | grad norm: 2.546 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      807/    1200 | consumed samples:        38736 | elapsed time per iteration (ms): 3265.7 | learning rate: 1.241E-05 | global batch size:    48 | lm loss: 5.177433E+00 | loss scale: 32768.0 | grad norm: 1.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      808/    1200 | consumed samples:        38784 | elapsed time per iteration (ms): 3269.5 | learning rate: 1.243E-05 | global batch size:    48 | lm loss: 5.199841E+00 | loss scale: 32768.0 | grad norm: 2.027 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      809/    1200 | consumed samples:        38832 | elapsed time per iteration (ms): 3271.1 | learning rate: 1.244E-05 | global batch size:    48 | lm loss: 5.146303E+00 | loss scale: 32768.0 | grad norm: 1.571 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      810/    1200 | consumed samples:        38880 | elapsed time per iteration (ms): 3271.7 | learning rate: 1.246E-05 | global batch size:    48 | lm loss: 5.101230E+00 | loss scale: 32768.0 | grad norm: 1.560 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      811/    1200 | consumed samples:        38928 | elapsed time per iteration (ms): 3267.4 | learning rate: 1.247E-05 | global batch size:    48 | lm loss: 5.169725E+00 | loss scale: 32768.0 | grad norm: 1.518 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      812/    1200 | consumed samples:        38976 | elapsed time per iteration (ms): 3271.8 | learning rate: 1.249E-05 | global batch size:    48 | lm loss: 5.157500E+00 | loss scale: 32768.0 | grad norm: 1.468 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      813/    1200 | consumed samples:        39024 | elapsed time per iteration (ms): 3276.1 | learning rate: 1.250E-05 | global batch size:    48 | lm loss: 5.040387E+00 | loss scale: 32768.0 | grad norm: 1.501 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      814/    1200 | consumed samples:        39072 | elapsed time per iteration (ms): 3331.4 | learning rate: 1.252E-05 | global batch size:    48 | lm loss: 5.076340E+00 | loss scale: 32768.0 | grad norm: 1.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      815/    1200 | consumed samples:        39120 | elapsed time per iteration (ms): 3276.0 | learning rate: 1.254E-05 | global batch size:    48 | lm loss: 5.070633E+00 | loss scale: 32768.0 | grad norm: 1.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      816/    1200 | consumed samples:        39168 | elapsed time per iteration (ms): 3266.4 | learning rate: 1.255E-05 | global batch size:    48 | lm loss: 5.213457E+00 | loss scale: 32768.0 | grad norm: 1.699 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      817/    1200 | consumed samples:        39216 | elapsed time per iteration (ms): 3277.4 | learning rate: 1.257E-05 | global batch size:    48 | lm loss: 5.147113E+00 | loss scale: 32768.0 | grad norm: 1.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      818/    1200 | consumed samples:        39264 | elapsed time per iteration (ms): 3270.0 | learning rate: 1.258E-05 | global batch size:    48 | lm loss: 5.223570E+00 | loss scale: 32768.0 | grad norm: 1.473 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      819/    1200 | consumed samples:        39312 | elapsed time per iteration (ms): 3271.4 | learning rate: 1.260E-05 | global batch size:    48 | lm loss: 5.111372E+00 | loss scale: 32768.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      820/    1200 | consumed samples:        39360 | elapsed time per iteration (ms): 3274.3 | learning rate: 1.261E-05 | global batch size:    48 | lm loss: 5.121271E+00 | loss scale: 32768.0 | grad norm: 2.257 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      821/    1200 | consumed samples:        39408 | elapsed time per iteration (ms): 3273.2 | learning rate: 1.263E-05 | global batch size:    48 | lm loss: 5.081742E+00 | loss scale: 32768.0 | grad norm: 2.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      822/    1200 | consumed samples:        39456 | elapsed time per iteration (ms): 3271.3 | learning rate: 1.265E-05 | global batch size:    48 | lm loss: 5.148527E+00 | loss scale: 32768.0 | grad norm: 1.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      823/    1200 | consumed samples:        39504 | elapsed time per iteration (ms): 3275.4 | learning rate: 1.266E-05 | global batch size:    48 | lm loss: 5.087272E+00 | loss scale: 32768.0 | grad norm: 1.488 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      824/    1200 | consumed samples:        39552 | elapsed time per iteration (ms): 3266.3 | learning rate: 1.268E-05 | global batch size:    48 | lm loss: 5.075418E+00 | loss scale: 32768.0 | grad norm: 1.581 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      825/    1200 | consumed samples:        39600 | elapsed time per iteration (ms): 3272.2 | learning rate: 1.269E-05 | global batch size:    48 | lm loss: 5.104400E+00 | loss scale: 32768.0 | grad norm: 1.394 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      826/    1200 | consumed samples:        39648 | elapsed time per iteration (ms): 3270.3 | learning rate: 1.271E-05 | global batch size:    48 | lm loss: 5.120263E+00 | loss scale: 32768.0 | grad norm: 1.564 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      827/    1200 | consumed samples:        39696 | elapsed time per iteration (ms): 3272.4 | learning rate: 1.272E-05 | global batch size:    48 | lm loss: 5.267777E+00 | loss scale: 32768.0 | grad norm: 3.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      828/    1200 | consumed samples:        39744 | elapsed time per iteration (ms): 3265.8 | learning rate: 1.274E-05 | global batch size:    48 | lm loss: 5.108149E+00 | loss scale: 32768.0 | grad norm: 2.048 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      829/    1200 | consumed samples:        39792 | elapsed time per iteration (ms): 3277.0 | learning rate: 1.276E-05 | global batch size:    48 | lm loss: 5.074726E+00 | loss scale: 32768.0 | grad norm: 2.497 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      830/    1200 | consumed samples:        39840 | elapsed time per iteration (ms): 3269.5 | learning rate: 1.277E-05 | global batch size:    48 | lm loss: 5.152175E+00 | loss scale: 32768.0 | grad norm: 2.841 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      831/    1200 | consumed samples:        39888 | elapsed time per iteration (ms): 3271.8 | learning rate: 1.279E-05 | global batch size:    48 | lm loss: 5.063527E+00 | loss scale: 32768.0 | grad norm: 1.981 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      832/    1200 | consumed samples:        39936 | elapsed time per iteration (ms): 3269.7 | learning rate: 1.280E-05 | global batch size:    48 | lm loss: 5.074251E+00 | loss scale: 32768.0 | grad norm: 1.789 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      833/    1200 | consumed samples:        39984 | elapsed time per iteration (ms): 3276.1 | learning rate: 1.282E-05 | global batch size:    48 | lm loss: 5.085022E+00 | loss scale: 32768.0 | grad norm: 1.562 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      834/    1200 | consumed samples:        40032 | elapsed time per iteration (ms): 3274.2 | learning rate: 1.283E-05 | global batch size:    48 | lm loss: 5.113671E+00 | loss scale: 32768.0 | grad norm: 1.622 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      835/    1200 | consumed samples:        40080 | elapsed time per iteration (ms): 3270.4 | learning rate: 1.285E-05 | global batch size:    48 | lm loss: 4.990367E+00 | loss scale: 32768.0 | grad norm: 1.521 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      836/    1200 | consumed samples:        40128 | elapsed time per iteration (ms): 3266.2 | learning rate: 1.287E-05 | global batch size:    48 | lm loss: 5.026018E+00 | loss scale: 32768.0 | grad norm: 1.447 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      837/    1200 | consumed samples:        40176 | elapsed time per iteration (ms): 3272.2 | learning rate: 1.288E-05 | global batch size:    48 | lm loss: 5.057575E+00 | loss scale: 32768.0 | grad norm: 1.379 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      838/    1200 | consumed samples:        40224 | elapsed time per iteration (ms): 3269.9 | learning rate: 1.290E-05 | global batch size:    48 | lm loss: 5.127805E+00 | loss scale: 32768.0 | grad norm: 1.308 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      839/    1200 | consumed samples:        40272 | elapsed time per iteration (ms): 3272.6 | learning rate: 1.291E-05 | global batch size:    48 | lm loss: 5.071900E+00 | loss scale: 32768.0 | grad norm: 1.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      840/    1200 | consumed samples:        40320 | elapsed time per iteration (ms): 3267.1 | learning rate: 1.293E-05 | global batch size:    48 | lm loss: 5.084360E+00 | loss scale: 32768.0 | grad norm: 1.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      841/    1200 | consumed samples:        40368 | elapsed time per iteration (ms): 3272.5 | learning rate: 1.294E-05 | global batch size:    48 | lm loss: 5.057465E+00 | loss scale: 32768.0 | grad norm: 1.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      842/    1200 | consumed samples:        40416 | elapsed time per iteration (ms): 3266.2 | learning rate: 1.296E-05 | global batch size:    48 | lm loss: 5.026387E+00 | loss scale: 32768.0 | grad norm: 1.469 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      843/    1200 | consumed samples:        40464 | elapsed time per iteration (ms): 3265.5 | learning rate: 1.298E-05 | global batch size:    48 | lm loss: 5.083187E+00 | loss scale: 32768.0 | grad norm: 1.444 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      844/    1200 | consumed samples:        40512 | elapsed time per iteration (ms): 3269.5 | learning rate: 1.299E-05 | global batch size:    48 | lm loss: 5.098682E+00 | loss scale: 32768.0 | grad norm: 1.337 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      845/    1200 | consumed samples:        40560 | elapsed time per iteration (ms): 3272.6 | learning rate: 1.301E-05 | global batch size:    48 | lm loss: 5.062024E+00 | loss scale: 32768.0 | grad norm: 1.414 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      846/    1200 | consumed samples:        40608 | elapsed time per iteration (ms): 3273.1 | learning rate: 1.302E-05 | global batch size:    48 | lm loss: 5.028492E+00 | loss scale: 32768.0 | grad norm: 1.422 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      847/    1200 | consumed samples:        40656 | elapsed time per iteration (ms): 3272.9 | learning rate: 1.304E-05 | global batch size:    48 | lm loss: 5.051425E+00 | loss scale: 32768.0 | grad norm: 1.545 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      848/    1200 | consumed samples:        40704 | elapsed time per iteration (ms): 3373.1 | learning rate: 1.305E-05 | global batch size:    48 | lm loss: 5.064445E+00 | loss scale: 32768.0 | grad norm: 1.472 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      849/    1200 | consumed samples:        40752 | elapsed time per iteration (ms): 3275.0 | learning rate: 1.307E-05 | global batch size:    48 | lm loss: 5.005372E+00 | loss scale: 32768.0 | grad norm: 1.403 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      850/    1200 | consumed samples:        40800 | elapsed time per iteration (ms): 3270.7 | learning rate: 1.309E-05 | global batch size:    48 | lm loss: 5.062498E+00 | loss scale: 32768.0 | grad norm: 1.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      851/    1200 | consumed samples:        40848 | elapsed time per iteration (ms): 2780.8 | learning rate: 1.310E-05 | global batch size:    48 | lm loss: 5.053450E+00 | loss scale: 32768.0 | grad norm: 1.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      852/    1200 | consumed samples:        40896 | elapsed time per iteration (ms): 1436.7 | learning rate: 1.312E-05 | global batch size:    48 | lm loss: 5.012702E+00 | loss scale: 32768.0 | grad norm: 1.312 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      853/    1200 | consumed samples:        40944 | elapsed time per iteration (ms): 1439.3 | learning rate: 1.313E-05 | global batch size:    48 | lm loss: 5.071036E+00 | loss scale: 32768.0 | grad norm: 1.362 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      854/    1200 | consumed samples:        40992 | elapsed time per iteration (ms): 1434.9 | learning rate: 1.315E-05 | global batch size:    48 | lm loss: 5.079245E+00 | loss scale: 32768.0 | grad norm: 1.493 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      855/    1200 | consumed samples:        41040 | elapsed time per iteration (ms): 1439.2 | learning rate: 1.316E-05 | global batch size:    48 | lm loss: 4.960236E+00 | loss scale: 32768.0 | grad norm: 1.325 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      856/    1200 | consumed samples:        41088 | elapsed time per iteration (ms): 1437.3 | learning rate: 1.318E-05 | global batch size:    48 | lm loss: 5.008577E+00 | loss scale: 32768.0 | grad norm: 1.336 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      857/    1200 | consumed samples:        41136 | elapsed time per iteration (ms): 1441.5 | learning rate: 1.320E-05 | global batch size:    48 | lm loss: 5.044402E+00 | loss scale: 32768.0 | grad norm: 1.318 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      858/    1200 | consumed samples:        41184 | elapsed time per iteration (ms): 1437.2 | learning rate: 1.321E-05 | global batch size:    48 | lm loss: 5.012194E+00 | loss scale: 32768.0 | grad norm: 1.344 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      859/    1200 | consumed samples:        41232 | elapsed time per iteration (ms): 1436.9 | learning rate: 1.323E-05 | global batch size:    48 | lm loss: 5.034430E+00 | loss scale: 32768.0 | grad norm: 1.326 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      860/    1200 | consumed samples:        41280 | elapsed time per iteration (ms): 1434.2 | learning rate: 1.324E-05 | global batch size:    48 | lm loss: 5.059266E+00 | loss scale: 32768.0 | grad norm: 1.492 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      861/    1200 | consumed samples:        41328 | elapsed time per iteration (ms): 1440.3 | learning rate: 1.326E-05 | global batch size:    48 | lm loss: 5.004678E+00 | loss scale: 32768.0 | grad norm: 1.441 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      862/    1200 | consumed samples:        41376 | elapsed time per iteration (ms): 1441.0 | learning rate: 1.328E-05 | global batch size:    48 | lm loss: 4.997869E+00 | loss scale: 32768.0 | grad norm: 1.465 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      863/    1200 | consumed samples:        41424 | elapsed time per iteration (ms): 1436.1 | learning rate: 1.329E-05 | global batch size:    48 | lm loss: 4.992743E+00 | loss scale: 32768.0 | grad norm: 1.398 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      864/    1200 | consumed samples:        41472 | elapsed time per iteration (ms): 1434.6 | learning rate: 1.331E-05 | global batch size:    48 | lm loss: 5.034234E+00 | loss scale: 32768.0 | grad norm: 1.377 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      865/    1200 | consumed samples:        41520 | elapsed time per iteration (ms): 1441.5 | learning rate: 1.332E-05 | global batch size:    48 | lm loss: 4.944192E+00 | loss scale: 32768.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      866/    1200 | consumed samples:        41568 | elapsed time per iteration (ms): 1434.0 | learning rate: 1.334E-05 | global batch size:    48 | lm loss: 5.083885E+00 | loss scale: 32768.0 | grad norm: 1.486 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      867/    1200 | consumed samples:        41616 | elapsed time per iteration (ms): 1439.3 | learning rate: 1.335E-05 | global batch size:    48 | lm loss: 5.089660E+00 | loss scale: 32768.0 | grad norm: 1.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      868/    1200 | consumed samples:        41664 | elapsed time per iteration (ms): 1438.8 | learning rate: 1.337E-05 | global batch size:    48 | lm loss: 5.044870E+00 | loss scale: 32768.0 | grad norm: 1.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      869/    1200 | consumed samples:        41712 | elapsed time per iteration (ms): 1440.6 | learning rate: 1.339E-05 | global batch size:    48 | lm loss: 5.020979E+00 | loss scale: 32768.0 | grad norm: 1.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      870/    1200 | consumed samples:        41760 | elapsed time per iteration (ms): 1437.6 | learning rate: 1.340E-05 | global batch size:    48 | lm loss: 4.951356E+00 | loss scale: 32768.0 | grad norm: 1.407 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      871/    1200 | consumed samples:        41808 | elapsed time per iteration (ms): 1437.6 | learning rate: 1.342E-05 | global batch size:    48 | lm loss: 4.918387E+00 | loss scale: 32768.0 | grad norm: 1.361 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      872/    1200 | consumed samples:        41856 | elapsed time per iteration (ms): 1435.7 | learning rate: 1.343E-05 | global batch size:    48 | lm loss: 4.972162E+00 | loss scale: 32768.0 | grad norm: 1.574 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      873/    1200 | consumed samples:        41904 | elapsed time per iteration (ms): 1443.5 | learning rate: 1.345E-05 | global batch size:    48 | lm loss: 5.038556E+00 | loss scale: 32768.0 | grad norm: 1.580 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      874/    1200 | consumed samples:        41952 | elapsed time per iteration (ms): 1435.3 | learning rate: 1.346E-05 | global batch size:    48 | lm loss: 5.102909E+00 | loss scale: 32768.0 | grad norm: 1.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      875/    1200 | consumed samples:        42000 | elapsed time per iteration (ms): 1449.3 | learning rate: 1.348E-05 | global batch size:    48 | lm loss: 4.951288E+00 | loss scale: 32768.0 | grad norm: 1.423 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      876/    1200 | consumed samples:        42048 | elapsed time per iteration (ms): 1435.5 | learning rate: 1.350E-05 | global batch size:    48 | lm loss: 4.961135E+00 | loss scale: 32768.0 | grad norm: 1.448 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      877/    1200 | consumed samples:        42096 | elapsed time per iteration (ms): 1441.6 | learning rate: 1.351E-05 | global batch size:    48 | lm loss: 5.018949E+00 | loss scale: 32768.0 | grad norm: 1.395 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      878/    1200 | consumed samples:        42144 | elapsed time per iteration (ms): 1439.2 | learning rate: 1.353E-05 | global batch size:    48 | lm loss: 5.057816E+00 | loss scale: 32768.0 | grad norm: 1.413 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      879/    1200 | consumed samples:        42192 | elapsed time per iteration (ms): 1436.3 | learning rate: 1.354E-05 | global batch size:    48 | lm loss: 5.022920E+00 | loss scale: 32768.0 | grad norm: 1.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      880/    1200 | consumed samples:        42240 | elapsed time per iteration (ms): 1442.3 | learning rate: 1.356E-05 | global batch size:    48 | lm loss: 4.995337E+00 | loss scale: 32768.0 | grad norm: 1.322 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      881/    1200 | consumed samples:        42288 | elapsed time per iteration (ms): 1442.7 | learning rate: 1.357E-05 | global batch size:    48 | lm loss: 4.952403E+00 | loss scale: 32768.0 | grad norm: 1.478 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      882/    1200 | consumed samples:        42336 | elapsed time per iteration (ms): 1435.4 | learning rate: 1.359E-05 | global batch size:    48 | lm loss: 5.039534E+00 | loss scale: 32768.0 | grad norm: 1.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      883/    1200 | consumed samples:        42384 | elapsed time per iteration (ms): 1439.4 | learning rate: 1.361E-05 | global batch size:    48 | lm loss: 5.069467E+00 | loss scale: 32768.0 | grad norm: 1.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      884/    1200 | consumed samples:        42432 | elapsed time per iteration (ms): 1435.9 | learning rate: 1.362E-05 | global batch size:    48 | lm loss: 5.030427E+00 | loss scale: 32768.0 | grad norm: 1.471 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      885/    1200 | consumed samples:        42480 | elapsed time per iteration (ms): 1443.5 | learning rate: 1.364E-05 | global batch size:    48 | lm loss: 5.021375E+00 | loss scale: 32768.0 | grad norm: 1.446 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      886/    1200 | consumed samples:        42528 | elapsed time per iteration (ms): 1434.6 | learning rate: 1.365E-05 | global batch size:    48 | lm loss: 4.941283E+00 | loss scale: 32768.0 | grad norm: 1.384 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      887/    1200 | consumed samples:        42576 | elapsed time per iteration (ms): 1440.6 | learning rate: 1.367E-05 | global batch size:    48 | lm loss: 5.048299E+00 | loss scale: 32768.0 | grad norm: 1.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      888/    1200 | consumed samples:        42624 | elapsed time per iteration (ms): 1435.6 | learning rate: 1.368E-05 | global batch size:    48 | lm loss: 4.990573E+00 | loss scale: 32768.0 | grad norm: 1.442 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      889/    1200 | consumed samples:        42672 | elapsed time per iteration (ms): 1443.8 | learning rate: 1.370E-05 | global batch size:    48 | lm loss: 4.998578E+00 | loss scale: 32768.0 | grad norm: 1.361 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      890/    1200 | consumed samples:        42720 | elapsed time per iteration (ms): 1437.9 | learning rate: 1.372E-05 | global batch size:    48 | lm loss: 5.002710E+00 | loss scale: 32768.0 | grad norm: 1.354 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      891/    1200 | consumed samples:        42768 | elapsed time per iteration (ms): 2219.9 | learning rate: 1.373E-05 | global batch size:    48 | lm loss: 5.028064E+00 | loss scale: 32768.0 | grad norm: 1.341 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      892/    1200 | consumed samples:        42816 | elapsed time per iteration (ms): 3833.4 | learning rate: 1.375E-05 | global batch size:    48 | lm loss: 5.005865E+00 | loss scale: 32768.0 | grad norm: 1.490 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      893/    1200 | consumed samples:        42864 | elapsed time per iteration (ms): 3835.6 | learning rate: 1.376E-05 | global batch size:    48 | lm loss: 4.993204E+00 | loss scale: 32768.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      894/    1200 | consumed samples:        42912 | elapsed time per iteration (ms): 3839.5 | learning rate: 1.378E-05 | global batch size:    48 | lm loss: 4.968788E+00 | loss scale: 32768.0 | grad norm: 1.282 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      895/    1200 | consumed samples:        42960 | elapsed time per iteration (ms): 3834.7 | learning rate: 1.379E-05 | global batch size:    48 | lm loss: 4.955633E+00 | loss scale: 32768.0 | grad norm: 1.405 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      896/    1200 | consumed samples:        43008 | elapsed time per iteration (ms): 3831.5 | learning rate: 1.381E-05 | global batch size:    48 | lm loss: 4.926654E+00 | loss scale: 32768.0 | grad norm: 1.462 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      897/    1200 | consumed samples:        43056 | elapsed time per iteration (ms): 3837.0 | learning rate: 1.383E-05 | global batch size:    48 | lm loss: 4.951380E+00 | loss scale: 32768.0 | grad norm: 1.350 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      898/    1200 | consumed samples:        43104 | elapsed time per iteration (ms): 3833.2 | learning rate: 1.384E-05 | global batch size:    48 | lm loss: 5.013827E+00 | loss scale: 32768.0 | grad norm: 1.454 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      899/    1200 | consumed samples:        43152 | elapsed time per iteration (ms): 3831.3 | learning rate: 1.386E-05 | global batch size:    48 | lm loss: 5.021867E+00 | loss scale: 32768.0 | grad norm: 1.302 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      900/    1200 | consumed samples:        43200 | elapsed time per iteration (ms): 3827.6 | learning rate: 1.387E-05 | global batch size:    48 | lm loss: 4.940875E+00 | loss scale: 32768.0 | grad norm: 1.428 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      901/    1200 | consumed samples:        43248 | elapsed time per iteration (ms): 3835.9 | learning rate: 1.389E-05 | global batch size:    48 | lm loss: 4.986885E+00 | loss scale: 32768.0 | grad norm: 1.466 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      902/    1200 | consumed samples:        43296 | elapsed time per iteration (ms): 3833.5 | learning rate: 1.390E-05 | global batch size:    48 | lm loss: 4.948869E+00 | loss scale: 32768.0 | grad norm: 1.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      903/    1200 | consumed samples:        43344 | elapsed time per iteration (ms): 3832.5 | learning rate: 1.392E-05 | global batch size:    48 | lm loss: 4.985087E+00 | loss scale: 32768.0 | grad norm: 1.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      904/    1200 | consumed samples:        43392 | elapsed time per iteration (ms): 3832.4 | learning rate: 1.394E-05 | global batch size:    48 | lm loss: 4.931373E+00 | loss scale: 32768.0 | grad norm: 1.569 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      905/    1200 | consumed samples:        43440 | elapsed time per iteration (ms): 3838.1 | learning rate: 1.395E-05 | global batch size:    48 | lm loss: 4.869908E+00 | loss scale: 32768.0 | grad norm: 1.382 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      906/    1200 | consumed samples:        43488 | elapsed time per iteration (ms): 3835.1 | learning rate: 1.397E-05 | global batch size:    48 | lm loss: 4.945275E+00 | loss scale: 32768.0 | grad norm: 1.393 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      907/    1200 | consumed samples:        43536 | elapsed time per iteration (ms): 3833.3 | learning rate: 1.398E-05 | global batch size:    48 | lm loss: 4.934757E+00 | loss scale: 32768.0 | grad norm: 1.327 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      908/    1200 | consumed samples:        43584 | elapsed time per iteration (ms): 3835.6 | learning rate: 1.400E-05 | global batch size:    48 | lm loss: 4.963677E+00 | loss scale: 32768.0 | grad norm: 1.304 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      909/    1200 | consumed samples:        43632 | elapsed time per iteration (ms): 3839.8 | learning rate: 1.401E-05 | global batch size:    48 | lm loss: 4.961169E+00 | loss scale: 32768.0 | grad norm: 1.605 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      910/    1200 | consumed samples:        43680 | elapsed time per iteration (ms): 3944.4 | learning rate: 1.403E-05 | global batch size:    48 | lm loss: 4.991115E+00 | loss scale: 32768.0 | grad norm: 1.780 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      911/    1200 | consumed samples:        43728 | elapsed time per iteration (ms): 3833.0 | learning rate: 1.405E-05 | global batch size:    48 | lm loss: 5.006304E+00 | loss scale: 32768.0 | grad norm: 1.688 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      912/    1200 | consumed samples:        43776 | elapsed time per iteration (ms): 3833.9 | learning rate: 1.406E-05 | global batch size:    48 | lm loss: 4.901243E+00 | loss scale: 32768.0 | grad norm: 1.431 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      913/    1200 | consumed samples:        43824 | elapsed time per iteration (ms): 3838.6 | learning rate: 1.408E-05 | global batch size:    48 | lm loss: 5.010064E+00 | loss scale: 32768.0 | grad norm: 1.583 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      914/    1200 | consumed samples:        43872 | elapsed time per iteration (ms): 3833.8 | learning rate: 1.409E-05 | global batch size:    48 | lm loss: 4.965777E+00 | loss scale: 32768.0 | grad norm: 1.312 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      915/    1200 | consumed samples:        43920 | elapsed time per iteration (ms): 3835.8 | learning rate: 1.411E-05 | global batch size:    48 | lm loss: 4.991353E+00 | loss scale: 32768.0 | grad norm: 1.352 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      916/    1200 | consumed samples:        43968 | elapsed time per iteration (ms): 3830.1 | learning rate: 1.412E-05 | global batch size:    48 | lm loss: 5.007258E+00 | loss scale: 32768.0 | grad norm: 1.391 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      917/    1200 | consumed samples:        44016 | elapsed time per iteration (ms): 3836.5 | learning rate: 1.414E-05 | global batch size:    48 | lm loss: 5.015459E+00 | loss scale: 32768.0 | grad norm: 1.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      918/    1200 | consumed samples:        44064 | elapsed time per iteration (ms): 3833.3 | learning rate: 1.416E-05 | global batch size:    48 | lm loss: 4.870026E+00 | loss scale: 32768.0 | grad norm: 1.262 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      919/    1200 | consumed samples:        44112 | elapsed time per iteration (ms): 3833.9 | learning rate: 1.417E-05 | global batch size:    48 | lm loss: 5.059922E+00 | loss scale: 32768.0 | grad norm: 1.450 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      920/    1200 | consumed samples:        44160 | elapsed time per iteration (ms): 3830.7 | learning rate: 1.419E-05 | global batch size:    48 | lm loss: 4.867715E+00 | loss scale: 32768.0 | grad norm: 1.453 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      921/    1200 | consumed samples:        44208 | elapsed time per iteration (ms): 3836.7 | learning rate: 1.420E-05 | global batch size:    48 | lm loss: 4.961184E+00 | loss scale: 32768.0 | grad norm: 1.288 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      922/    1200 | consumed samples:        44256 | elapsed time per iteration (ms): 3834.1 | learning rate: 1.422E-05 | global batch size:    48 | lm loss: 4.955062E+00 | loss scale: 32768.0 | grad norm: 1.288 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      923/    1200 | consumed samples:        44304 | elapsed time per iteration (ms): 3832.8 | learning rate: 1.423E-05 | global batch size:    48 | lm loss: 4.926320E+00 | loss scale: 32768.0 | grad norm: 1.301 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      924/    1200 | consumed samples:        44352 | elapsed time per iteration (ms): 3833.6 | learning rate: 1.425E-05 | global batch size:    48 | lm loss: 4.906274E+00 | loss scale: 32768.0 | grad norm: 1.328 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      925/    1200 | consumed samples:        44400 | elapsed time per iteration (ms): 3839.6 | learning rate: 1.427E-05 | global batch size:    48 | lm loss: 4.996305E+00 | loss scale: 32768.0 | grad norm: 1.325 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      926/    1200 | consumed samples:        44448 | elapsed time per iteration (ms): 3832.8 | learning rate: 1.428E-05 | global batch size:    48 | lm loss: 4.906466E+00 | loss scale: 32768.0 | grad norm: 1.281 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      927/    1200 | consumed samples:        44496 | elapsed time per iteration (ms): 3831.8 | learning rate: 1.430E-05 | global batch size:    48 | lm loss: 4.946364E+00 | loss scale: 32768.0 | grad norm: 1.318 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      928/    1200 | consumed samples:        44544 | elapsed time per iteration (ms): 3831.9 | learning rate: 1.431E-05 | global batch size:    48 | lm loss: 4.904430E+00 | loss scale: 32768.0 | grad norm: 1.364 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      929/    1200 | consumed samples:        44592 | elapsed time per iteration (ms): 3842.1 | learning rate: 1.433E-05 | global batch size:    48 | lm loss: 4.971917E+00 | loss scale: 32768.0 | grad norm: 1.323 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      930/    1200 | consumed samples:        44640 | elapsed time per iteration (ms): 3842.5 | learning rate: 1.434E-05 | global batch size:    48 | lm loss: 4.949146E+00 | loss scale: 32768.0 | grad norm: 1.456 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      931/    1200 | consumed samples:        44688 | elapsed time per iteration (ms): 3846.3 | learning rate: 1.436E-05 | global batch size:    48 | lm loss: 4.929554E+00 | loss scale: 32768.0 | grad norm: 1.565 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      932/    1200 | consumed samples:        44736 | elapsed time per iteration (ms): 3837.0 | learning rate: 1.438E-05 | global batch size:    48 | lm loss: 4.997159E+00 | loss scale: 32768.0 | grad norm: 1.392 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      933/    1200 | consumed samples:        44784 | elapsed time per iteration (ms): 3835.7 | learning rate: 1.439E-05 | global batch size:    48 | lm loss: 4.894542E+00 | loss scale: 32768.0 | grad norm: 1.320 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      934/    1200 | consumed samples:        44832 | elapsed time per iteration (ms): 3831.7 | learning rate: 1.441E-05 | global batch size:    48 | lm loss: 4.927622E+00 | loss scale: 32768.0 | grad norm: 1.349 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      935/    1200 | consumed samples:        44880 | elapsed time per iteration (ms): 3832.9 | learning rate: 1.442E-05 | global batch size:    48 | lm loss: 4.917808E+00 | loss scale: 32768.0 | grad norm: 1.331 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      936/    1200 | consumed samples:        44928 | elapsed time per iteration (ms): 3835.7 | learning rate: 1.444E-05 | global batch size:    48 | lm loss: 4.937590E+00 | loss scale: 32768.0 | grad norm: 1.430 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      937/    1200 | consumed samples:        44976 | elapsed time per iteration (ms): 3837.6 | learning rate: 1.445E-05 | global batch size:    48 | lm loss: 4.989191E+00 | loss scale: 32768.0 | grad norm: 1.529 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      938/    1200 | consumed samples:        45024 | elapsed time per iteration (ms): 3832.0 | learning rate: 1.447E-05 | global batch size:    48 | lm loss: 4.959288E+00 | loss scale: 32768.0 | grad norm: 1.399 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      939/    1200 | consumed samples:        45072 | elapsed time per iteration (ms): 3833.5 | learning rate: 1.449E-05 | global batch size:    48 | lm loss: 4.864261E+00 | loss scale: 32768.0 | grad norm: 1.297 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      940/    1200 | consumed samples:        45120 | elapsed time per iteration (ms): 3837.0 | learning rate: 1.450E-05 | global batch size:    48 | lm loss: 4.944425E+00 | loss scale: 32768.0 | grad norm: 1.409 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      941/    1200 | consumed samples:        45168 | elapsed time per iteration (ms): 3835.0 | learning rate: 1.452E-05 | global batch size:    48 | lm loss: 4.870486E+00 | loss scale: 32768.0 | grad norm: 1.536 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      942/    1200 | consumed samples:        45216 | elapsed time per iteration (ms): 3833.9 | learning rate: 1.453E-05 | global batch size:    48 | lm loss: 4.921926E+00 | loss scale: 32768.0 | grad norm: 1.402 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      943/    1200 | consumed samples:        45264 | elapsed time per iteration (ms): 3835.6 | learning rate: 1.455E-05 | global batch size:    48 | lm loss: 4.954865E+00 | loss scale: 32768.0 | grad norm: 1.250 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      944/    1200 | consumed samples:        45312 | elapsed time per iteration (ms): 3832.4 | learning rate: 1.456E-05 | global batch size:    48 | lm loss: 4.887511E+00 | loss scale: 32768.0 | grad norm: 1.211 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      945/    1200 | consumed samples:        45360 | elapsed time per iteration (ms): 3836.7 | learning rate: 1.458E-05 | global batch size:    48 | lm loss: 4.921312E+00 | loss scale: 32768.0 | grad norm: 1.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      946/    1200 | consumed samples:        45408 | elapsed time per iteration (ms): 3884.4 | learning rate: 1.460E-05 | global batch size:    48 | lm loss: 4.827180E+00 | loss scale: 32768.0 | grad norm: 1.245 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      947/    1200 | consumed samples:        45456 | elapsed time per iteration (ms): 3831.0 | learning rate: 1.461E-05 | global batch size:    48 | lm loss: 4.968146E+00 | loss scale: 32768.0 | grad norm: 1.234 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      948/    1200 | consumed samples:        45504 | elapsed time per iteration (ms): 3834.4 | learning rate: 1.463E-05 | global batch size:    48 | lm loss: 4.881737E+00 | loss scale: 32768.0 | grad norm: 1.226 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      949/    1200 | consumed samples:        45552 | elapsed time per iteration (ms): 3836.7 | learning rate: 1.464E-05 | global batch size:    48 | lm loss: 4.998432E+00 | loss scale: 32768.0 | grad norm: 1.183 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      950/    1200 | consumed samples:        45600 | elapsed time per iteration (ms): 3831.7 | learning rate: 1.466E-05 | global batch size:    48 | lm loss: 5.007378E+00 | loss scale: 32768.0 | grad norm: 2.273 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      951/    1200 | consumed samples:        45648 | elapsed time per iteration (ms): 3832.3 | learning rate: 1.467E-05 | global batch size:    48 | lm loss: 4.868994E+00 | loss scale: 32768.0 | grad norm: 1.315 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      952/    1200 | consumed samples:        45696 | elapsed time per iteration (ms): 3831.2 | learning rate: 1.469E-05 | global batch size:    48 | lm loss: 4.919675E+00 | loss scale: 32768.0 | grad norm: 1.307 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      953/    1200 | consumed samples:        45744 | elapsed time per iteration (ms): 3838.0 | learning rate: 1.471E-05 | global batch size:    48 | lm loss: 4.931740E+00 | loss scale: 32768.0 | grad norm: 1.363 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      954/    1200 | consumed samples:        45792 | elapsed time per iteration (ms): 3835.5 | learning rate: 1.472E-05 | global batch size:    48 | lm loss: 4.965386E+00 | loss scale: 32768.0 | grad norm: 1.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      955/    1200 | consumed samples:        45840 | elapsed time per iteration (ms): 3832.3 | learning rate: 1.474E-05 | global batch size:    48 | lm loss: 5.031573E+00 | loss scale: 32768.0 | grad norm: 2.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      956/    1200 | consumed samples:        45888 | elapsed time per iteration (ms): 3831.1 | learning rate: 1.475E-05 | global batch size:    48 | lm loss: 4.966691E+00 | loss scale: 32768.0 | grad norm: 1.948 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      957/    1200 | consumed samples:        45936 | elapsed time per iteration (ms): 3840.3 | learning rate: 1.477E-05 | global batch size:    48 | lm loss: 4.922041E+00 | loss scale: 32768.0 | grad norm: 1.418 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      958/    1200 | consumed samples:        45984 | elapsed time per iteration (ms): 3830.9 | learning rate: 1.478E-05 | global batch size:    48 | lm loss: 4.986791E+00 | loss scale: 32768.0 | grad norm: 1.336 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      959/    1200 | consumed samples:        46032 | elapsed time per iteration (ms): 3835.2 | learning rate: 1.480E-05 | global batch size:    48 | lm loss: 4.897542E+00 | loss scale: 32768.0 | grad norm: 1.267 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      960/    1200 | consumed samples:        46080 | elapsed time per iteration (ms): 3832.7 | learning rate: 1.482E-05 | global batch size:    48 | lm loss: 4.947811E+00 | loss scale: 32768.0 | grad norm: 1.313 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      961/    1200 | consumed samples:        46128 | elapsed time per iteration (ms): 1443.5 | learning rate: 1.483E-05 | global batch size:    48 | lm loss: 4.822493E+00 | loss scale: 32768.0 | grad norm: 1.274 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      962/    1200 | consumed samples:        46176 | elapsed time per iteration (ms): 1435.1 | learning rate: 1.485E-05 | global batch size:    48 | lm loss: 4.947109E+00 | loss scale: 32768.0 | grad norm: 1.292 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      963/    1200 | consumed samples:        46224 | elapsed time per iteration (ms): 1440.8 | learning rate: 1.486E-05 | global batch size:    48 | lm loss: 4.864611E+00 | loss scale: 32768.0 | grad norm: 1.246 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      964/    1200 | consumed samples:        46272 | elapsed time per iteration (ms): 1437.1 | learning rate: 1.488E-05 | global batch size:    48 | lm loss: 4.920734E+00 | loss scale: 32768.0 | grad norm: 1.319 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      965/    1200 | consumed samples:        46320 | elapsed time per iteration (ms): 1441.2 | learning rate: 1.490E-05 | global batch size:    48 | lm loss: 4.876105E+00 | loss scale: 32768.0 | grad norm: 1.336 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      966/    1200 | consumed samples:        46368 | elapsed time per iteration (ms): 1437.2 | learning rate: 1.491E-05 | global batch size:    48 | lm loss: 4.923575E+00 | loss scale: 32768.0 | grad norm: 1.315 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      967/    1200 | consumed samples:        46416 | elapsed time per iteration (ms): 1437.7 | learning rate: 1.493E-05 | global batch size:    48 | lm loss: 4.934511E+00 | loss scale: 32768.0 | grad norm: 1.278 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      968/    1200 | consumed samples:        46464 | elapsed time per iteration (ms): 1436.9 | learning rate: 1.494E-05 | global batch size:    48 | lm loss: 4.895890E+00 | loss scale: 32768.0 | grad norm: 1.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      969/    1200 | consumed samples:        46512 | elapsed time per iteration (ms): 1441.7 | learning rate: 1.496E-05 | global batch size:    48 | lm loss: 4.881251E+00 | loss scale: 32768.0 | grad norm: 1.232 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      970/    1200 | consumed samples:        46560 | elapsed time per iteration (ms): 1437.3 | learning rate: 1.497E-05 | global batch size:    48 | lm loss: 4.940112E+00 | loss scale: 32768.0 | grad norm: 1.236 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      971/    1200 | consumed samples:        46608 | elapsed time per iteration (ms): 1438.6 | learning rate: 1.499E-05 | global batch size:    48 | lm loss: 4.918411E+00 | loss scale: 32768.0 | grad norm: 1.208 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      972/    1200 | consumed samples:        46656 | elapsed time per iteration (ms): 1514.0 | learning rate: 1.501E-05 | global batch size:    48 | lm loss: 4.868036E+00 | loss scale: 32768.0 | grad norm: 1.187 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      973/    1200 | consumed samples:        46704 | elapsed time per iteration (ms): 1551.2 | learning rate: 1.502E-05 | global batch size:    48 | lm loss: 4.976703E+00 | loss scale: 32768.0 | grad norm: 1.290 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      974/    1200 | consumed samples:        46752 | elapsed time per iteration (ms): 1435.4 | learning rate: 1.504E-05 | global batch size:    48 | lm loss: 4.812320E+00 | loss scale: 32768.0 | grad norm: 1.224 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      975/    1200 | consumed samples:        46800 | elapsed time per iteration (ms): 1437.9 | learning rate: 1.505E-05 | global batch size:    48 | lm loss: 4.913858E+00 | loss scale: 32768.0 | grad norm: 1.210 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      976/    1200 | consumed samples:        46848 | elapsed time per iteration (ms): 1434.5 | learning rate: 1.507E-05 | global batch size:    48 | lm loss: 4.860982E+00 | loss scale: 32768.0 | grad norm: 1.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      977/    1200 | consumed samples:        46896 | elapsed time per iteration (ms): 1440.2 | learning rate: 1.508E-05 | global batch size:    48 | lm loss: 4.887905E+00 | loss scale: 32768.0 | grad norm: 1.175 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      978/    1200 | consumed samples:        46944 | elapsed time per iteration (ms): 1437.9 | learning rate: 1.510E-05 | global batch size:    48 | lm loss: 4.864428E+00 | loss scale: 32768.0 | grad norm: 1.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      979/    1200 | consumed samples:        46992 | elapsed time per iteration (ms): 1436.9 | learning rate: 1.512E-05 | global batch size:    48 | lm loss: 4.896111E+00 | loss scale: 32768.0 | grad norm: 1.281 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      980/    1200 | consumed samples:        47040 | elapsed time per iteration (ms): 1436.0 | learning rate: 1.513E-05 | global batch size:    48 | lm loss: 4.877704E+00 | loss scale: 32768.0 | grad norm: 1.411 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      981/    1200 | consumed samples:        47088 | elapsed time per iteration (ms): 1442.1 | learning rate: 1.515E-05 | global batch size:    48 | lm loss: 4.846342E+00 | loss scale: 32768.0 | grad norm: 1.424 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      982/    1200 | consumed samples:        47136 | elapsed time per iteration (ms): 1437.3 | learning rate: 1.516E-05 | global batch size:    48 | lm loss: 4.859331E+00 | loss scale: 32768.0 | grad norm: 1.281 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      983/    1200 | consumed samples:        47184 | elapsed time per iteration (ms): 1441.9 | learning rate: 1.518E-05 | global batch size:    48 | lm loss: 4.887243E+00 | loss scale: 32768.0 | grad norm: 1.273 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      984/    1200 | consumed samples:        47232 | elapsed time per iteration (ms): 1442.6 | learning rate: 1.519E-05 | global batch size:    48 | lm loss: 4.824870E+00 | loss scale: 32768.0 | grad norm: 1.339 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      985/    1200 | consumed samples:        47280 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.521E-05 | global batch size:    48 | lm loss: 4.927506E+00 | loss scale: 32768.0 | grad norm: 1.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      986/    1200 | consumed samples:        47328 | elapsed time per iteration (ms): 1437.8 | learning rate: 1.523E-05 | global batch size:    48 | lm loss: 4.830595E+00 | loss scale: 32768.0 | grad norm: 1.270 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      987/    1200 | consumed samples:        47376 | elapsed time per iteration (ms): 1434.9 | learning rate: 1.524E-05 | global batch size:    48 | lm loss: 4.846704E+00 | loss scale: 32768.0 | grad norm: 1.425 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      988/    1200 | consumed samples:        47424 | elapsed time per iteration (ms): 1440.4 | learning rate: 1.526E-05 | global batch size:    48 | lm loss: 4.912355E+00 | loss scale: 32768.0 | grad norm: 1.381 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      989/    1200 | consumed samples:        47472 | elapsed time per iteration (ms): 1441.6 | learning rate: 1.527E-05 | global batch size:    48 | lm loss: 4.874682E+00 | loss scale: 32768.0 | grad norm: 1.273 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      990/    1200 | consumed samples:        47520 | elapsed time per iteration (ms): 1437.9 | learning rate: 1.529E-05 | global batch size:    48 | lm loss: 4.855289E+00 | loss scale: 32768.0 | grad norm: 1.396 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      991/    1200 | consumed samples:        47568 | elapsed time per iteration (ms): 1440.6 | learning rate: 1.530E-05 | global batch size:    48 | lm loss: 4.804652E+00 | loss scale: 32768.0 | grad norm: 1.331 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      992/    1200 | consumed samples:        47616 | elapsed time per iteration (ms): 1434.2 | learning rate: 1.532E-05 | global batch size:    48 | lm loss: 4.817753E+00 | loss scale: 32768.0 | grad norm: 1.233 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      993/    1200 | consumed samples:        47664 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.534E-05 | global batch size:    48 | lm loss: 4.818590E+00 | loss scale: 32768.0 | grad norm: 1.268 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      994/    1200 | consumed samples:        47712 | elapsed time per iteration (ms): 1439.1 | learning rate: 1.535E-05 | global batch size:    48 | lm loss: 4.912619E+00 | loss scale: 32768.0 | grad norm: 1.937 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      995/    1200 | consumed samples:        47760 | elapsed time per iteration (ms): 1438.2 | learning rate: 1.537E-05 | global batch size:    48 | lm loss: 4.836234E+00 | loss scale: 32768.0 | grad norm: 1.301 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      996/    1200 | consumed samples:        47808 | elapsed time per iteration (ms): 1434.8 | learning rate: 1.538E-05 | global batch size:    48 | lm loss: 4.934799E+00 | loss scale: 32768.0 | grad norm: 1.370 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      997/    1200 | consumed samples:        47856 | elapsed time per iteration (ms): 1439.0 | learning rate: 1.540E-05 | global batch size:    48 | lm loss: 4.844072E+00 | loss scale: 32768.0 | grad norm: 1.350 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      998/    1200 | consumed samples:        47904 | elapsed time per iteration (ms): 1437.3 | learning rate: 1.541E-05 | global batch size:    48 | lm loss: 4.842559E+00 | loss scale: 32768.0 | grad norm: 1.314 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      999/    1200 | consumed samples:        47952 | elapsed time per iteration (ms): 1436.1 | learning rate: 1.543E-05 | global batch size:    48 | lm loss: 4.767199E+00 | loss scale: 32768.0 | grad norm: 1.482 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1000/    1200 | consumed samples:        48000 | elapsed time per iteration (ms): 1434.7 | learning rate: 1.545E-05 | global batch size:    48 | lm loss: 4.738292E+00 | loss scale: 32768.0 | grad norm: 1.216 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1001/    1200 | consumed samples:        48048 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.546E-05 | global batch size:    48 | lm loss: 4.844356E+00 | loss scale: 32768.0 | grad norm: 1.268 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1002/    1200 | consumed samples:        48096 | elapsed time per iteration (ms): 1439.3 | learning rate: 1.548E-05 | global batch size:    48 | lm loss: 4.856900E+00 | loss scale: 32768.0 | grad norm: 1.341 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1003/    1200 | consumed samples:        48144 | elapsed time per iteration (ms): 1439.7 | learning rate: 1.549E-05 | global batch size:    48 | lm loss: 4.853392E+00 | loss scale: 32768.0 | grad norm: 1.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1004/    1200 | consumed samples:        48192 | elapsed time per iteration (ms): 1436.6 | learning rate: 1.551E-05 | global batch size:    48 | lm loss: 4.899256E+00 | loss scale: 32768.0 | grad norm: 1.208 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1005/    1200 | consumed samples:        48240 | elapsed time per iteration (ms): 1441.5 | learning rate: 1.552E-05 | global batch size:    48 | lm loss: 4.737975E+00 | loss scale: 32768.0 | grad norm: 1.205 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1006/    1200 | consumed samples:        48288 | elapsed time per iteration (ms): 1437.8 | learning rate: 1.554E-05 | global batch size:    48 | lm loss: 4.846519E+00 | loss scale: 32768.0 | grad norm: 1.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1007/    1200 | consumed samples:        48336 | elapsed time per iteration (ms): 1438.5 | learning rate: 1.556E-05 | global batch size:    48 | lm loss: 4.852464E+00 | loss scale: 32768.0 | grad norm: 1.232 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1008/    1200 | consumed samples:        48384 | elapsed time per iteration (ms): 1435.0 | learning rate: 1.557E-05 | global batch size:    48 | lm loss: 4.789092E+00 | loss scale: 32768.0 | grad norm: 1.274 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1009/    1200 | consumed samples:        48432 | elapsed time per iteration (ms): 1440.0 | learning rate: 1.559E-05 | global batch size:    48 | lm loss: 4.833024E+00 | loss scale: 32768.0 | grad norm: 1.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1010/    1200 | consumed samples:        48480 | elapsed time per iteration (ms): 1435.7 | learning rate: 1.560E-05 | global batch size:    48 | lm loss: 4.751767E+00 | loss scale: 32768.0 | grad norm: 1.265 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1011/    1200 | consumed samples:        48528 | elapsed time per iteration (ms): 1438.2 | learning rate: 1.562E-05 | global batch size:    48 | lm loss: 4.819711E+00 | loss scale: 32768.0 | grad norm: 1.244 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1012/    1200 | consumed samples:        48576 | elapsed time per iteration (ms): 1435.2 | learning rate: 1.563E-05 | global batch size:    48 | lm loss: 4.801012E+00 | loss scale: 32768.0 | grad norm: 1.280 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1013/    1200 | consumed samples:        48624 | elapsed time per iteration (ms): 1440.3 | learning rate: 1.565E-05 | global batch size:    48 | lm loss: 4.828969E+00 | loss scale: 32768.0 | grad norm: 1.213 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1014/    1200 | consumed samples:        48672 | elapsed time per iteration (ms): 1439.5 | learning rate: 1.567E-05 | global batch size:    48 | lm loss: 4.759657E+00 | loss scale: 32768.0 | grad norm: 1.227 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1015/    1200 | consumed samples:        48720 | elapsed time per iteration (ms): 1436.2 | learning rate: 1.568E-05 | global batch size:    48 | lm loss: 4.888781E+00 | loss scale: 32768.0 | grad norm: 1.251 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1016/    1200 | consumed samples:        48768 | elapsed time per iteration (ms): 1435.1 | learning rate: 1.570E-05 | global batch size:    48 | lm loss: 4.756631E+00 | loss scale: 32768.0 | grad norm: 1.238 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1017/    1200 | consumed samples:        48816 | elapsed time per iteration (ms): 1442.4 | learning rate: 1.571E-05 | global batch size:    48 | lm loss: 4.740121E+00 | loss scale: 32768.0 | grad norm: 1.258 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1018/    1200 | consumed samples:        48864 | elapsed time per iteration (ms): 1439.0 | learning rate: 1.573E-05 | global batch size:    48 | lm loss: 4.780473E+00 | loss scale: 32768.0 | grad norm: 1.212 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1019/    1200 | consumed samples:        48912 | elapsed time per iteration (ms): 1436.2 | learning rate: 1.574E-05 | global batch size:    48 | lm loss: 4.791512E+00 | loss scale: 32768.0 | grad norm: 1.306 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1020/    1200 | consumed samples:        48960 | elapsed time per iteration (ms): 1435.3 | learning rate: 1.576E-05 | global batch size:    48 | lm loss: 4.790600E+00 | loss scale: 32768.0 | grad norm: 1.289 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1021/    1200 | consumed samples:        49008 | elapsed time per iteration (ms): 1440.8 | learning rate: 1.578E-05 | global batch size:    48 | lm loss: 4.812922E+00 | loss scale: 32768.0 | grad norm: 1.420 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1022/    1200 | consumed samples:        49056 | elapsed time per iteration (ms): 1435.0 | learning rate: 1.579E-05 | global batch size:    48 | lm loss: 4.809026E+00 | loss scale: 32768.0 | grad norm: 1.293 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1023/    1200 | consumed samples:        49104 | elapsed time per iteration (ms): 1437.2 | learning rate: 1.581E-05 | global batch size:    48 | lm loss: 4.731261E+00 | loss scale: 65536.0 | grad norm: 1.205 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1024/    1200 | consumed samples:        49152 | elapsed time per iteration (ms): 1437.7 | learning rate: 1.582E-05 | global batch size:    48 | lm loss: 4.772751E+00 | loss scale: 65536.0 | grad norm: 1.231 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1025/    1200 | consumed samples:        49200 | elapsed time per iteration (ms): 1444.6 | learning rate: 1.584E-05 | global batch size:    48 | lm loss: 4.851331E+00 | loss scale: 65536.0 | grad norm: 1.223 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1026/    1200 | consumed samples:        49248 | elapsed time per iteration (ms): 1439.6 | learning rate: 1.585E-05 | global batch size:    48 | lm loss: 4.764081E+00 | loss scale: 65536.0 | grad norm: 1.253 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1027/    1200 | consumed samples:        49296 | elapsed time per iteration (ms): 1438.1 | learning rate: 1.587E-05 | global batch size:    48 | lm loss: 4.777370E+00 | loss scale: 65536.0 | grad norm: 1.245 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1028/    1200 | consumed samples:        49344 | elapsed time per iteration (ms): 1436.3 | learning rate: 1.589E-05 | global batch size:    48 | lm loss: 4.778150E+00 | loss scale: 65536.0 | grad norm: 1.217 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1029/    1200 | consumed samples:        49392 | elapsed time per iteration (ms): 1442.8 | learning rate: 1.590E-05 | global batch size:    48 | lm loss: 4.764557E+00 | loss scale: 65536.0 | grad norm: 1.174 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration     1030/    1200 | consumed samples:        49440 | elapsed time per iteration (ms): 1438.0 | learning rate: 1.592E-05 | global batch size:    48 | lm loss: 4.748086E+00 | loss scale: 65536.0 | grad norm: 1.222 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration        1/     170 | consumed samples:           48 | elapsed time per iteration (ms): 88685.2 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4294967296.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        2/     170 | consumed samples:           96 | elapsed time per iteration (ms): 1504.2 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2147483648.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        3/     170 | consumed samples:          144 | elapsed time per iteration (ms): 1382.4 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1073741824.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        4/     170 | consumed samples:          192 | elapsed time per iteration (ms): 1408.2 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 536870912.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        5/     170 | consumed samples:          240 | elapsed time per iteration (ms): 1412.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 268435456.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        6/     170 | consumed samples:          288 | elapsed time per iteration (ms): 1407.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 134217728.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        7/     170 | consumed samples:          336 | elapsed time per iteration (ms): 1405.0 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 67108864.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        8/     170 | consumed samples:          384 | elapsed time per iteration (ms): 1407.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 33554432.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration        9/     170 | consumed samples:          432 | elapsed time per iteration (ms): 1409.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 16777216.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       10/     170 | consumed samples:          480 | elapsed time per iteration (ms): 1404.2 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 8388608.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       11/     170 | consumed samples:          528 | elapsed time per iteration (ms): 1402.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 4194304.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       12/     170 | consumed samples:          576 | elapsed time per iteration (ms): 1403.8 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 2097152.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       13/     170 | consumed samples:          624 | elapsed time per iteration (ms): 1408.0 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 1048576.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       14/     170 | consumed samples:          672 | elapsed time per iteration (ms): 1403.0 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 524288.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       15/     170 | consumed samples:          720 | elapsed time per iteration (ms): 1402.9 | learning rate: 0.000E+00 | global batch size:    48 | loss scale: 262144.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       16/     170 | consumed samples:          768 | elapsed time per iteration (ms): 1568.6 | learning rate: 1.573E-08 | global batch size:    48 | lm loss: 1.065781E+01 | loss scale: 262144.0 | grad norm: 157.254 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       17/     170 | consumed samples:          816 | elapsed time per iteration (ms): 1647.6 | learning rate: 3.146E-08 | global batch size:    48 | lm loss: 1.065981E+01 | loss scale: 262144.0 | grad norm: 164.358 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       18/     170 | consumed samples:          864 | elapsed time per iteration (ms): 1444.9 | learning rate: 4.719E-08 | global batch size:    48 | lm loss: 1.065036E+01 | loss scale: 262144.0 | grad norm: 159.068 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       19/     170 | consumed samples:          912 | elapsed time per iteration (ms): 1443.5 | learning rate: 6.291E-08 | global batch size:    48 | lm loss: 1.042427E+01 | loss scale: 262144.0 | grad norm: 159.995 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       20/     170 | consumed samples:          960 | elapsed time per iteration (ms): 1444.3 | learning rate: 7.864E-08 | global batch size:    48 | lm loss: 9.801708E+00 | loss scale: 262144.0 | grad norm: 138.662 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       21/     170 | consumed samples:         1008 | elapsed time per iteration (ms): 1408.7 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 131072.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       22/     170 | consumed samples:         1056 | elapsed time per iteration (ms): 1401.5 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 65536.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       23/     170 | consumed samples:         1104 | elapsed time per iteration (ms): 1402.4 | learning rate: 7.864E-08 | global batch size:    48 | loss scale: 32768.0 | number of skipped iterations:   1 | number of nan iterations:   0 |
 iteration       24/     170 | consumed samples:         1152 | elapsed time per iteration (ms): 1443.0 | learning rate: 9.437E-08 | global batch size:    48 | lm loss: 1.047623E+01 | loss scale: 32768.0 | grad norm: 789.675 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       25/     170 | consumed samples:         1200 | elapsed time per iteration (ms): 1448.6 | learning rate: 1.101E-07 | global batch size:    48 | lm loss: 1.015672E+01 | loss scale: 32768.0 | grad norm: 711.703 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       26/     170 | consumed samples:         1248 | elapsed time per iteration (ms): 1442.8 | learning rate: 1.258E-07 | global batch size:    48 | lm loss: 9.398643E+00 | loss scale: 32768.0 | grad norm: 298.790 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       27/     170 | consumed samples:         1296 | elapsed time per iteration (ms): 1443.2 | learning rate: 1.416E-07 | global batch size:    48 | lm loss: 9.068604E+00 | loss scale: 32768.0 | grad norm: 205.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       28/     170 | consumed samples:         1344 | elapsed time per iteration (ms): 1442.6 | learning rate: 1.573E-07 | global batch size:    48 | lm loss: 8.798186E+00 | loss scale: 32768.0 | grad norm: 62.547 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       29/     170 | consumed samples:         1392 | elapsed time per iteration (ms): 1445.6 | learning rate: 1.730E-07 | global batch size:    48 | lm loss: 8.744461E+00 | loss scale: 32768.0 | grad norm: 73.582 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       30/     170 | consumed samples:         1440 | elapsed time per iteration (ms): 1441.1 | learning rate: 1.887E-07 | global batch size:    48 | lm loss: 8.688231E+00 | loss scale: 32768.0 | grad norm: 52.181 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       31/     170 | consumed samples:         1488 | elapsed time per iteration (ms): 1442.8 | learning rate: 2.045E-07 | global batch size:    48 | lm loss: 8.584795E+00 | loss scale: 32768.0 | grad norm: 144.686 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       32/     170 | consumed samples:         1536 | elapsed time per iteration (ms): 1442.3 | learning rate: 2.202E-07 | global batch size:    48 | lm loss: 8.453249E+00 | loss scale: 32768.0 | grad norm: 76.355 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       33/     170 | consumed samples:         1584 | elapsed time per iteration (ms): 1447.2 | learning rate: 2.359E-07 | global batch size:    48 | lm loss: 8.406470E+00 | loss scale: 32768.0 | grad norm: 53.803 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       34/     170 | consumed samples:         1632 | elapsed time per iteration (ms): 1450.9 | learning rate: 2.517E-07 | global batch size:    48 | lm loss: 8.353151E+00 | loss scale: 32768.0 | grad norm: 47.773 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       35/     170 | consumed samples:         1680 | elapsed time per iteration (ms): 1490.5 | learning rate: 2.674E-07 | global batch size:    48 | lm loss: 8.301533E+00 | loss scale: 32768.0 | grad norm: 56.880 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       36/     170 | consumed samples:         1728 | elapsed time per iteration (ms): 1441.8 | learning rate: 2.831E-07 | global batch size:    48 | lm loss: 8.239415E+00 | loss scale: 32768.0 | grad norm: 46.611 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       37/     170 | consumed samples:         1776 | elapsed time per iteration (ms): 1451.7 | learning rate: 2.988E-07 | global batch size:    48 | lm loss: 8.239269E+00 | loss scale: 32768.0 | grad norm: 32.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       38/     170 | consumed samples:         1824 | elapsed time per iteration (ms): 1442.9 | learning rate: 3.146E-07 | global batch size:    48 | lm loss: 8.143072E+00 | loss scale: 32768.0 | grad norm: 27.417 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       39/     170 | consumed samples:         1872 | elapsed time per iteration (ms): 1442.8 | learning rate: 3.303E-07 | global batch size:    48 | lm loss: 8.125022E+00 | loss scale: 32768.0 | grad norm: 34.467 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       40/     170 | consumed samples:         1920 | elapsed time per iteration (ms): 1441.5 | learning rate: 3.460E-07 | global batch size:    48 | lm loss: 8.162258E+00 | loss scale: 32768.0 | grad norm: 64.037 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       41/     170 | consumed samples:         1968 | elapsed time per iteration (ms): 1448.9 | learning rate: 3.618E-07 | global batch size:    48 | lm loss: 8.111242E+00 | loss scale: 32768.0 | grad norm: 25.159 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       42/     170 | consumed samples:         2016 | elapsed time per iteration (ms): 1441.1 | learning rate: 3.775E-07 | global batch size:    48 | lm loss: 8.016221E+00 | loss scale: 32768.0 | grad norm: 28.157 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       43/     170 | consumed samples:         2064 | elapsed time per iteration (ms): 1441.4 | learning rate: 3.932E-07 | global batch size:    48 | lm loss: 8.029202E+00 | loss scale: 32768.0 | grad norm: 36.973 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       44/     170 | consumed samples:         2112 | elapsed time per iteration (ms): 1442.8 | learning rate: 4.089E-07 | global batch size:    48 | lm loss: 8.044934E+00 | loss scale: 32768.0 | grad norm: 44.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       45/     170 | consumed samples:         2160 | elapsed time per iteration (ms): 1559.7 | learning rate: 4.247E-07 | global batch size:    48 | lm loss: 7.920192E+00 | loss scale: 32768.0 | grad norm: 24.067 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       46/     170 | consumed samples:         2208 | elapsed time per iteration (ms): 1442.3 | learning rate: 4.404E-07 | global batch size:    48 | lm loss: 8.004175E+00 | loss scale: 32768.0 | grad norm: 49.900 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       47/     170 | consumed samples:         2256 | elapsed time per iteration (ms): 1442.6 | learning rate: 4.561E-07 | global batch size:    48 | lm loss: 8.005824E+00 | loss scale: 32768.0 | grad norm: 37.329 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       48/     170 | consumed samples:         2304 | elapsed time per iteration (ms): 1444.1 | learning rate: 4.719E-07 | global batch size:    48 | lm loss: 7.914961E+00 | loss scale: 32768.0 | grad norm: 18.774 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       49/     170 | consumed samples:         2352 | elapsed time per iteration (ms): 1449.3 | learning rate: 4.876E-07 | global batch size:    48 | lm loss: 7.940005E+00 | loss scale: 32768.0 | grad norm: 32.004 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       50/     170 | consumed samples:         2400 | elapsed time per iteration (ms): 1444.3 | learning rate: 5.033E-07 | global batch size:    48 | lm loss: 7.899236E+00 | loss scale: 32768.0 | grad norm: 19.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       51/     170 | consumed samples:         2448 | elapsed time per iteration (ms): 1443.3 | learning rate: 5.190E-07 | global batch size:    48 | lm loss: 7.903930E+00 | loss scale: 32768.0 | grad norm: 30.001 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       52/     170 | consumed samples:         2496 | elapsed time per iteration (ms): 1443.3 | learning rate: 5.348E-07 | global batch size:    48 | lm loss: 7.944133E+00 | loss scale: 32768.0 | grad norm: 27.530 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       53/     170 | consumed samples:         2544 | elapsed time per iteration (ms): 1444.9 | learning rate: 5.505E-07 | global batch size:    48 | lm loss: 7.817269E+00 | loss scale: 32768.0 | grad norm: 14.812 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       54/     170 | consumed samples:         2592 | elapsed time per iteration (ms): 1443.3 | learning rate: 5.662E-07 | global batch size:    48 | lm loss: 7.822289E+00 | loss scale: 32768.0 | grad norm: 64.708 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       55/     170 | consumed samples:         2640 | elapsed time per iteration (ms): 1443.4 | learning rate: 5.820E-07 | global batch size:    48 | lm loss: 7.954288E+00 | loss scale: 32768.0 | grad norm: 62.748 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       56/     170 | consumed samples:         2688 | elapsed time per iteration (ms): 1530.2 | learning rate: 5.977E-07 | global batch size:    48 | lm loss: 7.893144E+00 | loss scale: 32768.0 | grad norm: 24.510 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       57/     170 | consumed samples:         2736 | elapsed time per iteration (ms): 1448.7 | learning rate: 6.134E-07 | global batch size:    48 | lm loss: 7.804148E+00 | loss scale: 32768.0 | grad norm: 20.006 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       58/     170 | consumed samples:         2784 | elapsed time per iteration (ms): 1451.0 | learning rate: 6.291E-07 | global batch size:    48 | lm loss: 8.038012E+00 | loss scale: 32768.0 | grad norm: 122.185 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       59/     170 | consumed samples:         2832 | elapsed time per iteration (ms): 1443.1 | learning rate: 6.449E-07 | global batch size:    48 | lm loss: 7.895634E+00 | loss scale: 32768.0 | grad norm: 54.954 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       60/     170 | consumed samples:         2880 | elapsed time per iteration (ms): 1439.6 | learning rate: 6.606E-07 | global batch size:    48 | lm loss: 7.813709E+00 | loss scale: 32768.0 | grad norm: 19.897 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       61/     170 | consumed samples:         2928 | elapsed time per iteration (ms): 1449.6 | learning rate: 6.763E-07 | global batch size:    48 | lm loss: 7.746299E+00 | loss scale: 32768.0 | grad norm: 19.158 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       62/     170 | consumed samples:         2976 | elapsed time per iteration (ms): 1442.6 | learning rate: 6.921E-07 | global batch size:    48 | lm loss: 7.763969E+00 | loss scale: 32768.0 | grad norm: 22.732 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       63/     170 | consumed samples:         3024 | elapsed time per iteration (ms): 1444.9 | learning rate: 7.078E-07 | global batch size:    48 | lm loss: 7.722938E+00 | loss scale: 32768.0 | grad norm: 75.573 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       64/     170 | consumed samples:         3072 | elapsed time per iteration (ms): 1440.9 | learning rate: 7.235E-07 | global batch size:    48 | lm loss: 7.647756E+00 | loss scale: 32768.0 | grad norm: 23.917 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       65/     170 | consumed samples:         3120 | elapsed time per iteration (ms): 1447.2 | learning rate: 7.392E-07 | global batch size:    48 | lm loss: 7.665687E+00 | loss scale: 32768.0 | grad norm: 19.698 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       66/     170 | consumed samples:         3168 | elapsed time per iteration (ms): 1440.9 | learning rate: 7.550E-07 | global batch size:    48 | lm loss: 7.702944E+00 | loss scale: 32768.0 | grad norm: 17.024 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       67/     170 | consumed samples:         3216 | elapsed time per iteration (ms): 1441.3 | learning rate: 7.707E-07 | global batch size:    48 | lm loss: 7.670463E+00 | loss scale: 32768.0 | grad norm: 39.963 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       68/     170 | consumed samples:         3264 | elapsed time per iteration (ms): 1440.5 | learning rate: 7.864E-07 | global batch size:    48 | lm loss: 7.657525E+00 | loss scale: 32768.0 | grad norm: 39.064 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       69/     170 | consumed samples:         3312 | elapsed time per iteration (ms): 1446.5 | learning rate: 8.022E-07 | global batch size:    48 | lm loss: 7.680553E+00 | loss scale: 32768.0 | grad norm: 26.385 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       70/     170 | consumed samples:         3360 | elapsed time per iteration (ms): 1446.2 | learning rate: 8.179E-07 | global batch size:    48 | lm loss: 7.669929E+00 | loss scale: 32768.0 | grad norm: 18.246 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       71/     170 | consumed samples:         3408 | elapsed time per iteration (ms): 1443.5 | learning rate: 8.336E-07 | global batch size:    48 | lm loss: 7.642608E+00 | loss scale: 32768.0 | grad norm: 20.828 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       72/     170 | consumed samples:         3456 | elapsed time per iteration (ms): 1452.6 | learning rate: 8.493E-07 | global batch size:    48 | lm loss: 7.609447E+00 | loss scale: 32768.0 | grad norm: 18.801 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       73/     170 | consumed samples:         3504 | elapsed time per iteration (ms): 1448.6 | learning rate: 8.651E-07 | global batch size:    48 | lm loss: 7.620540E+00 | loss scale: 32768.0 | grad norm: 34.714 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       74/     170 | consumed samples:         3552 | elapsed time per iteration (ms): 1441.9 | learning rate: 8.808E-07 | global batch size:    48 | lm loss: 7.624036E+00 | loss scale: 32768.0 | grad norm: 30.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       75/     170 | consumed samples:         3600 | elapsed time per iteration (ms): 1441.7 | learning rate: 8.965E-07 | global batch size:    48 | lm loss: 7.543097E+00 | loss scale: 32768.0 | grad norm: 15.242 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       76/     170 | consumed samples:         3648 | elapsed time per iteration (ms): 1440.2 | learning rate: 9.123E-07 | global batch size:    48 | lm loss: 7.549984E+00 | loss scale: 32768.0 | grad norm: 17.899 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       77/     170 | consumed samples:         3696 | elapsed time per iteration (ms): 1453.3 | learning rate: 9.280E-07 | global batch size:    48 | lm loss: 7.516418E+00 | loss scale: 32768.0 | grad norm: 17.683 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       78/     170 | consumed samples:         3744 | elapsed time per iteration (ms): 1440.9 | learning rate: 9.437E-07 | global batch size:    48 | lm loss: 7.521658E+00 | loss scale: 32768.0 | grad norm: 12.711 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       79/     170 | consumed samples:         3792 | elapsed time per iteration (ms): 1442.6 | learning rate: 9.594E-07 | global batch size:    48 | lm loss: 7.360420E+00 | loss scale: 32768.0 | grad norm: 11.130 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       80/     170 | consumed samples:         3840 | elapsed time per iteration (ms): 1443.3 | learning rate: 9.752E-07 | global batch size:    48 | lm loss: 7.396046E+00 | loss scale: 32768.0 | grad norm: 18.426 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       81/     170 | consumed samples:         3888 | elapsed time per iteration (ms): 1447.9 | learning rate: 9.909E-07 | global batch size:    48 | lm loss: 7.360001E+00 | loss scale: 32768.0 | grad norm: 19.069 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       82/     170 | consumed samples:         3936 | elapsed time per iteration (ms): 1444.0 | learning rate: 1.007E-06 | global batch size:    48 | lm loss: 7.494289E+00 | loss scale: 32768.0 | grad norm: 27.401 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       83/     170 | consumed samples:         3984 | elapsed time per iteration (ms): 1442.6 | learning rate: 1.022E-06 | global batch size:    48 | lm loss: 7.420578E+00 | loss scale: 32768.0 | grad norm: 12.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       84/     170 | consumed samples:         4032 | elapsed time per iteration (ms): 1442.6 | learning rate: 1.038E-06 | global batch size:    48 | lm loss: 7.352755E+00 | loss scale: 32768.0 | grad norm: 14.693 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       85/     170 | consumed samples:         4080 | elapsed time per iteration (ms): 1446.0 | learning rate: 1.054E-06 | global batch size:    48 | lm loss: 7.374402E+00 | loss scale: 32768.0 | grad norm: 17.397 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       86/     170 | consumed samples:         4128 | elapsed time per iteration (ms): 1450.4 | learning rate: 1.070E-06 | global batch size:    48 | lm loss: 7.310581E+00 | loss scale: 32768.0 | grad norm: 13.383 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       87/     170 | consumed samples:         4176 | elapsed time per iteration (ms): 1443.8 | learning rate: 1.085E-06 | global batch size:    48 | lm loss: 7.289821E+00 | loss scale: 32768.0 | grad norm: 12.305 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       88/     170 | consumed samples:         4224 | elapsed time per iteration (ms): 1442.1 | learning rate: 1.101E-06 | global batch size:    48 | lm loss: 7.309093E+00 | loss scale: 32768.0 | grad norm: 22.296 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       89/     170 | consumed samples:         4272 | elapsed time per iteration (ms): 1451.6 | learning rate: 1.117E-06 | global batch size:    48 | lm loss: 7.299557E+00 | loss scale: 32768.0 | grad norm: 11.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       90/     170 | consumed samples:         4320 | elapsed time per iteration (ms): 1444.7 | learning rate: 1.132E-06 | global batch size:    48 | lm loss: 7.264783E+00 | loss scale: 32768.0 | grad norm: 18.931 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       91/     170 | consumed samples:         4368 | elapsed time per iteration (ms): 1444.4 | learning rate: 1.148E-06 | global batch size:    48 | lm loss: 7.266624E+00 | loss scale: 32768.0 | grad norm: 10.871 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       92/     170 | consumed samples:         4416 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.164E-06 | global batch size:    48 | lm loss: 7.272981E+00 | loss scale: 32768.0 | grad norm: 14.264 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       93/     170 | consumed samples:         4464 | elapsed time per iteration (ms): 1450.4 | learning rate: 1.180E-06 | global batch size:    48 | lm loss: 7.215261E+00 | loss scale: 32768.0 | grad norm: 11.619 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       94/     170 | consumed samples:         4512 | elapsed time per iteration (ms): 1444.1 | learning rate: 1.195E-06 | global batch size:    48 | lm loss: 7.183052E+00 | loss scale: 32768.0 | grad norm: 10.944 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       95/     170 | consumed samples:         4560 | elapsed time per iteration (ms): 1443.0 | learning rate: 1.211E-06 | global batch size:    48 | lm loss: 7.250178E+00 | loss scale: 32768.0 | grad norm: 12.542 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       96/     170 | consumed samples:         4608 | elapsed time per iteration (ms): 1443.2 | learning rate: 1.227E-06 | global batch size:    48 | lm loss: 7.103675E+00 | loss scale: 32768.0 | grad norm: 25.099 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       97/     170 | consumed samples:         4656 | elapsed time per iteration (ms): 1449.4 | learning rate: 1.243E-06 | global batch size:    48 | lm loss: 7.210084E+00 | loss scale: 32768.0 | grad norm: 11.887 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       98/     170 | consumed samples:         4704 | elapsed time per iteration (ms): 1444.1 | learning rate: 1.258E-06 | global batch size:    48 | lm loss: 7.219209E+00 | loss scale: 32768.0 | grad norm: 12.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration       99/     170 | consumed samples:         4752 | elapsed time per iteration (ms): 1444.7 | learning rate: 1.274E-06 | global batch size:    48 | lm loss: 7.175226E+00 | loss scale: 32768.0 | grad norm: 15.135 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      100/     170 | consumed samples:         4800 | elapsed time per iteration (ms): 1444.7 | learning rate: 1.290E-06 | global batch size:    48 | lm loss: 7.184348E+00 | loss scale: 32768.0 | grad norm: 9.487 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      101/     170 | consumed samples:         4848 | elapsed time per iteration (ms): 1446.6 | learning rate: 1.305E-06 | global batch size:    48 | lm loss: 7.160148E+00 | loss scale: 32768.0 | grad norm: 9.680 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      102/     170 | consumed samples:         4896 | elapsed time per iteration (ms): 1446.1 | learning rate: 1.321E-06 | global batch size:    48 | lm loss: 7.013313E+00 | loss scale: 32768.0 | grad norm: 9.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      103/     170 | consumed samples:         4944 | elapsed time per iteration (ms): 1448.5 | learning rate: 1.337E-06 | global batch size:    48 | lm loss: 7.052917E+00 | loss scale: 32768.0 | grad norm: 14.072 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      104/     170 | consumed samples:         4992 | elapsed time per iteration (ms): 1443.5 | learning rate: 1.353E-06 | global batch size:    48 | lm loss: 7.137936E+00 | loss scale: 32768.0 | grad norm: 19.676 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      105/     170 | consumed samples:         5040 | elapsed time per iteration (ms): 1556.8 | learning rate: 1.368E-06 | global batch size:    48 | lm loss: 7.164827E+00 | loss scale: 32768.0 | grad norm: 17.502 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      106/     170 | consumed samples:         5088 | elapsed time per iteration (ms): 1444.8 | learning rate: 1.384E-06 | global batch size:    48 | lm loss: 7.075429E+00 | loss scale: 32768.0 | grad norm: 8.596 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      107/     170 | consumed samples:         5136 | elapsed time per iteration (ms): 1444.6 | learning rate: 1.400E-06 | global batch size:    48 | lm loss: 7.101547E+00 | loss scale: 32768.0 | grad norm: 13.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      108/     170 | consumed samples:         5184 | elapsed time per iteration (ms): 1442.8 | learning rate: 1.416E-06 | global batch size:    48 | lm loss: 7.068012E+00 | loss scale: 32768.0 | grad norm: 14.846 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      109/     170 | consumed samples:         5232 | elapsed time per iteration (ms): 1449.4 | learning rate: 1.431E-06 | global batch size:    48 | lm loss: 7.079152E+00 | loss scale: 32768.0 | grad norm: 10.945 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      110/     170 | consumed samples:         5280 | elapsed time per iteration (ms): 1444.0 | learning rate: 1.447E-06 | global batch size:    48 | lm loss: 7.017496E+00 | loss scale: 32768.0 | grad norm: 11.762 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      111/     170 | consumed samples:         5328 | elapsed time per iteration (ms): 1442.3 | learning rate: 1.463E-06 | global batch size:    48 | lm loss: 7.066458E+00 | loss scale: 32768.0 | grad norm: 9.965 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      112/     170 | consumed samples:         5376 | elapsed time per iteration (ms): 1443.6 | learning rate: 1.478E-06 | global batch size:    48 | lm loss: 7.059348E+00 | loss scale: 32768.0 | grad norm: 12.484 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      113/     170 | consumed samples:         5424 | elapsed time per iteration (ms): 1448.1 | learning rate: 1.494E-06 | global batch size:    48 | lm loss: 6.929554E+00 | loss scale: 32768.0 | grad norm: 8.979 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      114/     170 | consumed samples:         5472 | elapsed time per iteration (ms): 1446.9 | learning rate: 1.510E-06 | global batch size:    48 | lm loss: 6.947205E+00 | loss scale: 32768.0 | grad norm: 19.922 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      115/     170 | consumed samples:         5520 | elapsed time per iteration (ms): 1444.1 | learning rate: 1.526E-06 | global batch size:    48 | lm loss: 7.013575E+00 | loss scale: 32768.0 | grad norm: 12.421 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      116/     170 | consumed samples:         5568 | elapsed time per iteration (ms): 1448.7 | learning rate: 1.541E-06 | global batch size:    48 | lm loss: 7.014450E+00 | loss scale: 32768.0 | grad norm: 12.932 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      117/     170 | consumed samples:         5616 | elapsed time per iteration (ms): 1447.9 | learning rate: 1.557E-06 | global batch size:    48 | lm loss: 6.933110E+00 | loss scale: 32768.0 | grad norm: 10.092 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      118/     170 | consumed samples:         5664 | elapsed time per iteration (ms): 1443.7 | learning rate: 1.573E-06 | global batch size:    48 | lm loss: 6.910919E+00 | loss scale: 32768.0 | grad norm: 17.253 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      119/     170 | consumed samples:         5712 | elapsed time per iteration (ms): 1443.4 | learning rate: 1.589E-06 | global batch size:    48 | lm loss: 6.975500E+00 | loss scale: 32768.0 | grad norm: 11.309 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      120/     170 | consumed samples:         5760 | elapsed time per iteration (ms): 1442.7 | learning rate: 1.604E-06 | global batch size:    48 | lm loss: 6.943404E+00 | loss scale: 32768.0 | grad norm: 10.007 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      121/     170 | consumed samples:         5808 | elapsed time per iteration (ms): 1574.6 | learning rate: 1.620E-06 | global batch size:    48 | lm loss: 6.917996E+00 | loss scale: 32768.0 | grad norm: 12.333 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      122/     170 | consumed samples:         5856 | elapsed time per iteration (ms): 1442.2 | learning rate: 1.636E-06 | global batch size:    48 | lm loss: 6.839823E+00 | loss scale: 32768.0 | grad norm: 10.541 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      123/     170 | consumed samples:         5904 | elapsed time per iteration (ms): 1440.7 | learning rate: 1.652E-06 | global batch size:    48 | lm loss: 6.870667E+00 | loss scale: 32768.0 | grad norm: 6.489 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      124/     170 | consumed samples:         5952 | elapsed time per iteration (ms): 1439.4 | learning rate: 1.667E-06 | global batch size:    48 | lm loss: 6.816160E+00 | loss scale: 32768.0 | grad norm: 6.637 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      125/     170 | consumed samples:         6000 | elapsed time per iteration (ms): 1447.6 | learning rate: 1.683E-06 | global batch size:    48 | lm loss: 6.807645E+00 | loss scale: 32768.0 | grad norm: 9.690 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      126/     170 | consumed samples:         6048 | elapsed time per iteration (ms): 1440.2 | learning rate: 1.699E-06 | global batch size:    48 | lm loss: 6.829272E+00 | loss scale: 32768.0 | grad norm: 7.975 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      127/     170 | consumed samples:         6096 | elapsed time per iteration (ms): 1438.5 | learning rate: 1.714E-06 | global batch size:    48 | lm loss: 6.810949E+00 | loss scale: 32768.0 | grad norm: 6.576 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      128/     170 | consumed samples:         6144 | elapsed time per iteration (ms): 1435.5 | learning rate: 1.730E-06 | global batch size:    48 | lm loss: 6.806122E+00 | loss scale: 32768.0 | grad norm: 7.266 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      129/     170 | consumed samples:         6192 | elapsed time per iteration (ms): 1449.2 | learning rate: 1.746E-06 | global batch size:    48 | lm loss: 6.732492E+00 | loss scale: 32768.0 | grad norm: 12.127 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      130/     170 | consumed samples:         6240 | elapsed time per iteration (ms): 1448.5 | learning rate: 1.762E-06 | global batch size:    48 | lm loss: 6.827133E+00 | loss scale: 32768.0 | grad norm: 10.474 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      131/     170 | consumed samples:         6288 | elapsed time per iteration (ms): 1437.9 | learning rate: 1.777E-06 | global batch size:    48 | lm loss: 6.708465E+00 | loss scale: 32768.0 | grad norm: 7.378 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      132/     170 | consumed samples:         6336 | elapsed time per iteration (ms): 1446.3 | learning rate: 1.793E-06 | global batch size:    48 | lm loss: 6.779068E+00 | loss scale: 32768.0 | grad norm: 11.020 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      133/     170 | consumed samples:         6384 | elapsed time per iteration (ms): 1445.4 | learning rate: 1.809E-06 | global batch size:    48 | lm loss: 6.751063E+00 | loss scale: 32768.0 | grad norm: 6.343 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      134/     170 | consumed samples:         6432 | elapsed time per iteration (ms): 1442.5 | learning rate: 1.825E-06 | global batch size:    48 | lm loss: 6.773484E+00 | loss scale: 32768.0 | grad norm: 13.935 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      135/     170 | consumed samples:         6480 | elapsed time per iteration (ms): 1445.7 | learning rate: 1.840E-06 | global batch size:    48 | lm loss: 6.725053E+00 | loss scale: 32768.0 | grad norm: 8.602 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      136/     170 | consumed samples:         6528 | elapsed time per iteration (ms): 1443.1 | learning rate: 1.856E-06 | global batch size:    48 | lm loss: 6.668398E+00 | loss scale: 32768.0 | grad norm: 8.018 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      137/     170 | consumed samples:         6576 | elapsed time per iteration (ms): 1453.1 | learning rate: 1.872E-06 | global batch size:    48 | lm loss: 6.681416E+00 | loss scale: 32768.0 | grad norm: 8.950 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      138/     170 | consumed samples:         6624 | elapsed time per iteration (ms): 1443.8 | learning rate: 1.887E-06 | global batch size:    48 | lm loss: 6.706676E+00 | loss scale: 32768.0 | grad norm: 8.038 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      139/     170 | consumed samples:         6672 | elapsed time per iteration (ms): 1443.7 | learning rate: 1.903E-06 | global batch size:    48 | lm loss: 6.785660E+00 | loss scale: 32768.0 | grad norm: 8.148 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      140/     170 | consumed samples:         6720 | elapsed time per iteration (ms): 1445.1 | learning rate: 1.919E-06 | global batch size:    48 | lm loss: 6.638913E+00 | loss scale: 32768.0 | grad norm: 11.220 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      141/     170 | consumed samples:         6768 | elapsed time per iteration (ms): 1449.1 | learning rate: 1.935E-06 | global batch size:    48 | lm loss: 6.691549E+00 | loss scale: 32768.0 | grad norm: 12.110 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      142/     170 | consumed samples:         6816 | elapsed time per iteration (ms): 1436.2 | learning rate: 1.950E-06 | global batch size:    48 | lm loss: 6.646757E+00 | loss scale: 32768.0 | grad norm: 6.427 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      143/     170 | consumed samples:         6864 | elapsed time per iteration (ms): 1442.7 | learning rate: 1.966E-06 | global batch size:    48 | lm loss: 6.661151E+00 | loss scale: 32768.0 | grad norm: 8.934 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      144/     170 | consumed samples:         6912 | elapsed time per iteration (ms): 1445.6 | learning rate: 1.982E-06 | global batch size:    48 | lm loss: 6.640087E+00 | loss scale: 32768.0 | grad norm: 15.008 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      145/     170 | consumed samples:         6960 | elapsed time per iteration (ms): 1450.3 | learning rate: 1.998E-06 | global batch size:    48 | lm loss: 6.558360E+00 | loss scale: 32768.0 | grad norm: 8.589 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      146/     170 | consumed samples:         7008 | elapsed time per iteration (ms): 1446.4 | learning rate: 2.013E-06 | global batch size:    48 | lm loss: 6.656762E+00 | loss scale: 32768.0 | grad norm: 8.646 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      147/     170 | consumed samples:         7056 | elapsed time per iteration (ms): 1442.6 | learning rate: 2.029E-06 | global batch size:    48 | lm loss: 6.615575E+00 | loss scale: 32768.0 | grad norm: 11.032 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      148/     170 | consumed samples:         7104 | elapsed time per iteration (ms): 1524.1 | learning rate: 2.045E-06 | global batch size:    48 | lm loss: 6.564539E+00 | loss scale: 32768.0 | grad norm: 10.261 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      149/     170 | consumed samples:         7152 | elapsed time per iteration (ms): 1448.5 | learning rate: 2.060E-06 | global batch size:    48 | lm loss: 6.616283E+00 | loss scale: 32768.0 | grad norm: 10.248 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      150/     170 | consumed samples:         7200 | elapsed time per iteration (ms): 1447.1 | learning rate: 2.076E-06 | global batch size:    48 | lm loss: 6.474820E+00 | loss scale: 32768.0 | grad norm: 6.304 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      151/     170 | consumed samples:         7248 | elapsed time per iteration (ms): 1445.8 | learning rate: 2.092E-06 | global batch size:    48 | lm loss: 6.589240E+00 | loss scale: 32768.0 | grad norm: 10.300 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      152/     170 | consumed samples:         7296 | elapsed time per iteration (ms): 1442.3 | learning rate: 2.108E-06 | global batch size:    48 | lm loss: 6.531324E+00 | loss scale: 32768.0 | grad norm: 9.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      153/     170 | consumed samples:         7344 | elapsed time per iteration (ms): 1444.6 | learning rate: 2.123E-06 | global batch size:    48 | lm loss: 6.586135E+00 | loss scale: 32768.0 | grad norm: 7.173 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      154/     170 | consumed samples:         7392 | elapsed time per iteration (ms): 1436.3 | learning rate: 2.139E-06 | global batch size:    48 | lm loss: 6.527660E+00 | loss scale: 32768.0 | grad norm: 6.387 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      155/     170 | consumed samples:         7440 | elapsed time per iteration (ms): 1446.2 | learning rate: 2.155E-06 | global batch size:    48 | lm loss: 6.537187E+00 | loss scale: 32768.0 | grad norm: 8.579 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      156/     170 | consumed samples:         7488 | elapsed time per iteration (ms): 1443.3 | learning rate: 2.171E-06 | global batch size:    48 | lm loss: 6.605680E+00 | loss scale: 32768.0 | grad norm: 12.265 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      157/     170 | consumed samples:         7536 | elapsed time per iteration (ms): 1441.6 | learning rate: 2.186E-06 | global batch size:    48 | lm loss: 6.532893E+00 | loss scale: 32768.0 | grad norm: 7.251 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      158/     170 | consumed samples:         7584 | elapsed time per iteration (ms): 1444.5 | learning rate: 2.202E-06 | global batch size:    48 | lm loss: 6.554538E+00 | loss scale: 32768.0 | grad norm: 10.840 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      159/     170 | consumed samples:         7632 | elapsed time per iteration (ms): 1437.9 | learning rate: 2.218E-06 | global batch size:    48 | lm loss: 6.523364E+00 | loss scale: 32768.0 | grad norm: 6.843 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      160/     170 | consumed samples:         7680 | elapsed time per iteration (ms): 1440.8 | learning rate: 2.233E-06 | global batch size:    48 | lm loss: 6.499016E+00 | loss scale: 32768.0 | grad norm: 7.162 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      161/     170 | consumed samples:         7728 | elapsed time per iteration (ms): 1443.2 | learning rate: 2.249E-06 | global batch size:    48 | lm loss: 6.488636E+00 | loss scale: 32768.0 | grad norm: 7.687 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      162/     170 | consumed samples:         7776 | elapsed time per iteration (ms): 1444.2 | learning rate: 2.265E-06 | global batch size:    48 | lm loss: 6.402086E+00 | loss scale: 32768.0 | grad norm: 8.321 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      163/     170 | consumed samples:         7824 | elapsed time per iteration (ms): 1438.3 | learning rate: 2.281E-06 | global batch size:    48 | lm loss: 6.453182E+00 | loss scale: 32768.0 | grad norm: 6.854 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      164/     170 | consumed samples:         7872 | elapsed time per iteration (ms): 1438.3 | learning rate: 2.296E-06 | global batch size:    48 | lm loss: 6.574172E+00 | loss scale: 32768.0 | grad norm: 6.757 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      165/     170 | consumed samples:         7920 | elapsed time per iteration (ms): 1443.0 | learning rate: 2.312E-06 | global batch size:    48 | lm loss: 6.555213E+00 | loss scale: 32768.0 | grad norm: 7.517 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      166/     170 | consumed samples:         7968 | elapsed time per iteration (ms): 1446.4 | learning rate: 2.328E-06 | global batch size:    48 | lm loss: 6.525514E+00 | loss scale: 32768.0 | grad norm: 9.908 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      167/     170 | consumed samples:         8016 | elapsed time per iteration (ms): 1444.6 | learning rate: 2.344E-06 | global batch size:    48 | lm loss: 6.441551E+00 | loss scale: 32768.0 | grad norm: 12.590 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      168/     170 | consumed samples:         8064 | elapsed time per iteration (ms): 1442.7 | learning rate: 2.359E-06 | global batch size:    48 | lm loss: 6.435333E+00 | loss scale: 32768.0 | grad norm: 11.047 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      169/     170 | consumed samples:         8112 | elapsed time per iteration (ms): 1446.4 | learning rate: 2.375E-06 | global batch size:    48 | lm loss: 6.447063E+00 | loss scale: 32768.0 | grad norm: 7.089 | number of skipped iterations:   0 | number of nan iterations:   0 |
 iteration      170/     170 | consumed samples:         8160 | elapsed time per iteration (ms): 1444.3 | learning rate: 2.391E-06 | global batch size:    48 | lm loss: 6.496104E+00 | loss scale: 32768.0 | grad norm: 10.991 | number of skipped iterations:   0 | number of nan iterations:   0 |
